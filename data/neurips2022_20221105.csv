id,title,keywords,ratings,confidences,withdraw,review_lengths,decision
09QFnDWPF8,Statistical Learning and Inverse Problems: A Stochastic Gradient Approach,"['Statistical Learning', 'Inverse Problems', 'Stochastic Gradient Descent']","[8, 5, 7]","[3, 3, 3]",0,"[875, 649, 214]",Accept
pnSyqRXx73,Efficiency Ordering of Stochastic Gradient Descent,"['Stochastic Gradient Descent', 'Asymptotic Analysis', 'Efficiency Ordering']","[5, 6, 7, 7]","[3, 3, 4, 4]",0,"[1280, 118, 287, 777]",Accept
EqJ5_hZSqgy,Self-Aware Personalized Federated Learning,"['Federared Learning', 'Personalization']","[7, 7, 3]","[3, 3, 3]",0,"[209, 303, 221]",Accept
xnI37HyfoP,Nonnegative Tensor Completion via Integer Optimization,"['tensor completion', 'machine learning']","[7, 6, 6]","[4, 3, 4]",0,"[445, 269, 1083]",Accept
OoNmOfYVhEU,TPU-KNN: K Nearest Neighbor Search at Peak FLOP/s,"['TPU', 'K-nearest neighbor search', 'Approximate nearest neighbor search', 'roofline model', 'accelerator']","[6, 5, 6, 6]","[4, 5, 4, 4]",0,"[162, 204, 446, 233]",Accept
0Dh8dz4snu,Equivariant Networks for Crystal Structures,"['materials', 'deep learning', 'symmetry', 'equivariance', 'crystals', 'graph neural networks', 'geometric deep learning']","[6, 4, 7]","[4, 2, 3]",0,"[1053, 495, 608]",Accept
s1yaWFDLxVG,Gradient Descent Is Optimal Under Lower Restricted Secant Inequality And Upper Error Bound,"['First-Order Optimization', 'Non-Convex', 'Deterministic', 'Gradient Descent', 'Restricted Secant Inequality', 'Error Bounds']","[7, 7, 7, 5]","[3, 3, 4, 4]",0,"[748, 334, 471, 591]",Accept
02dbnEbEFn,Decoupled Context Processing for Context Augmented Language Modeling,"['Retrieval Augmentation', 'Encoder-Decoder', 'Language Modeling', 'Efficiency']","[4, 5, 8]","[4, 4, 4]",0,"[247, 339, 541]",Accept
7eUOC9fEIRO,Planning to the Information Horizon of BAMDPs via Epistemic State Abstraction,"['Bayes-Adaptive Markov Decision Process', 'Bayesian reinforcement learning', 'Exploration', 'Planning']","[7, 7, 6, 5]","[4, 3, 4, 4]",0,"[643, 290, 1145, 932]",Accept
BUMiizPcby6,Trust Region Policy Optimization with Optimal Transport Discrepancies: Duality and Algorithm for Continuous Actions,"['Trust region policy optimization', 'optimal transport']","[5, 6, 7]","[3, 3, 4]",0,"[452, 354, 619]",Accept
kpSAfnHSgXR,Modeling Transitivity and Cyclicity in Directed Graphs via Binary Code Box Embeddings,"['graph representation learning', 'geometric representation learning', 'directed graphs', 'cyclic graphs', 'transitivity']","[6, 5, 5]","[3, 4, 3]",0,"[308, 704, 256]",Accept
qx51yfvLnE,Simple and Optimal Greedy Online Contention Resolution Schemes,"['contention resolution schemes', 'online algorithms', 'matroids', 'prophet inequalities']","[4, 6, 5, 7]","[3, 3, 4, 3]",0,"[713, 366, 272, 139]",Accept
KRk0lBRPpOC,Evaluating Latent Space Robustness and Uncertainty of EEG-ML Models under Realistic Distribution Shifts,"['dataset shifts', 'scalp EEG', 'representation learning', 'healthcare machine learning', 'model robustness', 'latent space', 'uncertainty quantification', 'distribution shift']","[4, 7, 3, 7]","[3, 3, 3, 5]",0,"[188, 1050, 242, 732]",Accept
TiZYrQ-mPup,COLD Decoding: Energy-based Constrained Text Generation with Langevin Dynamics,"['Text generation', 'constrained text generation', 'language models', 'natural language processing', 'langevin dynamics', 'decoding']","[6, 8, 7, 8]","[3, 3, 4, 3]",0,"[228, 193, 204, 339]",Accept
xuw7R0hP7G,From Gradient Flow on Population Loss to Learning with Stochastic Gradient Descent,"['Theory', 'Gradient flow', 'Stochastic Gradient Descent', 'Gradient Descent', 'SGD', 'Non-convex optimization', 'Lyapunov potentials']","[7, 6, 6, 6]","[3, 4, 4, 4]",0,"[282, 292, 709, 924]",Accept
yLilJ1vZgMe,Fast Neural Kernel Embeddings for General Activations,[],"[6, 6, 7, 7]","[1, 4, 3, 4]",0,"[240, 564, 459, 851]",Accept
XvI6h-s4un,On Reinforcement Learning and Distribution Matching for Fine-Tuning Language Models with no Catastrophic Forgetting,"['Reinforcement Learning', 'Language Models', 'Reward Maximization', 'Distribution Matching', 'Energy Based Models', 'Controlled Text Generation']","[7, 6, 7]","[4, 3, 4]",0,"[170, 344, 616]",Accept
ZMFQtvVJr40,Provably tuning the ElasticNet across instances,"['Elastic net', 'data-driven algorithm design', 'learning theory', 'regularization']","[8, 7, 5]","[4, 3, 2]",0,"[687, 1113, 725]",Accept
6iqd9JAVR1z,LAMP: Extracting Text from Gradients with Language Model Priors,"['federated learning', 'privacy', 'gradient leakage', 'natural language processing']","[7, 6, 6]","[3, 3, 3]",0,"[629, 289, 404]",Accept
uPyNR2yPoe,ELIGN: Expectation Alignment as a Multi-Agent Intrinsic Reward,"['Multi-agent intrinsic reward', 'multi-agent reinforcement learning']","[7, 4, 7, 7, 4]","[4, 4, 3, 4, 3]",0,"[364, 469, 1198, 564, 423]",Accept
82N_rasrUT_,Explicable Policy Search,"['Explainable Decision Making', 'Human-Aware AI']","[6, 3, 5, 7, 5]","[4, 3, 3, 5, 3]",0,"[1165, 452, 574, 1493, 744]",Accept
WBv9Z6qpA8x,"A Practical, Progressively-Expressive GNN","['GNN', 'k-WL', 'expressiveness']","[7, 7, 5, 4]","[3, 4, 4, 4]",0,"[653, 341, 409, 232]",Accept
F_9w7Wl78IH,The Impact of Task Underspecification in Evaluating Deep Reinforcement Learning,"['Reinforcement Learning', 'Evaluation', 'Scientific Progress', 'Reliability', 'Benchmarking']","[6, 7, 6]","[4, 3, 4]",0,"[863, 455, 884]",Accept
ffy-h0GKZbK,Chaotic Dynamics are Intrinsic to Neural Network Training with SGD,"['Optimization', 'Deep Learning', 'Chaos', 'Neural Networks', 'Curvature', 'Seconder Order Optimization', 'SGD', 'Hessian']","[6, 3, 6]","[4, 3, 4]",0,"[558, 261, 541]",Accept
6dfYc2IUj4,A PAC-Bayesian Generalization Bound for Equivariant Networks,"['generalization error', 'equivariant networks', 'group representation', 'PAC Bayesian']","[4, 6, 6, 6]","[4, 3, 2, 4]",0,"[195, 1442, 244, 568]",Accept
1vusesyN7E,Autoregressive Perturbations for Data Poisoning,"['autoregressive processes', 'poisons', 'data poisoning', 'data protection', 'imperceptible perturbations', 'adversarial machine learning']","[6, 6, 7, 5]","[4, 4, 5, 4]",0,"[301, 456, 409, 405]",Accept
SiSv_XDMksL,Near-Optimal No-Regret Learning Dynamics for General Convex Games,"['No-regret learning', 'optimism', 'extensive-form games', 'convex games']","[7, 6, 6, 7]","[1, 3, 4, 4]",0,"[218, 211, 1564, 431]",Accept
WcxJooGBCc,Learning the Structure of Large Networked Systems Obeying Conservation Laws,"['Structure Learning', 'Networked Systems', 'Conservation Laws', 'Gaussian Graphical models', 'Sparsistency', 'High dimensional regime']","[4, 7, 7, 6]","[4, 2, 2, 2]",0,"[192, 298, 334, 648]",Accept
CLMuNJSJfhv,Neural Payoff Machines: Predicting Fair and Stable Payoff Allocations Among Team Members,"['Cooperative games theory', 'Coalitional games', 'Shapley values', 'Bahnhof power index', 'The Core']","[5, 7, 4]","[3, 4, 4]",0,"[343, 246, 609]",Accept
St5q10aqLTO,Implicit Neural Representations with Levels-of-Experts,"['Implicit neural representations', 'neural fields', 'coordinate-based networks', 'hybrid representations', 'positional encoding']","[8, 7, 7, 5]","[4, 4, 2, 2]",0,"[239, 238, 757, 503]",Accept
9sKZ60VtRmi,LieGG: Studying Learned Lie Group Generators,"['invariance', 'equivariance', 'symmetry', 'Lie groups', 'interpretability']","[7, 6, 6]","[3, 3, 4]",0,"[617, 632, 1322]",Accept
YRDXX4IIA9,Local Bayesian optimization via maximizing probability of descent,"['local optimization', 'Bayesian optimization', 'active learning']","[6, 8, 7, 7]","[4, 4, 4, 4]",0,"[540, 434, 292, 1021]",Accept
cxZEBQFDoFK,"A Closer Look at Learned Optimization: Stability, Robustness, and Inductive Biases","['meta-learning', 'learned optimization']","[5, 7, 6, 7]","[4, 4, 4, 3]",0,"[137, 453, 283, 340]",Accept
8gUjpEsLCU,Empirical Gateaux Derivatives for Causal Inference,"['causal inference', 'double robustness', 'bias-adjustment', 'influence function', 'semiparametric', 'offline reinforcement learning']","[4, 7, 6]","[1, 3, 4]",0,"[366, 2306, 580]",Accept
QTjJMy-UNO,Adaptive Interest for Emphatic Reinforcement Learning,"['emphatic temporal difference', 'interest function', 'meta gradients', 'meta learning']","[7, 6, 7, 6]","[3, 4, 2, 5]",0,"[263, 719, 594, 241]",Accept
HBGvWy9Vxq,Human-Robotic Prosthesis as Collaborating Agents for Symmetrical Walking,"['collaborative multi-agent reinforcement learning', 'continuous control', 'human-robotic prosthesis collaboration', 'real world AI application']","[6, 5, 7]","[4, 4, 4]",0,"[536, 399, 922]",Accept
GisHNaleWiA,Uni[MASK]: Unified Inference in Sequential Decision Problems,"['Multi-task Learning', 'Unsupervised Learning', 'Reinforcement Learning', 'Deep Learning']","[8, 7, 9]","[4, 3, 5]",0,"[493, 366, 565]",Accept
hjqTeP05OMB,Leveraging the Hints: Adaptive Bidding in Repeated First-Price Auctions,"['Online learning', 'bandit', 'first-price auction']","[7, 7, 6, 7]","[4, 2, 3, 4]",0,"[581, 179, 233, 560]",Accept
8ViFz-5Mnnv,ReCo: Retrieve and Co-segment for Zero-shot Transfer,"['semantic segmentation', 'vision-language models', 'image retrieval', 'co-segmentation', 'zero-shot transfer']","[4, 4, 6, 6, 5]","[5, 3, 5, 3, 3]",0,"[171, 246, 393, 155, 235]",Accept
M_et7iOQC_s,Boosting the Performance of Generic Deep Neural Network Frameworks with Log-supermodular CRFs,"['conditional random fields', 'log-supermodular', 'structured prediction']","[6, 6, 5]","[2, 1, 2]",0,"[106, 368, 266]",Accept
_sYOodxTMcF,End-to-end Stochastic Optimization with Energy-based Model,"['end-to-end stochastic optimization', 'energy-based model', 'decision-focused learning']","[8, 6, 6, 5]","[4, 4, 4, 3]",0,"[652, 705, 1154, 851]",Accept
kXXPLBEBVGH,Context-enriched molecule representations improve few-shot drug discovery,[],"[5, 7, 4]","[4, 4, 4]",0,"[1113, 1288, 380]",Reject
scfOjwTtZ8S,EAGER: Asking and Answering Questions for Automatic Reward Shaping in Language-guided RL,"['language-conditioned RL', 'automatic reward shaping', 'intrinsic rewards', 'exploration', 'auxiliary objectives', 'question generation', 'question answering']","[6, 6, 8, 4]","[3, 4, 4, 4]",0,"[493, 254, 462, 339]",Accept
q9XPBhFgL6z,A Causal Analysis of Harm,"['harm', 'causality', 'utility']","[3, 5, 5, 6, 7]","[4, 3, 3, 4, 2]",0,"[1550, 610, 239, 451, 391]",Accept
dJgYhYKvr1,The Slingshot Mechanism: An Empirical Study of Adaptive Optimizers and the \emph{Grokking Phenomenon},"['optimization', 'adam', 'adamw', 'adaptive optimizers', 'grokking', 'training instability', 'instability', 'empirical', 'empirical science of deep learning', 'double descent']","[5, 5, 6]","[2, 4, 3]",0,"[623, 513, 556]",Reject
FR289LMkmxZ,On-Demand Sampling: Learning Optimally from Multiple Distributions,"['Sample Complexity', 'Distributionally Robust Optimization', 'Collaborative Learning', 'Learning Theory', 'Minmax Equilibria', 'Online Mirror Descent']","[8, 7, 7, 7]","[3, 3, 3, 3]",0,"[227, 473, 181, 399]",Accept
m6HNNpQO8dc,Logical Activation Functions: Logit-space equivalents of Probabilistic Boolean Operators,"['activation', 'activation functions', 'logit', 'probabilistic', 'Bayesian', 'Boolean', 'logic', 'dendritic computation']","[6, 7, 7]","[4, 2, 4]",0,"[708, 283, 247]",Accept
OptX3Db1P4,Dynamic pricing and assortment under a contextual MNL demand,"['dynamic pricing', 'assortment optimization', 'multinomial logit', 'online learning', 'contextual information']","[5, 6, 6]","[3, 2, 4]",0,"[388, 360, 1012]",Accept
uOdTKkg2FtP,Off-Team Learning,"['Multi-Agent Reinforcement Learning', 'Reinforcement Learning', 'Cooperative Multi-Agent Reinforcement Learning', 'Deep Reinforcement Learning']","[5, 7, 6]","[4, 3, 3]",0,"[550, 263, 429]",Accept
zBlj0Cs6dw1,A Deep Reinforcement Learning Framework for Column Generation,"['Reinforcement learning', 'Column Generation', 'Column selection', 'Machine learning for optimization']","[7, 5, 5, 6]","[4, 4, 4, 3]",0,"[625, 1318, 706, 485]",Accept
VPhhd5pv0Qs,Sublinear Algorithms for Hierarchical Clustering,"['hierarchical clustering', 'clustering', 'sublinear algorithms', 'graph algorithms']","[6, 8, 3, 7]","[3, 3, 3, 3]",0,"[359, 278, 287, 502]",Accept
d19Dsqtw421,A Few Expert Queries Suffices for Sample-Efficient RL with Resets and Linear Value Approximation,"['Reinforcement learning', 'imitation learning', 'function approximation', 'sample efficiency', 'linear realizability']","[7, 5, 6, 7]","[3, 3, 3, 4]",0,"[437, 162, 605, 276]",Accept
6mej19W1ppP,Certifying Some Distributional Fairness with Subpopulation Decomposition,"['Certifying Fairness', 'fairness constrained distribution', 'distribution shifts']","[7, 6, 6]","[3, 2, 4]",0,"[233, 100, 330]",Accept
QFMw21ZKaa_,Accelerating Certified Robustness Training via Knowledge Transfer,"['Adversarial machine learning', 'certified robustness', 'randomized smoothing']","[6, 7, 5, 5]","[5, 4, 3, 4]",0,"[276, 315, 727, 411]",Accept
lKULHf7oFDo,Fairness in Federated Learning via Core-Stability,"['Fairness', 'Federated Learning', 'Core-Stability', 'Social Choice']","[7, 7, 6]","[2, 3, 3]",0,"[480, 293, 326]",Accept
VHzCiK727EL,Learning NP-Hard Multi-Agent Assignment Planning using GNN: Inference on a Random Graph and Provable Auction-Fitted Q-learning,"['Multi-agent assignment planning', 'Reinforcement learning', 'Graph neural network', 'Mean-field inference']","[6, 4, 4]","[3, 2, 1]",0,"[236, 626, 227]",Accept
2S_GtHBtTUP,Memory safe computations with XLA compiler,"['xla', 'compiler', 'gaussian processes', 'sparse gaussian processes', 'k-nearest neighbour']","[7, 6, 5]","[4, 3, 3]",0,"[197, 274, 405]",Accept
TATzsweWfof,A Communication-efficient Algorithm with Linear Convergence for Federated Minimax Learning,"['federated learning', 'minimax optimization']","[4, 5, 5, 7]","[4, 3, 3, 4]",0,"[553, 542, 303, 1562]",Accept
h2imPVlCCyN,On Efficient Online Imitation Learning via Classification,"['Imitation Learning', 'Online Learning', 'Reinforcement Learning Theory']","[6, 6, 7, 7]","[3, 3, 3, 2]",0,"[146, 616, 756, 234]",Accept
VoLXWO1L-43,AMP: Automatically Finding Model Parallel Strategies with Heterogeneity Awareness,"['Machine Learning Systems', 'Model Parallelism', 'Automation', 'Heterogeneity']","[6, 6, 6, 5]","[4, 5, 3, 2]",0,"[212, 319, 344, 287]",Accept
8bk68fodvD5,Nonstationary Dual Averaging and Online Fair Allocation,"['online fair allocation', 'Fisher markets', 'fair division', 'online convex optimization', 'market equilibrium']","[5, 6, 6, 6]","[2, 2, 4, 1]",0,"[337, 301, 122, 90]",Accept
opw858PBJl6,"New Definitions and Evaluations for Saliency Methods: Staying Intrinsic, Complete and Sound","['saliency', 'saliency methods', 'saliency evaluation', 'soundness', 'sanity checks', 'interpretability']","[7, 8, 6, 8]","[4, 2, 3, 3]",0,"[716, 234, 292, 337]",Accept
2FNnBhwJsHK,A Unified Framework for Deep Symbolic Regression,"['symbolic regression', 'reinforcement learning', 'combinatorial optimization']","[5, 5, 7]","[4, 4, 4]",0,"[222, 516, 778]",Accept
epjxT_ARZW5,Pitfalls of Epistemic Uncertainty Quantification through Loss Minimisation,"['Uncertainty Quantification', 'Empirical Loss Minimisation', 'Proper Scoring Rules']","[7, 7, 6, 7]","[2, 3, 3, 4]",0,"[49, 502, 434, 245]",Accept
9-vs8BucEoo,Best of Both Worlds Model Selection,"['bandits', 'linear bandits', 'model selection', 'policy classes', 'best of both worlds', 'reinforcement learning', 'adversarial', 'stochastic']","[6, 7, 7]","[3, 4, 3]",0,"[174, 316, 503]",Accept
vWUmBjin_-o,Structuring Representations Using Group Invariants,"['Equivariance', 'Invariance', 'Geometry', 'Group Theory', 'Representation learning', 'Self-supervised learning']","[7, 7, 5, 6]","[2, 4, 3, 3]",0,"[957, 634, 642, 364]",Accept
u_7qyNFwkP8,The Query Complexity of Cake Cutting,"['fair division', 'cake cutting', 'query complexity', 'lower bounds', 'upper bounds']","[6, 6, 4, 8]","[2, 4, 4, 4]",0,"[203, 218, 191, 434]",Accept
cUOR-_VsavA,Structural Pruning via Latency-Saliency Knapsack,"['model compression', 'deep neural network pruning', 'latency reduction']","[6, 4, 6, 7]","[3, 5, 4, 3]",0,"[489, 282, 540, 197]",Accept
Roiw2Trm-qP,Subgame Solving in Adversarial Team Games,[],"[6, 3, 6, 5]","[2, 4, 5, 3]",0,"[575, 305, 388, 710]",Accept
0gouO5saq6K,Multi-Game Decision Transformers,"['Reinforcement Learning', 'Generalist Agent', 'Multi-Environment RL', 'Upside-Down RL', 'Decision Transformers']","[6, 8, 7, 7]","[4, 4, 3, 4]",0,"[481, 148, 473, 519]",Accept
fWHOcnHb1n,Parameter-free Regret in High Probability with Heavy Tails,"['Online learning', 'Parameter-free', 'Online Convex Optimization', 'Heavy tails', 'Regularization']","[7, 5, 4]","[3, 3, 4]",0,"[435, 300, 277]",Accept
0VhrZPJXcTU,Learning to Compare Nodes in Branch and Bound with Graph Neural Networks,[],"[5, 3, 3]","[3, 4, 3]",0,"[462, 159, 207]",Accept
W72rB0wwLVu,Communication Acceleration of Local Gradient Methods via an Accelerated Primal-Dual Algorithm with an Inexact Prox,"['ProxSkip', 'Communication Acceleration', 'Federated Learning', 'Local Gradient Descent', 'Federated Averaging', 'Primal-Dual Methods']","[7, 5, 6, 7]","[3, 4, 4, 4]",0,"[211, 371, 1125, 621]",Accept
ft4xGJ8tIZH,On the detrimental effect of invariances in the likelihood for variational inference,"['Bayesian Neural Networks', 'Variational Bayes', 'Variational Inference', 'Invariance', 'Symmetry', 'posterior collapse']","[4, 6, 7, 5]","[2, 3, 3, 4]",0,"[735, 476, 467, 756]",Accept
9cPDqh9fQMy,BayesPCN: A Continually Learnable Predictive Coding Associative Memory,"['machine learning', 'associative memory', 'predictive coding', 'continual learning', 'bayesian inference']","[4, 5, 5, 5]","[5, 3, 3, 5]",0,"[320, 814, 321, 610]",Accept
8oj_2Ypp0j,Robustness to Unbounded Smoothness of Generalized SignSGD,"['stochastic', 'optimization', 'noncovex', 'adam', 'transformer', 'clipping', 'signsgd', 'momentum', 'unbounded smoothness']","[6, 5, 7]","[4, 4, 5]",0,"[204, 277, 1053]",Accept
ikWvMRVQBWW,Generalization for multiclass classification with overparameterized linear models,"['overparameterized', 'multiclass', 'classification', 'theory', 'generalization', 'interpolation', 'bi-level', 'Gaussian model']","[7, 6, 5, 7]","[4, 4, 2, 1]",0,"[398, 454, 199, 152]",Accept
1l5hEEK_j13,Finite-Sample Maximum Likelihood Estimation of Location,[],"[6, 7, 6, 6]","[3, 4, 4, 3]",0,"[512, 621, 472, 790]",Accept
9xRZlV6GfOX,Graphein - a Python Library for Geometric Deep Learning and Network Analysis on Biomolecular Structures and Interaction Networks,"['Protein', 'Drug Discovery', 'Geometric Deep Learning', 'Biomolecules']","[6, 8, 7, 6]","[3, 5, 3, 2]",0,"[174, 222, 281, 514]",Accept
weoLjoYFvXY,Root Cause Analysis of Failures in Microservices through Causal Discovery,"['root cause analysis', 'causal discovery', 'causal graphs']","[4, 4, 4]","[4, 2, 3]",0,"[692, 399, 375]",Accept
JCbLxJ1E6SO,Robust Model Selection and Nearly-Proper Learning for GMMs,"['Mixtures of Gaussians', 'model selection', 'proper learning', 'density estimation']","[8, 7, 5, 8]","[3, 4, 4, 4]",0,"[352, 604, 443, 421]",Accept
5wdvW_hI7bP,Explain My Surprise: Learning Efficient Long-Term Memory by predicting uncertain outcomes,"['Memory', 'RNN', 'Information Theory', 'Reinforcement Learning', 'POMDP']","[5, 5, 5]","[3, 3, 3]",0,"[532, 242, 590]",Accept
O3My0RK9s_R,Structural Knowledge Distillation for Object Detection,"['computer vision', 'CNNs', 'knowledge distillation', 'object detection', 'deep learning']","[5, 7, 6, 8]","[5, 5, 5, 3]",0,"[212, 336, 133, 227]",Accept
hdZeYGNCTtN,Exploring the Latent Space of Autoencoders with Interventional Assays,"['Autoencoders', 'Interventions', 'Structured Representation', 'Manifold Learning']","[7, 7, 6]","[2, 3, 4]",0,"[483, 709, 1102]",Accept
NqDXfe2oC_1,Performative Power,"['markets', 'competition', 'power', 'performativity', 'prediction']","[7, 8, 6]","[4, 3, 3]",0,"[584, 1074, 751]",Accept
anqloMQdWtP,Debiased Machine Learning without Sample-Splitting for Stable Estimators,"['Double Machine Learning', 'Stability', 'Causal Inference', 'Treatment Effects', 'Debiased Machine Learning']","[3, 7, 6]","[3, 4, 4]",0,"[584, 516, 208]",Accept
J4pX8Q8cxHH,HyperTree Proof Search for Neural Theorem Proving,"['theorem proving', 'automated theorem proving', 'MCTS', 'reasoning', 'AI for math']","[5, 7, 4, 4]","[4, 4, 3, 3]",0,"[344, 458, 509, 877]",Accept
5Z3GURcqwT,Spherical Channels for Modeling Atomic Interactions,"['graph neural networks', 'equivariance', 'invariance', 'materials science', 'chemistry']","[7, 3, 5]","[4, 5, 3]",0,"[540, 330, 261]",Accept
WWVcsfI0jGH,Chroma-VAE: Mitigating Shortcut Learning with Generative Classifiers,"['deep generative model', 'variational autoencoder', 'generative classifier', 'shortcut learning', 'spurious correlation', 'simplicity bias']","[7, 7, 7, 4]","[3, 4, 3, 3]",0,"[257, 861, 321, 707]",Accept
tX_dIvk4j-s,VisCo Grids: Surface Reconstruction with Viscosity and Coarea Grids,"['surface reconstruction', 'implicit neural representations', 'signed distance functions']","[5, 4, 6, 4]","[4, 4, 5, 4]",0,"[218, 242, 405, 243]",Accept
AluQNIIb_Zy,Learning Probabilistic Models from Generator Latent Spaces with Hat EBM,"['EBM', 'latent sampling', 'generator network', 'MCMC', 'Langevin']","[6, 5, 7, 6]","[4, 4, 3, 5]",0,"[334, 607, 358, 278]",Accept
mux7gn3g_3,On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning ,"['Reinforcement Learning', 'Fine-tuning', 'Multi-task Learning', 'Meta Reinforcement Learning', 'Meta-RL']","[4, 6, 4]","[4, 4, 4]",0,"[272, 434, 584]",Accept
WBhqzpF6KYH,SatMAE: Pre-training Transformers for Temporal and Multi-Spectral Satellite Imagery,"['Self-supervised learning', 'Masked Autoencoder', 'Satellite imagery']","[7, 4, 6, 6]","[4, 3, 4, 4]",0,"[194, 307, 297, 534]",Accept
KQYodS0W0j,Maximizing and Satisficing in Multi-armed Bandits with Graph Information,"['Multi-armed Bandits', 'Pure Exploration', 'Graph Smoothness', 'Best Arm Identification', 'Sample Complexity']","[7, 7]","[2, 4]",0,"[426, 344]",Accept
L-ceBdl2DPb,$k$-Sliced Mutual Information: A Quantitative Study of Scalability with Dimension,[],"[3, 4, 6]","[4, 4, 3]",0,"[297, 566, 275]",Accept
6Kj1wCgiUp_,Distinguishing discrete and continuous behavioral variability using warped autoregressive HMMs,"['naturalistic behavior', 'clustering', 'markov models', 'time series']","[7, 6, 7]","[4, 3, 4]",0,"[670, 267, 713]",Accept
7-LTDcvNc_,Analyzing Data-Centric Properties for Graph Contrastive Learning,"['unsupervised representation learning', 'generalization', 'graph neural networks', 'augmentation', 'invariance', 'contrastive learning', 'self supervised learning']","[6, 7, 5]","[3, 3, 4]",0,"[315, 327, 231]",Accept
sADLRl2STMe,Combining Implicit and Explicit Regularization for Efficient Learning in Deep Networks,"['optimization', 'regularization', 'deep learning', 'matrix factorization', 'neural networks', 'efficient learning']","[5, 6, 8, 7]","[3, 3, 4, 3]",0,"[819, 376, 959, 571]",Accept
R9KnuFlvnU,WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents,"['language grounding', 'reinforcement learning', 'imitation learning', 'natural language processing', 'sim-to-real transfer', 'web tasks']","[6, 6, 7]","[3, 4, 3]",0,"[223, 214, 730]",Accept
Od4oKKwBx7Z,On Infinite Separations Between Simple and Optimal Mechanisms,"['mechanism design', 'revenue maximization', 'correlated distributions']","[3, 7, 6, 7]","[2, 4, 3, 3]",0,"[365, 603, 390, 564]",Accept
kjR8GiwqCK,IMED-RL: Regret optimal learning of ergodic Markov decision processes,"['Reinforcement Learning', 'sequential learning', 'average-reward', 'lower bound', 'regret minimization', 'upper bound', 'optimal', 'Bandit', 'ergodic']","[6, 6, 7]","[3, 4, 3]",0,"[182, 283, 340]",Accept
o-mxIWAY1T8,Semantic Probabilistic Layers for Neuro-Symbolic Learning,"['neuro-symbolic learning', 'structured-output prediction', 'structured-output spaces', 'tractable probabilistic inference', 'probabilistic reasoning']","[7, 8, 7, 5]","[3, 3, 2, 3]",0,"[127, 209, 262, 584]",Accept
NtJyGXo0nF,Adversarial training for high-stakes reliability,"['adversarial training', 'language model', 'redteaming', 'human adversaries', 'tool assisted']","[6, 5, 9]","[4, 4, 4]",0,"[592, 319, 842]",Accept
11WmFbrIt26,Provable Defense against Backdoor Policies in Reinforcement Learning,"['Adversarial Learning', 'Reinforcement Learning']","[6, 6, 5, 6]","[4, 3, 4, 3]",0,"[420, 309, 650, 171]",Accept
yb3HOXO3lX2,Defining and Characterizing Reward Gaming,"['reward hacking', 'reward gaming', 'reward learning', 'reward modeling', 'preference learning', 'specification', 'alignment', 'AI safety', 'theory', 'preference ordering', 'decision theory']","[6, 6, 8, 5]","[3, 2, 4, 3]",0,"[371, 281, 395, 657]",Accept
5yjM1sQ1uKZ,A Unified Framework for Alternating Offline Model Training and Policy Learning,"['Offline Reinforcement Learning', 'Model-based Reinforcement Learning', 'Mismatched Model Objectives']","[5, 6, 6, 7]","[4, 4, 4, 4]",0,"[464, 643, 487, 398]",Accept
5WuQNQwy56M,S4ND: Modeling Images and Videos as Multidimensional Signals with State Spaces,"['Deep learning', 'computer vision', 'state space model', 'S4']","[6, 7, 8, 7]","[3, 3, 3, 3]",0,"[935, 273, 223, 280]",Accept
TYMGhqlSFkC,JAWS: Auditing Predictive Uncertainty Under Covariate Shift,"['conformal prediction', 'uncertainty quantification', 'covariate shift', 'jackknife+', 'influence functions', 'error assessment', 'auditing']","[5, 7, 6, 4]","[3, 3, 3, 3]",0,"[229, 252, 649, 297]",Accept
pgF-N1YORd,Disentangling Transfer in Continual Reinforcement Learning,"['continual learning', 'reinforcement learning', 'transfer learning']","[6, 5, 7]","[3, 3, 3]",0,"[373, 307, 257]",Accept
LJdUUOmWjX,List-Decodable Sparse Mean Estimation via Difference-of-Pairs Filtering,"['list-decoding', 'sparse estimation', 'robust statistics', 'high-dimensional inference']","[8, 7, 8]","[4, 4, 4]",0,"[333, 286, 1399]",Accept
snUOkDdJypm,Finite-Time Last-Iterate Convergence for Learning in Multi-Player Games,"['learning in games', 'smooth monotone games', 'last-iterate convergence rate', 'Nash equilibrium']","[7, 7, 7, 8]","[3, 4, 4, 2]",0,"[154, 340, 236, 589]",Accept
g2dXxjD9Ucv,Normalizing Flows for Knockoff-free Controlled Feature Selection,"['controlled feature selection', 'variable selection', 'knockoffs', 'normalizing flows', 'false discovery rate control', 'Bayesian methods']","[7, 6, 4, 7]","[3, 2, 4, 3]",0,"[769, 255, 516, 549]",Accept
TG8KACxEON,Training language models to follow instructions with human feedback,[],"[7, 6, 8, 5]","[4, 4, 5, 3]",0,"[456, 364, 193, 229]",Accept
0OGMrvHnQbb,Efficiently Factorizing Boolean Matrices using Proximal Gradient Descent,"['Boolean Matrix Factorization', 'Non-negative Matrix Factorization', 'Proximal Point', 'Elastic Net', 'Model Selection']","[7, 4, 6]","[4, 3, 4]",0,"[612, 307, 239]",Accept
B5qRau1IxjM,Robust Anytime Learning of Markov Decision Processes,"['Markov Decision Process', 'Robust Reinforcement Learning', 'Model-based Reinforcement Learning', 'Formal Verification']","[4, 6, 6]","[3, 3, 4]",0,"[304, 439, 513]",Accept
EvtEGQmXe3,Neural Topological Ordering for Computation Graphs,"['Combinatorial Optimization', 'Graph Neural Network', 'Directed Acyclic Graph']","[6, 7, 6]","[4, 2, 5]",0,"[590, 197, 442]",Accept
5oS20NUCJEX,"Benign, Tempered, or Catastrophic: Toward a Refined Taxonomy of Overfitting","['overfitting', 'benign overfitting', 'generalization', 'kernel regression', 'powerlaws', 'eigenspectra']","[8, 6, 4]","[3, 3, 3]",0,"[795, 189, 236]",Accept
_1bgdFHhA70,"Evident: a Development Methodology and a Knowledge Base Topology for Data Mining, Machine Learning and General Knowledge Management","['Data Mining', 'Machine Learning', 'Knowledge Management', 'Computer History', 'Software Engineering', 'Database', 'Sensing Hardware', 'Philosophy', 'Knowledge Sharing & Retention', 'Project Management']","[2, 3, 3]","[4, 3, 2]",0,"[450, 482, 337]",Reject
yKDKNzjHg8N,Characterizing Datapoints via Second-Split Forgetting,"['example hardness', 'memorization', 'generalization', 'forgetting', 'unlearning']","[7, 8, 6, 8]","[2, 5, 4, 3]",0,"[166, 402, 796, 435]",Accept
mamv07NQWk,Regret Bounds for Multilabel Classification in Sparse Label Regimes,"['regret bounds', 'sparse multilabel classification']","[5, 7, 8]","[2, 3, 4]",0,"[372, 240, 340]",Accept
4wrB7Mo9_OQ,Resolving the data ambiguity for periodic crystals,"['computational geometry', 'data ambiguity', 'materials applications']","[6, 5, 5]","[4, 3, 3]",0,"[234, 244, 273]",Accept
3y80RPgHL7s,The Power and Limitation of Pretraining-Finetuning for Linear Regression under Covariate Shift,"['covariate shift', 'linear regression', 'risk bound', 'pretraining', 'finetuning']","[7, 7, 4, 5]","[3, 3, 4, 4]",0,"[751, 162, 131, 674]",Accept
OJ4mMfGKLN,Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency,"['time series', 'pre-training', 'contrastive learning', 'transfer learning', 'self-supervised learning']","[6, 6, 8, 8]","[5, 5, 4, 4]",0,"[410, 494, 231, 595]",Accept
lJx2vng-KiC,Exact learning dynamics of deep linear networks with prior knowledge,[],"[7, 7, 6, 7]","[2, 3, 4, 4]",0,"[244, 519, 1232, 724]",Accept
V22VeIZ9QU,Automatic Differentiation of Programs with Discrete Randomness,"['stochastic methods', 'automatic differentiation', 'reparameterization trick', 'discrete randomness', 'gradient based inference', 'differentiable stochastic programming', 'chain rule', 'compositionality']","[7, 6, 7, 6]","[2, 3, 2, 3]",0,"[342, 499, 472, 776]",Accept
9HBbWAsZxFt,Unsupervised Reinforcement Learning with Contrastive Intrinsic Control,"['Reinforcement Learning', 'Unsupervised Learning']","[3, 7, 6]","[4, 4, 4]",0,"[1179, 700, 538]",Accept
ue4gP8ZKiWb,Prompt Certified Machine Unlearning with Randomized Gradient Smoothing and Quantization,"['Certified machine unlearning', 'randomized gradient smoothing', 'gradient quantization', 'theoretical guarantee', 'prompt unlearning']","[3, 8, 8]","[3, 3, 4]",0,"[303, 411, 459]",Accept
A2Ya5aLtyuG,Do Current Multi-Task Optimization Methods in Deep Learning Even Help?,"['Multi-Task Optimization', 'Multi-Task Neural Networks', 'Task Interference', 'Reproducible Research']","[6, 7, 7]","[3, 4, 3]",0,"[498, 288, 241]",Accept
R1fj6401HJF,Instance-optimal PAC Algorithms for Contextual Bandits,"['contextual bandits', 'active learning', 'reinforcement learning']","[4, 7, 7, 6]","[3, 3, 3, 1]",0,"[471, 610, 446, 80]",Accept
LivA_JyyJM,Thinned random measures for sparse graphs with overlapping communities,"['bayesian nonparametrics', 'network analysis', 'stochastic blockmodels', 'generalized gamma process', 'completely random measures']","[6, 4, 6]","[4, 2, 2]",0,"[626, 422, 359]",Accept
p-56bnzZhQ7,Cryptographic Hardness of Learning Halfspaces with Massart Noise,"['learning theory', 'hardness of learning', 'halfspaces', 'Massart noise', 'Learning with Errors (LWE)']","[8, 8, 7, 6]","[3, 4, 3, 3]",0,"[201, 694, 443, 274]",Accept
cUY5OkP3VR,Hyperparameter Sensitivity in Deep Outlier Detection: Analysis and a Scalable Hyper-Ensemble Solution,"['deep outlier detection', 'unsupervised model selection', 'ensemble learning']","[5, 7, 6]","[3, 3, 5]",0,"[720, 813, 542]",Accept
yJV9zp5OKAY,Adversarial Auto-Augment with Label Preservation: A Representation Learning Principle Guided Approach,"['Data Augmentation', 'Representation Learning', 'Adversarial Auto-Augment']","[8, 4, 5, 5]","[3, 4, 3, 3]",0,"[458, 405, 481, 332]",Accept
e2M4CNa-UOS,Efficient Sequence Packing without Cross-contamination: Accelerating Large Language Models without Impacting Performance,"['deep learning', 'BERT', 'IPU', 'GPU', 'hardware-acceleration', 'padding', 'Wikipedia', 'NLP', 'bin-packing']","[4, 4, 8]","[3, 4, 3]",0,"[603, 582, 387]",Reject
9xVWIHFSyfl,Hybrid Neural Autoencoders for Stimulus Encoding in Visual and Other Sensory Neuroprostheses,"['Sensory Neuroprostheses', 'Bionic Vision', 'Brain Computer Interfaces', 'BCI', 'Stimulus Encoding', 'Autoencoder', 'Perception', 'Computational Modeling', 'Inverse Problem', 'Retinal Prostheses', 'Argus', 'Cortical Prostheses', 'Vision']","[7, 7, 7]","[4, 4, 4]",0,"[272, 276, 382]",Accept
mzze3bubjk,The Franz-Parisi Criterion and Computational Trade-offs in High Dimensional Statistics,"['Information-computation gaps', 'low-degree likelihood ratio', 'statistical physics', 'MCMC methods', 'sparse regression']","[8, 7, 7]","[3, 3, 3]",0,"[814, 1434, 638]",Accept
6qdUJblMHqy,Toward Efficient Robust Training against Union of $\ell_p$ Threat Models,"['Adversarial Robustness', 'Adversarial Defense', 'Adversarial Training', 'Multiple Threat Models', 'Fast Adversarial Training', 'Efficient Adversarial Training', 'Single-Step Adversarial Training']","[4, 4, 8, 7]","[3, 5, 4, 5]",0,"[131, 443, 275, 299]",Accept
yJE7iQSAep,On the Parameterization and Initialization of Diagonal State Space Models,"['Deep learning', 'sequence model', 'state space model', 'S4', 'HiPPO', 'diagonal state space']","[8, 5, 7, 6]","[3, 4, 3, 2]",0,"[379, 670, 286, 321]",Accept
kQgLvIFLyIu,Coreset for Line-Sets Clustering,[],"[7, 7, 5]","[3, 3, 5]",0,"[316, 652, 266]",Accept
SyD-b2m2meG,Multitasking Models are Robust to Structural Failure: A Neural Model for Bilingual Cognitive Reserve,"['multitask learning', 'robustness', 'linear representation learning']","[5, 7, 5, 7]","[2, 2, 4, 3]",0,"[143, 669, 437, 533]",Accept
w-Aq4vmnTOP,On Learning and Refutation in Noninteractive Local Differential Privacy,"['differential privacy', 'local privacy', 'agnostic learning', 'refutation', 'non-interactive']","[7, 7, 8, 6]","[2, 2, 3, 2]",0,"[147, 147, 227, 283]",Accept
StlwkcFsjaZ,Learning to Follow Instructions in Text-Based Games,"['reinforcement learning', 'linear temporal logic', 'textworld', 'text-based games', 'instruction following', 'natural language', 'instructions', 'GATA']","[4, 5, 8, 5]","[3, 4, 5, 4]",0,"[311, 369, 575, 373]",Accept
wph_3smhuec,Non-Convex Bilevel Games with Critical Point Selection Maps,"['Bilevel Optimization', 'Morse theory', 'gradient flows', 'Lojasiewicz gradient inequality']","[6, 6, 7, 2]","[1, 4, 3, 4]",0,"[100, 264, 284, 500]",Accept
agihaAKJ89X,Differentially Private Generalized Linear Models Revisited,"['differential privacy', 'supervised learning', 'generalized linear model', 'optimization']","[7, 6, 7]","[2, 3, 5]",0,"[284, 86, 377]",Accept
IUikebJ1Bf0,Autoformalization with Large Language Models,"['Large language models', 'Autoformalization', 'Formal Math', 'miniF2F.']","[6, 8, 4, 6]","[3, 5, 4, 4]",0,"[561, 332, 463, 479]",Accept
XzeTJBq1Ce2,The Role of Baselines in Policy Gradient Optimization,"['reinforcement learning', 'policy optimization', 'policy gradient', 'global convergence']","[5, 6, 6, 5]","[3, 3, 3, 3]",0,"[323, 910, 386, 458]",Accept
NoAZRVthZL,Learning Mixed Multinomial Logits with Provable Guarantees,"['Mixed Multinomial Logits (MMNL)', 'Non-parametric estimation', 'Statistical learning', 'Provable algorithms', 'Sample complexity', 'Conditional gradient (Frank-Wolfe)']","[6, 7, 6, 6]","[3, 3, 2, 3]",0,"[326, 141, 336, 550]",Accept
hTCZbhKaDJz,Phase transitions in when feedback is useful,"['Bayesian Inference', 'Predictive Coding', 'Efficient Coding', 'Linear Quadratic Gaussian']","[5, 8, 7, 7]","[3, 4, 3, 3]",0,"[273, 383, 708, 494]",Accept
q_AeTuxv02D,OOD Link Prediction Generalization Capabilities of Message-Passing GNNs in Larger Test Graphs,"['OOD', 'GNNs', 'link prediction', 'Message Passing GNNs', 'random graphs', 'graphon']","[5, 4, 7, 7]","[4, 3, 3, 4]",0,"[476, 629, 183, 860]",Accept
HnIQrSY7vPI,Sample-Efficient Reinforcement Learning of Partially Observable Markov Games,['RL theory'],"[4, 5, 6, 6]","[5, 3, 2, 3]",0,"[269, 263, 199, 624]",Accept
K1NPDQ7E-Cl,Collaborative Learning of Discrete Distributions under Heterogeneity and Communication Constraints,"['Collaborative Estimation', 'Sparse Heterogeneity', 'Communication Constraint', 'Discrete Distributions']","[7, 7, 4]","[4, 3, 2]",0,"[570, 464, 366]",Accept
pBJe5yu41Pq,"On Uncertainty, Tempering, and Data Augmentation in Bayesian Classification","['probabilistic methods', 'deep learning', 'Bayesian deep learning']","[7, 7, 6, 7]","[4, 3, 4, 5]",0,"[462, 706, 385, 620]",Accept
i-k6J4VkCDq,Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class,"['arbitrary trigger', 'backdoor attacks', 'generative models']","[6, 5, 4, 5]","[4, 3, 4, 5]",0,"[804, 272, 381, 395]",Accept
yHFATHaIDN,MABSplit: Faster Forest Training Using Multi-Armed Bandits,"['random forest', 'xgboost', 'CART', 'classification and regression trees', 'multi-armed bandits', 'best arm identification']","[6, 7, 5, 6]","[3, 3, 4, 4]",0,"[222, 542, 267, 939]",Accept
zz0FC7qBpkh,The Missing Invariance Principle found --  the Reciprocal Twin of Invariant Risk Minimization ,[],"[7, 8, 3, 6]","[3, 4, 3, 3]",0,"[438, 487, 424, 941]",Accept
isPnnaTZaP5,LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer Learning,"['parameter-efficient transfer learning', 'memory-efficient learning', 'transfer learning']","[6, 4, 4, 3]","[4, 4, 4, 4]",0,"[394, 533, 350, 987]",Accept
wKhUPzqVap6,On Feature Learning in the Presence of Spurious Correlations,"['spurious correlations', 'robustness', 'representation learning']","[7, 6, 7]","[4, 4, 4]",0,"[631, 447, 272]",Accept
yKYCwTvl8eU,Learning Concept Credible Models for Mitigating Shortcuts,"['shortcuts', 'spurious correlations', 'deep learning']","[5, 6, 7]","[4, 3, 3]",0,"[472, 194, 683]",Accept
JoukmNwGgsn,Peer Prediction for Learning Agents,"['information elicitation', 'peer prediction', 'online learning', 'truthful convergence']","[7, 6, 5, 5]","[3, 4, 1, 3]",0,"[340, 505, 238, 757]",Accept
dYhB_alLyCO,Mean Estimation with User-level Privacy under Data Heterogeneity,"['differential privacy', 'heterogeneous data', 'heterogeneous users', 'mean estimation', 'statistical inference', 'meta analysis']","[7, 7, 7, 6]","[4, 3, 2, 2]",0,"[381, 344, 333, 288]",Accept
VeQBBm1MmTZ,CryptoGCN: Fast and Scalable Homomorphically Encrypted Graph Convolutional Network Inference,"['Cryptographic inference', 'ST-GCN', 'Ciphertext data formatting']","[5, 6, 7]","[3, 4, 3]",0,"[547, 577, 377]",Accept
JLweqJeqhSq,Tight Analysis of Extra-gradient and Optimistic Gradient Methods For Nonconvex Minimax Problems,"['Minimax Optimization', 'Nonconvex Optimization']","[6, 6, 6, 7]","[4, 4, 4, 4]",0,"[608, 578, 1113, 194]",Accept
oUigTwc7Cw5,"Efficient coding, channel capacity, and the emergence of retinal mosaics","['efficient coding', 'retina', 'neuroscience', 'information theory']","[4, 7, 8, 8]","[3, 3, 4, 4]",0,"[312, 749, 488, 212]",Accept
eV4JI-MMeX,Amortized Inference for Causal Structure Learning,"['causality', 'amortized inference', 'causal discovery', 'structure learning', 'Bayesian causal discovery']","[6, 7, 6]","[4, 3, 3]",0,"[327, 322, 693]",Accept
MHE27tjD8m3,Robust Neural Posterior Estimation and Statistical Model Criticism,[],"[7, 6, 3, 3]","[4, 5, 3, 2]",0,"[458, 1509, 745, 519]",Accept
X3RuacCx1R,"Expected Frequency Matrices of Elections: Computation, Geometry, and Preference Learning","['Mallows model', 'visualizing experimental results', 'vote distributions', 'single-peaked elections']","[8, 7, 5]","[4, 3, 3]",0,"[364, 226, 462]",Accept
Q_WPshXgGI9,Confident Approximate Policy Iteration for Efficient Local Planning in $q^\pi$-realizable MDPs,"['Approximate Policy Iteration', 'Reinforcement Learning', 'Planning', 'Markov Decision Processes', 'Linear Function Approximation', 'Sample Complexity']","[7, 6, 6]","[4, 4, 3]",0,"[246, 95, 251]",Accept
jXgbJdQ2YIy,Escaping from the Barren Plateau via Gaussian Initializations in Deep Variational Quantum Circuits,"['quantum algorithm', 'vanishing gradient problem', 'optimization', 'gaussian initialization']","[6, 6, 7, 7]","[5, 4, 3, 4]",0,"[545, 255, 422, 603]",Accept
mCzMqeWSFJ,ComENet: Towards Complete and Efficient Message Passing for 3D Molecular Graphs,[],"[5, 6, 6, 6]","[3, 4, 3, 3]",0,"[151, 370, 333, 287]",Accept
8gjwWnN5pfy,Fairness without Demographics through Knowledge Distillation,"['fairness without demographics', 'knowledge distillation']","[6, 4, 6]","[4, 4, 4]",0,"[770, 511, 474]",Accept
pV7f1Rq71I5,Estimation of Entropy in Constant Space with Improved Sample Complexity,"['Sample complexity', 'Data streams', 'Shannon Entropy']","[7, 4, 7, 6]","[5, 3, 4, 5]",0,"[337, 497, 452, 333]",Accept
6rVXMHImDzv,Communication Efficient Distributed Learning for Kernelized Contextual Bandits,"['contextual bandit', 'kernelized method', 'distributed learning', 'communication efficiency']","[6, 6, 6, 5]","[3, 3, 4, 4]",0,"[437, 330, 272, 218]",Accept
dgWo-UyVEsa,Linear Label Ranking with Bounded Noise,"['Label Ranking', 'Noise', 'Gaussian', 'Linear Sorting Function']","[7, 8, 8, 7]","[2, 3, 4, 3]",0,"[204, 398, 223, 587]",Accept
rUb6iKYrgXQ,Data-Driven Conditional Robust Optimization,"['Robust Optimization', 'Contextual Optimization', 'Conditional Stochastic Optimization', 'Unsupervised learning', 'Deep Neural Networks', 'Conditional Robust Optimization']","[8, 7, 7]","[4, 2, 5]",0,"[932, 157, 562]",Accept
lWq3KDEIXIE,Learning Tractable Probabilistic Models from Inconsistent Local Estimates,"['Tractable Probabilistic Models', 'Parameter Learning', 'Inconsistent Data', 'Local Estimates']","[7, 7, 7, 3]","[4, 4, 4, 5]",0,"[253, 341, 355, 498]",Accept
KMaI40_UaGw,Learning from a Sample in Online Algorithms,"['Learning Augmented Algorithms', 'Online Algorithms', 'Sample Complexity', 'Load Balancing', 'Optimization', 'Steiner tree', 'Facility Location', 'Clustering']","[7, 7, 7]","[4, 3, 4]",0,"[241, 324, 371]",Accept
NgwrhCBPTVk,(Optimal) Online Bipartite Matching with Degree Information,"['online bipartite matching', 'learning-augmented algorithms', 'algorithms with predictions', 'online algorithms']","[6, 7, 7, 4]","[4, 4, 3, 3]",0,"[444, 306, 383, 547]",Accept
TVlKuUk-uj9,Can Adversarial Training Be Manipulated By Non-Robust Features?,"['Adversarial Training', 'Adversarial Robustness', 'Availability Attacks', 'Hypocritical Perturbations']","[5, 6, 5, 6]","[3, 3, 4, 2]",0,"[377, 199, 605, 495]",Accept
8xccCiF9JQ6,A Fast Scale-Invariant Algorithm for Non-negative Least Squares with Non-negative Data,"['acceleration', 'non-negative least squares', 'scale invariance']","[6, 7, 6, 7]","[4, 4, 3, 3]",0,"[1083, 439, 473, 707]",Accept
FR--mkQu0dw,When Does Differentially Private Learning Not Suffer in High Dimensions?,"['Differential Privacy', 'fine-tuning', 'DP convex optimization', 'pretrained models']","[8, 6, 7]","[3, 4, 3]",0,"[380, 223, 521]",Accept
znbTxnBPlx,Training stochastic stabilized supralinear networks by dynamics-neutral growth,"['cortical circuit', 'visual cortex', 'recurrent neural network', 'stabilized supralinear network', 'Gaussian scale mixture', 'Bayesian inference', 'Markov chain Monte Carlo']","[5, 7, 5]","[3, 3, 4]",0,"[1807, 465, 1110]",Accept
51f5sPXJD_E,Sparse Fourier Backpropagation in Cryo-EM Reconstruction,"['cryo-EM', 'NeRF', 'Fourier space reconstruction', 'VAE', 'generative modeling']","[4, 7, 7]","[5, 3, 4]",0,"[568, 759, 311]",Accept
zKBbP3R86oc,Not All Bits have Equal Value: Heterogeneous Precisions via Trainable Noise,[],"[6, 5, 8]","[4, 3, 4]",0,"[495, 190, 397]",Accept
CIaUMANM6gQ,Detecting Abrupt Changes in Sequential Pairwise Comparison Data,"['ranking', 'change point detection', 'Bradley-Terry model', 'high-dimensional statistics']","[6, 4, 7]","[3, 2, 2]",0,"[369, 383, 296]",Accept
QYhUhMOI4C,Uniqueness and Complexity of Inverse MDP Models,"['inverse models', 'reinforcement learning', 'causality', 'theory', 'multi-step models', 'reasoning']","[3, 6, 3]","[4, 2, 2]",0,"[533, 924, 1394]",Reject
e8PVEkSa4Fq,Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models,"['Foundation Model', 'Prompt Tuning', 'Generalization', 'Out-of-Distribution Robustness']","[5, 7, 6, 5]","[4, 3, 4, 4]",0,"[305, 127, 357, 233]",Accept
RQ8X_iK3HT5,When Combinatorial Thompson Sampling meets Approximation Regret,"['combinatorial multi-armed bandit', 'semi-bandit', 'thompson sampling', 'approximation regret', 'oracle', 'probabilistically triggered arms', 'greedy oracle']","[4, 7, 7, 6]","[3, 4, 5, 1]",0,"[942, 286, 458, 155]",Accept
Cntmos_Ndf0,Lifting Weak Supervision To Structured Prediction,"['Weak Supervision', 'Structured Prediction', 'Pseudo-Euclidean', 'Riemannian Manifolds', 'Learning with Noise']","[6, 7, 7]","[3, 3, 3]",0,"[945, 480, 361]",Accept
wYGIxXZ_sZx,What is a Good Metric to Study Generalization of Minimax Learners?,[],"[5, 6, 6, 6]","[4, 3, 3, 4]",0,"[325, 677, 474, 236]",Accept
JRXgTMqESS,Learning Audio-Visual Dynamics Using Scene Graphs for Audio Source Separation,"['Audio Source Separation', 'Multimodal Learning', 'Multi-task Learning', 'Scene Graphs']","[5, 6, 7, 6]","[3, 4, 3, 4]",0,"[397, 1003, 444, 345]",Accept
7yUxTNWyQGf,Lost in Latent Space: Examining failures of disentangled models at combinatorial generalisation,"['Combinatorial Generalisation', 'Disentanglement', 'Generative Models', 'Representation Learning']","[7, 7, 6, 6]","[4, 4, 4, 5]",0,"[893, 358, 568, 377]",Accept
2DZ9R7GXLY,TVLT: Textless Vision-Language Transformer,"['textless vision-and-language modeling', 'audiovisual', 'TVLT']","[6, 7, 8]","[4, 4, 4]",0,"[408, 243, 417]",Accept
D-X3kH-BkpN,Unpacking Reward Shaping: Understanding the Benefits of Reward Engineering on Sample Complexity,"['Reward Shaping', 'Regret Analysis']","[7, 8, 5, 8]","[4, 4, 2, 4]",0,"[619, 1017, 258, 644]",Accept
mwIPkVDeFg,Distributed Optimization for Overparameterized Problems: Achieving Optimal Dimension Independent Communication Complexity,"['Distributed Optimization', 'Overparameterized Problem', 'Quantization']","[7, 7, 4]","[4, 4, 4]",0,"[533, 377, 942]",Accept
NiCJDYpKaBj,Staircase Attention for Recurrent Processing of Sequences,[],"[6, 6, 7, 7]","[3, 5, 5, 4]",0,"[218, 981, 466, 485]",Accept
zD65Zdh6ZhI,On Computing Probabilistic Explanations for Decision Trees,"['explainability', 'formal XAI', 'decision trees', 'computational complexity', 'sufficient reasons']","[5, 6, 8]","[4, 3, 4]",0,"[656, 498, 653]",Accept
nyCr6-0hinG,Tensor Program Optimization with Probabilistic Programs,"['Tensor Program Optimization', 'Deep Learning Deployment', 'Machine Learning Compilation', 'Probabilistic Programming']","[6, 6, 6, 5]","[4, 4, 3, 4]",0,"[659, 594, 846, 318]",Accept
PQFr7FbGbO,A Multi-Resolution Framework for U-Nets with Applications to Hierarchical VAEs,"['U-Net', 'multi-resolution analysis', 'hierarchical variational autoencoders']","[8, 5, 7]","[3, 2, 2]",0,"[229, 497, 150]",Accept
GyWsthkJ1E2,Instability and Local Minima in GAN Training with Kernel Discriminators,"['GANs', 'stability', 'kernel', 'linearization']","[7, 6, 5]","[3, 3, 3]",0,"[789, 244, 254]",Accept
ok-SB1kz67Z,Introspective Learning : A Two-Stage approach for Inference in Neural Networks,"['Recognition', 'Active Learning', 'Out-of-distribution Detection', 'Model Calibration', 'Uncertainty']","[4, 7, 6, 3]","[3, 3, 3, 4]",0,"[237, 548, 133, 238]",Accept
GBEimWWM9ii,MMRR: Unsupervised Anomaly Detection through Multi-Level Masking and Restoration with Refinement,"['Deep Learning', 'Computer Vision', 'Anomaly Detection']","[2, 3, 5]","[5, 4, 4]",0,"[247, 821, 882]",Reject
AJzrFyqP0ci,Formalizing Consistency and Coherence of Representation Learning,"['autoencoders', 'neuro-symbolic', 'consistency', 'coherence', 'transfer learning']","[7, 5, 4]","[2, 5, 4]",0,"[723, 673, 301]",Accept
4L2zYEJ9d_,CARD: Classification and Regression Diffusion Models,[],"[5, 6, 5, 5]","[3, 3, 4, 3]",0,"[357, 543, 517, 341]",Accept
f2MyWR-6HrQ,Learning Modular Simulations for Homogeneous Systems,"['Neural differential equations', 'Dynamics', 'Graph networks']","[6, 6, 8]","[4, 3, 3]",0,"[277, 501, 233]",Accept
HXCPA2GXf_,Concept Embedding Models,"['Explainable Artificial Intelligence', 'Concept Bottleneck Models', 'Concept-based Explainability', 'Interpretability', 'XAI']","[7, 6, 7, 5]","[3, 3, 4, 4]",0,"[229, 177, 204, 377]",Accept
_gn5djJHKzj,Online Learning and Pricing for Network Revenue Management with Reusable Resources,"['pricing', 'network', 'bandits', 'stochastic systems', 'queueing network', 'mixing times']","[5, 4, 6, 7]","[4, 3, 3, 4]",0,"[336, 535, 424, 1110]",Accept
bx2roi8hca8,MAgNet: Mesh Agnostic Neural PDE Solver,"['physical simulations', 'implicit neural representations', 'graph neural networks', 'learned simulators']","[6, 5, 6]","[3, 4, 3]",0,"[523, 323, 465]",Accept
U2s1GFDDihU,Society of Agents: Regrets Bounds of Concurrent Thompson Sampling,[],"[6, 6, 6, 6]","[4, 4, 3, 4]",0,"[419, 317, 242, 304]",Accept
zSkYVeX7bC4,Exploring Length Generalization in Large Language Models,"['length generalization', 'multi-step reasoning', 'large language models', 'out-of-distribution generalization']","[7, 7, 7, 7]","[4, 5, 3, 4]",0,"[869, 257, 480, 796]",Accept
TItRK4VP9X2,Randomized Channel Shuffling: Minimal-Overhead Backdoor Attack Detection without Clean Datasets,[],"[6, 7, 7, 5]","[3, 4, 4, 4]",0,"[203, 413, 527, 716]",Accept
j9JL96S8Vl,Towards Practical Few-shot Query Sets: Transductive Minimum Description Length Inference,"['few-shot learning', 'transductive inference', 'minimum description length', 'primal-dual optimization', 'clustering']","[5, 7, 6, 5]","[2, 3, 3, 3]",0,"[225, 399, 307, 228]",Accept
Fhty8PgFkDo,Differentially Private Graph Learning via Sensitivity-Bounded Personalized PageRank,"['Differential privacy', 'Graph algorithms', 'Ranking', 'Personalized Page Rank']","[3, 6, 6, 7]","[4, 4, 5, 2]",0,"[309, 418, 70, 370]",Accept
4G1Sfp_1sz7,Generating Training Data with Language Models: Towards Zero-Shot Language Understanding,"['Zero-Shot Learning', 'Natural Language Understanding', 'Pretrained Language Models']","[5, 6, 6]","[4, 4, 3]",0,"[383, 318, 297]",Accept
Uynr3iPhksa,Recurrent Memory Transformer,"['memory augmented models', 'transformers', 'self-attention', 'recurrence']","[6, 6, 6]","[3, 4, 4]",0,"[286, 266, 986]",Accept
lArVAWWpY3,"Statistical, Robustness, and Computational Guarantees for Sliced Wasserstein Distances","['sliced optimal transport', 'Wasserstein distances', 'empirical convergence', 'robust statistics']","[7, 7, 7, 7]","[4, 4, 3, 2]",0,"[337, 1353, 376, 158]",Accept
xz-2eyIh7u,Collaborative Linear Bandits with Adversarial Agents: Near-Optimal Regret Bounds,"['Collaborative Linear Bandits', 'Adversarial Attacks', 'Multi-Agent Systems', 'Robustness', 'Provably Correct Algorithms']","[7, 6, 6, 7]","[3, 3, 4, 3]",0,"[339, 284, 534, 238]",Accept
gIGeujOKfyV,Neural Differential Equations for Learning to Program Neural Nets Through Continuous Learning Rules,"['Neural controlled differential equations', 'Neural ODEs', 'continuous-time sequence processing', 'linear Transformers', 'fast weight programmers']","[5, 7, 7]","[4, 4, 4]",0,"[606, 674, 474]",Accept
xOK40an4ag1,Operative dimensions in unconstrained connectivity of recurrent neural networks,"['recurrent neural networks', 'computation through dynamics', 'dimensionality']","[7, 8, 7, 6]","[3, 4, 4, 5]",0,"[355, 601, 476, 559]",Accept
06OVtS901hF,Multi-Class $H$-Consistency Bounds,"['multi-class classification', 'consistency', 'surrogate losses', 'adversarial learning']","[7, 7, 4]","[3, 1, 3]",0,"[264, 248, 187]",Accept
zdmYnIRXvKS,Biologically plausible solutions for spiking networks with efficient coding,"['spiking neural networks', 'optimization', 'loss function', 'information', 'population code', 'E-I network', 'Generalized leaky integrate-and-fire (LIF) neuron', 'biological constraints']","[2, 6, 6]","[5, 3, 3]",0,"[314, 255, 426]",Accept
HLzjd09oRx,Improving Multi-Task Generalization via Regularizing Spurious Correlation,"['spurious correlation', 'multi-task learning', 'multi-task generalization', 'out-of-distribution generalization']","[7, 7, 6, 7]","[4, 4, 3, 3]",0,"[411, 932, 318, 411]",Accept
GeT7TSy1_hL,Online Bipartite Matching with Advice: Tight Robustness-Consistency Tradeoffs for the Two-Stage Model,"['Online matching', 'online algorithms with advice', 'prediction augmented', 'learning augmented', 'two stage optimization']","[7, 7, 7, 6]","[4, 4, 4, 4]",0,"[269, 249, 399, 737]",Accept
9XQa6cgLo21,Safety Guarantees for Neural Network Dynamic Systems via Stochastic Barrier Functions,"['Safety Certificate', 'Neural Networks', 'Stochastic Dynamical Systems', 'Barrier Functions', 'Convex Optimization', 'Robotics and Control']","[6, 3, 7]","[4, 4, 2]",0,"[745, 611, 279]",Accept
OFsja-NZGbY,Zonotope Domains for Lagrangian Neural Network Verification,"['neural network verification', 'lagrangian duality', 'robustness', 'zonotopes']","[7, 6, 7, 6, 4]","[4, 2, 5, 4, 5]",0,"[586, 319, 437, 184, 484]",Accept
39XK7VJ0sKG,Neural Set Function Extensions: Learning with Discrete Functions in High Dimensions,"['deep learning', 'unsupervised learning', 'combinatorial optimization', 'algorithmic reasoning']","[6, 8]","[2, 2]",0,"[452, 380]",Accept
wwWCZ7sER_C,Algorithms with Prediction Portfolios,"['algorithms with predictions', 'multiple predictions', 'learnability', 'minimum cost matching', 'load balancing', 'completion time scheduling']","[6, 6, 6, 6]","[2, 3, 4, 3]",0,"[820, 455, 794, 439]",Accept
bot35zOudq,Pushing the limits of fairness impossibility: Who's the fairest of them all?,"['fairness in machine learning', 'fairness trade-off', 'impossibility theorem', 'non-convex optimization', 'mixed integer programming']","[5, 7, 7]","[3, 4, 3]",0,"[187, 378, 427]",Accept
b-WnRS7kSEN,Tsetlin Machine for Solving Contextual Bandit Problems,"['Contextual bandits', 'Tsetlin Machine']","[6, 3, 6]","[3, 3, 5]",0,"[552, 278, 231]",Accept
e8EkYPDHrsY,Learning with convolution and pooling operations in kernel methods,"['convolutional kernel', 'average pooling', 'kernel methods', 'generalization error']","[4, 7, 5, 7]","[4, 4, 3, 4]",0,"[235, 372, 281, 259]",Accept
5HaIds3ux5O,QUARK: Controllable Text Generation with Reinforced Unlearning,"['Language Generation', 'Language Models']","[6, 8, 7, 9]","[3, 4, 3, 4]",0,"[455, 151, 177, 434]",Accept
monPF76G5Uv,Global Normalization for Streaming Speech Recognition in a Modular Framework,[],"[7, 6, 6, 7]","[5, 4, 5, 3]",0,"[478, 887, 550, 127]",Accept
dZEZu7zxJBF,Learning sparse features can lead to overfitting in neural networks,"['feature learning', 'kernel methods', 'neural networks', 'overfitting']","[6, 7, 7, 6]","[2, 4, 4, 3]",0,"[661, 971, 558, 375]",Accept
dix1iktX7Qt,Multi-fidelity Monte Carlo: a pseudo-marginal approach,"['multi-fidelity modeling', 'Markov Chain Monte Carlo', 'multi-fidelity MCMC', 'pseudo-marginal MCMC']","[6, 5, 6, 7]","[3, 3, 4, 4]",0,"[406, 685, 545, 744]",Accept
RczPtvlaXPH,"Turbocharging Solution Concepts: Solving NEs, CEs and CCEs with Neural Equilibrium Solvers","['Game Theory', 'Nash Equilibrium', 'Correlated Equilibrium', 'Coarse Correlated Equilibrium']","[8, 6, 7]","[4, 4, 4]",0,"[468, 528, 931]",Accept
4B7azgAbzda,Learning dynamics of deep linear networks with multiple pathways,"['deep networks', 'linear networks', 'dynamical systems', 'theory', 'parallel pathways']","[6, 5, 8]","[3, 2, 3]",0,"[178, 192, 472]",Accept
G5ADoRKiTyJ,Fine-tuning language models to find agreement among humans with diverse preferences,"['large language models', 'LLMs', 'alignment', 'NLP', 'fine-tuning', 'reward modelling', 'preference modelling', 'human-centered AI']","[9, 6, 6, 3]","[5, 4, 4, 4]",0,"[258, 397, 1356, 643]",Accept
7nypt7cjNL,Parameters or Privacy: A Provable Tradeoff Between Overparameterization and Membership Inference,"['Membership inference', 'Privacy', 'Linear Regression', 'Overparameterization']","[7, 6, 5]","[4, 3, 3]",0,"[1114, 291, 509]",Accept
bAE1y8wG-ng,Few-Shot Fast-Adaptive Anomaly Detection,[],"[7, 8, 7]","[2, 4, 3]",0,"[231, 242, 393]",Accept
Vu-B0clPfq,Transformer Memory as a Differentiable Search Index,[],"[7, 7, 6, 6]","[5, 4, 4, 4]",0,"[555, 568, 589, 316]",Accept
ZBlaix34YX,LOT: Layer-wise Orthogonal Training on Improving l2 Certified Robustness,"['Adversarial Robustness', 'Lipschitz-bounded Models']","[6, 6, 6]","[3, 3, 4]",0,"[744, 317, 343]",Accept
wTp4KgVIJ5,SAGDA: Achieving $\mathcal{O}(\epsilon^{-2})$ Communication Complexity in Federated Min-Max Learning,"['federated learning', 'min-max', 'optimization', 'variance reduction']","[6, 6, 6]","[3, 3, 2]",0,"[730, 208, 449]",Accept
L3uTDctm3s9,Data Augmentation for Compositional Data: Advancing Predictive Models of the Microbiome,"['Data augmentation', 'compositional data', 'microbiome', 'supervised learning', 'contrastive learning']","[6, 7, 7]","[3, 4, 4]",0,"[484, 945, 415]",Accept
5TfqL2gWdV9,Invariance-Aware Randomized Smoothing Certificates,"['Robustness certification', 'Verification', 'Randomized smoothing', 'Invariances', 'Equivariances']","[6, 5, 5]","[3, 3, 4]",0,"[1089, 536, 197]",Accept
EZQnauHn-77,Deep Compression of Pre-trained Transformer Models,"['Quantization', 'Sparsity', 'Pruning', 'Pre-trained', 'Transformer', 'Foundation Model', 'Inference', 'NLP', 'vision', 'speech', 'BERT', 'Wav2vec', 'ViT']","[7, 8, 7]","[2, 2, 3]",0,"[234, 576, 252]",Accept
sn6BZR4WvUR,Chaotic Regularization and Heavy-Tailed Limits for Deterministic Gradient Descent,"['gradient descent', 'chaos', 'stochastic differential equations', 'heavy tails', 'homogenization']","[8, 4, 6, 6]","[2, 3, 2, 3]",0,"[250, 115, 619, 224]",Accept
hw-n6BUmiyI,Task Discovery: Finding the Tasks that Neural Networks Generalize on,"['Generalization', 'Understanding Neural Networks', 'Deep Learning']","[7, 6, 8, 7]","[4, 3, 4, 3]",0,"[798, 373, 471, 160]",Accept
UmvSlP-PyV,Beyond neural scaling laws: beating power law scaling via data pruning,"['data pruning', 'neural scaling', 'data subsetting', 'replicate theory']","[9, 8, 8, 7]","[4, 4, 2, 4]",0,"[463, 3132, 961, 1059]",Accept
HjNn9oD_v47,Unsupervised Learning for Combinatorial Optimization with Principled Objective Relaxation,"['learning for combinatorial optimization', 'model-based optimization', 'graph neural networks']","[7, 4, 7, 4]","[3, 2, 3, 4]",0,"[381, 678, 228, 586]",Accept
dXiGWqBoxaD,GPT3.int8(): 8-bit Matrix Multiplication for Transformers at Scale,"['quantization', '8-bit', 'transformers', 'inference']","[7, 5, 5, 6]","[4, 4, 4, 4]",0,"[805, 353, 338, 434]",Accept
d-kvI4YdNu,The Mechanism of Prediction Head in Non-contrastive Self-supervised Learning,"['Deep Learning Theory', 'Self-supervised Learning', 'Non-convex Optimization']","[6, 6, 4, 7]","[4, 2, 2, 4]",0,"[644, 249, 767, 1218]",Accept
bdfJCeWDKUB,Learning low-dimensional generalizable natural features from retina using a U-net,"['retina', 'efficient coding', 'convolutional neural network', 'synergy', 'natural scene']","[7, 7, 7, 2]","[3, 4, 3, 4]",0,"[236, 404, 644, 421]",Accept
IbBHnPyjkco,(De-)Randomized Smoothing for Decision Stump Ensembles,"['adversarial robustness', 'certified robustness', 'randomized smoothing', 'tree-based models']","[6, 7, 5]","[2, 3, 5]",0,"[300, 574, 325]",Accept
7SEi-ISNni7,Diffusion Visual Counterfactual Explanations,[],"[7, 7, 6, 5]","[3, 3, 4, 3]",0,"[337, 236, 209, 966]",Accept
L8pZq2eRWvX,ProtoVAE: A Trustworthy Self-Explainable Prototypical Variational Model,"['Interpretability', 'Explainable AI', 'Self-explaining Models', 'Deep Neural Networks']","[6, 6, 6]","[3, 4, 4]",0,"[271, 773, 736]",Accept
fDWNnSiHeka,Sketching based Representations for Robust Image Classification with Provable Guarantees,[],"[5, 6, 5]","[2, 3, 1]",0,"[317, 135, 133]",Accept
Vhd-jh9B8Hc,Active Ranking without Strong Stochastic Transitivity,"['ranking', 'noisy comparison', 'WST', 'SST', 'sample complexity']","[7, 7, 6]","[3, 4, 3]",0,"[308, 170, 837]",Accept
Tfb73TeKnJ-,Cross-Linked Unified Embedding for cross-modality representation learning,"['Multimodal Learning', 'Representation Learning', 'Semi-supervised Learning', 'Deep Autoencoders', 'Computational Biology and Bioinformatics', 'Single-cell Genomics']","[8, 5, 7]","[4, 1, 5]",0,"[129, 116, 170]",Accept
6QvmtRjWNRy,Subgroup Robustness Grows On Trees: An Empirical Baseline Investigation,"['robustness', 'fairness', 'tabular data', 'gradient boosting']","[5, 5, 6]","[4, 3, 4]",0,"[799, 341, 260]",Accept
ZXoSAAlBnW8,Recursive Reinforcement Learning,"['Recursive Markov Decision Processes', 'Reinforcement Learning', 'Probabilistic Pushdown Automata', 'Probabilistic Context-Free Grammars', 'Recursive State Machines', 'Branching Processes']","[7, 4, 6, 3]","[3, 4, 1, 3]",0,"[1263, 710, 496, 486]",Accept
uPdS_7pdA9p,Contrastive Adapters for Foundation Model Group Robustness,"['foundation models', 'robustness', 'hidden stratification', 'subpopulation shift']","[6, 7, 7]","[4, 5, 4]",0,"[736, 449, 490]",Accept
QLPzCpu756J,Lottery Tickets on a Data Diet: Finding Initializations with Sparse Trainable Networks,"['data pruning', 'linear mode connectivity', 'iterative magnitude pruning', 'loss landscape geometry', 'lottery ticket hypothesis', 'sparsity']","[6, 9, 7, 6]","[4, 4, 4, 3]",0,"[340, 308, 294, 343]",Accept
iBBcRUlOAPR,An empirical analysis of compute-optimal large language model training,"['NLP', 'Deep Learning', 'Large Language Models']","[7, 8, 8, 8]","[4, 4, 3, 5]",0,"[611, 133, 240, 281]",Accept
H88qfUs3U2W,Dynamic Pricing with Monotonicity Constraint under Unknown Parametric Demand Model,"['dynamic pricing', 'monotonicity constraint', 'multi-armed bandits', 'online learning', 'markdown pricing']","[6, 5, 5, 7, 5]","[3, 4, 4, 3, 3]",0,"[478, 357, 521, 1134, 251]",Accept
TThSwRTt4IB,On the Effectiveness of Lipschitz-Driven Rehearsal in Continual Learning,"['continual learning', 'lifelong learning', 'incremental learning', 'rehearsal', 'lipschitz continuity']","[6, 6, 6, 5]","[3, 4, 4, 5]",0,"[141, 592, 822, 468]",Accept
yoBaCtx_a3,An Algorithm for Learning Switched Linear Dynamics from Data,"['Control Systems', 'System Identification', 'Machine Learning', 'Hybrid Systems', 'Dynamical Systems', 'Ellipsoidal Algorithm', 'Separation Oracles']","[5, 8, 3, 7]","[4, 4, 4, 3]",0,"[309, 785, 1301, 506]",Accept
NENo__bExYu,Make Some Noise: Reliable and Efficient Single-Step Adversarial Training,"['single-step adversarial training', 'catastrophic overfitting', 'FGSM', 'efficient adversarial training', 'fast adversarial training']","[5, 5, 5, 7]","[5, 5, 4, 4]",0,"[169, 317, 339, 274]",Accept
7WvNQz9SWH2,Shape And Structure Preserving Differential Privacy,"['differential privacy', 'shape analysis', 'manifolds']","[5, 6, 6, 7]","[5, 3, 3, 3]",0,"[736, 347, 367, 132]",Accept
IRSyuxfYNb,Forward-Backward Latent State Inference for Hidden Continuous-Time semi-Markov Chains,"['forward-backward', 'continuous time', 'hsmm', 'ctsmc', 'semi-Markov', 'latent state inference']","[7, 6, 5, 7]","[4, 3, 3, 2]",0,"[286, 557, 476, 264]",Accept
rJjJda5q0E,Lifting the Information Ratio: An Information-Theoretic Analysis of Thompson Sampling for Contextual  Bandits,"['Thompson sampling', 'contextual bandits', 'information ratio']","[6, 6, 7]","[4, 3, 3]",0,"[682, 453, 136]",Accept
-zBN5sBzdvr,How Sampling Impacts the Robustness of Stochastic Neural Networks,"['Stochastic neural network', 'robustness', 'adversarial attacks']","[6, 6, 3, 7]","[2, 3, 4, 4]",0,"[258, 263, 500, 243]",Accept
AK6S9MZwM0,Robust Reinforcement Learning using Offline Data,"['Robust Reinforcement Learning', 'Offline Reinforcement Learning']","[6, 5, 6, 5]","[3, 3, 3, 3]",0,"[268, 209, 659, 429]",Accept
IU3nj1tqwyY,Characterizing the Ventral Visual Stream with Response-Optimized Neural Encoding Models,"['deep neural networks', 'computational neuroscience', 'ventral visual stream', 'fMRI']","[7, 7, 7]","[5, 5, 3]",0,"[549, 837, 690]",Accept
5OWV-sZvMl,NOMAD: Nonlinear Manifold Decoders for Operator Learning,"['Operator Learning', 'Manifold Learning', 'Functional Data', 'PDEs', 'Nonlinear Dimension Reduction']","[8, 7, 5, 6, 6]","[5, 2, 4, 4, 4]",0,"[468, 360, 494, 359, 294]",Accept
LzbrVf-l0Xq,Implications of Model Indeterminacy for Explanations of Automated Decisions,"['underspecification', 'Rashomon effect', 'explainability', 'robustness', 'epistemic uncertainty']","[8, 6, 7]","[3, 3, 4]",0,"[322, 452, 446]",Accept
j0J9upqN5va,Single Model Uncertainty Estimation via Stochastic Data Centering,"['uncertainty quantification', 'calibration', 'active learning', 'deep ensembles', 'sequential optimization']","[6, 7, 5, 6]","[3, 4, 3, 3]",0,"[783, 336, 404, 347]",Accept
YCniF6_3Jb,Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Priors,"['transfer learning', 'foundation models', 'priors', 'Bayesian neural networks']","[7, 5, 6]","[5, 2, 4]",0,"[503, 465, 255]",Accept
AODVskSug8,A Theoretical View on Sparsely Activated Networks,[],"[6, 6, 6, 5]","[3, 3, 3, 4]",0,"[431, 324, 431, 608]",Accept
57ZKV2YuwjL,Deep Counterfactual Estimation with Categorical Background Variables,"['counterfactuals', 'causal inference', 'causality', 'healthcare', 'time series']","[5, 4, 7, 6]","[3, 5, 4, 3]",0,"[333, 531, 545, 225]",Accept
mq-8p5pUnEX,Temporal Latent Bottleneck: Synthesis of Fast and Slow Processing Mechanisms in Sequence Learning,"['Transformers', 'Fast and Slow Mechanisms', 'Temporal Bottleneck']","[7, 6, 5, 5]","[3, 4, 5, 4]",0,"[672, 647, 2099, 540]",Accept
owDcdLGgEm,On the symmetries of the synchronization problem in Cryo-EM: Multi-Frequency Vector Diffusion Maps on the Projective Plane,"['cryo-EM', 'synchronization', 'representation-theory', 'equivariance', 'spectral']","[6, 5, 6]","[3, 2, 3]",0,"[259, 216, 474]",Accept
XmK56zbGeCp,Towards Trustworthy Automatic Diagnosis Systems by Emulating Doctors' Reasoning  with Deep Reinforcement Learning,"['Automatic Diagnosis', 'Deep Reinforcement Learning', 'Doctor reasoning', 'Differential Diagnosis']","[7, 6, 4, 6]","[4, 2, 4, 3]",0,"[334, 313, 400, 156]",Accept
yjWir-w3gki,Reinforcement Learning with Non-Exponential Discounting,"['discounting', 'reinforcement learning', 'optimal control', 'continuous time', 'human decision making', 'inverse reinforcement learning']","[5, 5, 7, 6]","[3, 2, 4, 4]",0,"[423, 724, 899, 751]",Accept
4LZo68TuF-4,Algorithms and Hardness for Learning Linear Thresholds from Label Proportions,"['learning from label proportions', 'linear thresholds', 'algorithm', 'hardness']","[4, 7, 7]","[4, 3, 3]",0,"[450, 278, 695]",Accept
w6tBOjPCrIO,MoCoDA: Model-based Counterfactual Data Augmentation,"['reinforcement learning', 'off-policy reinforcement learning', 'model-based reinforcement learning', 'offline reinforcement learning', 'data augmentation']","[7, 6, 7, 7]","[3, 4, 3, 4]",0,"[218, 196, 381, 1189]",Accept
rYkGxHPnCIf,Learning Optimal Flows for Non-Equilibrium Importance Sampling,"['non-equilibrium importance sampling', 'machine learning']","[6, 7, 7, 5]","[3, 4, 2, 2]",0,"[552, 535, 904, 626]",Accept
FlWdTyUznCc,Residual Multiplicative Filter Networks for Multiscale Reconstruction,"['Coordinate Networks', 'Implicit Neural Representations', 'Multiscale Representation Learning', 'Coarse-to-fine Reconstruction', 'Cryo-EM']","[7, 6, 5]","[4, 2, 4]",0,"[387, 937, 556]",Accept
XVfOai2ytN1,On global convergence of ResNets: From finite to infinite width using linear parameterization,"['Residual Neural Networks', 'Neural ODEs', 'Deep Learning']","[6, 1, 7]","[4, 3, 5]",0,"[380, 92, 318]",Accept
49TS-pwQWBa,Learning Robust Dynamics through Variational Sparse Gating,"['Deep Reinforcement Learning', 'Model Based Reinforcement Learning', 'World Models']","[6, 5, 5, 7]","[3, 4, 4, 3]",0,"[396, 391, 660, 291]",Accept
7yJMZwhIC2k,A Theoretical Framework for Inference Learning,"['Predictive Coding', 'Backpropagation', 'Synaptic Plasticity', 'Local Learning', 'Inference Learning']","[7, 6, 7]","[3, 4, 2]",0,"[339, 408, 218]",Accept
fRWwcgfXXZ,Deep Learning Methods for Proximal Inference via Maximum Moment Restriction,"['causal inference', 'proximal inference', 'unobserved confounding']","[8, 6, 6]","[4, 4, 5]",0,"[228, 684, 356]",Accept
uytgM9N0vlR,Does GNN Pretraining Help Molecular Representation?,"['Graph Pretraining', 'Molecular Representation', 'Self Supervised Learning']","[6, 7, 8, 3, 4]","[4, 4, 3, 5, 4]",0,"[368, 233, 547, 469, 418]",Accept
CMcptt6nFaQ,Structure-Aware Image Segmentation with Homotopy Warping,"['Structure-Aware', 'Image Segmentation', 'Homotopy']","[6, 6, 5, 7]","[3, 4, 4, 4]",0,"[298, 417, 544, 404]",Accept
kCtnkLv-_W0,Enhanced Meta Reinforcement Learning via Demonstrations in Sparse Reward Environments,"['Meta-Reinforcement Learning', 'Learning with Sparse Reward']","[5, 7, 7]","[3, 4, 4]",0,"[553, 380, 625]",Accept
U4BUMoVTrB2,DOPE: Doubly Optimistic and Pessimistic Exploration for Safe Reinforcement Learning,"['Constrained MDP', 'Safe Exploration', 'Constrained Reinforcement Learning']","[4, 7, 8]","[3, 2, 4]",0,"[459, 331, 295]",Accept
ITXgYOFi8b,Incentivizing Combinatorial Bandit Exploration,[],"[5, 6, 3, 7]","[2, 3, 2, 3]",0,"[286, 157, 106, 258]",Accept
LsWxgJZpRl,Near-optimal Distributional Reinforcement Learning towards Risk-sensitive Control,"['distributional reinforcement learning', 'risk-sensitive', 'sample complexity']","[5, 7, 6, 5]","[3, 3, 3, 3]",0,"[392, 325, 202, 398]",Reject
IQIY2LASzYx,A Simple Decentralized Cross-Entropy Method,"['planning', 'cross-entropy method', 'reinforcement learning']","[6, 6, 5, 6]","[3, 4, 4, 3]",0,"[164, 465, 153, 388]",Accept
e2gRdexoTZf,Structural Analysis of Branch-and-Cut and the Learnability of Gomory Mixed Integer Cuts,"['Gomory mixed integer cuts', 'automated algorithm configuration', 'integer programming', 'tree search', 'branch-and-bound', 'branch-and-cut', 'cutting planes', 'sample complexity', 'generalization guarantees', 'data-driven algorithm design']","[8, 8, 8, 8]","[3, 2, 4, 4]",0,"[247, 72, 472, 701]",Accept
AiNrnIrDfD9,Score-Based Generative Models Detect Manifolds,"['diffusion models', 'generative models', 'score-based generative models', 'stochastic differential equations', 'score matching', 'generalization', 'memorization']","[6, 6, 4, 7]","[2, 3, 3, 2]",0,"[345, 760, 499, 133]",Accept
FDmIo6o09H,Environment Diversification with Multi-head Neural Network for Invariant Learning,[],"[5, 6, 7, 7]","[4, 4, 5, 3]",0,"[430, 501, 681, 481]",Accept
wFwSFojKu6D,UnfoldML: Cost-Aware and Uncertainty-Based Dynamic 2D Prediction for Multi-Stage Classification,"['Cost-aware', 'Prediction pipeline', 'Multi-stage cascade', 'Uncertainty', 'ML for health', 'Systems for ML']","[4, 4, 5, 6]","[5, 5, 4, 2]",0,"[409, 348, 218, 170]",Accept
JJCnsgk4OIS,Learning Enhanced Representation for Tabular Data via Neighborhood Propagation,"['Tabular Prediction', 'Hypergraph']","[5, 7, 7]","[4, 4, 4]",0,"[288, 686, 981]",Accept
7vDt4_ulNyB,FiLM-Ensemble: Probabilistic Deep Learning via Feature-wise Linear Modulation,"['efficient ensembles', 'subnetwork', 'feature-wise linear modulation', 'uncertainty', 'robustness']","[3, 6, 6, 6]","[3, 4, 4, 5]",0,"[345, 483, 629, 446]",Accept
Ry9iNlpUy1-,Maximizing Revenue under Market Shrinkage and Market Uncertainty,"['Shrinking markets', 'automated mechanism design', 'market uncertainty', 'combinatorial auctions', 'revenue maximization', 'gross substitutes']","[7, 6, 6, 6]","[3, 3, 1, 3]",0,"[710, 361, 236, 129]",Accept
H3Gv7XEGzYV,FP8 Quantization: The Power of the Exponent,"['Neural network quantization', '8-bit floating point', 'post-training quantization', 'quantization-aware training']","[4, 5, 8, 4]","[4, 3, 4, 4]",0,"[382, 216, 300, 920]",Accept
WG3vmsteqR_,The Neural Covariance SDE: Shaped Infinite Depth-and-Width Networks at Initialization,"['Infinite-depth-and-width', 'SDE', 'activation shaping', 'initialization', 'NNGP', 'kernel shaping']","[7, 8, 6, 8]","[3, 4, 3, 2]",0,"[785, 678, 230, 425]",Accept
QSNoFvdIL41,Toward Understanding Privileged Features Distillation in Learning-to-Rank,"['Privileged Feature', 'Learning-to-rank', 'Distillation']","[5, 5, 7, 6]","[4, 3, 4, 3]",0,"[356, 353, 544, 356]",Accept
7YwwfU3DqKI,Outlier-Robust Sparse Estimation via Non-Convex Optimization,"['learning theory', 'high-dimensional robust statistics', 'non-convex optimization', 'sparse estimation']","[6, 6, 8]","[4, 4, 2]",0,"[413, 799, 125]",Accept
jF7u0APnGOv,Neural Abstractions,[],"[6, 7, 6]","[4, 3, 4]",0,"[592, 405, 275]",Accept
thgItcQrJ4y,Analyzing Sharpness along GD Trajectory: Progressive Sharpening and Edge of Stability,"['gradient descent trajectory', 'progressive sharpening', 'edge of stability', 'sharpness', 'deep learning theory']","[7, 3, 8]","[4, 4, 4]",0,"[205, 752, 915]",Accept
seYcx6CqPe,Template based Graph Neural Network with Optimal Transport Distances,"['Optimal Transport', 'Graph Neural Networks', 'Graph classification', 'Graph Representation Learning']","[8, 7, 6]","[3, 3, 4]",0,"[381, 483, 282]",Accept
xqYGGRt7kM,Single-pass Streaming Lower Bounds for Multi-armed Bandits Exploration with Instance-sensitive Sample Complexity,"['Pure Exploration Multi-armed Bandits', 'Streaming Lower Bounds', 'Sublinear algorithms for machine learning', 'Large-scale Learning']","[7, 8, 6, 6]","[3, 3, 3, 3]",0,"[1246, 329, 258, 503]",Accept
G4GpqX4bKAH,Embrace the Gap: VAEs Perform Independent Mechanism Analysis,"['variational autoencoder', 'ELBO', 'representation learning', 'independent mechanism analysis', 'variational inference']","[6, 6, 7]","[2, 4, 3]",0,"[197, 657, 746]",Accept
r0bjBULkyz,Active Bayesian Causal Inference,"['Bayesian methods', 'causal inference', 'causal discovery', 'causal reasoning', 'active learning', 'experimental design', 'probabilistic machine learning', 'Gaussian processes']","[7, 6, 9, 6]","[3, 4, 5, 4]",0,"[374, 808, 458, 471]",Accept
KJemAi9fymT,Learning Dense Object Descriptors from Multiple Views for Low-shot Category Generalization,"['low-shot', 'self-supervised', 'dense descriptor']","[5, 6, 5, 7]","[3, 4, 4, 2]",0,"[258, 453, 382, 894]",Accept
ZaDlbaahOqG,VisFIS: Visual Feature Importance Supervision with Right-for-the-Right-Reason Objectives,"['Visual question answering', 'feature importance supervision', 'right-for-the-right reason metrics', 'explanation faithfulness']","[5, 4, 8]","[5, 3, 5]",0,"[1045, 299, 234]",Accept
Jz-kcwIJqB,Data augmentation for efficient learning from parametric experts,"['behavior cloning', 'expert-driven learning']","[6, 6, 6, 5]","[4, 4, 5, 5]",0,"[675, 499, 227, 279]",Accept
GaLgQ5_CZwB,A theory of weight distribution-constrained learning,"['feedforward neural networks', 'weight distribution', 'optimal transport', 'connectomics']","[4, 4, 8, 7]","[2, 4, 3, 2]",0,"[613, 518, 416, 499]",Accept
VM7u8ecLrZV,Average Sensitivity of Euclidean k-Clustering,"['k-means', 'clustering', 'average sensitivity', 'consistent algorithms', 'dynamic algorithms']","[5, 5, 6]","[4, 3, 4]",0,"[351, 497, 448]",Accept
UavQ9HYye6n,Visual correspondence-based explanations improve AI robustness and human-AI team accuracy,"['visual correspondence', 'nearest neighbors', 'optimal transport', 'explainable AI', 'xai', 'human AI team']","[6, 6, 7, 3]","[3, 3, 3, 4]",0,"[266, 345, 81, 687]",Accept
OZKBReUF-wX,Meta-Reward-Net: Implicitly Differentiable Reward Learning for Preference-based Reinforcement Learning,"['preference-based reinforcement learning', 'human-in-the-loop reinforcement learning', 'deep reinforcement learning', 'bi-level optimization']","[7, 4, 7, 7]","[4, 4, 4, 4]",0,"[464, 403, 175, 1186]",Accept
-jnE7sxuMm,Flowification: Everything is a normalizing flow,['Normalizing flows'],"[7, 6, 5, 4]","[2, 3, 4, 3]",0,"[361, 238, 659, 513]",Accept
K_LtkDGdonK,Asynchronous Actor-Critic for Multi-Agent Reinforcement Learning,[],"[4, 7, 5]","[5, 4, 3]",0,"[224, 739, 241]",Accept
OYqCR-f-dg,SQ Lower Bounds for Learning Single Neurons with Massart Noise,"['learning theory', 'Statistical Query (SQ) model', 'Massart noise', 'single neuron', 'ReLU activation']","[7, 7, 5, 5]","[2, 3, 4, 4]",0,"[108, 238, 812, 728]",Accept
-5rFUTO2NWe,Object Representations as Fixed Points: Training Iterative Refinement Algorithms with Implicit Differentiation,"['objects', 'implicit differentiation', 'slot attention']","[5, 8, 7, 6]","[3, 4, 4, 3]",0,"[371, 238, 363, 386]",Accept
VeXBywV9FV,Operator Splitting Value Iteration,"['reinforcement learning', 'model-based reinforcement learning']","[7, 7, 8]","[3, 4, 4]",0,"[54, 422, 494]",Accept
K8JngctQ2Tu,Discovering and Overcoming Limitations of Noise-engineered Data-free Knowledge Distillation,"['Knowledge distillation', 'Gaussian noise', 'Batch normalization']","[5, 7, 4]","[5, 4, 4]",0,"[485, 302, 146]",Accept
tIZtD2kZ6zx,Drawing out of Distribution with Neuro-Symbolic Generative Models,"['Neuro-Symbolic Models', 'Generalisation', 'Unsupervised Learning', 'Omniglot']","[7, 2, 6, 6]","[3, 5, 4, 3]",0,"[647, 188, 637, 909]",Accept
0e0es11XAIM,Beyond Adult and COMPAS: Fair Multi-Class Prediction via Information Projection,"['group fairness', 'information projection', 'multi-class classification', 'new dataset']","[7, 8, 7, 8]","[3, 3, 3, 4]",0,"[363, 574, 487, 327]",Accept
lXuZaxEaI7,Batch size-invariance for policy optimization,"['reinforcement learning', 'policy gradient', 'learning rate']","[7, 6, 7, 4]","[4, 3, 4, 4]",0,"[451, 518, 397, 278]",Accept
y--ZUTfbNB,Faster Linear Algebra for Distance Matrices,"['distance matrices', 'numerical linear algebra', 'low-rank approximation', 'sublinear algorithms']","[8, 7, 8]","[4, 3, 4]",0,"[229, 280, 298]",Accept
OGGQs4xFHrr,CCCP is Frank-Wolfe in disguise,"['convex-concave procedure', 'cccp', 'frank-wolfe', 'conditional gradient method', 'difference of convex programming', 'expectation maximization', 'sinkhorn']","[8, 7, 3]","[4, 3, 4]",0,"[1311, 229, 526]",Accept
0Oy3PiA-aDp,Generalised Mutual Information for Discriminative Clustering,"['Unsupervised learning', 'Clustering', 'Deep learning', 'Information Theory']","[6, 4, 7]","[3, 4, 3]",0,"[154, 309, 341]",Accept
XUvSYc6TqDF,Controlled Sparsity via Constrained Optimization or: How I Learned to Stop Tuning Penalties and Love Constraints,"['sparsity', 'constrained optimization', 'deep learning', 'l0 regularization']","[7, 5, 8, 7]","[4, 4, 4, 3]",0,"[355, 233, 442, 1206]",Accept
v6NNlubbSQ,Nonparametric Uncertainty Quantification for Single Deterministic Neural Network,"['Uncertainty Quantification', 'Nonparametric Methods', 'Deep Learning', 'Machine Learning']","[6, 7, 6]","[3, 4, 5]",0,"[385, 271, 925]",Accept
2dgB38geVEU,RNNs of RNNs: Recursive Construction of Stable Assemblies of Recurrent Neural Networks,"['Neuroscience', 'Recurrent Neural Networks', 'Control Theory', 'Machine Learning', 'Dynamical Systems']","[8, 4, 5, 6]","[2, 4, 3, 4]",0,"[271, 480, 321, 1104]",Accept
1uSzacpyWLH,"Benchopt: Reproducible, efficient and collaborative optimization benchmarks","['reproducibility', 'optimization', 'lasso', 'resnet', 'logistic regression', 'open source software', 'benchmark']","[7, 7, 4]","[4, 4, 3]",0,"[779, 583, 327]",Accept
O1me2tPd_tr,Error Analysis of Tensor-Train Cross Approximation,[],"[6, 3, 5, 7]","[4, 3, 1, 3]",0,"[407, 279, 365, 260]",Accept
jwOg8J1yZ-a,Adversarially Robust Learning with Tolerance,"['Statistical Learning Theory', 'PAC Learning', 'Adversarial Learning', 'Compression', 'Perturb and Smooth']","[4, 4, 7, 7]","[3, 2, 4, 4]",0,"[370, 1013, 216, 338]",Reject
dwKwB2Cd-Km,Evaluation beyond Task Performance: Analyzing Concepts in AlphaZero in Hex,"['alphazero', 'deep reinforcement learning', 'explainability', 'interpretability', 'evaluation', 'concepts', 'hex', 'mcts']","[6, 3, 5, 6]","[4, 3, 3, 4]",0,"[814, 536, 549, 1133]",Accept
lHy09zPewmD,Non-monotonic Resource Utilization in the Bandits with Knapsacks Problem,"['multi-armed bandits', 'regret', 'knapsack constraints']","[6, 6, 7]","[2, 4, 3]",0,"[309, 440, 594]",Accept
i9XrHJoyLqJ,Improved Differential Privacy for SGD via Optimal Private Linear Operators on Adaptive Streams,"['federated learning', 'differential privacy', 'adaptive streams', 'machine learning', 'matrix mechanism', 'matrix factorization']","[6, 6, 7]","[3, 2, 3]",0,"[225, 123, 247]",Accept
bt25vx3aW_,Adversarial Robustness is at Odds with Lazy Training,[],"[5, 6, 5, 5]","[2, 3, 4, 3]",0,"[209, 442, 576, 348]",Accept
30bPCDjdxPU,Faster Reinforcement Learning with Value Target Lower Bounding,[],"[3, 5, 3, 3]","[3, 4, 4, 4]",0,"[936, 331, 384, 332]",Reject
4tGggvizjd8,On the generalization of learning algorithms that do not converge,"['deep learning theory', 'generalization', 'algorithmic stability', 'statistical learning theory']","[5, 4, 6, 8]","[2, 2, 4, 3]",0,"[340, 250, 310, 1092]",Accept
UFTcdcJrIl2,Task-Free Continual Learning via Online Discrepancy Distance Learning,"['Task-free continual learning', 'Variational autoencoder', 'Theoretical analysis for continual learning']","[7, 7, 6]","[3, 3, 3]",0,"[645, 852, 364]",Accept
_33ynl9VgCX,"On Convergence of FedProx: Local Dissimilarity Invariant Bounds, Non-smoothness and Beyond","['Federated learning', 'FedProx', 'Minibatch stochastic proximal point methods', 'Uniform stability', 'Non-convex optimization', 'Non-smooth optimization']","[6, 9, 6, 6]","[4, 4, 4, 3]",0,"[675, 141, 580, 364]",Accept
5btWTw1vcw1,Trajectory balance: Improved credit assignment in GFlowNets,"['GFlowNets', 'generative models', 'reinforcement learning', 'molecule design']","[8, 7, 7, 7]","[3, 2, 4, 1]",0,"[439, 60, 484, 454]",Accept
yCJVkELVT9d,Are Defenses for Graph Neural Networks Robust?,"['Adversarial Robustness', 'Graph Neural Networks', 'Adaptive Attacks']","[6, 7, 7]","[4, 4, 4]",0,"[308, 341, 376]",Accept
cV03Zw0V-3J,Information-Theoretic Safe Exploration with Gaussian Processes,"['Safe exploration', 'Gaussian process']","[6, 6, 6]","[3, 4, 3]",0,"[754, 887, 377]",Accept
OTKJttKN5c,Evaluating Robustness to Dataset Shift via Parametric Robustness Sets,"['Causality', 'Robustness', 'Distributional Robustness', 'Distribution Shift', 'Dataset Shift']","[7, 7, 6, 5]","[4, 3, 4, 2]",0,"[464, 298, 776, 275]",Accept
rG0jm74xtx,"Generative Time Series Forecasting with Diffusion, Denoise, and Disentanglement","['Time Series Forecasting', 'Generative Modeling', 'Diffusion Probabilistic Model']","[5, 5, 7]","[3, 4, 4]",0,"[379, 440, 200]",Accept
7ilJhkpm1H,MorphTE: Injecting Morphology in Tensorized Embeddings,"['word embeddings', 'compression', 'morpheme', 'tensor product']","[5, 8, 7]","[3, 3, 3]",0,"[138, 179, 218]",Accept
yhlMZ3iR7Pu,Diffusion Models as Plug-and-Play Priors,"['diffusion models', 'conditional generation', 'image segmentation']","[5, 6, 5, 5]","[3, 2, 3, 3]",0,"[462, 341, 218, 235]",Accept
KtDdr1zUE_1,Capturing Graphs with Hypo-Elliptic Diffusions,"['Graph Diffusion', 'Random Walks', 'Hypo-Elliptic Laplacian', 'Graph Tensor Networks', 'Graph Classification']","[5, 5, 6, 6]","[4, 2, 2, 4]",0,"[344, 468, 655, 718]",Accept
s6ygs1UCOw1,PAC Prediction Sets for Meta-Learning,"['uncertainty quantification', 'prediction sets', 'probably approximately correct', 'conformal prediction', 'meta learning', 'few-shot learning']","[6, 6, 6, 5, 6]","[4, 4, 5, 2, 3]",0,"[1030, 316, 701, 330, 176]",Accept
sPNtVVUq7wi,Supervised Training of Conditional Monge Maps,"['Optimal Transport', 'Single-Cell Dynamics', 'Convex Neural Networks']","[7, 7, 6, 6, 6]","[4, 3, 3, 2, 3]",0,"[868, 872, 506, 447, 753]",Accept
s71h4wo9bFI,Bridging Central and Local Differential Privacy in Data Acquisition Mechanisms,"['Mechanism design', 'algorithmic game theory', 'optimal data acquisition', 'differential privacy']","[4, 7, 7, 5]","[2, 2, 2, 3]",0,"[815, 238, 259, 284]",Accept
W7HvKO1erY,Exploration-Guided Reward Shaping for Reinforcement Learning under Sparse Rewards,"['reward shaping', 'intrinsic rewards', 'reinforcement learning', 'sparse-reward environments']","[4, 6, 6]","[3, 4, 2]",0,"[699, 744, 582]",Accept
Xo8_yHyw4S,Modular Flows: Differential Molecular Generation,"['normalizing flow', 'molecule generation', 'graph neural networks', 'neural ode']","[5, 5, 6, 6]","[4, 2, 3, 3]",0,"[229, 298, 284, 467]",Accept
9ZWgrozGP0,Provably Adversarially Robust Detection of Out-of-Distribution Data (Almost) for Free,"['adversarial robustness', 'out-of-distribution detection']","[6, 6, 5, 4]","[3, 3, 4, 5]",0,"[325, 414, 139, 571]",Accept
kY1RbKE7DWE,Anchor-Changing Regularized Natural Policy Gradient for Multi-Objective Reinforcement Learning,"['Multi-Objective Markov Decision Process', 'Constrained Markov Decision Process', 'Policy Optimization']","[7, 7, 7, 5]","[3, 3, 1, 2]",0,"[455, 369, 360, 202]",Accept
8gL4It6zjsh,Self-Explaining Deviations for Coordination,"['multi-agent', 'planning', 'zero-shot coordination']","[6, 6, 6, 8]","[4, 3, 3, 4]",0,"[581, 390, 360, 2398]",Accept
7uIGl1AB_M_,Overparameterization from Computational Constraints,"['Large models', 'Robustness', 'Adversarial examples', 'Computational hardness']","[6, 7, 5]","[1, 3, 1]",0,"[117, 257, 278]",Accept
LTCBavFWp5C,Quality Not Quantity: On the Interaction between Dataset Design and Robustness of CLIP,"['Distribution shift', 'machine learning dataset', 'image-text pretraining', 'robust machine learning']","[7, 6, 8]","[3, 3, 5]",0,"[298, 411, 793]",Accept
9-8YT5G36g-,Multi-Objective Deep Learning with Adaptive Reference Vectors,"['Mutli-Task Learning', 'Multi-Objective Optimization']","[5, 6, 7, 4, 5]","[1, 2, 3, 4, 2]",0,"[275, 198, 334, 291, 425]",Accept
DotEQCtY67g,Self-Supervised Learning Through Efference Copies,"['Self-supervised Learning', 'Theoretical Neuroscience', 'Sensory-Motor Learning', 'Representation Learning', 'Visual Features', 'Visual Perception', 'Deep Learning', 'Neural Networks', 'Embodied Intelligence', 'Inverse Models']","[5, 5, 5, 7]","[4, 3, 3, 4]",0,"[733, 584, 532, 703]",Accept
cYPja_wj9d,Mesoscopic modeling of hidden spiking neurons,"['recurrent spiking neural network', 'hidden spiking neurons', 'maximum likelihood', 'mean-field approximation', 'finite-size fluctuations', 'neural population dynamics', 'latent variable model', 'expectation-maximization algorithm', 'metastable dynamics']","[6, 7, 7, 8]","[5, 4, 4, 4]",0,"[546, 572, 508, 526]",Accept
FvdOlVWL-w,Learning Interface Conditions in Domain Decomposition Solvers,"['Domain Decomposition', 'Optimized Schwarz Methods', 'Graph Neural Networks', 'Unsupervised Learning']","[6, 6, 6]","[4, 3, 3]",0,"[257, 323, 138]",Accept
OZEmgSbRQW,Private and Communication-Efficient Algorithms for Entropy Estimation,"['Shannon entropy', 'collision entropy', 'Gini entropy', 'differentially private algorithms']","[5, 5, 7]","[2, 3, 3]",0,"[259, 496, 322]",Accept
nVV6S2sb_UL,Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in Federated Learning,[],"[4, 8, 7, 6]","[3, 3, 3, 4]",0,"[482, 487, 218, 820]",Reject
ccXKXStATD,Asymptotics of $\ell_2$ Regularized Network Embeddings,"['networks', 'embeddings', 'graphons', 'representation learning', 'network embeddings', 'regularization', 'asymptotics', 'exchangeable graphs']","[7, 5, 6, 7]","[3, 1, 2, 2]",0,"[416, 300, 401, 729]",Accept
gERv_uy69IA,K-LITE: Learning Transferable Visual Models with External Knowledge,"['external knowledge', 'task-level transfer', 'language-image pre-training']","[7, 6, 7, 7]","[4, 4, 3, 4]",0,"[246, 658, 299, 271]",Accept
qmy23tNBvbh,Kernel Multimodal Continuous Attention,"['attention', 'continuous attention', 'kernel methods']","[4, 8, 5, 7]","[2, 4, 2, 3]",0,"[544, 558, 292, 556]",Accept
Ikl-prGbDFU,Continual Learning In Environments With Polynomial Mixing Times,[],"[7, 5, 5, 7]","[3, 2, 2, 3]",0,"[285, 195, 423, 1583]",Accept
q5h7Ywx-sS,Stars: Tera-Scale Graph Building for Clustering and Learning,"['Graph Building', 'Clustering', 'Nearest Neighbor Search', 'Locality Sensitive Hashing']","[5, 6, 5, 7]","[2, 3, 3, 4]",0,"[129, 531, 807, 868]",Accept
yjybfsIUdNu,Multifidelity Reinforcement Learning with Control Variates,"['Reinforcement learning', 'multifidelity environments', 'multifidelity estimation']","[6, 7, 4]","[3, 4, 4]",0,"[1181, 910, 708]",Reject
5Cpune8BTWj,Evaluated CMI Bounds for Meta Learning: Tightness and Expressiveness,"['Meta learning', 'information theory', 'generalization bounds', 'PAC-Bayes']","[7, 6, 6]","[3, 4, 4]",0,"[290, 471, 329]",Accept
wu1Za9dY1GY,Graph Neural Networks are Dynamic Programmers,"['algorithmic reasoning', 'graph neural networks', 'category theory', 'polynomial functors', 'bellman-ford', 'integral transform', 'pullback', 'pushforward', 'monads', 'message passing', 'dynamic programming']","[6, 6, 5]","[3, 2, 2]",0,"[475, 215, 286]",Accept
Fd05J4Bu5Sp,On the Adversarial Robustness of Mixture of Experts,"['mixture of experts', 'moe', 'adversarial', 'robustness']","[5, 5, 6, 6]","[4, 3, 4, 4]",0,"[1293, 810, 1828, 380]",Accept
ejkwDKPowQl,Learning to Reconstruct Missing Data from Spatiotemporal Graphs with Sparse Observations,"['missing data', 'time series imputation', 'spatiotemporal graph neural networks']","[7, 6, 5, 6]","[3, 2, 4, 2]",0,"[362, 566, 438, 267]",Accept
GRd5UCkkXcV,A New Family of Generalization Bounds Using Samplewise Evaluated CMI,"['Generalization bounds', 'information theory', 'PAC-Bayes', 'multiclass classification', 'Natarajan dimension', 'deep learning']","[7, 7, 7, 5]","[4, 4, 3, 4]",0,"[718, 307, 197, 455]",Accept
KTOcrOR5mQ9,CS-Shapley: Class-wise Shapley Values for Data Valuation in Classification,"['data valuation', 'Shapley values', 'classification', 'value function']","[7, 6, 4, 5]","[4, 2, 3, 5]",0,"[394, 564, 969, 496]",Accept
00jwOr7UA4P,Anonymous Bandits for Multi-User Systems,"['anonymity', 'multi-armed bandits', 'online learning']","[6, 7, 7, 7]","[3, 3, 3, 2]",0,"[717, 490, 544, 574]",Accept
ccyZEIAiFwb,Are Two Heads the Same as One? Identifying Disparate Treatment in Fair Neural Networks,"['Machine Learning', 'Neural Networks', 'Algorithmic Fairness', 'Demographic Parity', 'Disparate Treatment']","[6, 3, 6]","[4, 4, 4]",0,"[127, 630, 584]",Accept
xqyEG7EhTZ,Tempo: Accelerating Transformer-Based Model Training through Memory Footprint Reduction,"['Implementation', 'Systems', 'Transformers']","[5, 5, 6, 6]","[3, 4, 4, 4]",0,"[357, 160, 269, 310]",Accept
crRhj1Y2wv,Towards a Unified Framework for Uncertainty-aware Nonlinear Variable Selection with Theoretical Guarantees,"['variable selection', 'posterior distribution', 'Bayesian nonparametric']","[6, 6, 6, 7]","[3, 3, 2, 4]",0,"[149, 241, 250, 901]",Accept
uOJZ_zU9qZm,Proppo: a Message Passing Framework for Customizable and Composable Learning Algorithms,"['machine learning frameworks', 'Monte Carlo gradient estimation', 'Automatic Differentiation']","[7, 3, 2]","[3, 4, 1]",0,"[453, 476, 70]",Accept
lSqaDG4dvdt,EZNAS: Evolving Zero-Cost Proxies For Neural Architecture Scoring,"['Zero Shot Neural Architecture Search', 'Neural Architecture Search', 'Program Synthesis', 'Evolutionary Search', 'Genetic Programming']","[5, 6, 6, 6]","[3, 3, 4, 4]",0,"[245, 195, 380, 173]",Accept
rO6UExXrFzz,Benefits of Additive Noise in Composing Classes with Bounded Capacity,"['Generalization Bound', 'Composition', 'Noise', 'Covering Number', 'Neural Networks']","[7, 7, 6]","[3, 3, 3]",0,"[343, 379, 277]",Accept
VHmdFPy4U_u,Trimmed Maximum Likelihood Estimation for Robust Generalized Linear Model,[],"[7, 7, 7]","[3, 4, 2]",0,"[247, 859, 718]",Accept
X0CKM7QV5k,On the Stability and Scalability of Node Perturbation Learning,"['Biologically Plausible Deep Networks', 'Credit Assignment', 'Neuroscience', 'Dynamical Systems']","[4, 6, 8, 6]","[4, 3, 4, 4]",0,"[1777, 504, 843, 979]",Accept
JavFPcsscd5,The Effects of Regularization and Data Augmentation are Class Dependent,"['data augmentation', 'class dependent bias', 'regularization', 'fairness', 'cross validation', 'risk minimization']","[7, 4, 4, 7]","[5, 4, 4, 4]",0,"[738, 603, 326, 360]",Accept
DRjUkfExCix,On the Effectiveness of Persistent Homology,"['persistent homology', 'Betti numbers', 'curvature', 'convexity', 'topology of data', 'geometry of data', 'point clouds']","[5, 3, 5, 6]","[4, 5, 4, 4]",0,"[508, 411, 179, 518]",Accept
VB_mBqL4VW-,Log-Linear-Time Gaussian Processes Using Binary Tree Kernels,"['Probabilistic methods', 'Gaussian processes', 'Scalable Gaussian processes']","[6, 7, 6, 6]","[4, 4, 3, 4]",0,"[396, 478, 295, 634]",Accept
Y11PmIjgyO,Hypothesis Testing for Differentially Private Linear Regression,"['differential privacy', 'linear regression', 'robust statistics', 'small-area analysis']","[6, 6, 7, 7]","[4, 3, 4, 3]",0,"[382, 443, 459, 773]",Accept
I47eFCKa1f3,BEER: Fast $O(1/T)$ Rate for Decentralized Nonconvex Optimization with Communication Compression,"['decentralized optimization', 'communication compression', 'nonconvex optimization']","[6, 6, 6]","[4, 4, 5]",0,"[228, 742, 385]",Accept
J7zY9j75GoG,"GlanceNets: Interpretable, Leak-proof Concept-based Models","['explainability', 'concept-based models', 'interpretability', 'disentanglement', 'concept leakage']","[6, 6, 6, 7, 5]","[4, 3, 4, 4, 4]",0,"[557, 1240, 888, 955, 460]",Accept
Vbj5H7-lKfs,Distributed Online Convex Optimization with Compressed Communication,"['distributed online optimization', 'compressed communication', 'no-regret algorithm']","[6, 5, 5, 3]","[4, 3, 1, 5]",0,"[466, 226, 50, 591]",Accept
cZN9_dF40i,Contextual Dynamic Pricing with Unknown Noise: Explore-then-UCB Strategy and Improved Regrets,[],"[6, 7, 4, 7]","[2, 3, 4, 5]",0,"[127, 260, 416, 638]",Accept
Y1sWzKW0k4L,Indicators of Attack Failure: Debugging and Improving Optimization of Adversarial Examples,"['Debugging', 'machine learning', 'adversarial machine learning']","[5, 6, 5, 6]","[3, 4, 3, 4]",0,"[383, 752, 480, 2743]",Accept
tz1PRT6lfLe,SoteriaFL: A Unified Framework for Private Federated Learning with Communication Compression,"['differential privacy', 'communication compression', 'nonconvex optimization', 'federated learning']","[8, 7, 4]","[4, 3, 2]",0,"[252, 609, 400]",Accept
Jk8RVjnHlsE,Variable-rate hierarchical CPC leads to acoustic unit discovery in speech,"['representation learning', 'self-supervised learning', 'acoustic unit discovery', 'speech', 'spoken language', 'contrastive predictive coding', 'hierarchical learning', '(application) signal and speech processing']","[5, 6, 6]","[4, 4, 4]",0,"[233, 495, 508]",Accept
LpgG0C6Y75,Hierarchical Agglomerative Graph Clustering in Poly-Logarithmic Depth ,"['hierarchical clustering', 'graph clustering', 'parallel algorithms', 'parallel graph algorithms', 'scalable algorithms']","[6, 7, 5]","[3, 3, 3]",0,"[198, 538, 230]",Accept
UxDO_gOhxhO,Scalable and Efficient Non-adaptive Deterministic Group Testing,"['Quantitative Group Testing', 'Queries', 'Learning Theory', 'Non-adaptive', 'Deterministic Algorithms']","[5, 6, 7, 3]","[3, 3, 3, 3]",0,"[247, 459, 529, 462]",Accept
AiY6XvomZV4,Learning to Configure Computer Networks with Neural Algorithmic Reasoning,"['neural algorithmic reasoning', 'computer networks', 'configuration synthesis', 'graph neural networks', 'systems']","[6, 6, 8, 4]","[3, 2, 3, 3]",0,"[358, 1991, 337, 1001]",Accept
0Fe7bAWmJr,Supervising the Multi-Fidelity Race of Hyperparameter Configurations,['hyperparameter optimization'],"[6, 8, 7, 7]","[4, 3, 4, 3]",0,"[508, 517, 47, 856]",Accept
a4zg0jiuVi,Anytime-Valid Inference For Multinomial Count Data,"['Anytime Valid', 'Sequential Testing', 'Experimentation', 'Bayesian Methods', 'Martingales', 'A/B Testing', 'Confidence Sequences', 'e-processes']","[4, 6, 8, 5]","[3, 3, 4, 3]",0,"[154, 560, 513, 348]",Accept
bA8CYH5uEn_,A Theoretical Study on Solving Continual Learning,"['Continual learning', 'lifelong learning']","[6, 5, 5, 5]","[3, 4, 4, 3]",0,"[394, 496, 365, 189]",Accept
LP0malvd4x,Understanding Deep Contrastive Learning via Coordinate-wise Optimization,"['contrastive learning', 'self-supervised learning', 'representation learning', 'principal component analysis', 'loss design', 'landscape analysis', 'deep linear network']","[7, 8, 6]","[4, 5, 3]",0,"[250, 219, 408]",Accept
g-OkeNXPy-X,Privacy Induces Robustness: Information-Computation Gaps and Sparse Mean Estimation,"['differential privacy', 'robustness', 'high-dimensional statistics', 'sparse mean estimation', 'sum-of-squares method', 'information-computation gaps', 'computational complexity of statistics', 'learning theory']","[7, 7, 6]","[3, 3, 2]",0,"[437, 245, 162]",Accept
c9I_NArDIjD,The trade-offs of model size in large recommendation models : 100GB to 10MB Criteo-tb DLRM model,"['embedding compression', 'DLRM', 'criteo TB']","[6, 5, 6]","[3, 3, 3]",0,"[265, 365, 295]",Accept
eYfIM88MTUE,Simple Unsupervised Object-Centric Learning for Complex and Naturalistic Videos,"['unsupervised object-centric learning', 'complex and naturalistic scenes', 'image transformer']","[3, 5, 7, 8]","[5, 4, 4, 4]",0,"[829, 382, 314, 573]",Accept
AlpR6dzKjfy,Robustness to Label Noise Depends on the Shape of the Noise Distribution,"['label noise', 'classification', 'robustness']","[7, 7, 3, 7]","[3, 3, 3, 4]",0,"[514, 281, 298, 314]",Accept
7lf58jWnDIS,MACK: Multimodal Aligned Conceptual Knowledge for Unpaired Image-text Matching,"['image-text matching', 'multimodal knowledge']","[7, 5, 5, 6]","[5, 4, 4, 3]",0,"[401, 157, 516, 656]",Accept
n7XbkHOwKn6,CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers,['pretraining'],"[6, 6, 3, 6]","[4, 4, 4, 4]",0,"[837, 380, 313, 193]",Reject
EXMjvwoqJBA,Intra-agent speech permits zero-shot task acquisition,[],"[5, 8, 5, 4]","[4, 4, 2, 3]",0,"[438, 261, 314, 782]",Accept
q41xK9Bunq1,Neural Attentive Circuits,"['Deep Learning', 'Low-Shot Adaptation', 'Attention Mechanisms', 'General Purpose Neural Architectures']","[6, 7, 6]","[4, 4, 3]",0,"[930, 736, 318]",Accept
Rgz_prESe-b,Learning Physics Constrained Dynamics Using Autoencoders,"['Autoencoder with Latent Physics', 'Deep Learning and its Application']","[6, 7, 7, 3]","[4, 4, 2, 4]",0,"[373, 228, 215, 611]",Accept
wQVjGP5NbP9,Near-Optimal Correlation Clustering with Privacy,"['Clustering', 'Correlation Clustering', 'Differential Privacy', 'Approximation Algorithms']","[7, 7, 7, 6]","[3, 3, 3, 3]",0,"[388, 179, 178, 286]",Accept
BRZos-8TpCf,Stochastic Halpern Iteration with Variance Reduction for Stochastic Monotone Inclusions,"['stochastic', 'monotone inclusion', 'Halpern iteration', 'last iterate convergence', 'variance reduction', 'min-max optimization']","[6, 4, 7, 6]","[3, 3, 4, 3]",0,"[689, 332, 567, 623]",Accept
HFkxZ_V0sBQ,Augmenting Online Algorithms with $\varepsilon$-Accurate Predictions,[],"[5, 6, 6, 7]","[4, 4, 4, 3]",0,"[402, 354, 1079, 431]",Accept
_56PoS9IRM-,PALMER: Perception - Action Loop with Memory for Long-Horizon Planning,"['representation learning', 'memory', 'planning', 'reinforcement learning', 'statistical contingencies']","[6, 7, 6, 7]","[4, 4, 4, 3]",0,"[413, 445, 681, 549]",Accept
UdgtTVTdswg,DataMUX: Data Multiplexing for Neural Networks,"['Neural networks', 'Multiplexing', 'Efficient inference']","[7, 8, 7, 7]","[4, 5, 3, 4]",0,"[610, 353, 253, 741]",Accept
UnygcA2BVzW,Learning (Very) Simple Generative Models Is Hard,"['generative models', 'statistical query', 'distribution learning', 'computational hardness', 'computational-statistical tradeoffs']","[7, 8, 7, 6]","[3, 3, 3, 2]",0,"[564, 673, 530, 172]",Accept
BCBac5kkg5G,Recurrent Convolutional Neural Networks Learn Succinct Learning Algorithms,"['recurrent convolutional neural networks', 'Turing completeness', 'universality', 'learning algorithms']","[5, 5, 7, 5]","[1, 1, 4, 3]",0,"[256, 551, 273, 244]",Accept
57Ryl7lLD4h,Assaying Out-Of-Distribution Generalization in Transfer Learning,"['Out-of-distribution generalization', 'robustness', 'distribution shifts', 'large-scale empirical study']","[6, 7, 5, 7]","[3, 4, 4, 3]",0,"[248, 568, 398, 1024]",Accept
KzC7Pejhp3z,Learning-Augmented Algorithms for Online Linear and Semidefinite Programming,"['Learning-augmented Online Algorithms', 'Primal-dual', 'Covering Linear Programming', 'Covering Semidefinite Programming']","[6, 7, 6]","[2, 2, 4]",0,"[306, 361, 406]",Accept
jglXPY6gH-1,Trustworthy Monte Carlo,"['Algorithm', 'Approximation scheme', 'Estimation', 'Monte Carlo', 'Probabilistic inference', 'Sampling', 'Theory', 'Verifiable']","[5, 3, 7, 6]","[2, 3, 2, 3]",0,"[128, 340, 269, 314]",Accept
xbgtFOO9J5D,Fair Rank Aggregation,"['Fairness', 'Ranking', 'Rank Aggregation', 'Kendall-Tau Metric', 'Algorithms and Theory', 'Approximation Algorithms', 'Combinatorial Optimization']","[4, 5, 6, 6]","[4, 3, 3, 5]",0,"[243, 497, 294, 441]",Accept
7JqqnRrZfz6,Holomorphic Equilibrium Propagation Computes Exact Gradients Through Finite Size Oscillations,"['Equilibrium propagation', 'credit assignment', 'bio-plausible deep learning', 'implicit differentiation']","[8, 9, 8, 8]","[2, 4, 3, 4]",0,"[275, 786, 295, 876]",Accept
fdyxLGHE6bU,Active Learning with Safety Constraints,"['bandits', 'linear bandits', 'active classification', 'active learning']","[4, 3, 5]","[1, 3, 2]",0,"[363, 354, 381]",Accept
GNHyNOR8Sn,A Boosting Approach to Reinforcement Learning,"['boosting', 'reinforcement learning', 'non-convex Frank-Wolfe']","[8, 6]","[4, 3]",0,"[1074, 563]",Accept
TIXwBZB3Jl6,VaiPhy: a Variational Inference Based Algorithm for Phylogeny,"['Phylogenetic Inference', 'Variational Inference', 'Bayesian Inference', 'Combinatorial Sequential Monte Carlo']","[8, 7, 6, 8]","[4, 3, 4, 3]",0,"[951, 726, 814, 215]",Accept
NnuYZ1el24C,Curious Exploration via Structured World Models Yields Zero-Shot Object Manipulation,"['Intrinsic Motivation', 'Reinforcement Learning', 'Model-based Planning', 'Manipulation', 'Zero-shot Generalization']","[8, 7, 6]","[4, 4, 4]",0,"[376, 404, 448]",Accept
vjKIKdXijK,Convexity Certificates from Hessians,"['disciplined convex programming', 'matrix calculus', 'classical machine learning']","[5, 5, 8]","[4, 1, 5]",0,"[352, 138, 936]",Accept
lYHUY4H7fs,Envy-free Policy Teaching to Multiple Agents,"['policy teaching', 'reward design', 'fairness', 'envy-freeness', 'price of fairness']","[4, 7, 6, 7]","[4, 3, 3, 4]",0,"[556, 689, 405, 823]",Accept
tJBYkwVDv5,Finite Sample Analysis Of Dynamic Regression Parameter Learning,"['dynamic regression', 'online regression', 'variance estimation', 'kalman filter']","[7, 7, 6]","[3, 4, 4]",0,"[285, 788, 386]",Accept
wGF5mreJVN,Learning to Navigate Wikipedia by Taking Random Walks,"['web navigation', 'wikipedia', 'retrieval', 'fact verification', 'question answering']","[6, 5, 5]","[4, 4, 3]",0,"[203, 217, 345]",Accept
aqALH2UAwQH,Efficient and Stable Fully Dynamic Facility Location,"['Clustering', 'Facility Location', 'Dynamic Algorithms', 'Consistent', 'Recourse', 'Approximation']","[7, 7, 6, 7]","[3, 4, 5, 3]",0,"[170, 244, 702, 279]",Accept
-IHPcl1ZhF5,RISE: Robust Individualized Decision Learning with Sensitive Variables,"['causal inference', 'individualized treatment rules', 'sensitive variables', 'robustness']","[6, 6, 6, 5]","[3, 3, 4, 3]",0,"[624, 376, 584, 574]",Accept
k98U0cb0Ig,Adaptive Stochastic Variance Reduction for Non-convex Finite-Sum Minimization,"['nonconvex optimization', 'variance reduction', 'finite-sum minimization', 'adaptive methods']","[6, 6, 5]","[4, 3, 4]",0,"[2331, 200, 191]",Accept
i3ewAfTbCxJ,Invariance Learning in Deep Neural Networks with Differentiable Laplace Approximations,"['Bayesian deep learning', 'Laplace approximation', 'invariance learning', 'Bayesian model selection']","[6, 7, 7]","[2, 3, 2]",0,"[332, 593, 418]",Accept
1beC9_dmOQ0,Jump Self-attention: Capturing High-order Statistics in Transformers,"['Neural Network', 'Transformer', 'Self-attention']","[6, 6, 6, 7]","[4, 4, 4, 4]",0,"[281, 654, 391, 324]",Accept
Ryy7tVvBUk,Predictive Coding beyond Gaussian Distributions,[],"[7, 7, 4, 7]","[3, 3, 3, 5]",0,"[404, 327, 1560, 223]",Accept
sWNT5lT7l9G,Constrained GPI for Zero-Shot Transfer in Reinforcement Learning,"['Reinforcement learning', 'Zero-shot transfer']","[6, 7, 6]","[3, 3, 4]",0,"[296, 372, 303]",Accept
h3jZCLjhtmV,Multi-agent Dynamic Algorithm Configuration,"['Multi-agent reinforcement learning', 'Multi-objective optimization', 'Evolutionary algorithm', 'Automated machine learning', 'Dynamic algorithm configuration.']","[8, 6, 5, 8]","[5, 4, 4, 4]",0,"[1904, 612, 217, 819]",Accept
fJt2KFnRqZ,An Adaptive Kernel Approach to Federated Learning of Heterogeneous Causal Effects,"['causal inference', 'causal effects', 'federated learning', 'kernel method']","[6, 7, 6, 6]","[3, 4, 3, 3]",0,"[168, 399, 519, 257]",Accept
wXNPMS11aUb,DevFly: Bio-Inspired Development of Binary Connections for Locality Preserving Sparse Codes,"['bioinspired', 'neurodevelopment', 'mushroom body', 'locality-sensitive hash', 'sparse coding']","[6, 4, 7]","[4, 3, 5]",0,"[799, 188, 365]",Accept
SUzPos_pUC,Monte Carlo Tree Search based Variable Selection for High Dimensional Bayesian Optimization,"['Black-box Optimization', 'High-dimensional Optimization', 'Bayesian Optimization', 'Variable Selection', 'Monte Carlo Tree Search']","[7, 7, 6, 6, 8]","[3, 3, 2, 3, 4]",0,"[183, 611, 583, 604, 757]",Accept
SWbdhfz3lBy,Learning from Few Samples: Transformation-Invariant SVMs with Composition and Locality at Multiple Scales,"['Support-Vector Machines', 'Kernel Methods', 'Learning from Few Samples']","[6, 7, 7]","[4, 3, 2]",0,"[320, 314, 257]",Accept
dqgzfhHd2-,Recovering Private Text in Federated Learning of Language Models,"['Federated learning', 'Privacy', 'Natural Language Processing']","[6, 6, 5, 4]","[5, 3, 4, 5]",0,"[761, 534, 402, 760]",Accept
KSKyVYcgp1u,Improved Coresets for Euclidean $k$-Means,"['Clustering', 'coresets', 'k-means', 'Euclidean']","[6, 5, 6, 5]","[3, 3, 4, 3]",0,"[313, 176, 265, 572]",Accept
7yvu4qOKtn1,Computational Doob h-transforms for Online Filtering of Discretely Observed Diffusions,"['diffusion', 'filtering', 'monte-carlo', 'particle-filters', 'BSDE']","[6, 6, 6, 5]","[2, 4, 4, 4]",0,"[648, 816, 912, 145]",Reject
pp7onaiM4VB,SPD domain-specific batch normalization to crack interpretable unsupervised domain adaptation in EEG,"['neurophysiology', 'electroencephalography', 'brain-computer interface', 'unsupervised domain adaptation', 'geometric deep learning', 'interpretability']","[7, 8, 7, 7]","[3, 3, 5, 4]",0,"[487, 327, 880, 1253]",Accept
9PNsCQpg-Ak,Better SGD using Second-order Momentum,"['second-order optimization', 'non-convex', 'hessian', 'sgd', 'optimal convergence rate']","[6, 7, 6]","[4, 4, 4]",0,"[332, 507, 303]",Accept
uCXNOeL0TG,Fairness for Workers Who Pull the Arms: An Index Based Policy for Allocation of Restless Bandit Tasks,"['sequential planning', 'load balancing', 'Whittle indices', 'markov decision processes']","[6, 3, 7]","[4, 4, 3]",0,"[340, 642, 406]",Reject
ArZWGF0Ifl7,Archimedes Meets Privacy: On Privately Estimating Quantiles in High Dimensions Under Minimal Assumptions,"['differential privacy', 'convex floating body', 'high-dimensional probability', 'quantile estimation']","[6, 7, 7, 6]","[2, 3, 3, 3]",0,"[231, 196, 405, 382]",Accept
GNt5ntEGjD3,A Unified Hard-Constraint Framework for Solving Geometrically Complex PDEs,"['PDE', 'neural network', 'physics']","[8, 6, 6, 3]","[4, 4, 4, 4]",0,"[173, 181, 384, 638]",Accept
yZgxl3bgumu,PhysGNN: A Physics--Driven Graph Neural Network Based Model for Predicting Soft Tissue Deformation in Image--Guided Neurosurgery,"['PhysGNN', 'Physics-Driven', 'Graph Neural Network', 'Tissue Deformation', 'Image-Guided Systems', 'GraphSAGE', 'GraphConv', 'Jumping Knowledge', 'Physical Simulation', 'Mechanical Simulation', 'Finite Element Method', 'Finite Element Analysis']","[5, 6, 7]","[4, 4, 3]",0,"[358, 221, 219]",Accept
5xiLuNutzJG,Rethinking Knowledge Graph Evaluation Under the Open-World Assumption,"['Knowledge graph', 'theory']","[7, 4, 8, 7]","[3, 3, 4, 4]",0,"[308, 278, 418, 261]",Accept
fUeOyt-2EOp,Thor: Wielding Hammers to Integrate Language Models and Automated Theorem Provers,"['Theorem proving', 'language models', 'neuro-symbolic method', 'automated theorem provers', 'MiniF2F', 'PISA']","[8, 6, 8]","[4, 4, 3]",0,"[308, 253, 201]",Accept
klElp42K9U0,Data-Efficient Pipeline for Offline Reinforcement Learning with Limited Data,"['offline reinforcement learning', 'hyperparameter selection', 'policy deployment', 'small data regime', 'batch value function tournament (BVFT)']","[7, 8, 6, 7, 7]","[5, 4, 3, 2, 4]",0,"[350, 317, 551, 387, 302]",Accept
DVfZKXSFW5m,Diversity vs. Recognizability: Human-like generalization in one-shot generative models,"['neuroscience', 'cognitive science', 'human generalization', 'one-shot image generation', 'generalization', 'generative model', 'spatial attention', 'context integration', 'diversity vs recognizability']","[8, 6, 7]","[4, 4, 4]",0,"[374, 1329, 497]",Accept
dLL4KXzKUpS,Where2comm: Communication-Efficient Collaborative Perception via Spatial Confidence Maps,"['Collaborative perception', '3D object detection']","[6, 6, 6, 6]","[3, 4, 3, 4]",0,"[526, 700, 496, 676]",Accept
vRrFVHxFiXJ,Predicting Cellular Responses to Novel Drug Perturbations at a Single-Cell Resolution,"['single cell', 'perturbation', 'disentanglement', 'transfer learning', 'drug discovery', 'unsupervised', 'genomics']","[7, 5, 8]","[3, 4, 4]",0,"[242, 323, 1447]",Accept
ttQ_3CiZqd3,The least-control principle for local learning at equilibrium,"['Biologically-plausible learning', 'local learning rules', 'predictive coding', 'neuroscience', 'equilibrium recurrent neural networks', 'meta learning', 'deep equilibrium models', 'implicit models', 'optimal control']","[6, 8, 8, 8]","[2, 5, 5, 5]",0,"[528, 651, 652, 2055]",Accept
MVDzIreiRqW,Evolution of Neural Tangent Kernels under Benign and Adversarial Training,[],"[6, 5, 8, 6]","[2, 4, 5, 4]",0,"[211, 178, 862, 256]",Accept
DwHIcEyias,Generalizing Consistent Multi-Class Classification with Rejection to be Compatible with Arbitrary Losses,"['classification with rejection', 'arbitrary losses', 'multi-class classification']","[7, 7, 7, 6]","[4, 3, 2, 4]",0,"[448, 208, 407, 873]",Accept
tglniD_fn9,Addressing Leakage in Concept Bottleneck Models,"['interpretable models', 'concept bottleneck model', 'leakage']","[6, 6, 7]","[4, 4, 4]",0,"[556, 382, 230]",Accept
jQgsZDspz5h,Contrastive and Non-Contrastive Self-Supervised Learning Recover Global and Local Spectral Embedding Methods,"['self-supervised learning', 'interpretability', 'understanding', 'local spectral methods', 'global spectral methods']","[5, 6, 6, 6]","[3, 3, 3, 4]",0,"[395, 412, 1005, 171]",Accept
6UtOXn1LwNE,Models of human preference for learning reward functions,"['reinforcement learning', 'learning reward functions', 'reward design', 'alignment', 'learning from preferences', 'regret', 'advantage', 'successor features']","[7, 4, 3, 4]","[4, 2, 3, 4]",0,"[396, 280, 677, 456]",Reject
zGPeowwxWb,Deep Equilibrium Approaches to Diffusion Models,"['diffusion models', 'deep equilibrium models', 'model inversion']","[6, 5, 7]","[2, 4, 4]",0,"[327, 647, 616]",Accept
lKFOwaYNQlb,Distributed Influence-Augmented Local Simulators for Parallel MARL in Large Networked Systems,"['Simulation', 'Multi-Agent Reinforcement Learning', 'Influence', 'State Abstraction.']","[5, 8, 7]","[3, 4, 3]",0,"[287, 496, 987]",Accept
NqbktPUkZf7,Neural Temporal Walks: Motif-Aware Representation Learning on Continuous-Time Dynamic Graphs,"['dynamic graph', 'representation learning', 'temporal walk', 'graph motif']","[5, 7, 7]","[4, 4, 4]",0,"[467, 343, 377]",Accept
tVHh_vD84EK,AutoST: Towards the Universal Modeling of Spatio-temporal Sequences,"['Neural Network', 'Spatio-temporal Forecasting', 'Architecture Search']","[6, 8, 5]","[3, 3, 4]",0,"[532, 123, 520]",Accept
BlF6CWzWKT7,Estimating individual treatment effects under unobserved confounding using binary instruments,"['Causal machine learning', 'treatment effect estimation', 'instrumental variables']","[7, 6, 6]","[3, 3, 3]",0,"[342, 775, 429]",Reject
wA7vZS-mSxv,Intrinsic dimensionality estimation using Normalizing Flows,"['Intrinsic Dimensionality', 'Normalizing Flows']","[8, 6, 6, 5]","[3, 3, 3, 3]",0,"[601, 611, 492, 316]",Accept
QvlcRh8hd8X,Neural Lyapunov Control of Unknown Nonlinear Systems with Stability Guarantees,"['neural networks', 'nonlinear dynamics', 'Lyapunov function', 'nonlinear control', 'stability guarantees']","[6, 6, 7]","[3, 3, 5]",0,"[482, 379, 719]",Accept
lfe1CdzuXBJ,Group Meritocratic Fairness in Linear Contextual Bandits,"['Bandits', 'Algorithmic Fairness', 'Relative Rank']","[7, 7, 5, 6]","[4, 4, 3, 4]",0,"[795, 330, 515, 656]",Accept
K8cD1Uv3wZy,Private Multiparty Perception for Navigation,"['Visual Navigation', 'Privacy', 'Multi-party Computation']","[7, 6, 4]","[3, 2, 2]",0,"[387, 545, 296]",Accept
AYkBQEm5AY,Scalable Multi-agent Covering Option Discovery based on Kronecker Graphs,"['Multi-agent Reinforcement Learning', 'Option Discovery', 'Kronecker Product']","[6, 7, 5, 7]","[2, 3, 4, 3]",0,"[273, 327, 623, 404]",Accept
NI6hB70ajO7,Beyond IID: data-driven decision-making in heterogeneous environments,"['data-driven algorithms', 'non-IID', 'sample average approximation', 'pricing', 'ski-rental', 'newsvendor']","[4, 7, 7, 7, 7]","[4, 3, 2, 3, 4]",0,"[305, 299, 452, 267, 1145]",Accept
wmwgLEPjL9,In Defense of the Unitary Scalarization for Deep Multi-Task Learning,"['Deep Multi-Task Learning', 'Optimization for Deep Learning', 'Deep Reinforcement Learning']","[6, 6, 5]","[3, 4, 4]",0,"[643, 501, 538]",Accept
eyE9Fb2AvOT,The Gyro-Structure of Some Matrix Manifolds,"['manifold learning', 'representation learning', 'deep learning', 'gyrovector spaces']","[7, 6, 7]","[3, 3, 2]",0,"[260, 395, 187]",Accept
1BJUwgi3ed,Controlling Confusion via Generalisation Bounds,"['PAC-Bayes', 'Generalisation bounds', 'Multiclass classification']","[5, 5, 7]","[4, 3, 2]",0,"[331, 249, 355]",Reject
0xdH-09oGD7,Effective Dimension in Bandit Problems under Censorship,"['Bandit Algorithms', 'Missing Data', 'Censored Processes', 'Statistical Learning Theory']","[4, 7, 6, 3]","[3, 4, 1, 2]",0,"[114, 380, 137, 253]",Accept
pHd0v8W30O,LAPO: Latent-Variable Advantage-Weighted Policy Optimization for Offline Reinforcement Learning,"['Offline reinforcement learning', 'imitation learning']","[6, 6, 6, 4]","[4, 4, 4, 4]",0,"[275, 381, 582, 884]",Accept
xOqqlH_E5k0,Augmented Deep Unrolling Networks for Snapshot Compressive Hyperspectral Imaging,"['Hyperspectral Imaging', 'Snapshot Compressive Imaging', 'Image Reconstruction', 'Deep Unrolling Networks']","[6, 4, 6, 4]","[4, 3, 3, 5]",0,"[288, 102, 759, 265]",Reject
0tpZgkAKVjB,Luckiness in Multiscale Online Learning,"['Online Learning', 'Multiscale Experts Problem', 'Second-order Regret Bounds', 'Stochastic Luckiness', 'FTRL']","[5, 6, 8, 7]","[3, 2, 3, 3]",0,"[270, 269, 387, 282]",Accept
wgRQ1IM4g_w,On Kernelized Multi-Armed Bandits with Constraints,"['kernelized bandits', 'Gaussian process bandits', 'regret bounds', 'constraint violation']","[6, 6, 6, 5]","[2, 3, 3, 4]",0,"[344, 180, 235, 700]",Accept
SiQAZV0yEny,Beyond Rewards: a Hierarchical Perspective on Offline Multiagent Behavioral Analysis,"['multiagent systems', 'interpretability', 'multiagent reinforcement learning', 'reinforcement learning', 'behavioral analysis']","[7, 6, 7, 7]","[5, 3, 4, 4]",0,"[334, 347, 478, 1175]",Accept
qmm__jMjMlL,Unsupervised Object Representation Learning using Translation and Rotation Group Equivariant VAE,"['deep learning', 'variational inference', 'representation learning', 'group equivariance']","[6, 4, 6]","[4, 3, 4]",0,"[688, 299, 501]",Accept
9zWlrwlT9-j,Unbiased Estimates for Multilabel Reductions of Extreme Classification with Missing Labels,[],"[5, 6, 5, 5]","[4, 3, 4, 3]",0,"[251, 306, 445, 334]",Reject
EqZuN4V_FLF,A Solver-free Framework for Scalable Learning in Neural ILP Architectures,"['constraint learning', 'neural ILP']","[7, 7, 7]","[2, 3, 5]",0,"[176, 198, 730]",Accept
ZE4lUw2iGcZ,Better Best of Both Worlds Bounds for Bandits with Switching Costs,"['Multi-Armed Bandits', 'Online Learning', 'Optimization', 'Decision Making']","[7, 6, 6, 7]","[5, 4, 4, 5]",0,"[705, 362, 439, 743]",Accept
wUUutywJY6,SoLar: Sinkhorn Label Refinery for Imbalanced Partial-Label Learning,"['Partial-label learning', 'Long-tailed learning', 'Optimal Transport']","[8, 8, 2]","[5, 5, 5]",0,"[306, 343, 310]",Accept
n7Rk_RDh90,3D Concept Grounding on Neural Fields,"['3D Visual Reasonng', 'Neural Fields', 'Concept Grounding', 'Neural Implicit representations']","[6, 8, 6, 6]","[4, 4, 4, 4]",0,"[679, 520, 213, 290]",Accept
Tz1lknIPVfp,Learning Dynamical Systems via Koopman Operator Regression in Reproducing Kernel Hilbert Spaces,"['Koopman operator', 'Markov transfer operator', 'DMD', 'supervised learning', 'dynamical systems', 'low rank approximation', 'spectral decomposition']","[3, 7, 8, 7]","[4, 2, 3, 3]",0,"[1081, 920, 881, 1011]",Accept
uLYc4L3C81A,Confident Adaptive Language Modeling,"['adaptive compute', 'early exit', 'language model', 'transformer', 'nlp']","[8, 7, 8, 7]","[4, 3, 4, 3]",0,"[147, 377, 481, 687]",Accept
G7MX_0J6JKX,Is Integer Arithmetic Enough for Deep Learning Training?,"['Integer Training', 'Accelerated Training', 'Integer-only SGD', 'Integer back-propagation']","[6, 6, 8, 5]","[3, 3, 4, 4]",0,"[382, 363, 649, 123]",Accept
tjFaqsSK2I3,A Unified Sequence Interface for Vision Tasks,"['generalist model', 'computer vision multi-task', 'sequence modeling']","[8, 5, 5, 5]","[4, 4, 3, 5]",0,"[483, 518, 247, 829]",Accept
-NOQJw5z_KY,Semantic Exploration from Language Abstractions and Pretrained Representations,[],"[6, 4, 8, 5]","[3, 3, 4, 3]",0,"[431, 219, 655, 553]",Accept
6wLXvkHstNR,Semantic uncertainty intervals for disentangled latent spaces,"['generative models', 'uncertainty estimation', 'distribution free statistics']","[6, 5, 4]","[4, 2, 1]",0,"[426, 614, 393]",Accept
X4WAq7JQHbA,Decomposable Non-Smooth Convex Optimization with Nearly-Linear Gradient Oracle Complexity,"['decomposable', 'non-smooth convex optimization', 'gradient oracle complexity', 'submodular function minimization']","[6, 7, 4, 7]","[4, 3, 3, 4]",0,"[340, 157, 348, 598]",Accept
PikKk2lF6P,Better Uncertainty Calibration via Proper Scores for Classification and Beyond,"['Calibration', 'Predictive Uncertainty', 'Classification', 'Regression']","[5, 8, 7]","[3, 3, 3]",0,"[355, 821, 285]",Accept
-_I3i2orAV,Look where you look! Saliency-guided Q-networks for generalization in visual Reinforcement Learning,"['Reinforcement learning', 'Generalization']","[7, 5, 5]","[3, 3, 5]",0,"[601, 673, 394]",Accept
h73nTbImOt9,Multi-Lingual Acquisition on Multimodal Pre-training for Cross-modal Retrieval,"['cross-lingual cross-modal retrieval', 'multilingual representation', 'multimodal representation']","[7, 5, 7, 6]","[4, 4, 4, 4]",0,"[1021, 387, 259, 693]",Accept
s_mEE4xOU-m,Learning Distributed and Fair Policies for Network Load Balancing as Markov Potential Game,"['MARL', 'load balancing', 'distributed systems']","[6, 6, 5, 6, 5]","[4, 5, 4, 3, 4]",0,"[189, 552, 336, 465, 487]",Accept
aoWo6iAxGx,Robust Imitation of a Few Demonstrations with a Backwards Model,"['imitation learning', 'model-based imitation learning', 'behavior cloning', 'covariate shift', 'robustness']","[5, 6, 6]","[4, 4, 5]",0,"[448, 561, 1293]",Accept
dqO59nI_R9A,Learning on Arbitrary Graph Topologies via Predictive Coding,['Cognitive Science'],"[5, 5, 7]","[3, 3, 2]",0,"[216, 281, 455]",Accept
lblv6NGI7un,Efficient Graph Similarity Computation with Alignment Regularization,"['graph neural networks', 'graph similarity learning', 'efficient model']","[6, 6, 5]","[4, 3, 4]",0,"[259, 336, 331]",Accept
v7SFDrS44Cf,Neural Estimation of Submodular Functions with Applications to Differentiable Subset Selection,"['neural set function', 'data selection']","[6, 6, 7]","[5, 4, 4]",0,"[727, 498, 460]",Accept
RF74aWLrvBp,Probabilistic Transformer: Modelling Ambiguities and Distributions for RNA Folding  and Molecule Design,"['Transformer', 'RNA folding', 'Molecular Design', 'Probabilistic Sequence Modelling', 'CVAE', 'Variational Inference', 'Hierarchical Distribution', 'ELBO', 'GECO']","[8, 7, 5]","[3, 3, 3]",0,"[747, 422, 290]",Accept
KSioDlJiUaz,Polynomial-Time Optimal Equilibria with a Mediator in Extensive-Form Games,[],"[4, 6, 5, 7]","[4, 4, 5, 3]",0,"[290, 819, 488, 393]",Accept
bVVIZjQ2AA,Discovered Policy Optimisation,[],"[6, 7, 5]","[4, 3, 4]",0,"[254, 369, 632]",Accept
zvNMzjOizmn,Langevin Autoencoders for Learning Deep Latent Variable Models,"['Langevin dynamics', 'deep latent variable models', 'amortized inference']","[5, 6, 7]","[3, 4, 4]",0,"[249, 466, 481]",Accept
kI_kL5vq6Oa,Risk-Driven Design of Perception Systems,"['Safety-critical autonomy', 'risk-sensitivity', 'perception', 'aircraft collision avoidance', 'object detection']","[6, 9, 6]","[4, 4, 4]",0,"[524, 275, 843]",Accept
edffTbw0Sws,Training Scale-Invariant Neural Networks on the Sphere Can Happen in Three Regimes,"['neural network training', 'scale invariance', 'batch normalization']","[8, 7, 5, 6]","[3, 3, 4, 3]",0,"[523, 143, 436, 759]",Accept
IZXIfq0CuTa,Highly Parallel Deep Ensemble Learning,"['parallel', 'deep ensemble learning', 'spectral tensor']","[6, 4, 4, 4]","[4, 4, 3, 2]",0,"[371, 160, 336, 426]",Reject
88ubVLwWvGD,You Never Stop Dancing: Non-freezing Dance Generation via Bank-constrained Manifold Projection,"['3D dance generation', 'music conditioned human motion prediction']","[8, 6, 7, 6]","[4, 4, 4, 4]",0,"[392, 464, 340, 695]",Accept
7XCFxnG8nGS,Regularized Molecular Conformation Fields,"['random fields', 'conformation generation', 'molecular fragmentation']","[7, 6, 7, 6]","[3, 4, 4, 4]",0,"[505, 330, 257, 538]",Accept
slKVqAflN5,A gradient sampling method with complexity guarantees for Lipschitz functions in high and low dimensions,"['nonconvex optimization', 'nonsmooth optimization', 'nonconvex nonsmooth optimization', 'Goldstein subdifferential', 'cutting plane method.']","[7, 7, 9, 7]","[3, 3, 3, 4]",0,"[410, 366, 437, 436]",Accept
Bwh6XmDEDe,Decoupled Self-supervised Learning for Graphs,[],"[5, 5, 7, 8]","[4, 5, 5, 4]",0,"[256, 492, 654, 755]",Accept
Y-sdZLIi9R9,Meta Reinforcement Learning with Finite Training Tasks - a Density Estimation Approach ,"['RL', 'Bayesian RL', 'Meta RL']","[6, 6, 6, 6]","[2, 3, 2, 5]",0,"[212, 390, 266, 740]",Accept
AyGJDpN2eR6,Exponentially Improving the Complexity of Simulating the Weisfeiler-Lehman Test with Graph Neural Networks,"['graph neural network', 'Weisfeiler-Lehman', 'graph isomorphism', 'expressivity']","[7, 6, 4]","[3, 4, 4]",0,"[368, 342, 968]",Accept
_jg6Sf6tuF7,Post-hoc estimators for learning to defer to an expert,"['learning to defer', 'adaptive inference']","[7, 6, 7]","[3, 4, 4]",0,"[363, 523, 302]",Accept
wFymjzZEEkH,"Personalized Federated Learning towards Communication Efficiency, Robustness and Fairness","['personalized federated learning', 'communication efficiency', 'robustness', 'fairness', 'low-dimensional projection', 'infimal convolution']","[4, 5, 6, 6, 5]","[3, 2, 4, 3, 3]",0,"[250, 284, 237, 200, 303]",Accept
GdHVClGh9N,Bayesian Optimistic Optimization: Optimistic Exploration for Model-based Reinforcement Learning,"['Model-based Reinforcement Learning', 'Exploration and Exploitation', 'Optimism in the Face of Uncertainty']","[5, 6, 6]","[2, 2, 3]",0,"[517, 289, 495]",Accept
ZLcwSgV-WKH,Pre-trained Adversarial Perturbations,"['Adversarial samples', 'pre-trained models', 'security']","[6, 5, 6, 5]","[3, 4, 2, 4]",0,"[197, 284, 172, 697]",Accept
NIJFp_n4MXt,A contrastive rule for meta-learning,"['meta-learning', 'meta-plasticity', 'synaptic consolidation', 'biologically-plausible learning', 'equilibrium propagation', 'complementary learning systems']","[8, 7, 6, 6]","[3, 3, 3, 3]",0,"[664, 185, 437, 1681]",Accept
h37KyWDDC6B,Finding Optimal Arms in Non-stochastic Combinatorial Bandits with Semi-bandit Feedback and Finite Budget,"['Combinatorial Bandits', 'Preference-based Bandits', 'Online Learning', 'Algorithm Selection']","[7, 6, 6]","[3, 2, 3]",0,"[630, 428, 205]",Accept
APXedc0hgdT,Rate-Distortion Theoretic Bounds on Generalization Error for Distributed Learning,"['Distributed learning', 'Generalization error', 'Rate-distortion', 'SVM']","[6, 6, 6]","[3, 3, 4]",0,"[706, 333, 472]",Accept
81LQV4k7a7X,ReFactor GNNs: Revisiting Factorisation-based Models from a Message-Passing Perspective,"['knowledge graph completion', 'link prediction', 'multi-relational graphs', 'graph neural networks', 'inductive reasoning']","[7, 6, 5]","[3, 3, 1]",0,"[652, 262, 457]",Accept
MloVsjTjlUY,Local Metric Learning for Off-Policy Evaluation in Contextual Bandits with Continuous Actions,"['Off-Policy Evaluation', 'Contextual Bandit', 'Continuous Actions', 'Importance Sampling', 'Local Kernel Metric Learning']","[7, 4, 7, 7, 6]","[3, 4, 3, 2, 4]",0,"[315, 306, 264, 238, 702]",Accept
edkno3SvKo,"Variance Reduced ProxSkip: Algorithm, Theory and Application to Federated Learning","['Federated Learning', 'Variance Reduction', 'Local SGD', 'ProxSkip', 'LSVRG', 'DIANA', 'Communication Compression', 'Local Training']","[7, 7, 6]","[4, 4, 5]",0,"[651, 426, 390]",Accept
D21DRzkZbSB,Learning Neural Acoustic Fields,"['Implicit representations', 'neural fields', 'deep learning']","[5, 8, 8, 8]","[4, 5, 4, 4]",0,"[295, 1152, 438, 178]",Accept
8cUGfg-zUnh,Partial Identification of Treatment Effects with Implicit Generative Models,"['partial identification', 'average treatment effect', 'generative adversarial networks']","[6, 6, 5, 8]","[4, 2, 4, 4]",0,"[696, 301, 474, 229]",Accept
JokpPqA294,ESCADA: Efficient Safety and Context Aware Dose Allocation for Precision Medicine,"['Multi-armed bandits', 'Bayesian optimization', 'Gaussian processes', 'Healthcare', 'Precision Medicine']","[4, 8, 7, 4]","[4, 3, 3, 3]",0,"[164, 238, 145, 404]",Accept
ekQ_xrVWwQp,A Data-Augmentation Is Worth A Thousand Samples: Analytical Moments And Sampling-Free Training,"['data augmentation', 'regularization', 'understanding', 'implicit regularization']","[4, 7, 7, 7]","[3, 3, 3, 3]",0,"[440, 616, 462, 584]",Accept
VOyYhoN_yg,Statistically Meaningful Approximation: a Case Study on Approximating Turing Machines with Transformers,"['approximation theory', 'generalization bounds', 'sample complexities', 'learning theory']","[6, 7, 7, 7]","[4, 3, 2, 4]",0,"[328, 544, 347, 340]",Accept
yRhbHp_Vh8e,Grounded Video Situation Recognition,"['Video Understanding', 'Visual Semantic Role Labelling', 'Spatio-temporal Grounding']","[7, 5, 6, 7]","[3, 3, 3, 3]",0,"[300, 321, 659, 437]",Accept
1tCuRbPts3J,Do Residual Neural Networks discretize Neural Ordinary Differential Equations?,"['Deep Learning theory', 'ResNets', 'Neural ODEs']","[5, 6, 7]","[4, 3, 3]",0,"[430, 350, 1154]",Accept
qk1qpCN-k6,"Information bottleneck theory of high-dimensional regression: relevancy, efficiency and optimality","['Information bottleneck', 'Information theory', 'Information efficiency', 'Optimal representation']","[5, 6, 5]","[3, 3, 4]",0,"[348, 963, 321]",Accept
mWaYC6CZf5,On the Representation Collapse of Sparse Mixture of Experts,[],"[3, 7, 7]","[5, 4, 4]",0,"[650, 462, 791]",Accept
qcRgqCXv1o2,Certifying Robust Graph Classification under Orthogonal Gromov-Wasserstein Threats,"['certification of robustness', 'Gromov-Wasserstein distance', 'convex relaxation']","[5, 7, 6]","[2, 3, 5]",0,"[311, 771, 509]",Accept
UHoGOaGjEq,Decentralized Training of Foundation Models in Heterogeneous Environments,"['Decentralized training', 'Foundation model.']","[7, 8, 8]","[4, 5, 4]",0,"[513, 293, 256]",Accept
MeYI0QcOIRg,Explicit Tradeoffs between Adversarial and Natural Distributional Robustness,"['robustness', 'adversarial', 'distributional', 'spurious correlations']","[5, 7, 6, 5]","[4, 4, 3, 4]",0,"[677, 303, 315, 655]",Accept
9DYKrsFSU2,Escaping Saddle Points for Effective Generalization on Class-Imbalanced Data,"['Long-Tailed Learning', 'Class-Imbalanced Learning', 'Saddle Points']","[6, 6, 6, 6]","[3, 3, 2, 3]",0,"[361, 124, 210, 217]",Accept
BCnZSP-Ryyp,Randomized Sketches for Clustering: Fast and Optimal Kernel $k$-Means,"['Kernel k-Means', 'Randomized Sketches', 'Statistical Analysis']","[5, 6, 9]","[3, 3, 5]",0,"[242, 346, 399]",Accept
nOdfIbo3A-F,Learning Articulated Rigid Body Dynamics with Lagrangian Graph Neural Network,"['Rigid body', 'dynamical systems', 'Lagrangian neural network', 'graph neural network']","[6, 8, 4, 5]","[4, 4, 3, 4]",0,"[463, 424, 505, 539]",Accept
FjqBs4XKe87,Prompt Injection: Parameterization of Fixed Inputs,"['Prompt', 'Injection', 'Parameterization', 'Language Model', 'Inference Efficiency', 'Distillation']","[7, 5, 7]","[3, 3, 4]",0,"[258, 384, 322]",Reject
jvFTMD5QTq,A composable machine-learning approach for steady-state simulations on high-resolution grids,"['machine learning', 'partial differential equations', 'computational science']","[6, 7, 6]","[3, 4, 4]",0,"[873, 439, 596]",Accept
d9usspxbWmk,Graph Learning Assisted Multi-Objective Integer Programming,"['Multi-objective integer programs', 'Graph learning', 'Objective-space decomposition', 'Attention']","[7, 5, 7]","[3, 2, 4]",0,"[414, 516, 764]",Accept
dbigt69sBqe,Disentangling the Predictive Variance of Deep Ensembles through the Neural Tangent Kernel,"['Deep Ensembles', 'Neural Tangent Kernel', 'Out-of-Distribution']","[7, 7, 7, 7, 7]","[2, 2, 2, 3, 3]",0,"[631, 922, 500, 653, 349]",Accept
nLGRGuzjtoR,Probing Classifiers are Unreliable for Concept Removal and Detection,"['Probing', 'Null-Space Removal', 'Adversarial Removal', 'Spurious Correlation', 'Fairness']","[8, 5, 8, 5]","[4, 3, 2, 4]",0,"[178, 477, 433, 756]",Accept
V5rlSPsHpkf,Learning to Scaffold: Optimizing Model Explanations for Teaching,"['explainable ai', 'interpretability', 'meta-learning', 'attention']","[8, 6, 8]","[4, 3, 2]",0,"[555, 547, 177]",Accept
xbhsFMxORxV,Public Wisdom Matters! Discourse-Aware Hyperbolic Fourier Co-Attention for Social Text Classification,"['Social Text Classification', 'Hyperbolic Geometry', 'Fourier Transform']","[6, 7, 8, 7]","[4, 3, 3, 3]",0,"[442, 403, 297, 562]",Accept
B3hDVlw95r,Positive-Unlabeled Learning using Random Forests via Recursive Greedy Risk Minimization,[],"[8, 5, 6, 6]","[4, 3, 3, 4]",0,"[1257, 413, 747, 474]",Accept
xpR25Tsem9C,Missing Data Imputation and Acquisition with Deep Hierarchical Models and Hamiltonian Monte Carlo,"['Variational Autoencoders', 'Hamiltonian Monte Carlo']","[6, 6, 6, 5, 7]","[4, 4, 3, 3, 4]",0,"[1453, 653, 218, 522, 520]",Accept
73h4EZYtSht,RnyiCL: Contrastive Representation Learning with Skew Rnyi Divergence,"['Contrastive learning', 'Self-supervised learning', 'Representation learning', 'Data augmentation']","[5, 7, 8, 6]","[2, 4, 5, 4]",0,"[281, 996, 532, 1032]",Accept
QDPonrGtl1,Fine-tuning Language Models over Slow Networks using Activation Quantization with Guarantees,"['Communication compression', 'Quantization', 'SGD']","[5, 5, 8, 6]","[2, 5, 4, 3]",0,"[364, 240, 318, 313]",Accept
bI1XXtO-hs2,Benefits of Permutation-Equivariance in Auction Mechanisms,"['Permutation-Equivariance', 'Auction Mechanisms']","[5, 7, 5, 6]","[2, 4, 2, 4]",0,"[388, 628, 455, 529]",Accept
5Ap96waLr8A,Efficient Methods for Non-stationary Online Learning,[],"[7, 6, 7, 8]","[4, 3, 3, 3]",0,"[447, 587, 209, 498]",Accept
Adl-fs-8OzL,Continuous MDP Homomorphisms and Homomorphic Policy Gradient,"['reinforcement learning', 'state abstraction', 'policy optimization', 'continuous control', 'representation learning in reinforcement learning']","[7, 7, 7]","[3, 3, 4]",0,"[628, 219, 1117]",Accept
zyrBT58h_J,Sustainable Online Reinforcement Learning for Auto-bidding,"['online reinforcement learning', 'offline RL', 'auto-bidding']","[7, 6, 7]","[3, 3, 4]",0,"[194, 236, 494]",Accept
M4OllVd70mJ,Learning to Branch with Tree MDPs,"['reinforcement learning', 'mixed integer programming', 'markov decision process']","[6, 6, 8]","[3, 3, 4]",0,"[336, 492, 765]",Accept
nrOLtfeiIdh,Learning Recourse on Instance Environment to Enhance Prediction Accuracy,"['Algorithmic Recourse', 'Intervention design']","[6, 5, 4, 7]","[3, 4, 3, 3]",0,"[793, 672, 545, 378]",Accept
p0LJa6_XHM_,Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch,"['Backdoor attacks', 'data poisoning', 'clean labels', 'adversarial examples', 'security']","[8, 5, 7, 5]","[5, 5, 5, 4]",0,"[390, 368, 567, 541]",Accept
oDoj_LKI3JZ,Sparse Gaussian Process Hyperparameters: Optimize or Integrate?,"['Gaussian processes', 'Sparse Gaussian processes', 'regression', 'Hamiltonian Monte Carlo', 'probabilistic inference']","[6, 6, 6, 7]","[3, 3, 3, 2]",0,"[652, 279, 594, 192]",Accept
CQaqJDWUGJ,MCL-GAN: Generative Adversarial Networks with Multiple Specialized Discriminators,[],"[4, 4, 5, 6]","[4, 4, 5, 3]",0,"[222, 310, 406, 259]",Accept
5oEk8fvJxny,Relaxing Equivariance Constraints with Non-stationary Continuous Filters,"['relaxed', 'equivariance', 'constraints', 'non-stationary', 'generalized', 'convolution', 'filters', 'kernel', 'soft equivariance', 'partial equivariance']","[7, 5, 4, 6]","[4, 4, 3, 3]",0,"[281, 640, 449, 347]",Accept
tfkeJG9yAX,"A general approximation lower bound in $L^p$ norm, with applications to feed-forward neural networks","['neural networks', 'approximation theory', 'lower bounds']","[6, 8, 4, 6]","[3, 3, 3, 3]",0,"[226, 527, 149, 295]",Accept
jm_opnaGmm5,Generalization Bounds for Gradient Methods via Discrete and Continuous Prior,"['theory', 'generalization', 'gradient descent', 'PAC-Baysian', 'Langevin Dynamics']","[5, 5, 5, 7]","[3, 3, 2, 4]",0,"[315, 315, 383, 488]",Accept
KHoV9zn1jLE,Implicitly regularized interaction between SGD and the loss landscape geometry,"['SGD', 'learning rate', 'batch size', 'optimization', 'generalization', 'implicit bias', 'implicit regularization', 'sharpness', 'scaling rule']","[3, 3, 7]","[4, 3, 5]",0,"[238, 477, 741]",Reject
DpKaP-PY8bK,Function Classes for Identifiable Nonlinear Independent Component Analysis,"['nonlinear ICA', 'independent component analysis', 'identifiability', 'blind source separation', 'unsupervised representation learning', 'conformal maps']","[6, 4, 4, 6]","[3, 3, 4, 3]",0,"[353, 361, 661, 118]",Accept
-cBZMMTImxT,Tree ensemble kernels for Bayesian optimization with known constraints over  mixed-feature spaces,"['Bayesian Optimization', 'Tree Ensembles', 'Global Optimization', 'Known Constraints', 'Black-box Optimization', 'Mixed-Variable Spaces', 'Hybrid Spaces']","[5, 6, 8]","[3, 3, 4]",0,"[442, 463, 1330]",Accept
dD3pwu4g8Fh,Anonymized Histograms in Intermediate Privacy Models,"['differential privacy', 'shuffle DP', 'pan privacy', 'anonymized histograms']","[6, 7, 7, 6]","[4, 2, 3, 2]",0,"[481, 229, 251, 336]",Accept
lbQTJN42uea,Subquadratic Kronecker Regression with Applications to Tensor Decomposition,"['Linear Regression', 'Kronecker Product', 'Leverage Score Sampling', 'Sketching', 'Iterative Methods', 'Tensor Decomposition']","[7, 7, 7, 7]","[3, 2, 3, 4]",0,"[287, 95, 198, 718]",Accept
jxezD-1XYr,CascadeXML: Rethinking Transformers for End-to-end Multi-resolution Training in Extreme Multi-label Classification,"['Large Output Spaces', 'Extreme Classification', 'Multi-label text classification', 'label-tree based negative mining']","[7, 7, 7, 5]","[5, 2, 4, 5]",0,"[376, 239, 298, 338]",Accept
IKcdgKKA_cs,Mathematically Modeling the Lexicon Entropy of Emergent Language,"['emergent language', 'emergent communication', 'stochastic process', 'modeling']","[6, 3, 3]","[4, 3, 4]",0,"[312, 629, 925]",Reject
aV9WSvM6N3,Unsupervised Learning From Incomplete Measurements for Inverse Problems,"['inverse problems', 'unsupervised learning', 'sensing theorems']","[8, 7, 3]","[4, 4, 5]",0,"[300, 421, 130]",Accept
x5ysKCMXR5s,Support Recovery in Sparse PCA with Incomplete Data,[],"[5, 5, 5, 7]","[4, 3, 2, 4]",0,"[648, 188, 209, 200]",Accept
aVnAsHaawE3,ULNeF: Untangled Layered Neural Fields for Mix-and-Match Virtual Try-On,"['Neural fields', 'deformable objects', 'contact handling', 'cloth', 'virtual try-on']","[5, 6, 7, 7]","[3, 4, 4, 4]",0,"[661, 431, 303, 347]",Accept
jOYdlD4oYrn,Private Isotonic Regression,"['isotonic regression', 'differential privacy', 'posets']","[7, 7, 7, 7]","[4, 4, 3, 4]",0,"[235, 482, 305, 176]",Accept
Jd2RfKd4Mjz,Real-Valued Backpropagation is Unsuitable for Complex-Valued Neural Networks,"['complex-valued neural network', 'complex backpropagation', 'neural tangent kernel']","[8, 5, 8]","[5, 3, 4]",0,"[356, 355, 116]",Accept
pNHT6oBaPr8,Learning Partial Equivariances From Data,"['partial equivariance', 'soft equivariance', 'group equivariance', 'group convolutional neural networks']","[5, 6, 6]","[4, 4, 3]",0,"[582, 778, 452]",Accept
ob8tk9Q_2tN,A Variant of Anderson Mixing with Minimal Memory Size,"['Anderson mixing', 'unconstrained optimization', 'stochastic optimization']","[7, 5, 7, 7]","[3, 3, 4, 5]",0,"[132, 110, 1165, 378]",Accept
TfMeY_L_l6t,A hybrid approach to seismic deblending: when physics meets self-supervision,"['Seismic deblending', 'self-supervised denoising', 'Plug-and-Play', 'inverse problems']","[6, 4, 4, 4]","[4, 2, 3, 4]",0,"[481, 207, 509, 192]",Reject
ftKnhsDquqr,Improved techniques for deterministic l2 robustness,"['provable defenses', 'adversarial examples', 'Lipschitz CNNs', 'formal guarantees']","[5, 7, 5, 5]","[3, 3, 3, 2]",0,"[385, 245, 530, 197]",Accept
7pNV4PCjbQy,Augmented RBMLE-UCB Approach for Adaptive Control of Linear Quadratic Systems,"['adaptive control', 'reinforcement learning', 'LQG systems']","[4, 4, 5, 8, 8]","[1, 3, 3, 4, 5]",0,"[304, 403, 341, 304, 118]",Accept
wmsw0bihpZF,Optimizing Data Collection for Machine Learning,"['data collection', 'sequential decision-making']","[4, 7, 5]","[4, 3, 4]",0,"[462, 481, 376]",Accept
7EP90NMAoK,On Sample Optimality in Personalized Collaborative and Federated Learning,"['Stochastic optimization', 'personalization', 'collaborative', 'federated']","[6, 6, 7, 6]","[2, 4, 3, 2]",0,"[130, 190, 871, 147]",Accept
d6mf9AFoR-O,Dual-discriminative Graph Neural Network for Imbalanced Graph-level Anomaly Detection,"['Graph-level Anomaly Detection', 'Graph Neural Networks']","[7, 5, 8, 6]","[4, 4, 5, 5]",0,"[545, 679, 517, 306]",Accept
HH3GHN_Q1Ba,Revisiting Populations in Multi-Agent Communication,"['Emergent Communication', 'Multi-agent Communication', 'Populations']","[4, 5, 6]","[4, 4, 3]",0,"[660, 759, 157]",Reject
4_oCZgBIVI,Sharper Convergence Guarantees for Asynchronous SGD for Distributed and Federated Learning,"['asynchronous SGD', 'delayed SGD', 'stochastic optimization', 'Federated Learning', 'distributed optimization']","[7, 7, 8]","[4, 4, 4]",0,"[281, 311, 318]",Accept
eMW9AkXaREI,Vision Transformers provably learn spatial structure,"['deep learning theory', 'vision transformers', 'implicit bias']","[4, 5, 5, 4]","[3, 4, 4, 3]",0,"[194, 1075, 870, 481]",Accept
5j6fWcPccO,Using Mixup as a Regularizer Can Surprisingly Improve Accuracy & Out-of-Distribution Robustness,"['mixup', 'reliability', 'distribution shift', 'robustness', 'out-of-distribution detection']","[6, 6, 6]","[3, 4, 4]",0,"[429, 371, 184]",Accept
0fKlU1OlANc,Unsupervised Adaptation  from Repeated Traversals for Autonomous Driving,[],"[5, 3, 5, 8]","[4, 4, 3, 3]",0,"[256, 747, 267, 706]",Accept
5haAJAcofjc,General Cutting Planes for Bound-Propagation-Based Neural Network Verification,"['neural network', 'formal verification', 'adversarial robustness']","[6, 7, 6]","[4, 4, 5]",0,"[199, 137, 456]",Accept
_D4cE66L9x3,Byzantine Spectral Ranking,"['ranking', 'learning to rank', 'pairwise comparisons', 'Byzantine']","[7, 5, 6, 7]","[3, 3, 4, 4]",0,"[246, 462, 567, 389]",Accept
zYc5FSxL6ar,Low-Rank Modular Reinforcement Learning via Muscle Synergy,"['Reinforcement Learning', 'Low-Rank', 'Muscle Synergy']","[7, 7, 6]","[3, 3, 4]",0,"[295, 305, 529]",Accept
q-LMlivZrV,CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP,"['Deep learning', 'Associative memory', 'Hopfield networks', 'Contrastive learning', 'Multimodal learning']","[5, 5, 4]","[4, 5, 4]",0,"[458, 174, 109]",Accept
5XtsqM57-Zb,Learning on the Edge: Online Learning with Stochastic Feedback Graphs,"['online learning', 'feedback graphs', 'bandits', 'random graphs']","[6, 6, 7, 7]","[3, 1, 4, 3]",0,"[353, 212, 383, 345]",Accept
l2CVt1ySC2Q,On Measuring Excess Capacity in Neural Networks,"['Deep learning theory', 'Rademacher complexity', 'Residual networks', 'Convolutions', 'Excess capacity']","[7, 6, 6]","[4, 3, 1]",0,"[1179, 839, 702]",Accept
q-snd9xOG3b,Log-Concave and Multivariate Canonical Noise Distributions for Differential Privacy,"['Gaussian differential privacy', 'tradeoff function', 'composition', 'group privacy']","[7, 6, 7]","[4, 3, 3]",0,"[519, 527, 224]",Accept
yhZLEvmyHYQ,Bayesian Active Learning with Fully Bayesian Gaussian Processes,[],"[6, 5, 7]","[2, 4, 4]",0,"[153, 731, 315]",Accept
ckQvYXizgd1,The computational and learning benefits of Daleian neural networks,"['neural coding', 'dales principle', 'spiking neural networks', 'recurrent neural networks', 'neural architecture', 'learning', 'information coding']","[6, 6, 8]","[4, 3, 5]",0,"[644, 243, 365]",Accept
dAZdQM32IoK,Robust Streaming PCA,"['Statistical Modeling', 'Machine Learning']","[7, 6, 6, 6]","[4, 2, 3, 3]",0,"[406, 331, 504, 335]",Accept
xT5rDp5VqKO,Coincidence Detection Is All You Need,"['coincidence detection', 'pattern recognition', 'neuromorphic signal processing', 'spiking neural network']","[2, 1, 2]","[5, 4, 4]",0,"[193, 314, 409]",Reject
AVh_HTC76u,A Reparametrization-Invariant Sharpness Measure Based on Information Geometry,"['Deep learning', 'Information geometry', 'Sharpness measure', 'Reparametrization invariance', 'Generalization', 'the Fisher information matrix']","[7, 6, 6, 7]","[4, 3, 4, 4]",0,"[232, 210, 681, 1034]",Accept
ocViyp73pFO,Disentangling Causal Effects from Sets of Interventions in the Presence of Unobserved Confounders,"['Causal Inference', 'Additive Noise Models', 'Joint Interventions']","[6, 6, 6, 5]","[4, 2, 3, 4]",0,"[244, 209, 505, 517]",Accept
zt4xNo0lF8W,Mask Matching Transformer for Few-Shot Segmentation,"['Few-Shot Segmentation', 'Transformer']","[5, 3, 4, 6]","[4, 5, 5, 4]",0,"[302, 495, 462, 752]",Accept
G8BExMno316,Adjoint-aided inference of Gaussian process driven differential equations,"['Uncertainty quantification', 'latent force', 'Gaussian process', 'differential equation', 'inverse problem']","[7, 5, 6, 4]","[3, 3, 3, 3]",0,"[415, 509, 605, 720]",Accept
q4IG88RJiMv,Estimating the Arc Length of the Optimal ROC Curve and Lower Bounding the Maximal AUC,"['ROC Curve', 'f-divergence', 'density ratio estimation', 'AUC maximization']","[6, 7, 6, 4]","[3, 4, 3, 4]",0,"[652, 261, 264, 290]",Accept
47lpv23LDPr,Unsupervised Learning of Group Invariant and Equivariant Representations,"['equivariance', 'invariance', 'representation learning', 'autoencoder', 'unsupervised learning']","[6, 7, 6, 6]","[4, 3, 4, 4]",0,"[150, 455, 794, 1390]",Accept
LffWuGtC9BE,Bounding and Approximating Intersectional Fairness through Marginal Fairness,"['Intersectional Fairness', 'Supervised Machine Learning']","[6, 5, 6]","[4, 4, 3]",0,"[525, 420, 341]",Accept
qHGCH75usg,BYOL-Explore: Exploration by Bootstrapped Prediction,"['Exploration', 'Deep Reinforcement Learning', 'Representation Learning', 'Self-Supervised Learning']","[6, 7, 7, 7]","[3, 3, 3, 4]",0,"[478, 571, 260, 1061]",Accept
-kS21GWVJU,Meta-sketch: A Neural Data Structure for Estimating Item Frequencies of Data Streams,"['Data streams', 'Sketches', 'Meta-learning', 'Memory-augmented neural network']","[4, 7, 7]","[5, 4, 3]",0,"[231, 397, 561]",Reject
cmKZD3wdJBT,Lipschitz Bandits with Batched Feedback,"['batched bandits', 'Lipschitz bandits']","[6, 6, 7, 6]","[4, 4, 4, 3]",0,"[270, 362, 231, 420]",Accept
z9CkpUorPI,NeuroSchedule: A Novel Effective GNN-based Scheduling Method for High-level Synthesis,"['High-level synthesis', 'Scheduling', 'Graph neural network', 'Rank loss']","[6, 5, 7, 6]","[5, 2, 4, 3]",0,"[386, 377, 282, 443]",Accept
Cd-b50MZ0Gc,Quantized Training of Gradient Boosting Decision Trees,"['Gradient Boosting', 'Quantized Training', 'Low-Precision Training', 'Decision Trees']","[7, 4, 7]","[4, 2, 3]",0,"[409, 113, 199]",Accept
-_AMpmyV0Ll,On the difficulty of learning chaotic dynamics with RNNs,"['Recurrent neural networks', 'Dynamical systems', 'Attractors', 'Time series analysis', 'Chaos', 'Exploding and vanishing gradient problem', 'Teacher forcing']","[7, 7, 9, 7]","[2, 3, 4, 4]",0,"[233, 520, 496, 973]",Accept
NzFtM5Pzvm,Embracing Consistency: A One-Stage Approach for Spatio-Temporal Video Grounding,"['Computer Vision', 'Video Understanding', 'Visual Grounding']","[6, 6, 6]","[4, 3, 4]",0,"[273, 439, 181]",Accept
Cr4_3ptitj,Meta-ticket: Finding optimal subnetworks for few-shot learning within randomly initialized neural networks,"['Meta-learning', 'Few-shot learning', 'Lottery ticket hypothesis']","[5, 5, 6, 5]","[5, 5, 4, 3]",0,"[317, 430, 332, 237]",Accept
ZPyKSBaKkiO,FR: Folded Rationalization with a Unified Encoder,"['Interpretability', 'NLP', 'cooperative game']","[6, 7, 5]","[3, 2, 4]",0,"[293, 127, 762]",Accept
aQySSrCbBul,Generalization Properties of NAS under Activation and Skip Connection Search,"['neural architecture search', 'convergence', 'generalization', 'neural tangent kernel']","[6, 6, 5, 6]","[4, 1, 4, 3]",0,"[287, 319, 685, 852]",Accept
Ku1afTnmozi,Improving Out-of-Distribution Generalization by Adversarial Training with Structured Priors,[],"[4, 7, 6, 5, 6]","[3, 5, 3, 3, 2]",0,"[254, 226, 377, 254, 191]",Accept
LODRFJr96v,Batch Bayesian Optimization on Permutations using the Acquisition Weighted Kernel,"['Bayesian Optimization', 'Batch Acquisition', 'Permutation', 'Bandit', 'Regret Analysis', 'Information Gain', 'Determinantal Point Processes']","[7, 6, 6, 5]","[3, 4, 3, 2]",0,"[604, 634, 265, 199]",Accept
6OLBVpoxrbW,Optimal Weak to Strong Learning,"['boosting', 'weak learning', 'sample complexity', 'lower bound']","[6, 8, 7]","[4, 3, 3]",0,"[281, 205, 319]",Accept
pZtdVOQuA3,Differentiable Rendering with Reparameterized Volume Sampling,"['neural radiance fields', 'differentiable rendering', 'importance sampling', 'reparameterization trick']","[3, 3, 4]","[4, 4, 3]",0,"[509, 628, 456]",Reject
eE-S1U5GG94,Principle Components Analysis based frameworks for efficient missing data imputation algorithms,[],"[2, 4, 4, 5]","[4, 4, 4, 3]",0,"[212, 206, 536, 98]",Reject
CflSnSkH--,Sequential Information Design: Learning to Persuade in the Dark,[],"[7, 6, 7, 7]","[2, 4, 3, 3]",0,"[188, 608, 711, 744]",Accept
6PpLxPPTPd,On Optimal Learning Under Targeted Data Poisoning,[],"[6, 6, 7, 7]","[3, 3, 3, 3]",0,"[460, 511, 425, 1030]",Accept
OkLee4SfLKh,Distilled Gradient Aggregation: Purify Features for Input Attribution in the Deep Neural Network,"['Explainable AI', 'Input Attribution']","[6, 7, 6, 3]","[4, 4, 4, 5]",0,"[562, 270, 1085, 1062]",Accept
3wg-rYuo5AN,Okapi: Generalising Better by Making Statistical Matches Match,"['Domain Generalisation', 'Semi-Supervised Learning', 'Statistical Matching']","[6, 6, 6, 3]","[3, 3, 4, 5]",0,"[602, 379, 448, 276]",Accept
FncDhRcRYiN,Accelerated Primal-Dual Gradient Method for Smooth and Convex-Concave Saddle-Point Problems with Bilinear Coupling,"['convex optimization', 'saddle-point problems', 'minimax optimization']","[7, 9, 6, 7]","[2, 4, 4, 3]",0,"[152, 236, 311, 415]",Accept
e62ZssObZp,Accelerating SGD for Highly Ill-Conditioned Huge-Scale Online Matrix Completion,"['huge scale optimization', 'stochastic gradient descent', 'SGD', 'scaled gradient descent', 'ScaledGD', 'preconditioned gradient descent', 'PrecGD']","[6, 7, 5]","[2, 4, 4]",0,"[422, 240, 581]",Accept
ZK6lzx0jqdZ,ShuffleMixer: An Efficient ConvNet for Image Super-Resolution,[],"[4, 5, 7, 3]","[4, 4, 5, 5]",0,"[401, 360, 460, 188]",Accept
rlN6fO3OrP,BadPrompt: Backdoor Attacks on Continuous Prompts,"['Continuous prompt', 'backdoor', 'few-shot learning']","[7, 5, 7, 5]","[3, 3, 4, 3]",0,"[371, 249, 300, 191]",Accept
B7Q2mbIFa6Q,A Characterization of Semi-Supervised Adversarially Robust PAC Learnability,"['Semi-Supervised Learning', 'Adversarial Robustness', 'PAC Learning', 'Sample Complexity', 'Combinatorial Dimensions', 'Partial Concept Classes']","[5, 7, 6, 8]","[3, 4, 4, 4]",0,"[453, 195, 461, 342]",Accept
YgmiL2Ur01P,The First Optimal Acceleration of High-Order Methods in Smooth Convex Optimization,"['convex optimization', 'tensor methods', 'high-order optimization', 'optimal algorithms']","[4, 7, 6, 7]","[3, 4, 2, 3]",0,"[436, 544, 112, 296]",Accept
L7AV_pDUVCK,A Multilabel Classification Framework for Approximate Nearest Neighbor Search,"['approximate nearest neighbor search', 'multilabel classification', 'statistical learning theory']","[4, 8, 3]","[5, 3, 3]",0,"[541, 439, 298]",Accept
XNjCGDr8N-W,Power and limitations of single-qubit native quantum neural networks,"['quantum machine learning', 'quantum neural networks', 'expressivity', 'function approximation', 'universal approximation', 'Fourier series']","[6, 7, 4, 5]","[3, 4, 3, 2]",0,"[245, 369, 149, 310]",Accept
nOw2HiKmvk1,Learning Debiased Classifier with Biased Committee,"['Debiasing', 'bootstrap ensemble', 'self-supervised learning', 'image classification', 'spurious correlation']","[6, 6, 6, 6]","[4, 4, 5, 4]",0,"[943, 846, 536, 396]",Accept
eow_ZGaw24j,Effectiveness of Vision Transformer for Fast and Accurate Single-Stage Pedestrian Detection,[],"[6, 6, 4, 4]","[4, 2, 3, 4]",0,"[445, 469, 175, 165]",Accept
_cXUMAnWJJj,Extrapolation and Spectral Bias of Neural Nets with Hadamard Product: a Polynomial Net Study,"['Neural tangent kernel', 'Hadamard product', 'extrapolation', 'spectral bias', 'kernel regression']","[7, 7, 5, 7]","[5, 3, 3, 4]",0,"[631, 394, 253, 285]",Accept
-3cHWtrbLYq,Local Identifiability of Deep ReLU Neural Networks: the Theory,"['Deep Learning', 'ReLU networks', 'Conditions of identifiability', 'Lifting operator']","[5, 5, 6]","[3, 4, 3]",0,"[795, 644, 391]",Accept
pD5Pl5hen_g,The First Optimal Algorithm for Smooth and Strongly-Convex-Strongly-Concave Minimax Optimization,"['convex optimization', 'minimax optimization', 'saddle point problems', 'optimal algorithms']","[7, 7, 7, 7]","[4, 3, 4, 2]",0,"[766, 205, 209, 114]",Accept
-8tU21J6BcB,On the Robustness of Graph Neural Diffusion to Topology Perturbations,[],"[6, 7, 6]","[3, 2, 4]",0,"[663, 439, 397]",Accept
BWa5IUE3L4,Graph Neural Network Bandits,"['Bandit optimization', 'Kernels', 'Graph Neural Networks', 'Regret bounds']","[7, 7, 5]","[3, 3, 4]",0,"[530, 373, 389]",Accept
cIpU8OzGSCU,SelecMix: Debiased Learning by Contradicting-pair Sampling,"['debias', 'spurious correlation', 'mixup']","[7, 4, 6]","[4, 1, 5]",0,"[430, 93, 314]",Accept
COAcbu3_k4U,Maximum Common Subgraph Guided Graph Retrieval: Late and Early Interaction Networks,"['Graph neural networks', 'graph retrieval']","[6, 6, 7]","[5, 4, 3]",0,"[243, 439, 247]",Accept
4iEoOIQ7nL,Proximal Point Imitation Learning,"['imitation learning theory', 'learning from demonstrations', 'proximal point method']","[5, 5, 8]","[2, 3, 4]",0,"[342, 358, 870]",Accept
pF8btdPVTL_,Benign Overfitting in Two-layer Convolutional Neural Networks,[],"[7, 5, 7, 7]","[3, 3, 4, 4]",0,"[299, 279, 608, 141]",Accept
4R5x8no2Ts-,Joint Entropy Search For Maximally-Informed Bayesian Optimization,"['Bayesian Optimization', 'Entropy Search', 'Hyperparameter Optimization', 'AutoML']","[6, 3, 6, 8]","[3, 3, 4, 3]",0,"[591, 2107, 610, 819]",Accept
QXiYW3TrgXj,On the Learning Mechanisms in Physical Reasoning,"['Intuitive physics', 'physical reasoning', 'dynamics prediction']","[7, 6, 6, 7]","[4, 4, 2, 4]",0,"[325, 473, 229, 185]",Accept
am86qcwErJm,Towards a Standardised Performance Evaluation Protocol for Cooperative MARL,"['multi-agent reinforcement learning', 'MARL', 'Evaluation', 'Cooperative MARL', 'Standardised evaluation protocol']","[5, 7, 8, 6]","[3, 3, 4, 3]",0,"[430, 391, 248, 523]",Accept
HaZuqj0Gvp2,Inverse Design for Fluid-Structure Interactions using Graph Network Simulators,"['design', 'graph neural networks']","[7, 6, 5, 7]","[3, 3, 4, 4]",0,"[428, 576, 647, 537]",Accept
1wz-ksUupt2,Optimal Query Complexities for Dynamic Trace Estimation,"['trace estimation', 'numerical linear algebra', 'query complexity lower bound']","[7, 7, 7]","[3, 4, 4]",0,"[485, 903, 641]",Accept
tvDRmAxGIjw,Towards Efficient Post-training Quantization of Pre-trained Language Models,"['post-training quantization', 'BERT', 'natural langauge processing', 'training efficiency']","[7, 5, 6, 7]","[3, 4, 3, 4]",0,"[274, 298, 481, 369]",Accept
8B66-1c5AW,On A Mallows-type Model For (Ranked) Choices,"['probabilistic ranking models', 'Mallows model', 'preference learning', 'choice modeling', 'top-$k$ list']","[6, 7, 7, 6]","[4, 4, 4, 4]",0,"[556, 325, 1105, 99]",Accept
-Lm0B9UYMy6,"Not too little, not too much: a theoretical analysis of graph (over)smoothing","['graph neural network', 'theory', 'oversmoothing', 'aggregation']","[8, 6, 8, 4]","[4, 3, 2, 4]",0,"[231, 158, 171, 1113]",Accept
nxl-IjnDCRo,On Analyzing Generative and Denoising Capabilities of Diffusion-based Deep Generative Models,"['Diffusion generative models', 'DDGM', 'denoising autoencoders']","[7, 6, 7, 3]","[4, 2, 3, 5]",0,"[419, 171, 346, 247]",Accept
icGMu0iPonB,A Robust Phased Elimination Algorithm for Corruption-Tolerant Gaussian Process Bandits,"['Bandit optimization', 'corruption-tolerant', 'Gaussian process', 'kernelized bandits']","[3, 6, 5, 6]","[4, 3, 3, 4]",0,"[415, 381, 390, 250]",Accept
ksVGCOlOEba,Optimal Brain Compression: A Framework for Accurate Post-Training Quantization and Pruning,"['compression', 'pruning', 'quantization', 'post-training', 'efficiency']","[6, 7, 6]","[3, 3, 4]",0,"[334, 347, 691]",Accept
F-L7BxiE_V,Movement Penalized Bayesian Optimization with Application to Wind Energy Systems,"['Bayesian Optimization', 'Metrical Task Systems']","[7, 5, 6, 6]","[2, 4, 3, 3]",0,"[569, 927, 343, 280]",Accept
XtxG6dBOpAQ,A Regret-Variance Trade-Off in Online Learning,"['Online learning', 'statistical learning', 'corrupted feedback', 'selective sampling', 'abstention']","[7, 4, 7]","[4, 3, 4]",0,"[442, 558, 466]",Accept
PpP9TiUZLoF,An $\alpha$-regret analysis of Adversarial Bilateral Trade,"['online learning', 'bilateral trade', 'pricing', 'partial feedback']","[8, 5, 6, 6, 7]","[4, 3, 3, 3, 3]",0,"[231, 423, 359, 731, 379]",Accept
RTan64GlCLV,Unified Optimal Transport Framework for Universal Domain Adaptation,"['Universal Domain Adaptation', 'Optimal Transport', 'Common Class Detection', 'Private Class Discovery', 'Representation Learning']","[7, 5, 5, 6]","[3, 5, 4, 3]",0,"[255, 185, 252, 643]",Accept
61UwgeIotn,Efficient Meta Reinforcement Learning for Preference-based Fast Adaptation,"['Preference-based Reinforcement Learning', 'Meta Reinforcement Learning']","[6, 7, 7, 6]","[4, 4, 4, 4]",0,"[466, 454, 1090, 305]",Accept
0zHXmOXwkIf,Paraphrasing Is All You Need for Novel Object Captioning,[],"[6, 7, 7, 7]","[4, 4, 3, 3]",0,"[352, 223, 743, 491]",Accept
FHgpw2Cn__,Consistency of Constrained Spectral Clustering under Graph Induced Fair Planted Partitions,"['Spectral clustering', 'fairness', 'constrained clustering', 'consistency']","[6, 6, 6, 7]","[3, 4, 4, 3]",0,"[454, 471, 556, 280]",Accept
EaRoPGzxRkO,Causal Discovery in Probabilistic Networks with an Identifiable Causal Effect,"['Causal Discovery', 'Causal Identification', 'ADMG', 'Causal Inference', 'Probabilistic Networks', 'NP-hard']","[6, 6, 5, 7]","[4, 4, 4, 4]",0,"[732, 156, 476, 1538]",Reject
UmaiVbwN1v,A Win-win Deal: Towards Sparse and Robust Pre-trained Language Models,"['BERT compression', 'sparse subnetwork', 'dataset bias', 'OOD generalization']","[4, 5, 5, 6]","[3, 4, 3, 3]",0,"[294, 314, 370, 941]",Accept
Wtg9TUL0d81,What Makes Graph Neural Networks Miscalibrated?,"['Graph Neural Networks', 'Post-hoc Calibration']","[6, 6, 8, 5]","[2, 4, 4, 3]",0,"[229, 609, 188, 467]",Accept
0dt8wdYIAV,Sequence-to-Set Generative Models,"['generative models', 'set data', 'sequences', 'e-commerce orders', 'representation learning']","[6, 6, 6]","[4, 3, 1]",0,"[331, 271, 247]",Accept
TPOJzwv2pc,Active Exploration for Inverse Reinforcement Learning,"['inverse reinforcement learning', 'active learning', 'reward-free exploration']","[7, 7, 7, 7]","[2, 4, 3, 3]",0,"[603, 350, 263, 90]",Accept
a7-YO5NJGyp,A Universal Error Measure for Input Predictions Applied to Online Graph Problems,"['learning-augmented algorithms', 'untrusted predictions', 'prediction error', 'online algorithms', 'network design', 'routing', 'TSP']","[6, 6, 7, 6]","[4, 3, 4, 4]",0,"[382, 399, 839, 742]",Accept
xpdaDM_B4D,FeLMi : Few shot Learning with hard Mixup,"['few-shot learning', 'mixup']","[8, 3, 5, 5]","[5, 4, 4, 4]",0,"[292, 349, 433, 319]",Accept
--fdtqo-iKM,Reinforcement Learning in a Birth and Death Process: Breaking the Dependence on the State Space,"['Markov decision processes', 'structured reinforcement learning', 'regret analysis', 'queueing systems']","[6, 7, 5, 5]","[4, 4, 2, 4]",0,"[259, 430, 230, 278]",Accept
FCNMbF_TsKm,Meta-Learning with Self-Improving Momentum Target,"['meta-learning', 'momentum network', 'knowledge distillation']","[6, 6, 6, 7]","[5, 4, 4, 4]",0,"[596, 472, 308, 316]",Accept
p9lC_i9WeFE,Generalization Analysis of Message Passing Neural Networks on Large Random Graphs,"['graph neural networks', 'message passing', 'generalization', 'convergence', 'large random graphs']","[7, 7, 5]","[2, 2, 3]",0,"[383, 321, 568]",Accept
uyEYNg2HHFQ,Hyper-Representations as Generative Models: Sampling Unseen Neural Network Weights,"['Weight Generation', 'Representation Learning', 'Model Zoo', 'Hyper-Representations', 'Ensembling']","[4, 7, 6]","[4, 3, 3]",0,"[411, 231, 635]",Accept
HOG-G4arLnU,Isometric 3D Adversarial Examples in the Physical World,"['3D adversarial examples', 'physical attacks', 'isometry']","[6, 8, 5]","[4, 5, 4]",0,"[679, 603, 225]",Accept
RJemsN3V_kt,Uncovering the Structural Fairness in Graph Contrastive Learning,"['Degree Bias', 'Graph Contrastive Learning', 'Graph Neural Networks']","[7, 8, 7, 7]","[4, 4, 4, 5]",0,"[369, 440, 241, 371]",Accept
w0QoqmUT9vJ,Ordered Subgraph Aggregation Networks,"['GNNs', 'expressivity', 'subgraphs', 'differentiating through discrete structures']","[7, 7, 7, 7]","[3, 5, 4, 3]",0,"[270, 1835, 233, 454]",Accept
_P4JCoz83Mb,Distilling Representations from GAN Generator via Squeeze and Span,"['Representation Learning', 'Generative Adversarial Network', 'Knowledge Distillation', 'Self-Supervised Learning']","[5, 6, 5]","[3, 5, 4]",0,"[450, 483, 265]",Accept
MwSXgQSxL5s,Provably expressive temporal graph networks,"['graph neural networks', 'temporal graphs', 'link prediction']","[7, 8, 7, 5]","[3, 3, 3, 4]",0,"[279, 491, 513, 716]",Accept
TkJIkNrzpNJ,Exploitability Minimization in Games and Beyond,"['Pseudo-games', 'exploitability minimization', 'equilibrium computation']","[6, 6, 5, 6]","[2, 2, 2, 3]",0,"[314, 433, 459, 737]",Accept
XBXEfw6OxRh,Black-box coreset variational inference,"['Bayesian coresets', 'approximate inference', 'variational inference', 'probabilistic machine learning']","[7, 5, 5]","[4, 3, 3]",0,"[592, 302, 785]",Accept
yZcPRIZEwOG,Policy Optimization with Linear Temporal Logic Constraints,"['Reinforcement Learning', 'RL', 'Linear Temporal Logic', 'LTL', 'Constrained', 'Policy', 'Optimization', 'Learning']","[7, 7, 6]","[2, 3, 3]",0,"[400, 578, 533]",Accept
4d_tnQ_agHI,An Analytical Theory of Curriculum Learning in Teacher-Student Networks,"['learning', 'curriculum learning', 'theory', 'statistical mechanics', 'generalization model', 'fading', 'structured data']","[6, 6, 5]","[3, 4, 3]",0,"[318, 303, 891]",Accept
m2JJO3iEe_5,Smoothed Embeddings for Certified Few-Shot Learning,"['Certified robustness', 'randomized smoothing', 'few-shot learning']","[5, 7, 6, 7]","[2, 4, 3, 4]",0,"[407, 331, 734, 379]",Accept
rP9xfRSF4F,When to Intervene: Learning Optimal Intervention Policies for Critical Events,"['time-series', 'neural survival analysis', 'optimal stopping']","[7, 6, 5, 5]","[3, 3, 2, 2]",0,"[543, 581, 1986, 426]",Accept
KieCChVB6mN,Sparse Probabilistic Circuits via Pruning and Growing,[],"[8, 7, 9, 7]","[4, 3, 4, 4]",0,"[565, 603, 406, 441]",Accept
uCBx_6Hc7cu,On the relationship between variational inference and auto-associative memory,"['Associative Memory', 'Variational Inference', 'Predictive Coding', 'Hopfield Networks', 'Variational Autoencoders']","[3, 5, 5, 5]","[3, 4, 4, 4]",0,"[391, 257, 762, 709]",Accept
36-xl1wdyu,Neural network architecture beyond width and depth,"['Neural Network Approximation', 'Nested Architecture', 'Parameter Sharing', 'Function Composition']","[6, 6, 5]","[2, 4, 2]",0,"[231, 794, 173]",Accept
v1bxRZJ9c8V,Learning interacting dynamical systems with latent Gaussian process ODEs,"['Gaussian Processes', 'Ordinary Differential Equations', 'Interacting Dynamical Systems']","[6, 7, 9, 4]","[3, 3, 4, 3]",0,"[355, 461, 328, 171]",Accept
xI5660uFUr,Selective compression learning of latent representations for variable-rate image compression,"['NN-based image compression', 'variable-rate image compression', 'selective compression of representations']","[6, 5, 5, 4]","[5, 4, 5, 4]",0,"[591, 407, 512, 516]",Accept
fRbvozXEGTb,Bring Your Own Algorithm for Optimal Differentially Private Stochastic Minimax Optimization,[],"[8, 5, 5, 7]","[2, 4, 1, 4]",0,"[86, 419, 115, 268]",Accept
7TleYo6Tmlo,Zero-Sum Stochastic Stackelberg Games,"['Stackelberg games', 'Equilibrium Computation', 'Market equilibrium']","[6, 5, 7]","[3, 3, 4]",0,"[594, 242, 382]",Accept
2TdPjch_ogV,Learnable Graph Convolutional Attention Networks,"['GNN', 'GCN', 'GAT']","[6, 5, 3, 6]","[3, 4, 5, 5]",0,"[481, 376, 263, 358]",Reject
IpBjWtJp40j,The Hessian Screening Rule,"['screening-rules', 'lasso', 'l1-regularization', 'high-dimensional']","[6, 6, 6, 3]","[3, 3, 3, 3]",0,"[214, 423, 359, 408]",Accept
1PRnYiuJkQx,A gradient estimator via L1-randomization for online zero-order optimization with two point feedback,"['zero-order optimization', 'online learning']","[7, 6, 7]","[3, 4, 3]",0,"[632, 295, 202]",Accept
Fjw_7Hv-mwB,Shielding Federated Learning: Aligned Dual Gradient Pruning Against  Gradient Leakage,[],"[3, 4, 7, 4, 4, 5]","[4, 3, 3, 5, 4, 3]",0,"[598, 409, 370, 578, 659, 356]",Reject
uzn0WLCfuC_,Expected Improvement for Contextual Bandits,"['Expected Improvement', 'Linear Bandits', 'Neural Contextual Bandits', 'Contextual Bandits', 'Neural Tangent Kernel', 'Greedy Strategy']","[8, 6, 6, 6]","[3, 3, 4, 3]",0,"[258, 227, 574, 203]",Accept
lUyAaz-iA4u,Dynamics of SGD with Stochastic Polyak Stepsizes: Truly Adaptive Variants and Convergence to Exact Solution,"['Optimization', 'Convex Optimization', 'SGD', 'Gradient Descent', 'Adaptive Methods', 'Polyak Stepsize']","[4, 6, 8, 6]","[4, 3, 5, 4]",0,"[340, 248, 1300, 332]",Accept
DylWBluOgqN,Collaborative Decision Making Using Action Suggestions,"['collaboration', 'decision making', 'human-ai collaboration', 'pomdp', 'state estimation']","[5, 7, 6]","[5, 4, 3]",0,"[769, 1077, 590]",Accept
_FMJmDEPLzs,BinauralGrad: A Two-Stage Conditional Diffusion Probabilistic Model for Binaural Audio Synthesis,"['Binaural audio synthesis', 'Audio warping', 'Two-stage framework', 'Conditional diffusion probabilistic model']","[8, 5, 7]","[4, 4, 5]",0,"[185, 342, 381]",Accept
YG4Dg7xtETg,MAtt: A Manifold Attention Network for EEG Decoding,"['Attention network', 'Riemannian geometry', 'SPD manifold', 'EEG', 'Brain-computer interface']","[7, 4, 6, 8, 5]","[5, 3, 4, 3, 4]",0,"[217, 297, 569, 136, 490]",Accept
kK200QKfvjB,Feature Learning in $L_2$-regularized DNNs: Attraction/Repulsion and Sparsity,"['Deep Learning', 'L2 regularization', 'feature learning']","[5, 5, 7]","[3, 3, 3]",0,"[666, 329, 180]",Accept
rAVqc7KSGDa,Revisiting Active Sets for Gaussian Process Decoders,['Gaussian Processes'],"[5, 5, 7]","[4, 4, 3]",0,"[393, 536, 585]",Accept
Ixp6pznZgv7,Matching in Multi-arm Bandit with Collision,[],"[6, 3, 5, 4, 5]","[2, 3, 4, 3, 3]",0,"[235, 552, 487, 578, 468]",Accept
gvwDosudtyA,Optimistic Posterior Sampling for Reinforcement Learning with Few Samples and Tight Guarantees,[],"[6, 7, 5]","[3, 4, 3]",0,"[249, 255, 369]",Accept
UMdY6-r7yRu,Measuring Data Reconstruction Defenses in Collaborative Inference Systems,[],"[5, 4, 7]","[3, 5, 4]",0,"[541, 477, 496]",Accept
U07d1Y-x2E,Memory Efficient Continual Learning with Transformers,"['continual learning', 'transformers', 'ViT', 'BERT', 'text classification', 'image classification', 'adapters']","[6, 5, 6]","[4, 3, 3]",0,"[661, 366, 372]",Accept
JVtoIJrSxuO,Oracle Inequalities for Model Selection in Offline Reinforcement Learning,"['offline reinforcement learning', 'reinforcement learning', 'model selection']","[4, 3, 7]","[4, 3, 4]",0,"[315, 128, 703]",Accept
aaar9y7qjfw,Laplacian Autoencoders for Learning Stochastic Representations,"['Laplace Approximation', 'Bayesian Learning', 'Unsupervised Representation Learning']","[7, 6, 7]","[3, 3, 4]",0,"[303, 377, 180]",Accept
k3MX8EK6Zf,Assistive Teaching of Motor Control Tasks to Humans,"['teaching', 'shared autonomy', 'human-AI interaction', 'education', 'reinforcement learning']","[6, 6, 5, 6]","[2, 4, 4, 4]",0,"[707, 393, 531, 495]",Accept
gsdHDI-p6NI,Sound and Complete Verification of Polynomial Networks,"['branch and bound', 'adversarial robustness', 'adversarial examples', 'certified robustness', 'polynomial network verification']","[7, 5, 7]","[5, 4, 4]",0,"[616, 250, 582]",Accept
zFW48MVzCKC,Multiagent Q-learning with Sub-Team Coordination,"['Cooperative multi-agent reinforcement learning', 'Centralized training with decentralized execution', 'Value Factorization', 'Sub-team coordination']","[5, 6, 6, 6]","[3, 4, 3, 4]",0,"[968, 251, 232, 477]",Accept
GJGU6FgB7mg,Relational Reasoning via Set Transformers: Provable Efficiency and Applications to MARL,"['Multi-Agent Reinforcement Learning', 'Transformer', 'generalization']","[4, 7, 6]","[3, 1, 3]",0,"[377, 220, 136]",Accept
MhpB7Rxyyr,HyperDomainNet: Universal Domain Adaptation for Generative Adversarial Networks,"['GAN', 'StyleGAN', 'Transfer Learning', 'Domain Adaptation', 'CLIP', 'HyperNetwork']","[6, 5, 6]","[3, 3, 4]",0,"[529, 509, 291]",Accept
13S0tUMqynI,Challenging Common Assumptions in Convex Reinforcement Learning,"['Convex reinforcement learning', 'Reinforcement learning with general utilities', 'Theoretical aspects of reinforcement learning']","[7, 7, 8, 4]","[4, 3, 4, 3]",0,"[393, 605, 703, 1470]",Accept
ch5Uth1IGj_,Neural-Symbolic Entangled Framework for Complex Query Answering,"['neural and symbolic', 'complex query answering', 'knowledge graph']","[7, 5, 7]","[2, 4, 3]",0,"[107, 379, 840]",Accept
KTf5SGYZQvt,Near Instance-Optimal PAC Reinforcement Learning for Deterministic MDPs,[],"[7, 7, 6, 5]","[3, 5, 3, 4]",0,"[386, 440, 413, 643]",Accept
QZDmftWNAMJ,S2P: State-conditioned Image Synthesis for Data Augmentation in Offline Reinforcement Learning,"['Offline Reinforcement Learning', 'Generative Model', 'Data Augmentation']","[5, 5, 7, 7]","[4, 4, 4, 4]",0,"[248, 547, 572, 643]",Accept
KAIyxWrP9-,A Differentially Private Linear-Time fPTAS for the Minimum Enclosing Ball Problem,"['Differential Privacy', 'Minimum Enclosing Ball', 'fPTAS']","[7, 7, 6, 7]","[2, 4, 3, 4]",0,"[531, 458, 422, 1059]",Accept
B26CPuYw9VA,Debiased Causal Tree: Heterogeneous Treatment Effects Estimation with Unmeasured Confounding,"['Deconfounding', 'Heterogeneous treatment effects estimation', 'Confounding entropy', 'Boosting', 'Causal tree']","[5, 9, 6]","[3, 4, 4]",0,"[490, 498, 852]",Accept
zLVLB-OncUY,Optimal Positive Generation via Latent Transformation for Contrastive Learning,"['Contrastive Learning', 'Self-Supervised Learning', 'Generative Model', 'GAN']","[5, 6, 6, 5]","[3, 4, 5, 3]",0,"[361, 516, 275, 169]",Accept
iAWNOXfLz0,AnoFormer: Time Series Anomaly Detection using Transformer-based GAN with Two-Step Masking,"['Anomaly detection', 'Transformer', 'Masking', 'Time series', 'Entropy']","[5, 4, 3]","[4, 5, 4]",0,"[429, 386, 468]",Reject
5zwnqUwphT,A Simple Contrastive Learning Objective for Alleviating Neural Text Degeneration,"['language model', 'contrastive learning', 'repetition', 'degeneration']","[6, 4, 3]","[4, 4, 5]",0,"[249, 513, 179]",Reject
zK6PjBczve,Graph Coloring via Neural Networks for Haplotype Assembly and Viral Quasispecies Reconstruction,"['Computational Biology', 'Genomics', 'Haplotypes Assembly']","[7, 4, 7, 6]","[3, 4, 4, 3]",0,"[284, 420, 291, 839]",Accept
BejkSpqao_N,Theoretically Better and Numerically Faster Distributed Optimization with Smoothness-Aware Quantization Techniques,"['Distributed optimization', 'smoothness matrices', 'gradient quantization']","[6, 6, 7, 7]","[3, 4, 2, 3]",0,"[123, 218, 421, 2405]",Accept
4Q9CmC3ypdE,Joint Learning of 2D-3D Weakly Supervised Semantic Segmentation,"['Weakly supervised semantic segmentation', 'Point cloud']","[6, 5, 6, 6]","[3, 5, 2, 3]",0,"[402, 648, 379, 613]",Accept
uFSrUpapQ5K,Off-Policy Evaluation with Deficient Support Using Side Information,"['Off-Policy Evaluation', 'Inverse Propensity Score', 'Importance Sampling', 'Contextual Bandits', 'Recommendation Systems', 'Deficient Support']","[6, 6, 6, 5]","[3, 4, 4, 4]",0,"[255, 572, 240, 479]",Accept
g9fSNChD0S,Random Rank: The One and Only Strategyproof and Proportionally Fair Randomized Facility Location Mechanism,"['Facility location', 'Randomized Social Choice', 'Fairness in Collective Decision Problems', 'Voting']","[7, 6, 4, 6]","[3, 4, 4, 3]",0,"[208, 337, 352, 344]",Accept
4cdxptfCCg,Measuring and Reducing Model Update Regression in Structured Prediction for NLP,"['Model Update Regression', 'Structured Prediction', 'Backward Compatibility']","[7, 8, 4, 6]","[3, 4, 4, 4]",0,"[724, 293, 457, 645]",Accept
Qvh0SAPrYzH, Non-Monotonic Latent Alignments for CTC-Based Non-Autoregressive Machine Translation,"['Non-Monotonic', 'Latent Alignments', 'CTC', 'Non-Autoregressive', 'machine translation']","[7, 7, 5]","[4, 2, 4]",0,"[121, 163, 299]",Accept
ePhEbo039l,Focal Modulation Networks,"['Focal Modulation', 'Self-Attention', 'Convolution', 'Visual Backbone', 'Image Classification', 'Object Detection', 'Image Segmentation']","[6, 7, 6, 6]","[4, 4, 3, 4]",0,"[339, 282, 156, 189]",Accept
NM3AbzX-dq,Expansion and Shrinkage of Localization for Weakly-Supervised Semantic Segmentation,"['deformable', 'expansion', 'shrinkage', 'weakly-supervised semantic segmentation']","[6, 5, 8]","[5, 4, 5]",0,"[210, 335, 731]",Accept
CCahlgHoQG,Measures of Information Reflect Memorization Patterns,"['OOD generalization', 'memorization', 'spurious correlations', 'challenge sets', 'evaluation', 'model selection', 'information']","[6, 6, 5, 4]","[4, 4, 3, 4]",0,"[407, 231, 414, 672]",Accept
S4KGBKBhCPo,Clipped Stochastic Methods for Variational Inequalities with Heavy-Tailed Noise,"['heavy-tailed noise', 'variational inequalities', 'extragradient method', 'gradient descent-ascent', 'high-probability bounds', 'clipping']","[6, 6, 7]","[3, 3, 3]",0,"[98, 327, 276]",Accept
Nf_XI3uVGaZ,Where do Models go Wrong? Parameter-Space Saliency Maps for Explainability,"['parameter saliency', 'explainability', 'saliency maps']","[9, 5, 7, 6]","[3, 3, 4, 4]",0,"[318, 126, 777, 187]",Accept
3SLW-YIw7tX,Reinforcement Learning with Neural Radiance Fields,"['RL', 'NeRF', 'Computer Vision', 'Representation Learning', 'Robotic Manipulation', 'Neural Implicit Representations']","[6, 7, 5]","[4, 4, 5]",0,"[521, 138, 225]",Accept
xUK4E1jpV7z,Unlabelled Sample Compression Schemes for Intersection-Closed Classes and Extremal Classes,"['Sample compression', 'Vapnik Chervonenkis dimension', 'Ample classes', 'Extremal classes', 'Intersection-closed classes']","[7, 6, 5, 7]","[3, 2, 3, 3]",0,"[225, 401, 195, 286]",Accept
odOQU9PYrkD,Structuring Uncertainty for Fine-Grained Sampling in Stochastic Segmentation Networks,"['stochastic segmentation', 'sample control', 'uncertainty representation', 'factor model', 'factor rotations', 'aleatoric uncertainty']","[7, 6, 7]","[3, 4, 1]",0,"[554, 396, 228]",Accept
u5oLvX8x4wH,Revisit last-iterate convergence of mSGD under milder requirement on step size,"['stochastic gradient descent', 'momentum', 'convergence']","[6, 7, 7, 7, 5]","[2, 2, 4, 3, 4]",0,"[401, 312, 425, 220, 506]",Accept
aUoCgjJfmY9,Graph Convolution Network based Recommender Systems: Learning Guarantee and Item Mixture Powered Strategy,"['generalization ability', 'recommender system', 'graph learning']","[6, 7, 6]","[3, 3, 2]",0,"[427, 363, 526]",Accept
ufRSbXtgbOo,Multi-agent Performative Prediction with Greedy Deployment and Consensus Seeking Agents,"['Performative prediction', 'Multi-agent', 'Decentralized stochastic algorithm.']","[7, 4, 6, 4]","[4, 3, 3, 1]",0,"[616, 234, 406, 162]",Accept
yP0vpghGoLF,Last-Iterate Convergence of Optimistic Gradient Method for Monotone Variational Inequalities,"['optimistic gradient method', 'monotone variational inequalities', 'last-iterate convergence', 'computer-aided proofs']","[6, 6, 5]","[4, 3, 4]",0,"[420, 391, 310]",Accept
fkiFqG-muu,Collaborative Learning by Detecting Collaboration Partners,['Collaborative learning'],"[5, 6, 7, 5]","[2, 2, 2, 4]",0,"[166, 408, 226, 359]",Accept
0RMDK39mGg,A Stochastic Linearized Augmented Lagrangian Method for Decentralized Bilevel Optimization,"['Decentralized bilevel optimization', 'stochastic linearized augmented Lagrangian method (SLAM)', 'multi-agent actor-critic algorithm']","[7, 5, 8, 6]","[2, 3, 3, 3]",0,"[315, 335, 227, 415]",Accept
px87A_nzK-T,Kernel Memory Networks: A Unifying Framework for Memory Modeling,"['attractor networks', 'autoassociative memory', 'kernel methods', 'Hopfield network']","[6, 7, 5]","[3, 4, 2]",0,"[253, 331, 296]",Accept
uOii2cEN2w_,Batch Bayesian optimisation via density-ratio estimation with guarantees,"['Bayesian optimization', 'Gaussian processes', 'density-ratio estimation', 'regret bounds', 'approximate Bayesian inference']","[7, 5, 6, 4]","[4, 2, 4, 3]",0,"[419, 300, 433, 356]",Accept
2_AZxVpFlGP,Towards Consistency in Adversarial Classification,"['adversarial', 'consistency', 'calibration']","[7, 9, 6]","[3, 3, 4]",0,"[304, 619, 211]",Accept
h3RYh6IBBS,Revisiting Neural Scaling Laws in Language and Vision,"['Scaling Laws', 'Computer Vision', 'Neural Machine Translation', 'Language Modeling', 'Big Bench']","[7, 5, 8]","[3, 3, 3]",0,"[427, 360, 151]",Accept
4XP0ZuQKXmV,Asynchronous SGD Beats Minibatch SGD Under Arbitrary Delays,"['Stochastic', 'Convex', 'Non-convex', 'Asynchronous', 'Parallel', 'Optimization']","[8, 7, 3]","[4, 4, 3]",0,"[628, 196, 327]",Accept
ibxa2Y0y8yr,MetricFormer: A Unified Perspective of Correlation Exploring in Similarity Learning,[],"[7, 7, 5, 6]","[4, 4, 4, 3]",0,"[219, 260, 311, 201]",Accept
ogNrYe9CJlH,A Reduction to Binary Approach for Debiasing Multiclass Datasets,"['Fairness', 'Classification', 'Demographic Parity', 'Deep Learning', 'Computer Vision', 'Healthcare']","[5, 4, 6, 5, 6]","[3, 4, 3, 2, 3]",0,"[208, 384, 369, 404, 395]",Accept
jjJgLNrCQB,"Chromatic Correlation Clustering, Revisited",[],"[6, 5, 5, 8]","[3, 3, 4, 5]",0,"[128, 444, 1370, 194]",Accept
Pu-QtT0h2E,DeVRF: Fast Deformable Voxel Radiance Fields for Dynamic Scenes,"['dynamic radiance field', 'volumetric representation', 'dynamic novel view synthesis.']","[6, 4, 6]","[4, 4, 3]",0,"[333, 511, 321]",Accept
BTeJpF_BhQ6, Learning Deep Input-Output Stable Dynamics,"['Dynamical systems', 'Input-output stability', 'Nonlinear system identification']","[5, 7, 5]","[4, 5, 4]",0,"[348, 507, 599]",Accept
CwkX0j8YFm,A Neural Pre-Conditioning Active Learning Algorithm to Reduce Label Complexity,"['Active learning', 'neural tangent kernel', 'semi-supervised learning']","[3, 6, 6, 4]","[3, 3, 4, 4]",0,"[682, 501, 211, 443]",Accept
0pdLvHwh-L,Inducing Equilibria via Incentives: Simultaneous Design-and-Play Ensures Global Convergence,[],"[7, 6, 5]","[2, 3, 3]",0,"[258, 327, 530]",Accept
x4JZ3xX5mtv,Bridging Implicit and Explicit Geometric Transformations for Single-Image View Synthesis,"['Single-Image View Synthesis', 'Transformer']","[7, 6, 6, 6]","[4, 4, 3, 4]",0,"[548, 461, 756, 436]",Reject
F5TbbyTgbC,Combinatorial Bandits with Linear Constraints: Beyond Knapsacks and Fairness,[],"[6, 6, 8, 7]","[2, 4, 4, 3]",0,"[269, 377, 274, 379]",Accept
TC42kAO8XLS,Unifying and Boosting Gradient-Based Training-Free Neural Architecture Search,"['Neural Architecture Search', 'Training-free', 'Neural Tangent Kernel', 'Hybrid', 'Bayesian Optimization']","[8, 6, 6, 6]","[4, 3, 4, 3]",0,"[241, 355, 218, 1115]",Accept
6y0lgLb9tny,Palm up: Playing in the Latent Manifold for Unsupervised Pretraining,[],"[6, 3, 7, 7]","[3, 4, 5, 3]",0,"[449, 241, 1139, 253]",Accept
AyajSjTAzmg,SCINet: Time Series Modeling and Forecasting with Sample Convolution and Interaction,"['Time series forecasting', 'Sample convolution', 'downsampling']","[5, 6, 5, 5]","[4, 4, 4, 3]",0,"[418, 181, 518, 228]",Accept
WaGvb7OzySA,CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning,"['code generation', 'deep reinforcement learning', 'pretrained language model', 'program synthesis']","[4, 7, 7, 7]","[4, 4, 4, 4]",0,"[620, 237, 563, 722]",Accept
0RTJcuvHtIu,Flexible Diffusion Modeling of Long Videos,"['generative modeling', 'denoising diffusion probabilistic model', 'video modeling']","[4, 7, 4]","[4, 5, 5]",0,"[437, 512, 346]",Accept
EeCdsAj80Wr,WT-MVSNet: Window-based Transformers for Multi-view Stereo,[],"[6, 7, 7, 6]","[4, 4, 4, 5]",0,"[1349, 235, 430, 333]",Accept
XlIUm7Obm6,Concentration of Data Encoding in Parameterized Quantum Circuits,"['quantum machine learning', 'quantum neural networks', 'data encoding', 'quantum classifier', 'parameterized quantum circuits']","[7, 7, 7]","[2, 3, 3]",0,"[176, 106, 290]",Accept
9_O9mTLYJQp,Label Noise in Adversarial Training: A Novel Perspective to Study Robust Overfitting,"['Adversarial training', 'Label noise', 'Robust overfitting', 'Double descent']","[6, 6, 6]","[3, 3, 3]",0,"[599, 349, 467]",Accept
LceHl9wKmoQ,Learning Structure from the Ground up---Hierarchical Representation Learning by Chunking,"['Representation Learning', 'Structure Learning', 'Cognitive Science', 'Neuroscience']","[7, 6, 8, 5]","[3, 4, 4, 4]",0,"[584, 708, 352, 290]",Accept
9v1_6m0ZKC,360-MLC: Multi-view Layout Consistency for Self-training and Hyper-parameter Tuning,"['self-training', 'scene understanding', 'omnidirectional vision']","[6, 5, 6, 7]","[5, 3, 3, 4]",0,"[350, 233, 322, 660]",Accept
WOppMAJtvhv,How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders,[],"[4, 5, 4, 8]","[4, 3, 4, 5]",0,"[413, 454, 668, 424]",Accept
2OpRgzLhoPQ,Prune and distill: similar reformatting of image information along rat visual cortex and deep neural networks,"['convolutional neural networks', 'computational neuroscience', 'rat', 'visual cortex', 'ventral stream', 'intrinsic dimensionality', 'vision', 'representation analysis']","[6, 8, 4, 7]","[3, 4, 4, 4]",0,"[570, 606, 398, 683]",Accept
0qaIM4W9Q1s,Meta-Complementing the Semantics of Short Texts in Neural Topic Models,"['neural topic model', 'short text', 'graph neural networks', 'semantic complement']","[8, 6, 7, 4]","[4, 3, 4, 4]",0,"[392, 326, 423, 302]",Accept
a7YeDeacHpL,Towards Improving Calibration in Object Detection Under Domain Shift,"['Domain Shift', 'Uncertanity', 'Calibration', 'Object Detection', 'Out-of-domain calibration']","[6, 8, 6, 5]","[3, 4, 4, 3]",0,"[121, 330, 286, 117]",Accept
XCIKp-icFm,Injecting Domain Knowledge from Empirical Interatomic Potentials to Neural Networks for Predicting Material Properties,"['Domain Knowledge', 'Neural Networks', 'Empirical Interatomic Potentials', 'Material Property Prediction']","[7, 6, 5, 6]","[4, 3, 3, 4]",0,"[330, 524, 280, 301]",Accept
V5hy17mwu3R,Experimental Design for Linear Functionals in Reproducing Kernel Hilbert Spaces,"['experiment design', 'active learning', 'confidence sets']","[8, 8, 7]","[3, 3, 1]",0,"[679, 511, 244]",Accept
MT1GId7fJiP,GAL: Gradient Assisted Learning for Decentralized Multi-Organization Collaborations,"['Assisted Learning', 'Decentralized Machine Learning']","[7, 5, 6, 6]","[3, 4, 3, 4]",0,"[114, 229, 255, 1036]",Accept
f966GJIEF9,Risk Bounds of Multi-Pass SGD for Least Squares  in  the Interpolation Regime,"['Stochastic gradient descent', 'generalization', 'least square', 'interpolation']","[6, 6, 6, 8]","[5, 4, 3, 5]",0,"[477, 413, 560, 545]",Accept
utahaTbcHdP,Imbalance Trouble: Revisiting Neural-Collapse Geometry,"['neural collapse', 'implicit bias', 'interpolation', 'max-margin', 'class imbalance', 'convex relaxations']","[7, 8, 6, 7, 6]","[3, 4, 4, 4, 2]",0,"[644, 298, 427, 492, 195]",Accept
5swt6zUFrVp,An Adaptive Deep RL Method for Non-Stationary Environments with Piecewise Stable Context,[],"[6, 5, 5, 4]","[4, 3, 4, 4]",0,"[741, 510, 461, 268]",Accept
XevwsaZ-4z,Text-Adaptive Multiple Visual Prototype Matching for Video-Text Retrieval,['Video-Text Retrieval'],"[5, 5, 7, 6]","[5, 4, 4, 5]",0,"[430, 305, 616, 963]",Accept
LRMmgkcoCnW,Active Learning with Neural Networks: Insights from Nonparametric Statistics,[],"[6, 6, 7, 7]","[3, 3, 4, 3]",0,"[421, 195, 1160, 214]",Accept
rHnbVaqzXne,A Rotated Hyperbolic Wrapped Normal Distribution for Hierarchical Representation Learning,"['Hyperbolic space', 'Hierarchical representation learning', 'Distribution in Riemannian manifold']","[5, 7, 6]","[3, 4, 4]",0,"[728, 894, 1209]",Accept
rcMG-hzYtR,Max-Min Off-Policy Actor-Critic Method Focusing on Worst-Case Robustness to Model Misspecification,"['Deep Reinforcement Learning', 'Maxmin Optimization', 'Sim2Real']","[4, 5, 7, 5]","[3, 3, 4, 4]",0,"[261, 340, 804, 515]",Accept
v9pljSdlUNP,An In-depth Study of Stochastic Backpropagation,"['Memory efficient training method', 'stochastic backpropagation', 'image classification', 'object detection']","[7, 8, 6, 5]","[1, 2, 3, 4]",0,"[95, 676, 583, 265]",Accept
hFa75frAh0,FlowHMM: Flow-based continuous hidden Markov models,"['Hidden Markov Models', 'Continuous Normalizing Flow models']","[7, 4, 8, 5, 7]","[3, 4, 4, 3, 4]",0,"[349, 586, 215, 508, 572]",Accept
EWyhkNNKsd,Lazy and Fast Greedy MAP Inference for Determinantal Point Process,"['determinantal point process', 'maximum a posteriori inference', 'submodular function maximization', 'greedy algorithm', 'Cholesky factorization']","[5, 7, 4, 6]","[4, 3, 5, 3]",0,"[261, 440, 379, 455]",Accept
kGQz0lt6Zu6,Coresets for Wasserstein Distributionally Robust Optimization Problems,"['coreset', 'robust optimization', 'wasserstein distance']","[7, 7, 6, 5]","[3, 3, 3, 3]",0,"[427, 341, 212, 660]",Accept
JyXuBiBTR6m,LBD: Decouple Relevance and Observation for Individual-Level Unbiased Learning to Rank,"['learning to rank', 'unbiased learning to rank', 'decouple']","[6, 6, 6, 4]","[4, 3, 3, 4]",0,"[686, 284, 617, 471]",Accept
lQ--doSB2o,Robust Feature-Level Adversaries are Interpretability Tools,"['Interpretability', 'Explainability', 'Adversarial Attacks']","[4, 6, 8, 7]","[4, 3, 4, 3]",0,"[526, 572, 724, 444]",Accept
fcO9Cgn-X-R,Capturing Failures of Large Language Models via Human Cognitive Biases,"['open-ended generation', 'ai safety', 'codex', 'robustness', 'cognitive biases']","[5, 6, 6, 7, 7]","[4, 3, 4, 4, 4]",0,"[297, 530, 529, 1255, 507]",Accept
tPiE70y40cv,Coresets for Relational Data and The Applications,"['coreset', 'relational data', 'optimization']","[7, 6, 7, 7]","[5, 4, 2, 2]",0,"[300, 1550, 492, 569]",Accept
4T3kbrzfeR,Contrastive Language-Image Pre-Training with Knowledge Graphs,"['vision-language pre-training', 'knowledge graph']","[5, 8, 5, 6]","[3, 4, 4, 4]",0,"[249, 270, 465, 410]",Accept
r6_zHM2POTd,A time-resolved theory of information encoding in recurrent neural networks,"['network dynamics', 'encoding', 'mean-field theory', 'balanced state', 'information theory', 'recurrent neural networks', 'dynamical systems', 'chaos', 'noise']","[5, 4, 6, 7]","[4, 3, 3, 4]",0,"[571, 434, 313, 829]",Accept
MaYzugDmQV,Towards Understanding the Mixture-of-Experts Layer in Deep Learning,[],"[6, 6, 4, 7]","[3, 3, 5, 3]",0,"[200, 499, 291, 794]",Accept
N2AGw9s-wvX,Knowledge-Aware Bayesian Deep Topic Model,"['Topic modeling', 'hierarchical document representation', 'knowledge graph', 'WordNet']","[4, 5, 7]","[4, 2, 3]",0,"[508, 329, 311]",Accept
VgST3vrBAo8,Near-Optimal Goal-Oriented Reinforcement Learning in Non-Stationary Environments,"['reinforcement learning', 'stochastic shortest path', 'dynamic regret minimization', 'non-stationary environments']","[7, 6, 7]","[4, 4, 4]",0,"[99, 83, 268]",Accept
fORXbIlTELP,Deciding What to Model: Value-Equivalent Sampling for Reinforcement Learning,"['Reinforcement learning', 'Efficient exploration', 'Information theory', 'Bayesian reinforcement learning', 'Value equivalence']","[5, 6, 6, 5]","[1, 3, 3, 2]",0,"[428, 302, 621, 312]",Accept
tQRoZ9nRgM,Dynamic Learning in Large Matching Markets,"['multi-armed bandits', 'matching', 'learning', 'regret', 'algorithms', 'explore-then-commit', 'infinitely many arms']","[7, 6, 6, 5]","[3, 4, 4, 3]",0,"[705, 384, 576, 542]",Accept
lC5-Ty_0FiN,Redundant representations help generalization in wide neural networks,"['generalization', 'wide neural networks']","[7, 6, 5]","[3, 3, 4]",0,"[699, 256, 442]",Accept
Xm0976LQTn_,Single Loop Gaussian Homotopy Method for Non-convex Optimization,"['Gaussian homotopy', 'Gaussian smoothing', 'Non-convex optimization', 'Worst-case iteration complexity', 'Zeroth-order optimization']","[6, 5, 7]","[2, 3, 4]",0,"[313, 788, 398]",Accept
XrGEkCOREX2,MEMO: Test Time Robustness via Adaptation and Augmentation,"['distribution shift', 'test time adaptation', 'data augmentation']","[7, 7, 5, 6]","[3, 4, 4, 4]",0,"[579, 394, 434, 233]",Accept
nN3aVRQsxGd,How Powerful are K-hop Message Passing Graph Neural Networks,"['Graph Neural Network', 'Expressive Power', 'Graph Isomorphism', 'Weisfeiler-Lehman']","[5, 6, 3, 4]","[5, 4, 4, 3]",0,"[347, 510, 423, 301]",Accept
mxnxRw8jiru,Private Set Generation with Discriminative Information,['Differentially private data generation'],"[6, 7, 7]","[4, 4, 3]",0,"[278, 1098, 260]",Accept
VAeAUWHNrty,"Shape, Light, and Material Decomposition from Images using Monte Carlo Rendering and Denoising","['Applications', 'Optimization', 'Deep Learning']","[6, 8, 6, 5]","[5, 4, 3, 3]",0,"[488, 502, 298, 288]",Accept
YYyAVk8TrOQ,Grounded Reinforcement Learning: Learning to Win the Game under Human Commands,"['Reinforcement Learning', 'Language Grounding', 'Human-AI Interaction']","[6, 5, 5, 7, 6]","[4, 3, 3, 4, 4]",0,"[949, 392, 464, 347, 928]",Accept
OXourTLd9UO,Spherization Layer: Representation Using Only Angles,"['representation learning', 'hyperspherical learning', 'angular similarity', 'spherization']","[7, 7, 7, 5]","[3, 3, 4, 2]",0,"[350, 255, 168, 192]",Accept
L9EXtg7h6XE,When to Ask for Help: Proactive Interventions in Autonomous Reinforcement Learning,[],"[6, 6, 7]","[4, 2, 3]",0,"[368, 203, 489]",Accept
A3DCaxhxBfl,"Learning in Observable POMDPs, without Computationally Intractable Oracles","['Partially-observable Markov Decision Processes', 'barycentric spanner', 'policy cover']","[7, 7, 7]","[3, 4, 4]",0,"[667, 311, 292]",Accept
6pC5OtP7eBx,Geodesic Graph Neural Network for Efficient Graph Representation Learning,"['Graph Learning', 'Geodesic', 'Graph Neural Network', 'GNN', 'Fast Inference']","[7, 6, 7]","[4, 4, 5]",0,"[724, 1000, 698]",Accept
4tM0P_4N8D9,Symmetry-induced Disentanglement on Graphs,"['Generative models', 'disentanglement', 'latent variable models', 'graph neural networks']","[5, 6, 8, 8]","[3, 3, 3, 5]",0,"[453, 263, 511, 180]",Accept
6OhjECfqt2,DARE: Disentanglement-Augmented Rationale Extraction,"['Rationale Extraction', 'Disentanglement', 'Mutual Information']","[6, 5, 5, 5]","[4, 4, 4, 4]",0,"[372, 312, 627, 584]",Accept
Ik8iimy4oFF,Tractable Optimality in Episodic Latent MABs,"['multi-armed bandits', 'partially observable MDPs', 'experimental design', 'latent variable models', 'method-of-moments', 'maximum likelihood estimation']","[6, 5, 6, 7]","[2, 2, 3, 3]",0,"[601, 829, 273, 284]",Accept
ZgWT_u19Ue5,Empirical Phase Diagram for Three-layer Neural Networks with Infinite Width,"['training dynamics', 'neural networks', 'phase diagram', 'initialization']","[4, 7, 6]","[3, 4, 3]",0,"[648, 360, 389]",Accept
2jTCojmmh82,Unsupervised Point Cloud Completion and Segmentation by Generative Adversarial Autoencoding Network,"['Point cloud completion', 'Point cloud segmentation', 'Unsupervised learning', 'GAN']","[5, 6, 6]","[2, 4, 4]",0,"[373, 211, 596]",Accept
_RL7wtHkPJK,Concrete Score Matching: Generalized Score Matching for Discrete Data,"['generative model', 'discrete data', 'score matching']","[8, 5, 6]","[4, 4, 3]",0,"[772, 377, 364]",Accept
nJJjv0JDJju,Improving Diffusion Models for Inverse Problems using Manifold Constraints,"['Diffusion model', 'Inverse problem', 'Manifold constraint']","[8, 7, 6, 6, 6]","[4, 4, 4, 4, 4]",0,"[345, 715, 552, 748, 813]",Accept
sZAbXH4ezvg,MGNNI: Multiscale Graph Neural Networks with Implicit Layers,"['implicit graph neural networks', 'graph neural networks', 'implicit models', 'equilibrium models', 'graph representation learning']","[6, 7, 6, 7]","[2, 4, 4, 5]",0,"[233, 543, 330, 482]",Accept
5JQqvQ1ujSv,DHRL: A Graph-Based Approach for Long-Horizon and Sparse Hierarchical Reinforcement Learning,"['Reinforcement Learning', 'Hierarchical RL', 'Robotics']","[7, 7, 7, 7]","[3, 4, 4, 4]",0,"[249, 372, 694, 663]",Accept
AKp6ZKrs_1,Making Look-Ahead Active Learning Strategies Feasible with Neural Tangent Kernels,"['active learning', 'neural tangent kernels', 'retraining']","[7, 5, 5, 6]","[4, 4, 4, 1]",0,"[741, 403, 377, 447]",Accept
Jz98aDK5gMW,Bridging the Gap from Asymmetry Tricks to Decorrelation Principles in Non-contrastive Self-supervised Learning,[],"[5, 5, 5, 5]","[4, 3, 4, 5]",0,"[300, 513, 853, 421]",Accept
tlUnxtAmcJq,So3krates: Equivariant attention for interactions on arbitrary length-scales in molecular systems,"['equivariance', 'self-attention', 'message passing', 'molecules', 'force fields', 'non-local']","[7, 6, 7]","[4, 3, 4]",0,"[806, 263, 226]",Accept
_kZVnosHbV3,Meta-Query-Net: Resolving Purity-Informativeness Dilemma in Open-set Active Learning,"['Active Learning', 'Open-set Noise']","[6, 5, 7, 7]","[4, 4, 2, 3]",0,"[295, 892, 589, 490]",Accept
htR7ZXXe_TY,On Elimination Strategies for Bandit Fixed-Confidence Identification,[],"[6, 5, 5, 6]","[4, 3, 4, 4]",0,"[695, 335, 535, 664]",Accept
_S9amb2-M-I,Influencing Long-Term Behavior in Multiagent Reinforcement Learning,"['multiagent reinforcement learning', 'active Markov game', 'active average reward formulation']","[6, 6, 4, 6]","[4, 3, 5, 4]",0,"[172, 394, 239, 640]",Accept
ripJhpwlA2v,When Does Group Invariant Learning Survive Spurious Correlations?,"['invariant learning', 'environment inference', 'spurious correlation']","[7, 6, 5]","[3, 3, 4]",0,"[233, 286, 420]",Accept
TQn44YPuOR2,Maximum Likelihood Training of Implicit Nonlinear Diffusion Model,"['Diffusion Model', 'Score-based Model', 'Generative Model', 'Image Generation']","[6, 6, 7, 6]","[2, 3, 3, 4]",0,"[217, 903, 278, 760]",Accept
wUctlvhsNWg,Personalized Online Federated Learning with Multiple Kernels,[],"[4, 5, 6, 4]","[3, 4, 4, 4]",0,"[371, 789, 249, 290]",Accept
CZZFRxbOLC,Patching open-vocabulary models by interpolating weights,"['zero-shot models', 'open-vocabulary models', 'model editing', 'model patching', 'vision-and-language', 'image-text models', 'CLIP']","[4, 5, 5]","[4, 3, 3]",0,"[607, 438, 292]",Accept
e65KZ0ixi0,Evaluating Graph Generative Models with Contrastively Learned Features,"['generative model evaluation', 'graph generative models', 'self-supervised learning']","[6, 6, 6]","[3, 3, 5]",0,"[584, 274, 936]",Accept
ipAz7H8pPnI,Differentially Private Learning Needs Hidden State (Or Much Faster Convergence),"['differential privacy', 'noisy stochastic gradient descent', 'last-iterate analysis', 'privacy amplification']","[7, 8, 4, 7]","[4, 3, 2, 3]",0,"[360, 168, 345, 726]",Accept
pHdiaqgh_nf,Mind Reader: Reconstructing complex images from brain activities,[],"[6, 6, 6, 6]","[5, 4, 3, 4]",0,"[380, 186, 604, 560]",Accept
dC_Cho7PzT,Adapting to Online Label Shift with Provable Guarantees,"['online label shift', 'dynamic regret']","[6, 9, 5]","[3, 4, 2]",0,"[378, 360, 377]",Accept
gKe_A-DxzkH,Data-Driven Model-Based Optimization via Invariant Representation Learning,"['model-based optimization', 'offline learning']","[6, 7, 6, 5, 5]","[3, 4, 3, 5, 2]",0,"[272, 221, 487, 427, 498]",Accept
Ih2bG6h1r4S,Atlas: Universal Function Approximator For Memory Retention,"['universal function approximation', 'artificial neural networks', 'splines', 'catastrophic forgetting', 'continual learning']","[5, 3, 3]","[4, 4, 4]",0,"[556, 537, 393]",Reject
B2rqx0w63U,Provably Feedback-Efficient Reinforcement Learning via Active Reward Learning,"['Reinforcement Learning', 'Human-in-the-loop', 'Active Learning', 'Theory']","[6, 6, 7, 7]","[4, 3, 3, 2]",0,"[590, 463, 529, 501]",Accept
4FSfANJp8Qx,Sharp Analysis of Stochastic Optimization under Global Kurdyka-Lojasiewicz Inequality,"['stochastic optimization', 'nonconvex optimization', 'first order method', 'Kurdyka-Lojasiewicz condition', 'variance reduction']","[4, 6, 7, 5]","[3, 4, 3, 5]",0,"[799, 266, 503, 384]",Accept
XSV1T9jMuz9,GALOIS: Boosting Deep Reinforcement Learning via Generalizable Logic Synthesis,"['deep reinforcement learning', 'program synthesis']","[6, 6, 6]","[3, 2, 5]",0,"[354, 853, 554]",Accept
flNZJ2eOet,What Can Transformers Learn In-Context? A Case Study of Simple Function Classes,"['in-context learning', 'transformers', 'linear regression']","[6, 8, 8, 7]","[4, 4, 4, 5]",0,"[258, 761, 501, 318]",Accept
-Oh_TKISy89,A Scalable Deterministic Global Optimization Algorithm for Training Optimal Decision Tree,"['optimal decision tree', 'branch and bound', 'mixed integer programs', 'grouping decomposition', 'sample reduction']","[5, 6, 7, 4]","[2, 4, 4, 3]",0,"[322, 526, 541, 460]",Accept
q85GV4aSpt,Understanding Square Loss in Training Overparametrized Neural Network Classifiers,"['Nonparametric classification', 'square loss', 'generalization error', 'robustness', 'calibration error', 'neural tangent kernel']","[6, 5, 5, 8]","[4, 3, 4, 4]",0,"[356, 392, 408, 320]",Accept
5dHQyEcYDgA,Additive MIL: Intrinsically Interpretable Multiple Instance Learning for Pathology,"['Interpretability', 'Explainability', 'Multiple Instance Learning', 'Medical Imaging', 'Digital Pathology', 'Histopathology', 'Saliency', 'Additive Models', 'Shapley Values', 'Explainable AI']","[6, 7, 8]","[4, 4, 4]",0,"[285, 401, 565]",Accept
CT5KJGfX4s-,Undersampling is a Minimax Optimal Robustness Intervention in Nonparametric Classification,"['theory of distribution shift', 'nonparametric classification', 'undersampling']","[8, 7, 8]","[3, 4, 4]",0,"[140, 423, 720]",Reject
PLmNPSKJr8e,Minimax Optimal Fixed-Budget Best Arm Identification in Linear Bandits,"['best arm identification', 'linear bandits']","[7, 8, 5, 5]","[3, 3, 3, 4]",0,"[295, 451, 269, 322]",Accept
PDNEqcU-pP,Learning with little mixing,"['Learning Theory', 'Nonlinear Dynamical Systems', 'Learning with dependent data']","[7, 7, 4, 4]","[1, 4, 3, 2]",0,"[144, 514, 80, 254]",Accept
Qry8exovcNA,Explaining Graph Neural Networks with Structure-Aware Cooperative Games,"['Graph Neural Networks', 'Explainablity', 'Cooperative Game Theory', 'Deep Learning']","[7, 7, 5]","[4, 5, 4]",0,"[427, 594, 204]",Accept
SrwrRP3yfq8,Global Optimal K-Medoids Clustering of One Million Samples,"['Large-Scale', 'Global Optimization', 'K-Medoids', 'Clustering', 'Lagrangian Relaxation', 'Branch and Bound', 'Bound Tightening']","[7, 7, 5, 5]","[4, 4, 4, 3]",0,"[321, 234, 226, 407]",Accept
zofwPmKL-DO,Quantum Algorithms for Sampling Log-Concave Distributions and Estimating Normalizing Constants,"['Quantum computing', 'logconcave sampling', 'normalizing constants', 'MCMC methods']","[6, 5, 3]","[3, 4, 5]",0,"[602, 129, 277]",Accept
rF6zwkyMABn,Nearly Optimal Best-of-Both-Worlds Algorithms for Online Learning with Feedback Graphs,"['multi-armed bandit', 'learning with feedback graphs', 'best-of-both-worlds algorithm', 'follow the regularized leader']","[8, 7, 7, 7]","[4, 5, 4, 4]",0,"[264, 263, 890, 572]",Accept
UpNCpGvD96A,"Identification, Amplification and Measurement: A bridge to Gaussian Differential Privacy","['Differential privacy', 'Gaussian differential privacy', 'Privacy profile']","[6, 6, 5, 7]","[2, 3, 3, 3]",0,"[174, 306, 235, 433]",Accept
akddwRG6EGi,High-dimensional Asymptotics of Feature Learning: How One Gradient Step Improves the Representation,"['random matrix theory', 'two-layer neural network', 'kernel method', 'feature learning']","[8, 7, 7]","[4, 3, 2]",0,"[368, 434, 639]",Accept
vfCd1Vt8BGq,On Leave-One-Out Conditional Mutual Information For Generalization,[],"[5, 7, 8, 6]","[3, 2, 2, 4]",0,"[320, 323, 326, 858]",Accept
H4GmqyYMxFP,Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs,[],"[7, 7, 8, 5]","[2, 4, 4, 4]",0,"[221, 373, 145, 255]",Accept
lmmKGi7zXn,Infinite Recommendation Networks: A Data-Centric Approach,"['Dataset Distillation', 'NTK', 'Data-centric AI', 'Recommender Systems']","[6, 7, 4, 5]","[3, 4, 4, 3]",0,"[567, 64, 608, 255]",Accept
_AsEqoBu3s,Giving Feedback on Interactive Student Programs with Meta-Exploration,"['meta-reinforcement learning', 'education', 'exploration']","[8, 6, 8]","[4, 3, 4]",0,"[622, 495, 528]",Accept
hGdAzemIK1X,Quantum Speedups of Optimizing Approximately Convex Functions with Applications to Logarithmic Regret Stochastic Convex Bandits,"['Approximately convex functions', 'quantum computing', 'stochastic convex bandits', 'logarithmic regret']","[5, 7, 6, 7]","[2, 3, 2, 1]",0,"[309, 559, 277, 184]",Accept
UmDaZksRyk,A Consolidated Cross-Validation Algorithm for Support Vector Machines via Data Reduction,"['Cross-validation', 'Data reduction', 'Exact leave-one-out lemma', 'Reproducing kernel Hilbert spaces', 'Support vector machines']","[7, 3, 7, 8]","[5, 4, 4, 4]",0,"[281, 250, 157, 295]",Accept
2EUJ4e6H4OX,Losses Can Be Blessings: Routing Self-Supervised Speech Representations Towards Efficient Multilingual and Multitask Speech Processing,"['automated speech recognition', 'self-supervised learning']","[7, 7, 5]","[4, 5, 4]",0,"[607, 295, 751]",Accept
eUy2ULXQXKs,Understanding the Evolution of Linear Regions in Deep Reinforcement Learning,['Reinforcement Learning'],"[5, 6, 5, 5]","[2, 4, 4, 3]",0,"[263, 588, 761, 605]",Accept
_Lz540aYDPi,What's the Harm? Sharp Bounds on the Fraction Negatively Affected by Treatment,"['Fairness', 'causal inference', 'partial identification', 'individual treatment effects', 'debiased machine learning']","[7, 5, 6]","[1, 3, 3]",0,"[309, 284, 419]",Accept
0Ww7UVEoNue,Active Learning Helps Pretrained Models Learn the Intended Task,"['pretrained models', 'active learning', 'few shot learning', 'alignment']","[5, 4, 7]","[2, 4, 3]",0,"[98, 490, 355]",Accept
fY6OzqOiTnu,Improving Certified Robustness via Statistical Learning with Logical Reasoning,"['certified robustness', 'logical reasoning']","[6, 6, 5, 8]","[3, 3, 3, 1]",0,"[487, 544, 339, 131]",Accept
ZPUkqTf6a-P,Truly Deterministic Policy Optimization,"['Reinforcement Learning', 'Policy Gradient', 'Deterministic Policy Gradients']","[5, 6, 8]","[5, 3, 3]",0,"[377, 541, 352]",Accept
joZ4CuOyKY8,DiSC: Differential Spectral Clustering of Features,"['differential features', 'spectral clustering', 'feature selection', 'manifold learning', 'graph theory']","[4, 7, 6, 6]","[3, 3, 4, 4]",0,"[141, 228, 510, 939]",Accept
jBTQGGy9qA-,DASCO: Dual-Generator Adversarial Support Constrained Offline Reinforcement Learning,"['Offline Reinforcement Learning', 'Generative Adversarial Networks']","[6, 6, 5, 7, 6]","[2, 2, 4, 4, 4]",0,"[287, 481, 394, 254, 365]",Accept
RYTGIZxY5rJ,Bag of Tricks for FGSM Adversarial Training,['adversarial training'],"[6, 3, 6, 5]","[4, 5, 4, 5]",0,"[416, 365, 124, 978]",Reject
Kx1VCs1treH,FourierNets enable the design of highly non-local optical encoders for computational imaging,"['computational microscopy', 'computational photography', 'computer vision', 'deep learning']","[6, 7, 7]","[5, 4, 3]",0,"[278, 629, 758]",Accept
gE1zBYKaEWW,Provable Subspace Identification Under Post-Nonlinear Mixtures,[],"[8, 7, 5, 6]","[3, 4, 3, 4]",0,"[277, 256, 261, 408]",Accept
atb3yifRtX,You Cant Count on Luck: Why Decision Transformers and RvS Fail in Stochastic Environments,"['representation learning', 'reinforcement learning', 'model-based reinforcement learning', 'decision transformer']","[7, 7, 4]","[4, 4, 4]",0,"[433, 532, 454]",Accept
4X0q4uJ1fR,Sample Constrained Treatment Effect Estimation,"['average treatment effect estimation', 'individual treatment effect estimation', 'experimental design', 'randomized numerical linear algebra', 'discrepancy minimization', 'causal inference']","[5, 7, 7]","[4, 3, 2]",0,"[360, 475, 341]",Accept
2ZfUNW7SoaS,Online Decision Mediation,"['Decision System', 'Decision Mediation', 'Decision Support']","[7, 5, 6]","[3, 4, 2]",0,"[292, 576, 241]",Accept
Hr8475tQGKE,Two-layer neural network on infinite dimensional data:  global optimization guarantee in the mean-field regime,"['mean-field regime', 'neural network', 'optimization', 'functional data analysis']","[6, 5, 9]","[2, 3, 3]",0,"[214, 352, 329]",Accept
uzqUp0GjKDu,Unsupervised Learning under Latent Label Shift,"['unsupervised learning', 'label shift', 'topic modeling', 'domain adaptation', 'mixture proportion estimation', 'unsupervised structure discovery', 'anchor word', 'deep learning']","[7, 5, 7, 7]","[4, 4, 3, 4]",0,"[234, 390, 631, 363]",Accept
syU-XvinTI1,No Free Lunch from Deep Learning in Neuroscience: A Case Study through Models of the Entorhinal-Hippocampal Circuit,"['neuroscience', 'deep learning', 'grid cells', 'path integration', 'representation learning']","[8, 7, 6, 6]","[2, 2, 4, 3]",0,"[435, 929, 259, 631]",Accept
907ZdmPmmH_,Are all Frames Equal? Active Sparse Labeling for Video Action Detection,"['active sparse labeling', 'video action detection']","[6, 6, 3, 7]","[4, 4, 5, 5]",0,"[771, 648, 242, 675]",Accept
OQs0pLKGGpS,Tractable Function-Space Variational Inference in Bayesian Neural Networks,"['Variational Inference', 'Bayesian Neural Networks', 'Uncertainty Quantification']","[7, 6, 4, 6]","[3, 3, 2, 4]",0,"[787, 252, 1424, 276]",Accept
B2PpZyAAEgV,Transform Once: Efficient Operator Learning in Frequency Domain,"['convolutions', 'long range dependencies', 'neural operators', 'high-resolution', 'frequency', 'transform', 'differential equation', 'dynamics', 'turbulence', 'fluid flows', 'PDE']","[3, 6, 7, 8]","[4, 4, 5, 4]",0,"[316, 276, 724, 505]",Accept
_3XVbh6L2c,Reinforcement Learning with Automated Auxiliary Loss Search,"['Reinforcement learning', 'Representation learning', 'Auxiliary Loss']","[5, 8, 7]","[4, 3, 5]",0,"[594, 466, 602]",Accept
u8FDFtoMKp2,Zero-shot Transfer Learning within a Heterogeneous Graph via Knowledge Transfer Networks,"['graph neural networks', 'heterogeneous graph', 'heterogeneous graph neural networks', 'transfer learning', 'domain adaptation']","[6, 6, 8, 7]","[4, 3, 4, 4]",0,"[177, 329, 246, 690]",Accept
9WJU4Lu2KTX,Uncertainty Estimation for Multi-view Data: The Power of Seeing the Whole Picture,[],"[3, 8, 6]","[4, 5, 4]",0,"[247, 939, 509]",Accept
D45iCWZYcff,Sub-exponential time Sum-of-Squares lower bounds for Principal Components Analysis,"['Sparse PCA', 'Sum of Squares', 'Tensor PCA', 'lower bounds']","[5, 7, 7, 7, 7]","[4, 4, 3, 5, 3]",0,"[811, 979, 790, 474, 395]",Accept
_h2FKc6E_YV,Rethinking and Scaling Up Graph Contrastive Learning: An Extremely Efficient Approach with Group Discrimination,"['Graph Contrastive Learning', 'Self-supervised Graph Representation Learning', 'Unsupervised Graph Representation Learning', 'Graph Representation Learning']","[7, 7, 6, 5]","[4, 4, 4, 5]",0,"[269, 548, 522, 685]",Accept
1X5zpwWoHwu,Nearly-Tight Bounds for Testing Histogram Distributions,"['distribution testing', 'histograms', 'binning', 'probability distributions', 'lower bounds', 'sub-linear algorithms']","[8, 7, 8, 6]","[4, 3, 4, 3]",0,"[382, 365, 325, 413]",Accept
EEcFW47sktI,Conditional Diffusion Process for Inverse Halftoning,[],"[6, 5, 3, 5]","[3, 3, 1, 2]",0,"[148, 185, 349, 845]",Accept
fbUybomIuE,Analyzing Lottery Ticket Hypothesis from PAC-Bayesian Theory Perspective,[],"[8, 7, 7, 3]","[5, 5, 3, 2]",0,"[491, 782, 508, 423]",Accept
WIJ2SfPTj8c,ISAAC Newton: Input-based Approximate Curvature for Newton's Method,[],"[7, 5, 5, 5]","[3, 4, 5, 2]",0,"[281, 625, 523, 277]",Reject
U2bAR6qzF9E,Self-Similarity Priors: Neural Collages as Differentiable Fractal Representations,"['implicit representations', 'compression', 'deep equilibrium models', 'generative models', 'fractal', 'fixed-point']","[6, 5, 5]","[2, 2, 3]",0,"[212, 532, 434]",Accept
_WqHmwoE7Ud,"PlasticityNet: Learning to Simulate Metal, Sand, and Snow for Optimization Time Integration","['neural network', 'plasticity', 'optimization-based time integrator']","[8, 7, 6, 6]","[4, 3, 3, 4]",0,"[392, 157, 626, 404]",Accept
-Zzi_ZmlDiy,Long-Form Video-Language Pre-Training with Multimodal Temporal Contrastive Learning,['video-language pre-training'],"[4, 4, 6, 7]","[4, 5, 3, 3]",0,"[260, 374, 264, 417]",Accept
vF3WefcoePW,Deep Differentiable Logic Gate Networks,"['logic gate', 'logic operator', 'differentiable', 'relaxation', 'continuous']","[8, 3, 8, 6]","[4, 4, 4, 4]",0,"[392, 779, 504, 791]",Accept
1GAjC_FauE,SemiFL: Semi-Supervised Federated Learning for Unlabeled Clients with Alternate Training,"['Federated Learning', 'Semi-Supervised Learning']","[3, 5, 5, 3]","[4, 4, 4, 4]",0,"[630, 397, 341, 266]",Accept
4JYq_Kw4zw,Non-Stationary Bandits under Recharging Payoffs: Improved Planning with Sublinear Regret,[],"[6, 7, 7]","[2, 3, 5]",0,"[252, 317, 118]",Accept
xNeAhc2CNAl,Extreme Compression for Pre-trained Transformers Made Simple and Efficient,"['Extreme Compression', 'Binary Quantization', 'Layer Reduction', 'BERT', 'Knowledge Distillation', 'Understanding Quantization', 'Empirical Investigation']","[6, 6, 6, 7]","[3, 4, 3, 3]",0,"[166, 430, 553, 380]",Accept
PwlW5Jri1Xt,Meta-Auto-Decoder for Solving Parametric Partial Differential Equations,"['Parametric PDE', 'Meta-learning', 'Auto-decoder', 'Physics-Informed Learning']","[6, 6, 6]","[3, 4, 3]",0,"[386, 359, 126]",Accept
zbt3VmTsRIj,Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees,"['Reinforcement Learning', 'Inverse Reinforcement Learning']","[6, 6, 5, 5]","[3, 3, 3, 4]",0,"[538, 393, 162, 696]",Accept
hk8v6BoKs-w,CoNSoLe: Convex Neural Symbolic Learning,"['Symbolic Regression', 'Physical Equations', 'Neural Networks', 'Convex Guarantees', 'Deep Q Learning']","[6, 6, 6, 7]","[3, 2, 2, 3]",0,"[1352, 478, 208, 363]",Accept
U138nQxHh3,Understanding and Improving Robustness of Vision Transformers through Patch-based Negative Augmentation,"['Robustness', 'Distributional shift', 'Vision transformers']","[5, 5, 7, 7]","[5, 3, 4, 4]",0,"[237, 189, 280, 555]",Accept
62GLWUoOLb5,Scalable Distributional Robustness in a Class of Non-Convex Optimization with Guarantees,"['distributional robustness', 'variance regularization', 'non-convex optimization', 'global optimization', 'fractional program', 'mixed-integer second order cone']","[7, 6, 7, 7]","[3, 2, 2, 1]",0,"[239, 199, 560, 461]",Accept
b8fgqTCBJe,Finding and Listing Front-door Adjustment Sets,"['causality', 'algorithm', 'adjustment']","[8, 6, 7, 7]","[4, 4, 4, 4]",0,"[287, 326, 655, 357]",Accept
9PQ13zJ1HME,Retaining Knowledge for Learning with Dynamic Definition,[],"[5, 8, 6, 6]","[4, 2, 3, 3]",0,"[758, 212, 661, 554]",Accept
j2Vtg_jhKZ,Transferring Pre-trained Multimodal Representations with Cross-modal Similarity Matching,[],"[5, 3, 6, 7, 5]","[3, 4, 3, 4, 4]",0,"[516, 359, 337, 473, 837]",Accept
Fh9l_pVsBfv,Gaussian Copula Embeddings,"['representation learning', 'gaussian copula', 'heterogeneous data', 'vectorial embedding', 'probabilistic models']","[5, 7, 7]","[3, 4, 3]",0,"[266, 198, 595]",Accept
pgBpQYss2ba,On the Complexity of Adversarial Decision Making,"['Decision making', 'learning theory', 'bandits', 'reinforcement learning theory', 'online learning', 'adversarial', 'non-stochastic', 'decision-estimation coefficient', 'information ratio']","[7, 6, 7]","[4, 3, 3]",0,"[613, 213, 298]",Accept
QPg5TTAdizy,Exploiting the Relationship Between Kendall's Rank Correlation and Cosine Similarity for Attribution Protection,[],"[7, 7, 7]","[3, 3, 3]",0,"[333, 512, 129]",Accept
UEhzUupXbL2,M2N: Mesh Movement Networks for PDE Solvers,"['Partial Differential Equation', 'Mesh Adaptation', 'Mesh Movement', 'Moving Mesh', 'r-Adaptation', 'MongeAmpere', 'Deep Learning', 'Neural Network', 'Neural Spline', 'Graph Attention Network']","[6, 4, 7, 4]","[2, 4, 3, 5]",0,"[209, 443, 276, 350]",Accept
zAuiZpZ478l,Hierarchical Lattice Layer for Partially Monotone Neural Networks,"['partially monotone regression', 'partially monotone neural networks', 'monotonicity constraints']","[7, 7, 7]","[4, 5, 3]",0,"[325, 725, 539]",Accept
cPVuuk1lZb3,Emergence of Hierarchical Layers in a Single Sheet of Self-Organizing Spiking Neurons,"['Spiking Neural Networks', 'Neuroscience', 'Neural Architecture Search', 'Self-organizing maps']","[7, 5, 8, 6]","[4, 5, 4, 4]",0,"[714, 406, 165, 247]",Accept
uuaMrewU9Kk,Skills Regularized Task Decomposition for Multi-task Offline Reinforcement Learning,"['mutli-task reinforcement learning', 'offline reinforcement learning', 'task inference', 'skill embedding']","[7, 7, 7]","[3, 5, 4]",0,"[533, 344, 389]",Accept
lNokkSaUbfV,Masked Autoencoding for Scalable and Generalizable Decision Making,"['reinforcement learning', 'unsupervised pretraining', 'zero-shot', 'transfer learning']","[7, 7, 8]","[3, 4, 4]",0,"[394, 380, 192]",Accept
cx5ViLfcVq,Information-Theoretic Analysis of Unsupervised Domain Adaptation,"['unsupervised domain adaptation', 'generalization', 'information theory', 'regularization']","[4, 4, 4, 6]","[4, 3, 4, 3]",0,"[169, 428, 487, 434]",Reject
iUOUnyS6uTf,STNDT: Modeling Neural Population Activity with Spatiotemporal Transformers,"['neuroscience', 'systems neuroscience', 'computational neuroscience', 'neural population dynamics', 'brain-computer interfaces', 'neuroprosthetics', 'electrophysiology', 'neural coding', 'transformers']","[6, 6, 4]","[4, 3, 4]",0,"[737, 190, 878]",Accept
rH-X09cB50f,Understanding Cross-Domain Few-Shot Learning Based on Domain Similarity and Few-Shot Difficulty,"['Cross-domain Few-shot Learning', 'Pre-training', 'Domain Similarity', 'Few-Shot Difficulty']","[5, 4, 5]","[4, 3, 4]",0,"[300, 315, 324]",Accept
JUXn1vXcrLA,ALMA: Hierarchical Learning for Composite Multi-Agent Tasks,"['multi-agent', 'MARL', 'RL', 'reinforcement learning', 'HRL', 'hierarchical reinforcement learning']","[6, 5, 7]","[5, 3, 3]",0,"[230, 320, 407]",Accept
nzuuao_V-B_,Foreseeing Privacy Threats from Gradient Inversion Through the Lens of Angular Lipschitz Smoothness,"['Federated Learning', 'Privacy Leakage', 'Gradient Inversion', 'Lipschitz Smoothness']","[3, 6, 2, 3]","[4, 4, 4, 4]",0,"[441, 266, 888, 730]",Reject
8LeCgKb6UX,Graph Reordering for Cache-Efficient Near Neighbor Search,"['near-neighbor search', 'embedding search', 'graph ordering', 'machine learning systems']","[6, 7, 6]","[3, 4, 4]",0,"[289, 410, 181]",Accept
H547BtAyOJ4,Integral Probability Metrics PAC-Bayes Bounds,"['PAC-Bayes', 'Learning Theory', 'Generalization bound']","[7, 7, 6, 6]","[4, 4, 4, 4]",0,"[324, 463, 328, 1057]",Accept
atd4X6U1jT,Human-AI Collaborative Bayesian Optimisation,"['Human-AI Teaming', 'Bayesian Optimisation', 'Bayesian Learning', 'Classification', 'Hyperparameter Optimisation', 'Kernel Methods']","[6, 6, 6]","[3, 2, 4]",0,"[305, 335, 449]",Accept
xqyDqMojMfC,Constrained Stochastic Nonconvex Optimization with State-dependent Markov Data,"['Constrained Optimization', 'Nonconvex Optimization', 'Projection-free Algorithm', 'Dependent Data', 'State-dependent Markov Data']","[4, 6, 6, 5]","[3, 2, 3, 3]",0,"[304, 198, 496, 244]",Accept
WbnvmtD9N1g,"Double Bubble, Toil and Trouble: Enhancing Certified Robustness through Transitivity","['certified robustness', 'adversarial', 'guarantees', 'adversarial defence', 'adversarial attack']","[6, 7, 6, 5]","[4, 3, 4, 3]",0,"[1341, 184, 776, 537]",Accept
WxWO6KPg5g2,Deep Surrogate Assisted Generation of Environments,"['Automatic Environment Generation', 'Surrogate Models', 'Quality Diversity Optimization']","[4, 3, 7, 7]","[3, 3, 4, 4]",0,"[149, 485, 472, 379]",Accept
MNQMy2MpbcO,Batch Multi-Fidelity Active Learning with Budget Constraints,"['Multi-Fidelity Active Learning', 'Budget Constrint', 'High-dimensional Outputs', 'Physical Simulation', 'Computational Physics']","[6, 7, 6, 6]","[3, 2, 3, 2]",0,"[370, 314, 641, 800]",Accept
2Ln-TWxVtf,Time-Conditioned Dances with Simplicial Complexes: Zigzag Filtration Curve based Supra-Hodge Convolution Networks for Time-series Forecasting,"['Multivariate time series', 'Graph neural networks', 'Zigzag persistent homology']","[6, 7, 6, 5]","[4, 3, 3, 3]",0,"[179, 82, 483, 356]",Accept
wN1CBFFx7JF,Theoretical analysis of deep neural networks for temporally dependent observations,[],"[6, 4, 5]","[2, 3, 4]",0,"[394, 84, 552]",Accept
sQ2LdeHNMej,Federated Hypergradient Descent,"['federated learning', 'hyperparameter tuning', 'hypergradient descent']","[6, 5, 5]","[3, 1, 3]",0,"[500, 248, 784]",Reject
ONFaDyl_uVq,Learning to Mitigate AI Collusion on Economic Platforms,"['Multi-agent Systems', 'Reinforcement Learning', 'Platform Design']","[4, 7, 5, 6]","[3, 2, 4, 4]",0,"[344, 521, 593, 142]",Accept
qSs7C7c4G8D,A Unified Analysis of Federated Learning with Arbitrary Client Participation,"['federated learning', 'partial client participation', 'convergence analysis']","[7, 7, 7]","[4, 4, 4]",0,"[326, 326, 659]",Accept
CF1ThuQ8vpG,Iterative Feature Matching: Toward Provable Domain Generalization with Logarithmic Environments,"['Domain generalization', 'out-of-distribution generalization', 'invariant risk minimization', 'IRM', 'deep learning theory', 'domain generalization theory']","[4, 5, 7]","[4, 3, 4]",0,"[138, 692, 1768]",Accept
yNPsd3oG_s,Training with More Confidence: Mitigating Injected and Natural Backdoors During Training,[],"[7, 5, 6]","[4, 4, 4]",0,"[396, 362, 899]",Accept
Z26xiZkbjgE,Why Robust Generalization in Deep Learning is Difficult: Perspective of Expressive Power,"['deep learning theory', 'adversarial robustness', 'robust generalization gap', 'expressive power']","[7, 6, 7]","[4, 3, 3]",0,"[246, 334, 435]",Accept
GdMqXQx5fFR,Few-shot Task-agnostic Neural Architecture Search for Distilling Large Language Models,"['Pre-trained Language Models', 'Knowledge Distillation', 'Neural Architecture Search']","[7, 7, 4]","[4, 4, 2]",0,"[280, 242, 434]",Accept
X5eFS09r9hm,Why Not Other Classes?: Towards Class-Contrastive Back-Propagation Explanations,"['explainable artificial intelligence', 'attribution explanations', 'contrastive explanations']","[6, 6, 4]","[3, 3, 4]",0,"[441, 505, 579]",Accept
R8Cngx78A-V,PAC: Assisted Value Factorization with Counterfactual Predictions in Multi-Agent Reinforcement Learning,"['reinforcement learning', 'Multi-agent reinforcement learning']","[6, 5, 5, 4]","[4, 4, 3, 3]",0,"[151, 371, 184, 514]",Accept
lTZBRxm2q5,Learning Fractional White Noises in Neural Stochastic Differential Equations,"['Neural Differential Equation', 'Neural Stochastic Differential Equation', 'Gaussian Process']","[7, 7, 3, 8, 4]","[4, 2, 4, 4, 3]",0,"[1663, 327, 722, 1470, 593]",Accept
Snp3iEj7NJ,On the Epistemic Limits of Personalized Prediction,"['Fairness', 'Accountability', 'and Transparency', 'Information Theory', 'Predictive Models']","[6, 5, 4]","[4, 3, 4]",0,"[696, 514, 381]",Accept
B4EsCSj1vQL,Deep Learning: When Conventional Wisdom Fails to be Wise,"['neural networks', 'deep learning', 'overparameterization', 'generalization', 'overfitting.']","[2, 3, 2, 2]","[5, 4, 5, 5]",0,"[439, 1620, 703, 248]",Reject
_ekGcr07Dsp,Meta-DMoE: Adapting to Domain Shift by Meta-Distillation from Mixture-of-Experts,"['Domain generalization', 'Mixture-of-Experts', 'Meta-learning', 'Knowledge distillation', 'Test-time adaptation']","[6, 6, 6]","[4, 4, 2]",0,"[210, 790, 219]",Accept
LvW71lgly25,Few-shot Relational Reasoning via Connection Subgraph Pretraining,"['Few-shot learning', 'knowledge graphs', 'graph neural networks', 'self-supervised pretraining']","[7, 7, 6]","[3, 3, 3]",0,"[668, 222, 176]",Accept
hq-p55-qil9,Associating Objects and Their Effects in Video through Coordination Games,[],"[4, 6, 7, 7]","[4, 3, 4, 3]",0,"[689, 188, 118, 447]",Accept
Gf5DxrgD2cT,Provably Efficient Model-Free Constrained RL with Linear Function Approximation,"['Reinforcement Learning Theory', 'Theory of Constrained Reinforcement Learning', 'Linear MDP', 'Model-free RL', 'Soft-max']","[7, 5, 7, 7]","[2, 3, 5, 3]",0,"[237, 233, 239, 570]",Accept
lYZQRpqLesi,Get More at Once: Alternating Sparse Training with Gradient Correction,"['Sparse training', 'Alternating training scheme']","[4, 6, 5, 5]","[3, 4, 4, 5]",0,"[270, 526, 471, 304]",Accept
zqQKGaNI4lp,Consistent Interpolating Ensembles via the Manifold-Hilbert Kernel,"['Ensemble methods', 'kernel methods', 'interpolation']","[5, 7, 7, 6]","[1, 2, 1, 1]",0,"[277, 377, 451, 170]",Accept
OQtY993Y4TV,Learning Symmetric Rules with SATNet,"['group equivariance', 'deep learning', 'MAXSAT', 'SATNet']","[7, 6, 8]","[4, 3, 4]",0,"[1212, 1126, 466]",Accept
Lz2N6UqRYqB,Off-Policy Evaluation for Episodic Partially Observable Markov Decision Processes under Non-Parametric Models,"['Off-Policy Evaluation', 'Non-parametric Instrumental Variable', 'Reinforcement Learning Theory', 'Ill-posedness']","[7, 7, 6]","[4, 2, 3]",0,"[187, 445, 219]",Accept
bhvUOhnsgZ,A simple but strong baseline for online continual learning: Repeated Augmented Rehearsal,"['continual learning', 'experience replay', 'online learning', 'forggetting', 'online continual learning']","[6, 7, 7, 5]","[4, 4, 4, 3]",0,"[524, 704, 326, 95]",Accept
w0O3F4cTNfG,Causal Discovery in Linear Latent Variable Models Subject to Measurement Error,"['Causal discovery', 'Measurement error', 'Latent variable models', 'Faithfulness', 'Structural identification']","[7, 6, 7]","[3, 4, 3]",0,"[419, 128, 446]",Accept
jtW73TIGnd,Maximum-Likelihood Quantum State Tomography by Soft-Bayes,[],"[4, 5, 4, 3]","[2, 4, 5, 4]",0,"[225, 279, 189, 363]",Reject
An5MaWw4L4I,Finite-Time Regret of Thompson Sampling Algorithms for Exponential Family Multi-Armed Bandits,"['Bandit algorithms', 'Thompson sampling', 'exponential family distribution', 'finite-time regret bound', 'minimax optimality', 'asymptotic optimality']","[7, 8, 3, 6]","[4, 4, 4, 4]",0,"[372, 544, 1382, 518]",Accept
o8nYuR8ekFm,PAC-Bayes Compression Bounds So Tight That They Can Explain Generalization,"['PAC-Bayes', 'Generalization', 'Compression', 'Generalization Bounds', 'PAC-Bayes Bounds', ""Occam's Razor"", 'Transfer Learning', 'Data-Dependent Priors']","[6, 7, 4, 4]","[3, 3, 3, 2]",0,"[867, 725, 230, 393]",Accept
LtJMqnbslJe,Fault-Aware Neural Code Rankers,"['program synthesis', 'code generation', 'AI for code']","[7, 6, 7]","[4, 4, 4]",0,"[482, 473, 365]",Accept
NYpU9BRODos,Accelerated Training of Physics-Informed Neural Networks (PINNs) using Meshless Discretizations,[],"[4, 8, 7]","[4, 4, 3]",0,"[436, 557, 802]",Accept
oR5WIUtsXmx,On the Frequency-bias of Coordinate-MLPs,"['Coordinate networks', 'implicit neural representations', 'implicit regularization']","[7, 6, 6, 5]","[3, 4, 3, 4]",0,"[549, 375, 332, 885]",Accept
2ndfW2bw4mi,Geodesic Self-Attention for 3D Point Clouds,"['Point Cloud', 'Geodesic', 'Attention', 'Transformer', 'Computer Vision.']","[4, 6, 6]","[4, 4, 3]",0,"[239, 251, 405]",Accept
I3mLa12s_H,Point Transformer V2: Grouped Vector Attention and Partition-based Pooling,"['3D Computer Vision', 'Point Cloud', 'Transformer']","[4, 5, 6, 6]","[4, 4, 4, 4]",0,"[401, 197, 376, 696]",Accept
avJW5-PRzV,A Simple Approach to Automated Spectral Clustering,[],"[6, 5, 7, 8]","[3, 4, 5, 5]",0,"[318, 424, 396, 563]",Accept
v_0F4IZJZw,Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models,"['language model', 'toxicity', 'ethics']","[6, 7, 6, 6]","[3, 3, 4, 4]",0,"[556, 256, 522, 672]",Accept
PfStAhJ2t1g,A Variational Edge Partition Model for Supervised Graph Representation Learning,"['probabilistic graph modeling', 'graph deep learning']","[7, 7, 7, 6]","[2, 3, 3, 4]",0,"[197, 262, 523, 748]",Accept
HZ20IYYAwah,Sparsity in Continuous-Depth Neural Networks,"['Neural ODEs', 'interpretability', 'sparsity', 'dynamical systems']","[5, 7, 6, 7]","[3, 3, 3, 2]",0,"[286, 881, 388, 142]",Accept
dSJuEcqmEIF,Invariant and Transportable Representations for Anti-Causal Domain Shifts,"['causality', 'spurious correlation', 'invariant prediction', 'domain shift', 'image classification', 'domain adaptation']","[6, 6, 7]","[3, 4, 4]",0,"[413, 361, 602]",Accept
Tean8bBjlbB,Transition to Linearity of General Neural Networks with Directed Acyclic Graph Architecture,"['wide neural networks', 'directed acyclic graph', 'transition to linearity', 'neural tangent kernel', 'over-parameterization']","[5, 6, 4, 4]","[5, 3, 4, 2]",0,"[150, 846, 944, 387]",Accept
xatjGRWLRO,Self-Supervised Pretraining for Large-Scale Point Clouds,"['Deep Learning', '3D Computer Vision', 'Self-supervised Learning']","[6, 6, 6]","[4, 3, 2]",0,"[552, 681, 429]",Accept
X82LFUs6g5Z,Cooperative Distribution Alignment via JSD Upper Bound,"['Unsupervised dataset alignment', 'Invertible flows']","[4, 6, 7, 5]","[4, 4, 4, 3]",0,"[320, 446, 868, 230]",Accept
3s9IrEsjLyk,Diffusion-LM Improves Controllable Text Generation,"['controllable text generation', 'controlled generation', 'infilling', 'language model', 'diffusion model']","[7, 8, 6, 7]","[5, 4, 3, 4]",0,"[322, 300, 393, 300]",Accept
JpZ5du_Kdh,The Stability-Efficiency Dilemma: Investigating Sequence Length Warmup for Training GPT Models,"['natural language processing', 'language model pre-training', 'autoregressive language model', 'training instability']","[8, 5, 6, 6]","[3, 5, 3, 4]",0,"[442, 753, 768, 824]",Accept
jdJo1HIVinI,Mixture-of-Experts with Expert Choice Routing,[],"[7, 6, 7, 7]","[5, 5, 5, 4]",0,"[286, 304, 559, 484]",Accept
peFP9Pl-6-_,Sampling in Constrained Domains with Orthogonal-Space Variational Gradient Descent,[],"[5, 6, 7, 6]","[2, 2, 4, 4]",0,"[116, 290, 688, 532]",Accept
HvJC_KsSx8S,Precise Learning Curves and Higher-Order Scalings for Dot-product Kernel Regression  ,"['Dot product kernel', 'NTK', 'NNGP', 'Marchenko-Pastur distribution', 'Learning Curves']","[6, 7, 5, 7, 6]","[2, 4, 2, 3, 4]",0,"[515, 768, 346, 386, 348]",Accept
l7aekTjF6CO,Is Sortition Both Representative and Fair?,"['computational social choice', 'sortition', 'fairness']","[5, 8, 7]","[4, 3, 4]",0,"[346, 616, 469]",Accept
pIYYJflkhZ,SoftPatch: Unsupervised Anomaly Detection with Noisy Data,"['Anomaly Detection', 'Noisy Label', 'Outlier Detection']","[4, 3, 7, 8]","[5, 5, 4, 4]",0,"[285, 639, 112, 176]",Accept
052QkenIdSI,Identifying good directions to escape the NTK regime and efficiently learn low-degree plus sparse polynomials ,"['deep learning theory', 'neural tangent kernel', 'beyond NTK', 'optimization landscape', 'learning polynomials']","[7, 6, 5]","[3, 4, 4]",0,"[398, 749, 345]",Accept
M34VHvEU4NZ,Weighted Distillation with Unlabeled Examples,"['distillation', 'importance reweighting']","[8, 3, 5, 5]","[4, 4, 4, 2]",0,"[1339, 288, 213, 267]",Accept
Ix37FJYDkBp,SemMAE: Semantic-Guided Masking for Learning Masked Autoencoders,"['Semantic-Guided Masking', 'Masked Autoencoders', 'Self-Supervised Learning', 'Semantic part learning']","[7, 3, 7]","[5, 4, 4]",0,"[473, 257, 433]",Accept
bQCOA4dq_T,Counterfactual Neural Temporal Point Process for Estimating Causal Influence of Misinformation on Social Media,"['Causal Inference', 'Temporal Point Process', 'Misinformation Influence', 'Counterfactual Analysis', 'Fake News', 'Social Media', 'Deep Learning']","[4, 6, 6]","[4, 4, 3]",0,"[436, 679, 763]",Accept
ZEQ5Gf8DiD,Compositional Generalization in Unsupervised Compositional Representation Learning: A Study on Disentanglement and Emergent Language,"['compositional generalization', 'generalization', 'compositionality', 'disentanglement', 'emergent Language', 'unsupervised representation learning', 'discrete representations']","[8, 6, 5, 6]","[4, 3, 2, 4]",0,"[296, 699, 396, 305]",Accept
jwVZZzzNKkW,Redundancy-Free Message Passing for Graph Neural Networks,"['redundancy-free', 'graph neural networks', 'graph similarity', 'over-squashing']","[5, 6, 7, 7]","[4, 3, 3, 4]",0,"[534, 409, 444, 369]",Accept
PIXGY1WgU-S,Few-Shot Audio-Visual Learning of Environment Acoustics,"['Audio-Visual Learning', 'RIR prediction']","[8, 5, 6, 8]","[3, 3, 4, 3]",0,"[335, 159, 347, 416]",Accept
Haj8_Rwqq_H,Incrementality Bidding via Reinforcement Learning under Mixed and Delayed Rewards,"['Learning to Bid', 'Incrementality Bidding', 'Reinforcement Learning']","[6, 7, 7, 7]","[2, 3, 4, 3]",0,"[315, 282, 306, 255]",Accept
k4KHXS6_zOV,Implicit Bias of Gradient Descent on Reparametrized Models: On Equivalence to Mirror Descent,"['implicit bias', 'gradient descent', 'mirror descent']","[5, 8, 6]","[4, 4, 3]",0,"[549, 381, 631]",Accept
x_HUcWi1aF1,Provably Efficient Offline Multi-agent Reinforcement Learning via Strategy-wise Bonus,"['multi-agent reinforcement learning', 'offline reinforcement learning', 'reinforcement learning theory']","[6, 7, 4]","[3, 3, 5]",0,"[467, 290, 171]",Accept
xp5VOBxTxZ,Understanding the Generalization Benefit of Normalization Layers: Sharpness Reduction,"['normalization', 'sharpness', 'gradient descent', 'scale-invariance', 'theoretical analysis', 'edge of stability']","[6, 6, 6, 6, 8]","[5, 3, 3, 1, 3]",0,"[548, 344, 514, 272, 358]",Accept
Qh89hwiP5ZR,Tree Mover's Distance: Bridging Graph Metrics and Stability of Graph Neural Networks,"['generalization of graph neural networks', 'stability', 'graph metrics']","[6, 7, 5, 6]","[4, 3, 4, 4]",0,"[650, 154, 271, 616]",Accept
FlrQGoHPcvo,Quantifying Statistical Significance of Neural Network-based Image Segmentation by Selective Inference,"['Image Segmentation', 'Uncertainty Quantification', 'Selective Inference', 'Statistical Hypothesis Testing', 'p-value']","[5, 6, 6]","[3, 3, 4]",0,"[154, 529, 513]",Accept
l5UNyaHqFdO,Adam Can Converge Without Any Modification On Update Rules,"['optimization', 'deep learning', 'adam']","[6, 6, 4, 8]","[4, 3, 5, 4]",0,"[361, 487, 668, 710]",Accept
S-Vig7pTRXq,When are Offline Two-Player Zero-Sum Markov Games Solvable?,"['zero-sum Markov game', 'offline reinforcement learning', 'reinforcement learning theory']","[8, 7, 6, 7]","[2, 4, 2, 3]",0,"[313, 219, 358, 516]",Accept
WljzqTo9xzw,Optimal Neural Network Approximations of Wasserstein Gradient Direction via Convex Optimization,"['Bayesian inference', 'Wasserstein gradient descent', 'neural networks', 'convex optimization']","[6, 6, 5, 5]","[3, 3, 3, 4]",0,"[481, 357, 510, 411]",Reject
mhQLcMjWw75,Federated Learning from Pre-Trained Models: A Contrastive Learning Approach,"['Federated Learning', 'Contrastive Learning', 'Pre-trained Models']","[6, 5, 8, 4]","[4, 3, 5, 4]",0,"[288, 313, 418, 252]",Accept
Xm9iN3UsdpH,Lower Bounds and Nearly Optimal Algorithms in Distributed Learning with Communication Compression,"['Distributed Learning', 'Communication Compression', 'Optimal Complexity', 'Non-convex Optimization']","[8, 7, 6]","[3, 4, 4]",0,"[1378, 301, 764]",Accept
b6to5kfFhQh,Left Heavy Tails and the Effectiveness of the Policy and Value Networks in DNN-based best-first search for Sokoban Planning,['rl'],"[8, 5, 7, 8]","[4, 4, 3, 3]",0,"[462, 472, 662, 252]",Accept
sOVNpUEgKMp,Learning Generalizable Models for Vehicle Routing Problems via Knowledge Distillation,"['learning to optimize', 'vehicle routing problem', 'knowledge distillation', 'generalization', 'combinatorial optimization']","[7, 5, 6, 5]","[4, 5, 3, 1]",0,"[274, 270, 269, 230]",Accept
N-PiuVbkEpp,Online Algorithms for the Santa Claus Problem,"['fair allocation', 'online algorithm', 'maxmin', 'random order model', 'optimal competitive ratio']","[6, 6, 6, 6]","[4, 4, 3, 4]",0,"[279, 394, 373, 512]",Accept
Y6xuQZP7t3,Invariance Learning based on Label Hierarchy,"['Invariance', 'out-of-distribution generalization', 'deep learning']","[6, 5, 5, 6]","[4, 5, 4, 4]",0,"[258, 479, 424, 672]",Accept
tUH1Or4xblM,Segmenting Moving Objects via an Object-Centric Layered Representation,"['motion segmentation', 'multi-object video segmentation', 'object-centric representation', 'layered representation', 'Transformer', 'Sim2Real generalisation']","[5, 5, 6, 6]","[4, 4, 4, 4]",0,"[774, 474, 338, 505]",Accept
n4wnZAdBavx,Efficient Multi-agent Communication via Self-supervised Information Aggregation,"['Multi-agent reinforcement learning', 'Communication', 'State representation learning']","[5, 7, 7]","[4, 4, 3]",0,"[639, 267, 1053]",Accept
DdxNka9tMRd,Global Convergence of Federated Learning for Mixed Regression,"['Federated Learning', 'clustering', 'global convergence', 'FedAvg', 'FedProx', 'empirical process']","[7, 7, 5]","[4, 4, 3]",0,"[244, 1005, 318]",Accept
5Ce7l5e_aGl,"Decentralized, Communication- and Coordination-free Learning in Structured Matching Markets","['Stable matching', 'Multi-armed bandits', 'Decentralized Algorithm']","[7, 7, 7, 5]","[1, 2, 4, 4]",0,"[123, 325, 393, 401]",Accept
eK8Z4Ydt2_b,Robust On-Policy Sampling for Data-Efficient Policy Evaluation in Reinforcement Learning,"['Reinforcement Learning', 'policy evaluation', 'on-policy', 'data collection']","[6, 8, 6, 4]","[3, 3, 3, 3]",0,"[293, 328, 772, 748]",Accept
dsxuTEf01d5,Dual-Curriculum Contrastive Multi-Instance Learning for Cancer Prognosis Analysis with Whole Slide Images,"['Prognosis Analysis', 'Whole Slide Images', 'Multi-Instance Learning', 'Curriculum Learning', 'Contrastive learning']","[7, 7, 6]","[3, 2, 3]",0,"[352, 319, 401]",Accept
l1WlfNaRkKw,A Theory of PAC Learnability under Transformation Invariances,"['transformation invariance', 'data augmentation', 'PAC learning', 'sample complexity']","[7, 8, 7]","[3, 3, 3]",0,"[413, 728, 381]",Accept
R2XFXfK0SVe,Private Graph All-Pairwise-Shortest-Path Distance Release with Improved Error Rate,"['All-Pairwise-Shortest-Path', 'Distance Release', 'Differential Privacy']","[7, 6, 6, 7]","[4, 3, 4, 4]",0,"[480, 494, 347, 934]",Accept
z64kN1h1-rR,"Why So Pessimistic? Estimating Uncertainties for Offline RL through Ensembles, and Why Their Independence Matters","['offline reinforcement learning', 'batch reinforcement learning', 'ensembles', 'uncertainty estimation']","[4, 5, 6, 8]","[4, 4, 3, 4]",0,"[1415, 223, 674, 731]",Accept
kgT6D7Z4Xv9,Path Independent Equilibrium Models Can Better Exploit Test-Time Computation,"['equilibrium models', 'attractor networks', 'test time compute', 'out of distribution generalization']","[4, 6, 6, 4]","[3, 2, 3, 3]",0,"[371, 373, 573, 820]",Accept
Qi4vSM7sqZq,Surprising Instabilities in Training Deep Networks and a Theoretical Analysis ,['Deep Learning Theory Stability Analysis'],"[5, 6, 5, 6]","[3, 3, 3, 3]",0,"[360, 235, 227, 319]",Accept
eNlaFpjpZf,Beyond the Return: Off-policy Function Estimation under User-specified Error-measuring Distributions,"['off-policy evaluation', 'marginalized importance sampling', 'finite-sample analyses']","[5, 6, 6]","[3, 4, 3]",0,"[285, 1175, 457]",Accept
LSKlp_aceOC,Merging Models with Fisher-Weighted Averaging,"['transfer learning', 'parameter averaging', 'ensembling']","[5, 5, 7, 6, 7]","[4, 4, 4, 4, 5]",0,"[408, 270, 570, 333, 733]",Accept
ttC9p-CtYT,Continuous Deep Q-Learning in Optimal Control Problems: Normalized Advantage Functions Analysis,"['continuous reinforcement learning', 'deep q-learning', 'optimal control problems', 'normalized advantage functions']","[5, 5, 6]","[3, 4, 4]",0,"[480, 794, 406]",Accept
AUJT3rj2F5U,Distributed Distributionally Robust Optimization with Non-Convex Objectives,[],"[6, 5, 5]","[4, 3, 3]",0,"[299, 172, 462]",Accept
GwwC16ECrM5,Energy-Based Contrastive Learning of Visual Representations,"['Energy-Based Models', 'Contrastive Learning']","[7, 6, 7]","[3, 5, 4]",0,"[435, 423, 532]",Accept
65eqtvEShR8,On the Statistical Efficiency of Reward-Free Exploration in Non-Linear RL,"['Reinforcement learning', 'reward-free exploration', 'sample complexity analysis', 'general non-linear function approximation']","[5, 5, 6, 7]","[3, 3, 3, 4]",0,"[559, 270, 597, 484]",Accept
2ge7_pORL_n,BiMLP: Compact Binary Architectures for Vision Multi-Layer Perceptrons,"['vision MLP', 'binary neural network', 'compact architecture', 'representation ability']","[4, 5, 6, 7]","[4, 3, 4, 4]",0,"[546, 188, 179, 357]",Accept
71ICQGB92Yz,Multi-block Min-max Bilevel Optimization with Applications in Multi-task Deep AUC Maximization,[],"[4, 7, 7, 8]","[4, 3, 3, 5]",0,"[462, 221, 1064, 318]",Accept
hPfJut2PeLa,Rethinking the Reverse-engineering of Trojan Triggers,['Backdoor/Trojan defense'],"[6, 7, 6, 6]","[4, 3, 4, 3]",0,"[464, 208, 245, 504]",Accept
EZZsnke1kt,Agreement-on-the-line: Predicting the Performance of Neural Networks under Distribution Shift,"['generalization', 'out-of-distribution generalization', 'robustness']","[7, 8, 7, 8]","[4, 4, 4, 4]",0,"[395, 546, 626, 730]",Accept
boItpVtQ14K,A Statistical Online Inference Approach in Averaged Stochastic Approximation,"['stochastic approximation', 'functional central limit theorem', 'statistical inference']","[6, 4, 7]","[3, 5, 5]",0,"[435, 466, 501]",Accept
I59qJ0sJ2nh,A Ranking Game for Imitation Learning,"['Imitation Learning', 'Inverse Reinforcement Learning', 'Deep Reinforcement Learning', 'Robotics', 'Robot Learning']","[5, 6, 7, 6, 5]","[4, 3, 3, 2, 4]",0,"[425, 633, 205, 497, 721]",Reject
diV1PpaP33,Beyond Not-Forgetting: Continual Learning with Backward Knowledge Transfer,[],"[4, 4, 5, 7]","[5, 3, 2, 3]",0,"[689, 844, 91, 600]",Accept
prQkA_NjuuB,Neural Conservation Laws: A Divergence-Free Perspective,"['density estimation', 'automatic differentiation', 'generative modeling', 'optimal transport maps', 'structured deep learning']","[7, 5, 7]","[2, 2, 3]",0,"[482, 381, 992]",Accept
MjaROj4BOwk,Sparse Hypergraph Community Detection Thresholds in Stochastic Block Model,"['community detection', 'hypergraph stochastic block model', 'Kesten-Stigun threshold']","[6, 7, 4]","[3, 4, 3]",0,"[298, 277, 614]",Accept
4NpoSrT8uU-,Deep Bidirectional Language-Knowledge Graph Pretraining,"['pretraining', 'language model', 'knowledge graph', 'question answering', 'commonsense', 'reasoning', 'foundation model', 'self-supervised learning', 'biomedical']","[8, 6, 5]","[4, 4, 3]",0,"[309, 437, 820]",Accept
toR64fsPir,Structure-Preserving Embedding of Multi-layer Networks,"['Community detection', 'latent space model', 'multi-layer network', 'network embedding', 'tensor decomposition']","[4, 7, 5]","[3, 4, 4]",0,"[239, 489, 349]",Reject
u6GIDyHitzF,An Asymptotically Optimal Batched Algorithm for the Dueling Bandit Problem,[],"[6, 6, 6]","[3, 4, 4]",0,"[270, 219, 870]",Accept
Cl9dcH6Xkcj,Faster Deep Reinforcement Learning with Slower Online Network,[],"[7, 6, 8]","[3, 4, 4]",0,"[232, 656, 204]",Accept
mhp4wLwiAI-,Old can be Gold: Better Gradient Flow can Make Vanilla-GCNs Great Again,"['Deep Graph Neural Networks', 'Gradient Flow', 'Initialization', 'Isometric Learning']","[3, 5, 4, 8]","[4, 5, 2, 4]",0,"[294, 320, 261, 377]",Accept
_h29VprPHD,Offline Goal-Conditioned Reinforcement Learning via $f$-Advantage Regression,"['offline reinforcement learning', 'goal-conditioned reinforcement learning', 'deep reinforcement learning']","[7, 8, 5, 8]","[4, 4, 4, 4]",0,"[1030, 400, 589, 668]",Accept
3yO3MiSOkH4,Graph Few-shot Learning with Task-specific Structures,"['Graph Neural Networks', 'Few-shot Learning', 'Graph Mining']","[5, 6, 6, 6]","[4, 3, 2, 5]",0,"[308, 385, 166, 1132]",Accept
XY5g3mkVge,Pre-Trained Model Reusability Evaluation for Small-Data Transfer Learning,"['transfer learning', 'metric learning', 'meta-learning']","[5, 6, 6]","[3, 3, 2]",0,"[238, 373, 293]",Accept
M-seILmeISn,Tight Mutual Information Estimation With Contrastive Fenchel-Legendre Optimization,"['mutual information', 'variational inference', 'contrastive learning', 'few-shot learning', 'meta learning']","[8, 8, 6, 5]","[5, 2, 3, 3]",0,"[760, 239, 199, 794]",Accept
nyn2ewuF-g9,Trade-off between Payoff and Model Rewards in Shapley-Fair Collaborative Machine Learning,"['collaborative machine learning', 'model reward', 'payoff reward', 'Shapley value']","[6, 6, 4, 7, 5]","[4, 4, 4, 3, 2]",0,"[353, 683, 542, 284, 299]",Accept
W8nyVJruVg,Minimax-Optimal Multi-Agent RL in Markov Games With a Generative Model,"['Markov games', 'sample complexity', 'Nash equilibrium', 'coarse correlated equilibrium', 'adversarial learning', 'Follow-the-Regularized-Leader']","[7, 7, 7]","[3, 4, 3]",0,"[179, 624, 184]",Accept
QYQH9w9Z8bO,Effects of Data Geometry in Early Deep Learning,"['Deep learning', 'geometry', 'manifolds', 'deep learning theory']","[5, 7, 6, 6]","[3, 1, 2, 3]",0,"[833, 220, 329, 998]",Accept
gt-l9Hu2ndd,Model Preserving Compression for Neural Networks,"['interpolative decomposition', 'compression', 'neural network']","[5, 8, 2]","[2, 4, 5]",0,"[255, 182, 333]",Accept
f-FQE1fjPK,NSNet: A General Neural Probabilistic Framework for Satisfiability Problems,"['satisfiability problems', 'model counting', 'graphical model', 'Belief Propagation', 'graph neural network', 'marginal inference', 'partition function estimation']","[5, 3, 7, 6]","[5, 4, 4, 3]",0,"[630, 157, 544, 756]",Accept
_QzJJGH_KE,RORL: Robust Offline Reinforcement Learning via Conservative Smoothing,"['Offline reinforcement learning', 'robust reinforcement learning', 'adversarial attack']","[6, 6, 6, 5]","[3, 4, 3, 4]",0,"[157, 299, 497, 521]",Accept
RBhIkQRpzFK,GraphQNTK: Quantum Neural Tangent Kernel for Graph Data,[],"[4, 7, 5]","[2, 4, 3]",0,"[535, 602, 155]",Accept
AYII8AkvD1e,Diffusion Curvature for Estimating Local Curvature in High Dimensional Data,"['local curvature estimation', 'neural network loss landscape', 'diffusion']","[5, 3, 5, 6]","[4, 5, 3, 4]",0,"[600, 505, 270, 486]",Accept
JkEz1fqN3hX,Rethinking Value Function Learning for Generalization in Reinforcement Learning,['RL generalization'],"[6, 5, 7]","[4, 4, 4]",0,"[685, 492, 307]",Accept
XZhipvOUBB,LISA: Learning Interpretable Skill Abstractions from Language,"['Imitation Learning', 'Natural language processing', 'compositional representation learning']","[6, 6, 6, 6]","[4, 3, 4, 4]",0,"[290, 479, 592, 910]",Accept
vNrSXIFJ9wz,"VF-PS: How to Select Important Participants in Vertical Federated Learning, Efficiently and Securely?","['Vertical federated learning', 'participant valuation', 'participant selection', 'mutual information']","[7, 6, 6]","[3, 3, 3]",0,"[266, 179, 316]",Accept
xjXN3wEvCGG,Surprise-Guided Search for Learning Task Specifications From Demonstrations,"['Learning from Demonstrations', 'Specification Mining', 'Markov Decision Process', 'Inverse Reinforcement Learning', 'Formal Methods', 'Symbolic Learning']","[6, 6, 3]","[3, 3, 1]",0,"[585, 812, 152]",Reject
jWgGtPmi8c,Outlier-Robust Sparse Mean Estimation for Heavy-Tailed Distributions,"['sparse estimation', 'robust statistics', 'heavy-tailed estimation']","[6, 4, 5, 3, 7]","[4, 4, 1, 4, 4]",0,"[677, 224, 116, 584, 979]",Accept
-76EsjcHnbj,Instance-Dependent Policy Learning for Linear MDPs via Online Experiment Design,"['reinforcement learning', 'reinforcement learning theory', 'sequential decision making', 'function approximation', 'PAC', 'instance-dependence']","[6, 8, 8]","[4, 4, 3]",0,"[435, 696, 246]",Accept
fARM4P0gAJV,Explainable Spatio-Temporal Forecasting with Shape Functions,"['Spatio-temporal Forecasting', 'Shape Function', 'Spatial Weight Matrix']","[6, 7, 4]","[4, 3, 4]",0,"[392, 294, 258]",Reject
suHUJr7dV5n,On the Convergence Theory for Hessian-Free Bilevel Algorithms,"['Convergence Rate', 'Computational Complexity', 'Jacobian Matrix', 'Stochastic Algorithm', 'Bilevel Optimization']","[7, 5, 7, 7]","[3, 5, 3, 4]",0,"[259, 470, 444, 502]",Accept
wo-a8Ji6s3A,Asymptotic Behaviors of Projected Stochastic Approximation: A Jump Diffusion Perspective,"['Diffusion Approximation', 'Federated Learning', 'Loopless Algorithm', 'Jump Diffusion', 'Bias-variance Tradeoff', 'Asymptotic Normal', 'Asymptotic Biased']","[7, 6, 8]","[2, 2, 3]",0,"[249, 269, 216]",Accept
5hgYi4r5MDp,Recall Distortion in Neural Network Pruning and the Undecayed Pruning Algorithm,[],"[7, 6, 5]","[4, 3, 2]",0,"[1021, 343, 264]",Accept
_cFdPHRLuJ,Curriculum Reinforcement Learning using Optimal Transport via Gradual Domain Adaptation,"['reinforcement learning', 'curriculum learning', 'domain adaptation']","[5, 6, 6, 7]","[4, 3, 2, 3]",0,"[451, 627, 139, 395]",Accept
jqzoJw7xamd,TaSIL: Taylor Series Imitation Learning,"['learning theory', 'control theory', 'nonlinear systems', 'imitation learning']","[6, 7, 4, 5]","[2, 4, 3, 4]",0,"[245, 214, 598, 600]",Accept
LdKdbHw3A_6,A Unifying Framework of Off-Policy General Value Function Evaluation,"['general value function', 'general Bellman operation', 'off-policy evaluation']","[6, 5, 5, 7]","[3, 2, 2, 2]",0,"[417, 339, 495, 467]",Accept
CHMJSfuIX8,Using Embeddings for Causal Estimation of Peer Influence in Social Networks,"['causality', 'peer contagion', 'social networks', 'embeddings']","[7, 5, 7, 7]","[4, 3, 3, 3]",0,"[462, 669, 270, 569]",Accept
qw3MZb1Juo,Preservation of the Global Knowledge by Not-True Distillation in Federated Learning,"['deep learning', 'federated learning', 'continual learning', 'knowledge distillation']","[7, 4, 5]","[4, 4, 3]",0,"[390, 290, 216]",Accept
lIeuKiTZsLY,Latent Hierarchical Causal Structure Discovery with Rank Constraints,"['Latent hierarchical causal structure identification', 'Rank deficiency constraint']","[7, 4, 8]","[3, 3, 4]",0,"[303, 203, 1441]",Accept
drVX99PekKf,Bandit Theory and Thompson Sampling-Guided Directed Evolution for Sequence Optimization,"['optimization', 'evolution', 'bandit', 'regret', 'Thompson sampling']","[5, 5, 6, 7]","[4, 5, 2, 3]",0,"[1679, 837, 130, 347]",Accept
rg_yN3HpCp,Label-invariant Augmentation for Semi-Supervised Graph Classification,"['Graph Contrastive Learning', 'Semi-supervised Classification']","[6, 7, 6]","[4, 3, 4]",0,"[224, 229, 457]",Accept
uLhKRH-ovde,A Communication-Efficient Distributed Gradient Clipping Algorithm for Training Deep Neural Networks,"['Distributed Training', 'Gradient Clipping', 'Communication-Efficient', 'Optimization']","[5, 5, 4, 5]","[4, 4, 4, 4]",0,"[424, 232, 246, 980]",Accept
_sQ6pLNVHoh,Task-Agnostic Graph Explanations,"['Graph neural networks', 'explainability', 'task-agnostic']","[6, 7, 6, 6]","[3, 4, 5, 3]",0,"[284, 441, 737, 271]",Accept
AyiiHcRzTd,Communication-Efficient Topologies for Decentralized Learning with $O(1)$ Consensus Rate,"['Decentralized optimization', 'network topologies', 'maximum degree', 'consensus rate', 'communication-efficient']","[7, 5, 6]","[5, 3, 3]",0,"[333, 102, 415]",Accept
LCOv-GVVDkp,Human-AI Shared Control via Policy Dissection,"['Human-AI interaction', 'Interpetability', 'Decision and Control']","[6, 4, 4, 7]","[4, 3, 2, 4]",0,"[734, 409, 128, 487]",Accept
AWeZdGJ89lC,QC-StyleGAN - Quality Controllable Image Generation and Manipulation,"['StyleGAN', 'GAN Inversion', 'Image restoration', 'Image Generation', 'Image Manipulation', 'Image Editing', 'Degradation Synthesis']","[7, 5, 6, 4]","[2, 5, 4, 3]",0,"[206, 414, 230, 322]",Accept
8gQEmEgWAkc,VoiceBlock: Privacy through Real-Time Adversarial Attacks with Audio-to-Audio Models,"['privacy', 'adversarial examples', 'speech', 'speaker recognition']","[7, 7, 8]","[4, 4, 3]",0,"[611, 193, 539]",Accept
NSophzmqq8Y,Kernel similarity matching with Hebbian networks,"['Hebbian learning', 'kernel similarity matching', 'similarity matching']","[6, 7, 6, 6]","[2, 5, 2, 3]",0,"[194, 380, 341, 308]",Accept
G25uStbmC7,OPEN: Orthogonal Propagation with Ego-Network Modeling,"['Graph Neural Network', 'ego-network', 'propagation scheme']","[5, 4, 7]","[1, 3, 3]",0,"[189, 298, 359]",Accept
8uiblU3fEjE,Embedding game: dimensionality reduction as a two-person zero-sum game,"['manifold learning', 'game theory', 'embedding', 'nonlinear dimensionality reduction']","[3, 2, 4]","[4, 3, 4]",0,"[609, 181, 268]",Reject
VBbxHvbJd94,An efficient graph generative model for navigating ultra-large combinatorial synthesis libraries,[],"[5, 7, 6]","[2, 4, 3]",0,"[491, 428, 450]",Accept
YUEP3ZmkL1,Your Out-of-Distribution Detection Method is Not Robust!,"['Out-of-distribution Detection', 'Adversarial Robustness', 'Attack']","[3, 7, 6, 6]","[4, 4, 4, 4]",0,"[280, 397, 849, 254]",Accept
OrcLKV9sKWp,Prunings Effect on Generalization Through the Lens of Training and Regularization,"['pruning', 'generalization', 'empirical deep learning']","[7, 6, 6]","[5, 3, 4]",0,"[1102, 406, 339]",Accept
xbJAITw9Z6t,Stacked unsupervised learning with a network architecture found by supervised meta-learning,"['stacked unsupervised learning', 'meta-learning', 'unsupervised clustering']","[5, 5, 6]","[3, 4, 4]",0,"[352, 221, 419]",Reject
MOGt8ZizQJL,Quantile Constrained Reinforcement Learning: A Reinforcement Learning Framework Constraining Outage Probability,"['Reinforcement Learning', 'Reinforcement Learning Theory', 'Constrained Reinforcement Learning', 'Safe Reinforcement Learning']","[7, 6, 7, 5]","[3, 4, 5, 3]",0,"[489, 386, 325, 355]",Accept
iWg5LjFbeT_,Branch & Learn for Recursively and Iteratively Solvable Problems in Predict+Optimize,[],"[6, 5, 6, 7]","[1, 3, 3, 3]",0,"[98, 297, 478, 960]",Accept
TIQfmR7IF6H,Minimax Optimal Algorithms for Fixed-Budget Best Arm Identification,"['Best Arm Identification', 'Online Learning']","[7, 6, 4, 7]","[4, 3, 4, 4]",0,"[653, 649, 411, 145]",Accept
sFapsu4hYo,Exposing and Exploiting Fine-Grained Block Structures for Fast and Accurate Sparse Training,['sparse training'],"[5, 6, 4, 6]","[3, 3, 4, 4]",0,"[355, 282, 443, 404]",Accept
A7l8WZIKz3,Model-Based Opponent Modeling,"['multi-agent reinforcement learning', 'opponent modeling']","[4, 7, 6, 3]","[4, 4, 4, 4]",0,"[471, 236, 752, 1694]",Accept
AKM3C3tsSx3,A General Framework for Auditing Differentially Private Machine Learning,"['differential privacy', 'privacy evaluation', 'private machine learning']","[6, 6, 6]","[3, 3, 4]",0,"[290, 253, 465]",Accept
ObgXE0EMIqH,Non-Linguistic Supervision for Contrastive Learning of Sentence Embeddings,[],"[6, 6, 4, 5, 8]","[3, 3, 4, 4, 4]",0,"[221, 317, 300, 301, 817]",Accept
u6p_NvZ23qt,A Non-Asymptotic Moreau Envelope Theory for High-Dimensional Generalized Linear Models,[],"[7, 6, 6]","[3, 2, 3]",0,"[313, 480, 300]",Accept
Vc4QUfqr4do,ACIL: Analytic Class-Incremental Learning with Absolute Memorization and Privacy Protection,"['Class incremental learning', 'absolute memorization', 'exemplar-free', 'privacy protection', 'recursive', 'large-phase']","[8, 7, 7]","[3, 4, 3]",0,"[263, 355, 207]",Accept
f_kvHrM4Q0,Co-Modality Graph Contrastive Learning  for Imbalanced Node Classification,"['graph neural network', 'multi-modal learning', 'graph contrastive learning']","[8, 5, 5]","[4, 4, 4]",0,"[659, 289, 230]",Accept
QMrs1nggaL,Faster and Scalable Algorithms for Densest Subgraph and Decomposition,"['densest subgraph', 'densest subgraph decomposition', 'scalable algorithms', 'supermodular', 'densest supermodular set', 'proximal gradient method']","[7, 7, 7, 7]","[2, 3, 2, 4]",0,"[160, 259, 147, 338]",Accept
SCD0hn3kMHw,In What Ways Are Deep Neural Networks Invariant and How Should We Measure This?,"['Invariance and equivariance', 'augmentation training', 'out-of-distribution generalization']","[5, 6, 7, 7]","[4, 3, 4, 4]",0,"[1222, 792, 1558, 607]",Accept
u6OfmaGIya1,Second Thoughts are Best: Learning to Re-Align With Human Values from Text Edits,"['human values', 'ai safety', 'alignment', 'social impact', 'human-AI interaction']","[6, 5, 7, 5]","[4, 3, 3, 3]",0,"[468, 369, 218, 733]",Accept
PRd7VG_ki_,FourierFormer: Transformer Meets Generalized Fourier Integral Theorem,"['transformers', 'fourier integral', 'nonparametric kernel regression']","[8, 5, 6, 6]","[4, 4, 3, 4]",0,"[249, 257, 395, 302]",Accept
CwQCeJnteii,Decision-based Black-box Attack Against Vision Transformers via Patch-wise Adversarial Removal,"['Adversarial attack', 'Black-box attack', 'Decision-based attack', 'Vision transformer']","[6, 5, 6, 6]","[4, 3, 2, 3]",0,"[400, 377, 251, 319]",Accept
oWqWiazEb62,Calibrated Data-Dependent Constraints with Exact Satisfaction Guarantees,[],"[7, 7, 7]","[3, 4, 3]",0,"[941, 490, 317]",Accept
msFfpucKMf,Robust Option Learning for Adversarial Generalization,"['Reinforcement Learning', 'Options', 'Generalization']","[6, 3, 3]","[5, 3, 3]",0,"[448, 736, 918]",Reject
h8Bd7Gm3muB,Efficient Dataset Distillation using Random Feature Approximation,[],"[6, 6, 7]","[3, 4, 4]",0,"[706, 551, 250]",Accept
8qugS9JqAxD,On the Symmetries of Deep Learning Models and their Internal Representations,"['symmetry in deep learning', 'representation learning', 'representation similarity']","[6, 7, 7]","[2, 4, 4]",0,"[549, 499, 1295]",Accept
CwG-o0ind6t,Non-identifiability and the Blessings of Misspecification in Models of Molecular Fitness,"['identifiability', 'misspecification', 'robustness', 'proteins', 'phylogenetics']","[7, 9, 7, 7]","[1, 4, 4, 4]",0,"[382, 315, 160, 736]",Accept
A7O7Fl5Qo9W,On the Sample Complexity of Stabilizing LTI Systems on a Single Trajectory,"['linear time-invariant systems', 'sample complexity', 'stability', 'learning-based control']","[6, 6, 6, 5]","[3, 4, 5, 4]",0,"[321, 333, 892, 414]",Accept
uxWr9vEdsBh,A Lagrangian Duality Approach to Active Learning,"['Active Learning', 'Lagrangian Duality', 'Constrained Learning', 'Convex Optimization']","[7, 7, 7, 5]","[3, 4, 3, 3]",0,"[667, 633, 152, 391]",Accept
Ypp6z77A6_,Fast Bayesian Estimation of Point Process Intensity as Function of Covariates,"['Point Process', 'Gaussian Cox Process', 'Kernel method', 'Permanental Process', 'Gaussian Process']","[3, 7, 5, 5, 5]","[4, 4, 2, 3, 4]",0,"[209, 414, 519, 307, 327]",Accept
z0M3qHDqH20,HUMUS-Net: Hybrid Unrolled Multi-scale Network Architecture for Accelerated MRI Reconstruction,"['Vision Transformers', 'MRI reconstruction', 'inverse problems', 'deep learning', 'fastMRI']","[5, 7, 5, 6]","[4, 3, 4, 4]",0,"[521, 159, 651, 370]",Accept
pBz3h8VibKY,Interaction-Grounded Learning with Action-inclusive Feedback,"['interaction-grounded learning', 'interactive machine learning', 'reinforcement learning', 'contextual bandits', 'human-AI interaction']","[5, 7, 4]","[2, 1, 3]",0,"[426, 417, 698]",Accept
PGQrtAnF-h,Identifiability of deep generative models without auxiliary information,"['deep generative models', 'variational autoencoders', 'identifiability', 'nonparametric statistics', 'latent variable models', 'representation learning']","[8, 7, 6]","[3, 2, 2]",0,"[717, 425, 363]",Accept
2clwrA2tfik,Dataset Distillation using Neural Feature Regression,"['Deep Learning', 'Dataset Distillation', 'Bi-Level Optimization', 'Meta Learning', 'Continual Learning', 'Privacy-Preserving']","[7, 8, 7, 7]","[2, 5, 4, 3]",0,"[193, 721, 301, 432]",Accept
0SgKq4ZC9r,Decomposed Knowledge Distillation for Class-Incremental Semantic Segmentation,"['class-incremental learning', 'continual learning', 'incremental learning', 'semantic segmentation']","[6, 4, 6]","[4, 4, 5]",0,"[275, 385, 601]",Accept
YsRH6uVcx2l,On Learning Fairness and Accuracy on Multiple Subgroups,"['algorithmic fairness', 'deep learning', 'social aspects of machine learning']","[7, 8, 7, 5]","[4, 5, 3, 3]",0,"[670, 431, 239, 746]",Accept
IILJ0KWZMy9,Low-rank lottery tickets: finding efficient low-rank neural networks via matrix differential equations,"['Neural Network Compression', 'Low Rank Matrices', 'Dynamical Low Rank Approximation', 'Neural Network Training', 'Pruning']","[6, 7, 4]","[4, 4, 5]",0,"[739, 177, 626]",Accept
hzbguA9zMJ,"If Influence Functions are the Answer, Then What is the Question?","['Influence Function', 'Interpretability']","[6, 7, 6, 7]","[4, 4, 2, 5]",0,"[261, 289, 312, 453]",Accept
NYF6jNTAui,Locally Hierarchical Auto-Regressive Modeling for Image Generation,[],"[4, 7, 6]","[4, 4, 5]",0,"[508, 414, 639]",Accept
exDlhqs1Qr,Amortized Proximal Optimization,"['second-order optimization', 'learning rate adaptation', 'proximal point method', 'meta-learning']","[7, 7, 7]","[4, 5, 3]",0,"[488, 533, 829]",Accept
JXY11Tc9mwY,Submodular Maximization in Clean Linear Time,"['Submodular maximization', 'query complexity', 'cardinality constraint', 'Knapsack constraint', 'p-set system constraint', 'information-theoretic lower bound']","[8, 6, 6, 4]","[3, 4, 3, 4]",0,"[250, 505, 380, 431]",Accept
L2Niz4Olng,MMC Transformer: Multiscale Multigrid Comparator Transformer for Few-Shot Video Segmentation,"['few-shot video segmentation', 'video object segmentation', 'few-shot learning', 'actor/action segmentation']","[4, 4, 7, 3]","[3, 3, 4, 3]",0,"[616, 113, 337, 401]",Reject
rOimdw0-sx9,Distributionally Adaptive Meta Reinforcement Learning,"['Meta reinforcement learning', 'Distributional robustness']","[4, 5, 7, 6]","[4, 3, 5, 4]",0,"[829, 871, 932, 320]",Accept
Nx4gNemvNvx,Byzantine-tolerant federated Gaussian process regression for streaming data,"['Security', 'federated learning', 'Gaussian process regression', 'Byzantine resilience']","[6, 5, 5]","[5, 4, 3]",0,"[158, 727, 301]",Accept
uAIQymz0Qp,DMAP: a Distributed Morphological Attention Policy for learning to locomote with a changing body,"['Computational Neuroscience', 'Reinforcement learning', 'Sensorimotor learning', 'Motor adaptation', 'Motor learning', 'Morphology Perturbations']","[7, 7, 7, 7]","[4, 4, 4, 4]",0,"[356, 663, 436, 488]",Accept
jRrpiqxtrWm,Simplified Graph Convolution with Heterophily,"['graph', 'network', 'convolution', 'homophily', 'heterophily', 'disassortative', 'classification']","[6, 3, 4, 5]","[3, 4, 4, 4]",0,"[255, 423, 329, 302]",Accept
ANkIj-WI2XA,Learning Generalized Policy Automata for Relational Stochastic Shortest Path Problems,"['Generalization', 'Sequential Decision Making', 'Transfer Learning', 'Stochastic Shortest Path Problems', 'Relational Abstractions', 'Model-based Policy Learning']","[7, 8, 7, 7]","[5, 4, 3, 3]",0,"[825, 553, 544, 571]",Accept
GbpEszOdiTV,A Combinatorial Perspective on the Optimization of Shallow ReLU Networks,"['ReLU', 'zonotope', 'combinatorial', 'optimization']","[6, 5, 5, 7]","[2, 4, 3, 4]",0,"[160, 221, 463, 466]",Accept
PPlAVQDeL6,Physics-Informed Implicit Representations of Equilibrium Network Flows,"['network flow estimation', 'implicit neural networks', 'contraction theory']","[5, 5, 7, 5]","[4, 2, 4, 3]",0,"[487, 126, 244, 211]",Accept
eHePKMLuNmy,Revisiting Optimal Convergence Rate for Smooth and Non-convex Stochastic Decentralized Optimization,"['decentralized optimization', 'stochastic optimization', 'non-convex optimization', 'optimal complexity']","[7, 7, 5, 6]","[2, 4, 3, 5]",0,"[165, 515, 565, 715]",Accept
MXX18i8puEk,Nest Your Adaptive Algorithm for Parameter-Agnostic Nonconvex Minimax Optimization,"['Nonconvex optimization', 'minimax optimization', 'adaptive algorithm']","[6, 7, 5]","[3, 2, 2]",0,"[988, 221, 388]",Accept
4n1PS9WvdYv,On Deep Generative Models for Approximation and Estimation of Distributions on Manifolds,"['Deep generative models', 'distribution estimation', 'low-dimensional manifold']","[6, 7, 7, 6, 7]","[4, 3, 3, 1, 3]",0,"[594, 761, 605, 481, 183]",Accept
sjaQ2bHpELV,Online Reinforcement Learning for Mixed Policy Scopes,"['Causal inference', 'Reinforcement Learning', 'Graphical Models']","[7, 5, 6, 7]","[2, 3, 2, 2]",0,"[273, 348, 439, 174]",Accept
VVsNTPK1FBp,Diversified Recommendations for Agents with Adaptive Preferences,"['online learning', 'bandits', 'convex optimization', 'recommender systems', 'fairness']","[5, 5, 7, 7]","[3, 1, 4, 1]",0,"[140, 356, 389, 486]",Accept
df1g_KeEjQ,VectorAdam for Rotation Equivariant Geometry Optimization,"['adam', 'optimizer', 'geometry optimization']","[5, 7, 8, 4]","[4, 4, 3, 3]",0,"[389, 452, 361, 404]",Accept
WaKGmSI2-8g,Scalable design of Error-Correcting Output Codes using Discrete Optimization with Graph Coloring,"['Error-Correcting Output Codes', 'Graph Coloring', 'Discrete optimization', 'classification', 'transfer-learning']","[8, 6, 6]","[4, 4, 2]",0,"[349, 1182, 422]",Accept
lhLEGeBC-ru,Polynomial time guarantees for the Burer-Monteiro method,"['Semidefinite programming', 'Burer-Monteiro', 'Low rank factorization']","[7, 7, 7, 8]","[3, 2, 2, 4]",0,"[608, 658, 188, 829]",Accept
PM5gVmG2Jj,Conformal Prediction with Temporal Quantile Adjustments,"['conformal prediction', 'time series forecasting', 'cross-sectional data', 'time series regression', 'prediction interval', 'uncertainty quantification']","[8, 5, 6, 7]","[5, 4, 3, 1]",0,"[166, 417, 163, 295]",Accept
giOus054WOy,Neurosymbolic Deep Generative Models for Sequence Data with Relational Constraints,"['neurosymbolic', 'sequence', 'program synthesis', 'generative', 'constraint', 'music', 'poetry']","[6, 7, 8, 5]","[4, 4, 4, 3]",0,"[865, 335, 404, 297]",Accept
kUOm0Fdtvh,AdaFocal: Calibration-aware Adaptive Focal Loss,"['neural network calibration', 'uncertainity', 'out of distribution detection', 'focal loss']","[4, 5, 6, 6]","[3, 4, 4, 4]",0,"[443, 281, 205, 942]",Accept
bDyLgfvZ0qJ,SIXO: Smoothing Inference with Twisted Objectives,"['smoothing', 'variational', 'objectives', 'fivo', 'sequential Monte Carlo', 'inference', 'twisted', 'time series']","[8, 8, 8]","[3, 4, 4]",0,"[890, 158, 537]",Accept
maSvlkPHc-k,On the Discrimination Risk of Mean Aggregation Feature Imputation in Graphs,"['imputation', 'fairness', 'graphs']","[6, 4, 4, 4, 6, 6]","[3, 4, 4, 3, 4, 3]",0,"[764, 233, 286, 777, 211, 347]",Accept
ytnwPTrpl38,Generalizing Goal-Conditioned Reinforcement Learning with Variational Causal Reasoning,"['Reinforcement Learning', 'Generalization', 'Causal Reasoning']","[6, 6, 6]","[4, 4, 5]",0,"[806, 343, 544]",Accept
Ri3T9dwZ_rG,Free Probability for predicting the performance of feed-forward fully connected neural networks,"['Infinite width regime', 'Lyapounov exponents', 'Singular spectrum of Jacobians of neural networks', 'Stability', 'Free Probability Theory', 'Numerical Methods', 'Newton-Raphson method']","[7, 6, 7, 6, 6]","[4, 2, 3, 3, 3]",0,"[364, 374, 154, 636, 613]",Accept
fJ924S1j5xh,Syndicated Bandits: A Framework for Auto Tuning Hyper-parameters in Contextual Bandit Algorithms,"['contextual bandits', 'online learning', 'hyperparameter optimization']","[6, 6, 6, 7]","[3, 4, 4, 4]",0,"[440, 271, 386, 304]",Accept
XSNfXG9HBAu,Domain Adaptation meets Individual Fairness. And they get along.,"['Domain adaptation', 'Individual fairness', 'Covariate shift']","[3, 5, 7]","[3, 3, 3]",0,"[444, 430, 578]",Accept
PPjSKy40XUB,End-to-end Algorithm Synthesis with Recurrent Networks: Extrapolation without Overthinking,"['Extrapolations', 'algorithm synthesis', 'recurrent networks', 'algorithmic reasoning']","[7, 7, 6, 7]","[3, 3, 5, 4]",0,"[409, 1147, 582, 728]",Accept
MZmv_B1DM3,Optimal Scaling for Locally Balanced Proposals in Discrete Spaces,"['MCMC', 'Discrete', 'Locally Balanced', 'Optimal Acceptance Rate']","[6, 6, 8]","[4, 4, 4]",0,"[1128, 557, 685]",Accept
VY1dqOF2RjC,ZSON: Zero-Shot Object-Goal Navigation using Multimodal Goal Embeddings,"['Object-Goal Navigation', 'Visual Navigation', 'Embodied AI']","[8, 4, 5, 5]","[4, 5, 3, 5]",0,"[418, 248, 375, 312]",Accept
DpxXyntc12v,Training Subset Selection for Weak Supervision,"['weak supervision', 'data editing', 'subset selection', 'weakly-supervised learning']","[7, 6, 8, 5]","[4, 5, 4, 4]",0,"[394, 246, 324, 353]",Accept
7cL46kHUu4,Fair Infinitesimal Jackknife: Mitigating the Influence of Biased Training Data Points Without Refitting,"['Fairness', 'Influence Functions', 'Infinitesimal Jackknife']","[6, 6, 5]","[3, 4, 4]",0,"[419, 526, 360]",Accept
wjqr6aqkLUV,Towards Understanding the Condensation of Neural Networks at Initial Training,"['neural networks', 'training', 'condensation dynamics', 'implicit regularization']","[5, 5, 6]","[4, 4, 3]",0,"[306, 592, 396]",Accept
c6ibx0yl-aG,An Analysis of Ensemble Sampling,"['Ensemble sampling', 'Thompson sampling', 'bandit', 'information theory']","[5, 7, 8, 5]","[3, 3, 4, 2]",0,"[497, 664, 230, 184]",Accept
FxVH7iToXS,Signal Propagation in Transformers: Theoretical Perspectives and the Role of Rank Collapse,"['Theory of Transformers', 'Transformers', 'Rank Collapse', 'Gradient Vanishing']","[5, 7, 4]","[4, 4, 4]",0,"[241, 362, 305]",Accept
vmjckXzRXmh,Beyond Separability: Analyzing the Linear Transferability of Contrastive Representations to Related Subpopulations,"['representation learning theory', 'self-supervised learning theory', 'contrastive learning theory', 'domain adaptation theory', 'deep learning theory']","[7, 7, 5, 4]","[3, 4, 4, 3]",0,"[461, 631, 256, 584]",Accept
dUSI4vFyMK,Convergence for score-based generative modeling with polynomial complexity,"['Langevin sampling', 'score-based generative modelling', 'diffusion model', 'reverse SDE', 'annealing', 'prediction-correction']","[6, 9, 7, 7, 7]","[2, 3, 2, 5, 4]",0,"[1037, 349, 232, 445, 960]",Accept
-h6WAS6eE4,Locating and Editing Factual Associations in GPT,"['interpretability', 'NLP', 'transformers', 'GPT']","[4, 7, 7]","[3, 4, 3]",0,"[299, 522, 231]",Accept
qYc8VnmUwbv,Efficient and Near-Optimal Smoothed Online Learning for Generalized Linear Functions,"['online learning', 'smoothed online learning', 'convex geometry']","[8, 8, 6, 7]","[3, 2, 3, 3]",0,"[158, 474, 492, 474]",Accept
Jd70afzIvJ4,Leveraging Factored Action Spaces for Efficient Offline Reinforcement Learning in Healthcare,"['reinforcement learning', 'offline rl', 'action space factorization', 'bias-variance trade-off', 'domain knowledge', 'healthcare', 'sepsis']","[7, 6, 7, 5]","[3, 4, 3, 3]",0,"[594, 805, 585, 432]",Accept
AqexjBWRQFx,Convergent Representations of Computer Programs in Human and Artificial Neural Networks,"['Code representations', 'Brain representations', 'Cognitive neuroscience', 'Neuroimaging', 'Multivoxel pattern analysis', 'Representation decoding analysis', 'Representation similarity analysis', 'fMRI analysis', 'ML for PL/SE', 'ML4code']","[7, 3, 6, 6]","[5, 4, 2, 5]",0,"[686, 345, 312, 837]",Accept
-uezmSLXVoE,Active Learning Polynomial Threshold Functions,"['Statistical Learning Theory', 'Active Learning', 'Polynomial Threshold Functions', 'Enriched Queries']","[6, 8, 8, 7]","[4, 3, 4, 3]",0,"[349, 506, 452, 347]",Accept
Ncyc0JS7Q16,Toward Robust Spiking Neural Network Against Adversarial Perturbation,"['Spiking Neural Network', 'Certified Training', 'Adversarial Attack']","[8, 4, 6]","[5, 4, 4]",0,"[247, 270, 343]",Accept
SNElc7QmMDe,Towards Optimal Communication Complexity in Distributed Non-Convex Optimization,"['Distributed Optimization', 'Intermittent Communication Setting', 'Federated Learning', 'Non-convex Optimization', 'Lower Bounds', 'Stochastic Optimization']","[6, 6, 6]","[4, 3, 4]",0,"[170, 427, 656]",Accept
b-SNWfqkZc,A Projection-free Algorithm for Constrained Stochastic Multi-level Composition Optimization,"['Projection-Free algorithm', 'Conditional gradient algorithm', 'Stochastic multi-level composition optimization', 'Moving-average', 'Oracle complexity', 'High-probability bounds']","[5, 5, 5]","[4, 3, 4]",0,"[238, 235, 437]",Accept
4PJbcrW_7wC,Sketch-GNN: Scalable Graph Neural Networks with Sublinear Training Complexity,"['Graph Neural Networks', 'Scalability', 'Tensor Sketch', 'Sublinear Complexity']","[7, 7, 7, 6]","[4, 3, 4, 4]",0,"[749, 298, 815, 573]",Accept
oPzICxVFqVM,Score-based Generative Modeling Secretly Minimizes the Wasserstein Distance,"['score-based generative models', 'optimal transport', 'Wasserstein distance']","[8, 7, 6, 5]","[2, 1, 4, 3]",0,"[385, 536, 726, 366]",Accept
r4RRwBCPDv5,VC Theoretical Explanation of Double Descent,[],"[2, 3, 7]","[5, 3, 5]",0,"[367, 479, 134]",Reject
_5rdhnrbl-z,Bayesian Spline Learning for Equation Discovery of Nonlinear Dynamics with Quantified Uncertainty,"['Equation Discovery', 'Deep Learning', 'Spline Learning', 'Bayesian Method']","[5, 7, 6, 5]","[2, 2, 4, 3]",0,"[366, 659, 249, 330]",Accept
eJM0aA5Qhhk,Few-shot Learning for Feature Selection with Hilbert-Schmidt Independence Criterion,"['Meta-learning', 'Few-shot learning', 'Supervised Feature Selection']","[7, 6, 5, 6]","[4, 4, 4, 2]",0,"[370, 429, 356, 221]",Accept
8ON84BdnSn,Understanding Hyperdimensional Computing for Parallel Single-Pass Learning,"['hyperdimensional computing', 'vector symbolic architecture']","[7, 7, 7, 7]","[3, 2, 3, 2]",0,"[308, 550, 298, 494]",Accept
APQY2WZFZkd,Rapidly Mixing Multiple-try Metropolis Algorithms for Model Selection Problems,"['Bayesian model selection', 'Markov chain Monte Carlo', 'mixing time', 'Multiple-try Metropolis']","[7, 7, 7]","[3, 3, 4]",0,"[830, 311, 261]",Accept
D4fuQ1MveDM,Learning Options via Compression,"['hierarchical reinforcement learning', 'skill learning']","[7, 7, 6, 7]","[3, 4, 3, 3]",0,"[362, 182, 209, 357]",Accept
Xt9smkoTgQf,Understanding Non-linearity in Graph Neural Networks from the Bayesian-Inference Perspective,"['Graph Neural Network', 'Bayesian Method', 'Theory']","[7, 6, 3]","[3, 3, 3]",0,"[446, 350, 431]",Accept
agQGDz6gPOo,Improving Self-Supervised Learning by Characterizing Idealized Representations,"['Self-Supervised Learning', 'Invariances', 'Contrastive Learning', 'Machine Learning', 'Representation Learning']","[7, 5, 6, 7]","[4, 3, 4, 3]",0,"[401, 595, 764, 972]",Accept
rwyISFoSmXd,Conformalized Fairness via Quantile Regression,"['Fairness', 'Quantile regression', 'Conformal prediction', 'Optimal transport', 'Functional synchronization']","[7, 6, 4, 5]","[3, 3, 3, 2]",0,"[792, 1156, 327, 215]",Accept
VK9jfSPnnb,A Simple and Optimal Policy Design for Online Learning with Safety against Heavy-tailed Risk,[],"[7, 6, 7, 6]","[4, 4, 4, 4]",0,"[560, 278, 176, 452]",Accept
lHuPdoHBxbg,C2FAR: Coarse-to-Fine Autoregressive Networks for Precise Probabilistic Forecasting,"['time series', 'probabilistic forecasting', 'autoregressive generative models', 'neural networks']","[7, 7, 6]","[4, 4, 5]",0,"[410, 276, 738]",Accept
ZJqqSa8FsH9,Chain of Thought Imitation with Procedure Cloning,"['Imitation Learning', 'behavioral cloning', 'generalization', 'sequence modeling']","[7, 4, 4, 7]","[3, 4, 3, 4]",0,"[278, 764, 686, 1410]",Accept
MbBTrAvee-N,Hedging as Reward Augmentation in Probabilistic Graphical Models,"['hedging', 'influence diagram', 'bayesian network', 'reward augmentation']","[7, 6, 5]","[3, 4, 3]",0,"[603, 454, 217]",Accept
7vlIVOBKarp,Multiview Human Body Reconstruction from Uncalibrated Cameras,"['3D human body reconstruction', 'Multiview', 'Uncalibrated', 'Fusion', 'Dense keypoints']","[6, 7, 6, 7, 7]","[3, 4, 3, 5, 3]",0,"[608, 203, 508, 337, 504]",Accept
493VFz-ZvDD,Layer Freezing & Data Sieving: Missing Pieces of a Generic Framework for Sparse Training,"['Sparse training', 'model compression', 'efficient training']","[6, 6, 7, 3]","[3, 4, 4, 5]",0,"[246, 299, 318, 982]",Accept
NSWNgQgoF71,Efficiently Computing Local Lipschitz Constants of Neural Networks via Bound Propagation,[],"[7, 4, 6]","[4, 4, 3]",0,"[801, 589, 367]",Accept
qPb0m0NXt4j,Emergent Graphical Conventions in a Visual Communication Game,"['Visual communication', 'Emergent languages', 'Representation learning']","[8, 6, 6, 6]","[4, 3, 5, 5]",0,"[511, 597, 924, 346]",Accept
24fiAU_9vT,Few-Shot Non-Parametric Learning with Deep Latent Variable Model,"['Data Compression', 'Kolmogorov Complexity', 'Few-Shot Learning', 'Generative Model']","[9, 7, 6]","[3, 3, 4]",0,"[383, 223, 518]",Accept
m8vzptcFKsT,"Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization)","['over-parameterized model', 'robustness', 'perturbation stability', 'initialization scheme']","[5, 7, 7]","[2, 4, 4]",0,"[274, 390, 402]",Accept
-TJpOACwpl5,Uncalibrated Models Can Improve Human-AI Collaboration,"['Human-calibrated AI', 'Human-in-the-loop AI']","[7, 7, 5, 5]","[5, 4, 5, 4]",0,"[172, 663, 619, 1118]",Accept
ii9X4vtZGTZ,$\alpha$-ReQ : Assessing {\bf Re}presentation {\bf Q}uality in Self-Supervised Learning by measuring eigenspectrum decay,"['Representation analysis', 'Representation learning', 'Self Supervised Learning', 'Eigenspectrum', 'Overparameterized Linear regression', 'Computer vision', 'Model Selection']","[6, 5, 5]","[3, 3, 4]",0,"[866, 556, 905]",Accept
2NcrByUfu9,Maximum a posteriori natural scene reconstruction from retinal ganglion cells with deep denoiser priors,"['retina', 'ganglion cell', 'natural scenes', 'image reconstruction', 'image prior', 'Plug and Play', 'encoding model', 'neural coding', 'neuroscience', 'neural decoding']","[6, 8, 5]","[3, 5, 3]",0,"[534, 388, 460]",Accept
RHa77BXv6k,Continuously Tempered PDMP samplers,"['PDMP', 'Zig-Zag', 'tempering', 'MCMC', 'Monte Carlo', 'Markov Chain', 'Probabilistic Inference']","[6, 6, 8]","[3, 5, 4]",0,"[290, 406, 962]",Accept
g0QM7IBuCh,Generalization Gap in Amortized Inference,"['variational inference', 'amortized inference', 'vae', 'lossless compression']","[6, 6, 7, 6]","[3, 4, 3, 3]",0,"[591, 433, 323, 741]",Accept
Ir8b8lG_Vc,Policy Optimization for Markov Games: Unified Framework and Faster Convergence,"['policy optimization', 'multi-agent reinforcement learning', 'reinforcement learning theory', 'Markov games']","[7, 6, 6]","[4, 2, 2]",0,"[337, 342, 238]",Accept
WBp4dli3No6,Robust Learning against Relational Adversaries,"['adversarial machine learning', 'relational adversaries', 'input normalization', 'input transformation', 'defense mechanism with guarantee']","[6, 9, 8]","[2, 4, 3]",0,"[335, 122, 213]",Accept
Mg-PzsJkEmg,Falconn++: A Locality-sensitive Filtering Approach for Approximate Nearest Neighbor Search,"['Approximate nearest neighbor search', 'locality-sensitive', 'recall-speed tradeoff']","[6, 6, 6]","[3, 4, 4]",0,"[359, 282, 809]",Accept
KUOKpojFr_,ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model,"['language', 'shape generation', '3D representation', 'text-shape dataset']","[7, 5, 4]","[4, 4, 5]",0,"[333, 765, 649]",Accept
QeaYt6w5Xa1,Beyond black box densities: Parameter learning for the deviated components,"['Mixture Model', 'Wasserstein Metric', 'Statistical Learning Theory']","[6, 6, 6, 5]","[3, 2, 2, 2]",0,"[567, 196, 691, 285]",Accept
FLzTj4ia8BN,Monte Carlo Augmented Actor-Critic for Sparse Reward Deep Reinforcement Learning from Suboptimal Demonstrations,"['reinforcement learning', 'sparse reward reinforcement learning', 'reinforcement learning from demonstrations', 'online reinforcement learning']","[6, 6, 5, 5]","[4, 4, 4, 4]",0,"[420, 515, 388, 452]",Accept
DoQElY73YR,Friendly Noise against Adversarial Noise: A Powerful Defense against Data Poisoning Attack,"['Data Poisoning', 'Friendly Noise']","[3, 5, 6, 5]","[4, 4, 3, 4]",0,"[400, 348, 212, 246]",Accept
_LceCyuVcH,Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners,"['video-language', 'few-shot', 'language model', 'in-context learning']","[6, 3, 6, 4]","[4, 5, 5, 5]",0,"[981, 328, 751, 248]",Accept
hUjMhflYvGc,Dynamic Tensor Product Regression,"['Regression', 'Sketching', 'Tensor Product', 'Kronecker Product', 'Dynamic data structures']","[7, 5, 4]","[4, 3, 3]",0,"[1771, 303, 619]",Accept
-BxFk0t7wN,Data-Efficient Augmentation for Training Neural Networks,"['Data Augmentation', 'Deep Learning', 'Coresets']","[6, 6, 6]","[4, 3, 4]",0,"[1466, 392, 337]",Accept
KBUgVv8z7OA,What Can the Neural Tangent Kernel Tell Us About Adversarial Robustness?,"['Neural Tangent Kernel', 'Adversarial Examples', 'Non Robust Features', 'Linearised Networks']","[4, 6, 4, 8]","[4, 5, 3, 3]",0,"[552, 1058, 680, 257]",Accept
9lQmaKMxIUD,Near-Optimal Private and Scalable $k$-Clustering,"['differential privacy', 'clustering', 'massively parallel computation', 'approximation algorithms']","[7, 8, 8, 7]","[3, 3, 3, 3]",0,"[163, 206, 540, 146]",Accept
k5idxiVdJ3p,On Scrambling Phenomena for Randomly Initialized Recurrent Networks,"['RNNs', 'Scrambling', 'Jacobian', 'dynamical systems', 'trajectories', 'chaos']","[4, 9, 6, 5]","[3, 4, 2, 2]",0,"[253, 619, 218, 179]",Accept
BsSP7pZGFQO,Meta-Learning Dynamics Forecasting Using Task Inference,"['Meta-Learning', 'Dynamical Systems', 'Generalizability']","[8, 7, 7]","[3, 4, 3]",0,"[663, 222, 521]",Accept
D0aqV81d0_k,Optimal Dynamic Regret in LQR Control,"['Online linear regression', 'Dynamic regret', 'Individual sequence prediction', 'Online learning', 'Online non-paramteric regression', 'LQR control']","[6, 6, 6]","[3, 3, 4]",0,"[497, 241, 337]",Accept
x26Mpsf45P3,Bellman Residual Orthogonalization for Offline Reinforcement Learning,"['offline RL', 'weight function', 'confidence intervals', 'policy optimization']","[6, 8, 7, 7]","[3, 3, 3, 4]",0,"[514, 420, 435, 743]",Accept
jFVfKsmKa-,"Bounded-Regret MPC via Perturbation Analysis: Prediction Error, Constraints, and Nonlinearity","['Model Predictive Control', 'Regret', 'Perturbation Analysis', 'Prediction Error']","[5, 6, 5, 8]","[3, 3, 3, 3]",0,"[222, 307, 660, 357]",Accept
rhdfTOiXBng,NaturalProver: Grounded Mathematical Proof Generation with Language Models,"['language modeling', 'reasoning', 'neural theorem proving']","[7, 7, 7]","[4, 3, 4]",0,"[633, 756, 242]",Accept
etY_XXnPkoC,The Implicit Delta Method,"['Uncertainty quantification', 'Wald confidence intervals', 'maximum likelihood inference']","[8, 6, 5, 7]","[1, 4, 3, 4]",0,"[127, 449, 415, 1251]",Accept
hqRwcqzegr7,Globally Gated Deep Linear Networks,"['Neural Network Architectures', 'Kernel Methods', 'Deep Learning Theory', 'Gaussian Processes', 'Finite Width Networks', 'Gated Linear Networks']","[7, 7, 7]","[2, 2, 3]",0,"[458, 290, 674]",Accept
bEMrmaw8gOB,Model-based RL with Optimistic Posterior Sampling: Structural Conditions and Sample Complexity,"['Reinforcement Learning', 'Model-based RL', 'Sample Complexity']","[7, 7, 7, 6]","[3, 4, 2, 3]",0,"[269, 560, 78, 227]",Accept
WPXRVQaP9Oq,On the Safety of Interpretable Machine Learning: A Maximum Deviation Approach,"['safety', 'interpretability', 'explainability']","[6, 5, 5]","[4, 1, 5]",0,"[456, 417, 328]",Accept
U1m_93ansV,Towards Safe Reinforcement Learning with a Safety Editor Policy,"['Safe RL', 'constrained Markov decision process', 'safety layer', 'first-order safety method', 'model-free RL']","[7, 7, 6, 7]","[4, 4, 4, 4]",0,"[536, 496, 723, 845]",Accept
N6zHSyChCF2,Discrete Compositional Representations as an Abstraction for Goal Conditioned Reinforcement Learning,"['goal conditioned RL', 'discrete bottleneck', 'vq-vae', 'self-supervised representations', 'hierarchical RL']","[6, 6, 6]","[4, 4, 3]",0,"[298, 798, 922]",Accept
FkPZGtTxXx6,Natural image synthesis for the retina with variational information bottleneck representation,"['Neuroscience', 'neural coding', 'generative model', 'variational autoencoders', 'neural latent models', 'information bottleneck']","[5, 7, 6, 6]","[2, 4, 3, 4]",0,"[381, 399, 451, 438]",Accept
ecevn9kPm4,Riemannian Diffusion Models,"['diffusion models', 'density estimation', 'generative models', 'Riemannian manifolds', 'variational inference']","[5, 7, 7]","[2, 3, 4]",0,"[352, 257, 172]",Accept
cwWSpO6rl3Z,Near-Isometric Properties of Kronecker-Structured Random Tensor Embeddings,"['Structured non-symmetric rank-1 tensor', 'Uniform deviation bound', 'Applications of random tensor embeddings']","[6, 8, 5]","[2, 4, 4]",0,"[260, 530, 505]",Accept
i-UdJ6fWUFc,Semi-supervised Active Linear Regression,"['Active Learning', 'Semi-supervised Learning', 'Ridge Regression', 'Kernel Ridge Regression']","[6, 7, 7]","[3, 3, 4]",0,"[514, 200, 717]",Accept
03Qml_SaPqV,Adversarially Robust Learning: A Generic Minimax Optimal Learner and Characterization,"['adversarially robust PAC learning', 'sample complexity']","[9, 8, 7]","[4, 4, 4]",0,"[248, 492, 312]",Accept
YPpSngE-ZU,MACE: Higher Order Equivariant Message Passing Neural Networks for Fast and Accurate Force Fields,"['GNN', 'graph neural network', 'equivariance', 'higher order', 'message passing neural network', 'point clouds', 'molecules']","[7, 6, 8]","[4, 3, 4]",0,"[326, 501, 683]",Accept
yJEUDfzsTX7,Regret Bounds for Risk-Sensitive Reinforcement Learning,"['Risk-sensitive reinforcement learning', 'CVaR objective']","[5, 7, 7, 7]","[3, 4, 3, 2]",0,"[215, 394, 248, 173]",Accept
s776AhRFm67,Boosting Barely Robust Learners: A New Perspective on Adversarial Robustness,"['boosting', 'adversarial robustness', 'sample complexity', 'oracle complexity']","[7, 3, 4, 7, 8]","[3, 2, 3, 4, 5]",0,"[316, 142, 340, 512, 422]",Accept
zkk_7sV6gm8,Timing is Everything: Learning to Act Selectively with Costly Actions and Budgetary Constraints,[],"[5, 6, 5]","[2, 3, 3]",0,"[1173, 587, 499]",Reject
prKLyXwzIW,Robust Generalized Method of Moments: A Finite Sample Viewpoint,"['robust statistics', 'generalized method of moments']","[5, 6, 7, 7]","[3, 4, 3, 2]",0,"[581, 324, 321, 441]",Accept
ALIYCycCsTy,Improving Intrinsic Exploration with Language Abstractions,"['reinforcement learning', 'intrinsic motivation', 'exploration', 'language', 'deep rl', 'language-guided rl']","[4, 7, 6]","[4, 4, 4]",0,"[486, 461, 513]",Accept
X1oVDZIABwF,On the Global Convergence Rates of Decentralized Softmax Gradient Play in Markov Potential Games,"['multiagent learning', 'Markov potential games', 'policy gradient', 'Nash equilibrium']","[5, 6, 5, 5]","[5, 4, 4, 5]",0,"[680, 273, 492, 342]",Accept
szt95rn-ql,Single-phase deep learning in cortico-cortical networks,"['cortical microcircuits', 'deep learning', 'synaptic plasticity', 'biologically plausible learning', 'neuroscience']","[8, 8, 7, 7]","[4, 4, 4, 3]",0,"[225, 759, 315, 501]",Accept
mhe2C2VWwCW,Predictive Querying for Autoregressive Neural Sequence Models,"['probabilistic querying', 'neural sequence models', 'recurrent neural networks']","[7, 6, 8]","[3, 3, 4]",0,"[289, 427, 469]",Accept
xvlaiSHgPrC,Composition Theorems for Interactive Differential Privacy,"['Differential Privacy', 'Composition Theorems', 'Interactive mechanism']","[5, 3, 6, 7]","[5, 3, 3, 3]",0,"[255, 206, 235, 857]",Accept
6V4vRCbVA3J,Efficient Frameworks for Generalized Low-Rank Matrix Bandit Problems,"['contextual bandits', 'online learning']","[7, 5, 5, 7]","[2, 3, 3, 4]",0,"[222, 358, 272, 1376]",Accept
TERVhuQVTe,GULP: a prediction-based metric between representations,"['representations', 'CCA', 'CKA', 'transfer learning', 'neural networks']","[7, 6, 7, 6]","[4, 4, 4, 3]",0,"[513, 566, 137, 971]",Accept
FYGrMDwQyL,Online Allocation and Learning in the Presence of Strategic Agents,"['Online Learning', 'Incentive Compatibility', 'Resource Allocation']","[6, 5, 7]","[4, 3, 4]",0,"[452, 444, 518]",Accept
_qsh1p43SIf,Reduced Representation of Deformation Fields for Effective Non-rigid Shape Matching,"['non-rigid 3D shape correspondence', '3D shape deformation', '3D Vision', 'Computer Graphics']","[7, 5, 6, 4]","[3, 4, 4, 3]",0,"[304, 360, 896, 570]",Accept
MPARWTuMiPh,Interpreting Operation Selection in Differentiable Architecture Search: A Perspective from Influence-Directed Explanations,"['neural architecture search', 'influence function', 'operation selection']","[3, 6, 7, 9]","[5, 4, 4, 5]",0,"[229, 895, 327, 757]",Accept
wt7cd9m2cz2,Learning single-index models with shallow neural networks,"['single-index models', 'gradient descent', 'landscape analysis', 'random feature approximation', 'shallow neural networks']","[7, 6, 7, 7, 8]","[4, 2, 4, 3, 4]",0,"[319, 547, 437, 1029, 502]",Accept
3nbKUphLBg5,Sequence Model Imitation Learning with Unobserved Contexts,"['imitation learning', 'causal inference']","[3, 6, 7]","[3, 3, 3]",0,"[535, 210, 571]",Accept
XiwkvDTU10Y,Repairing Neural Networks by Leaving the Right Past Behind,"['model repairment', 'interpretability', 'continual learning', 'data deletion', 'debugging', 'interpretability']","[6, 6, 6]","[4, 2, 3]",0,"[389, 391, 373]",Accept
6HFRBaPmp,Doubly-Asynchronous Value Iteration: Making Value Iteration Asynchronous in Actions,"['Reinforcement learning', 'dynamic programming', 'planning']","[8, 6, 6]","[1, 4, 3]",0,"[187, 269, 155]",Accept
3PAIKtWQsc,Learning Two-Player Markov Games: Neural Function Approximation and Correlated Equilibrium,[],"[7, 6, 7, 6]","[2, 4, 3, 4]",0,"[129, 194, 442, 548]",Accept
6NTFiNpQJ6,Differentially Private Linear Sketches: Efficient Implementations and Applications,"['Differential Privacy', 'Linear Sketch', 'Frequency', 'Top K', 'Quantile']","[4, 7, 6, 4]","[4, 2, 4, 3]",0,"[194, 456, 336, 229]",Accept
g-H3oNARs2,On the role of overparameterization in off-policy Temporal Difference learning with linear function approximation,"['reinforcement learning', 'optimization', 'ranoverparamerizationdom matrix theory', 'random graphs', 'overparameterization']","[9, 6, 5, 5]","[5, 3, 2, 2]",0,"[385, 293, 228, 305]",Accept
M3WW7TqoMvc,Fast Bayesian Coresets via Subsampling and Quasi-Newton Refinement,"['Bayesian coresets', 'Markov chain Monte Carlo', 'data subsampling']","[8, 7, 7, 7]","[3, 3, 3, 3]",0,"[443, 503, 983, 999]",Accept
x0LCDsbJ5JF,Learning Spatially-Adaptive Squeeze-Excitation Networks for Image Synthesis and Image Recognition,"['Squeeze Excitation', 'Spatially-Adaptive Squeeze Excitation', 'Low-shot Image Synthesis', 'Image Classification']","[4, 5, 3, 5, 5]","[3, 2, 4, 4, 4]",0,"[76, 254, 524, 191, 208]",Reject
hPVXHzzK0z,Single-Stage Visual Relationship Learning using Conditional Queries,"['Scene graph generation', 'DETR', 'Transformer']","[5, 5, 4, 5, 6]","[4, 4, 4, 3, 4]",0,"[527, 453, 1155, 271, 340]",Accept
6FkSHynJr1,Probable Domain Generalization via Quantile Risk Minimization,"['domain generalization', 'out-of-distribution generalization', 'invariant prediction', 'causality', 'robust optimization', 'risk-aware optimization']","[6, 5, 6, 7]","[4, 4, 4, 3]",0,"[821, 448, 320, 447]",Accept
1_gypPuWUC3,Teacher Forcing Recovers Reward Functions for Text Generation,"['Text Generation', 'Natural Language Processing', 'Reinforcement Learning']","[7, 7, 6, 6]","[3, 4, 2, 3]",0,"[272, 897, 411, 311]",Accept
SL4SwMNnwIe,Acceleration in Distributed Sparse Regression,"['distributed optimization', 'acceleration', 'high-dimensional statistics', 'linear convergence']","[7, 7, 5, 7]","[2, 4, 4, 3]",0,"[314, 317, 344, 373]",Accept
ztcfHweENtU,"Distributive Justice as the Foundational Premise of Fair ML: Unification, Extension, and Interpretation of Group Fairness Metrics","['algorithmic decision making', 'group fairness', 'distributive justice', 'welfare', 'egalitarianism', 'maximin', 'prioritarianism', 'sufficientarianism']","[6, 6, 4]","[3, 3, 4]",0,"[305, 246, 731]",Reject
6scShPCpdDu,Embed and Emulate: Learning to estimate parameters of dynamical systems with uncertainty quantification,"['Learned emulators', 'contrastive learning', 'parameter estimation', 'inverse problems', 'climate forecasting']","[6, 7, 8]","[3, 3, 4]",0,"[667, 650, 553]",Accept
QEODRZ7j3L_,DGD^2: A Linearly Convergent Distributed Algorithm For High-dimensional Statistical Recovery,"['Distributed optimization', 'convex optimization', 'high-dimensional statistics', 'linear convergence']","[7, 8, 7]","[4, 5, 3]",0,"[240, 545, 109]",Accept
R5yl-ySZR0U,Draft-and-Revise: Effective Image Generation with Contextual RQ-Transformer,"['image generation', 'discrete image representation', 'transformer']","[7, 5, 6, 4]","[3, 4, 4, 4]",0,"[356, 248, 245, 511]",Accept
pyLFJ9TBZw,Generative multitask learning mitigates target-causing confounding,"['causal representation learning', 'causal machine learning', 'multitask learning', 'causality', 'robustness', 'out-of-distribution generalization']","[5, 5, 7]","[4, 3, 4]",0,"[1247, 166, 257]",Accept
1mFfKXYMg5a,Minimax Optimal Online Imitation Learning via Replay Estimation,['imitation learning'],"[8, 7, 7]","[2, 4, 4]",0,"[498, 1005, 1514]",Accept
yTJze_xm-u6,Variational Model Perturbation for Source-Free Domain Adaptation,"['transfer learning', 'domain adaptation', 'variational inference', 'model perturbation']","[7, 7, 8, 6]","[3, 3, 5, 4]",0,"[540, 515, 753, 593]",Accept
JyTT03dqCFD,The Neural Testbed: Evaluating Joint Predictions,"['Deep Learning', 'Bayesian', 'Uncertainty', 'Testbed', 'open source']","[6, 2, 6, 7]","[3, 3, 3, 4]",0,"[471, 606, 594, 336]",Accept
tzNWhvOomsK,Tight Lower Bounds on Worst-Case Guarantees for Zero-Shot Learning with Attributes,"['ZSL', 'theory', 'lower bound', 'Zero-Shot Learning', 'machine learning', 'learning with less data']","[5, 6, 7, 6]","[4, 4, 3, 3]",0,"[469, 168, 1053, 560]",Accept
Wl1ZIgMqLlq,"Deep Ensembles Work, But Are They Necessary?","['Deep Ensembles', 'Uncertainty Quantification', 'Robustness', 'Dataset Shift']","[7, 7, 8, 7]","[5, 3, 4, 3]",0,"[519, 315, 326, 263]",Accept
CIYF4tpQzgK,Recursive Reasoning in Minimax Games: A Level $k$ Gradient Play Method,"['GAN', 'Game Theory', 'Adversarial Leraning']","[5, 4, 7, 8]","[3, 3, 3, 3]",0,"[411, 791, 463, 397]",Accept
ErUlLrGaVEU,The Privacy Onion Effect: Memorization is Relative,"['memorization', 'privacy', 'auditing']","[6, 6, 7, 7]","[4, 3, 4, 4]",0,"[658, 194, 532, 484]",Accept
1LmgISIDZJ,Learning to Sample and Aggregate: Few-shot Reasoning over Temporal Knowledge Graphs,"['Few-shot knowledge graph reasoning', 'Temporal knowledge graph', 'Meta learning']","[6, 5, 7]","[2, 3, 3]",0,"[221, 143, 552]",Accept
KXybrIUJnya,A Character-Level Length-Control Algorithm for Non-Autoregressive Sentence Summarization,"['summarization', 'non-autoregressive generation', 'length control']","[4, 7, 6, 6]","[4, 4, 5, 4]",0,"[295, 307, 219, 250]",Accept
KwwBBSzQgRX,Optimal Rates for Regularized Conditional Mean Embedding Learning,"['Kernel Methods', 'Learning Theory']","[9, 7, 7, 7]","[2, 3, 4, 2]",0,"[110, 210, 371, 186]",Accept
7WuCttgNQ79,Scaling Multimodal Pre-Training via Cross-Modality Gradient Harmonization,"['Cross-Modality Alignment', 'Multimodal Pre-Training', 'Modality-agnostic']","[7, 5, 7]","[4, 5, 4]",0,"[399, 350, 344]",Accept
PbKa0yApPq5,A permutation-free kernel two-sample test,"['two-sample testing', 'kernel-mmd', 'permutation-free tests', 'U-statistics']","[7, 7, 7, 7]","[4, 4, 3, 4]",0,"[238, 194, 249, 726]",Accept
edgCBcwZxgd,Deep Architecture Connectivity Matters for Its Convergence: A Fine-Grained Analysis,"['Neural Network Gaussian Process', 'Convergence', 'Neural Network Architecture']","[6, 7, 7]","[4, 4, 4]",0,"[783, 316, 389]",Accept
5aZ8umizItU,Seeing the forest and the tree: Building representations of both individual and collective dynamics with transformers,"['Transformers', 'population dynamics', 'multi-variate time-series', 'neural activity', 'many-body systems']","[5, 5, 8, 8]","[4, 4, 3, 4]",0,"[494, 654, 746, 190]",Accept
11nMVZK0WYM,Pruning has a disparate impact on model accuracy,"['Model pruning', 'Fairness']","[7, 6, 7]","[4, 4, 3]",0,"[1299, 336, 523]",Accept
oNWqs_JRcDD,Efficient Non-Parametric Optimizer Search for Diverse Tasks,"['AutoML', 'Optimizer Search', 'Optimization', 'Adversarial Robustness', 'Graph Neural Networks', 'BERT']","[6, 4, 7]","[3, 3, 4]",0,"[387, 219, 552]",Accept
OFJSAMwskM,Triangulation candidates for Bayesian optimization,"['surrogate modeling', 'Gaussian process', 'active learning', 'sequential design', 'space-filling design', 'Delaunay triangulation', 'convex hull']","[6, 7, 5, 8]","[1, 4, 4, 5]",0,"[68, 526, 474, 439]",Accept
9XWHdVCynhp,Rashomon Capacity: A Metric for Predictive Multiplicity in Classification,"['Rashomon effect', 'Rashomon set', 'predictive multiplicity', 'channel capacity', 'Rashomon capacity', 'probabilistic classifier.']","[7, 4, 5]","[3, 4, 4]",0,"[468, 804, 490]",Accept
8rfYWE3nyXl,Are All Losses Created Equal: A Neural Collapse Perspective,"['Deep Learning', 'Neural Collapse', 'Loss Functions']","[7, 7, 6]","[3, 3, 4]",0,"[859, 363, 234]",Accept
ST5ZUlz_3w,"Interventions, Where and How? Experimental Design for Causal Models at Scale","['Causal Discovery', 'Active Learning', 'Bayesian Deep Learning']","[6, 6, 5, 8, 5, 7]","[4, 3, 3, 3, 3, 2]",0,"[404, 282, 253, 424, 886, 344]",Accept
r5rzV51GZx,CoPur: Certifiably Robust Collaborative Inference via Feature Purification,"['Robust Collaborative Inference', 'Feature Purification', 'Adversarial Machine Learning', 'Vertical Federated Inference', 'Robust Decomposition']","[6, 5, 6, 4, 5]","[2, 4, 4, 4, 2]",0,"[160, 701, 299, 268, 378]",Accept
wZEfHUM5ri,CroCo: Self-Supervised Pre-training for 3D Vision Tasks by Cross-View Completion,[],"[5, 6, 6, 6]","[4, 5, 4, 4]",0,"[386, 436, 790, 234]",Accept
F2mhzjHkQP,On the SDEs and Scaling Rules for Adaptive Gradient Algorithms,"['stochastic differential equations', 'Adam', 'RMSprop', 'scaling rule']","[5, 8, 7, 6]","[3, 3, 3, 3]",0,"[281, 205, 244, 265]",Accept
6Nh0D44tRAz,Scalable Representation Learning in Linear Contextual Bandits with Constant Regret Guarantees,[],"[7, 7, 7]","[4, 3, 3]",0,"[277, 286, 222]",Accept
dTTKMy00PTJ,Universal Rates for Interactive Learning,"['interactive learning', 'universal learning rates', 'learning theory']","[9, 7, 8]","[3, 4, 3]",0,"[281, 584, 389]",Accept
5g7l7EJoZT,Wavelet Feature Maps Compression for Image-to-Image CNNs,"['Convolutional Neural Networks', 'Quantization', 'Wavelet Transform']","[6, 6, 5, 5]","[4, 4, 4, 3]",0,"[375, 444, 218, 322]",Accept
98TSEoHOoQE,AutoMTL: A Programming Framework for Automating Efficient Multi-Task Learning,"['Applications: Multi-Task Learning', 'Infrastructure: Programming Framework for MTL']","[6, 6, 5]","[4, 4, 4]",0,"[487, 303, 552]",Accept
g05fHAvNeXx,What You See is What You Get: Principled Deep Learning via Distributional Generalization,"['deep learning', 'differential privacy', 'disparate impact', 'distributional robustness', 'DRO', 'adversarial robustness', 'robust overfitting', 'distributional generalization']","[6, 5, 5, 8]","[4, 5, 3, 5]",0,"[417, 808, 394, 422]",Accept
mUeMOdJ2IJp,Subspace Recovery from Heterogeneous Data with Non-isotropic Noise,"['subspace recovery', 'heteroscedasticity', 'principal component analysis', 'federated learning']","[7, 6, 6, 5]","[3, 3, 3, 3]",0,"[445, 171, 229, 473]",Accept
XFnDhcEH9FF,Hyperbolic Embedding Inference for Structured Multi-Label Prediction,"['Structured multi-Label prediction', 'hyperbolic geometry']","[6, 5, 7, 6]","[4, 2, 4, 3]",0,"[1163, 191, 183, 558]",Accept
lxsL16YeE2w,UViM: A Unified Modeling Approach for Vision with Learned Guiding Codes,"['computer vision', 'deep learning', 'discrete representations', 'unified model']","[7, 7, 8]","[4, 4, 3]",0,"[766, 370, 475]",Accept
DTsCy9Lyj5-,BOME! Bilevel Optimization Made Easy: A Simple First-Order Approach,['bilevel optimization'],"[6, 7, 4, 6]","[2, 2, 5, 4]",0,"[113, 383, 466, 259]",Accept
12nqqeQnDW7,Coordinate Linear Variance Reduction for Generalized Linear Programming,"['Linear Programming', 'Variance Reduction', 'Min-max optimization', 'Distributionally Robust Optimization']","[6, 5, 6, 6]","[4, 3, 4, 4]",0,"[165, 325, 127, 721]",Accept
2-CflpDkezH,Finding Correlated Equilibrium of Constrained Markov Game: A Primal-Dual Approach,"['constrained Markov game', 'correlated equilibrium', 'strong duality', 'reinforcement learning', 'primal-dual algorithm']","[6, 6, 6, 6, 7]","[2, 4, 3, 2, 4]",0,"[207, 414, 518, 454, 231]",Accept
rApvGord7j,Fair Bayes-Optimal Classifiers Under Predictive Parity,"['Fair Bayes-optimal classifier', 'Predictive parity', 'Group-wise thresholding rule', 'Fair-Bayes-DPP algorithm']","[5, 4, 6, 6]","[3, 4, 3, 4]",0,"[526, 446, 526, 1192]",Accept
EI1x5B1-o8M,"First Hitting Diffusion Models for Generating Manifold, Graph and Categorical Data",['diffusion model'],"[6, 7, 3, 5]","[4, 2, 4, 4]",0,"[267, 279, 436, 724]",Accept
Yq6g9xluV0,Rapid Model Architecture Adaption for Meta-Learning,['NAS'],"[4, 6, 6, 6]","[2, 4, 4, 4]",0,"[386, 413, 209, 332]",Accept
aZQJMVx8fk,Density-driven Regularization for Out-of-distribution Detection,[],"[7, 5, 7, 4]","[5, 3, 5, 5]",0,"[941, 699, 453, 359]",Accept
YeuBRKq_yZ-,Nearly Optimal Algorithms for Linear Contextual Bandits with Adversarial Corruptions,"['linear bandits', 'adversarial corruption']","[6, 6, 6, 6]","[4, 3, 3, 4]",0,"[282, 661, 375, 368]",Accept
IE32oIlhXz,On the Generalization Power of the Overfitted Three-Layer Neural Tangent Kernel Model,[],"[5, 6, 7, 7]","[3, 4, 3, 3]",0,"[801, 719, 223, 418]",Accept
XiLasGufCM,Insights into Pre-training via Simpler Synthetic Tasks,"['Pre-training', 'synthetic tasks', 'understanding']","[5, 6, 7, 4]","[3, 3, 4, 5]",0,"[265, 385, 582, 868]",Accept
mhP6mHgrg1c,ORIENT: Submodular Mutual Information Measures for Data Subset Selection under Distribution Shift,"['Data Subset Selection', 'Submodular Mutual Information Measures', 'Supervised Domain Adaptation', 'Efficient Domain Adaptation', 'Distribution Shift']","[3, 7, 6, 7]","[4, 3, 4, 3]",0,"[329, 111, 682, 274]",Accept
p_BVHgrvHD4,An Information-Theoretic Framework for Deep Learning,"['Information Theory', 'Deep Learning', 'Nonparametric Statistics']","[6, 5, 7, 4]","[4, 3, 2, 5]",0,"[447, 200, 260, 397]",Accept
9T0Bnap5-j7,DeepFoids: Adaptive Bio-Inspired Fish Simulation with Deep Reinforcement Learning,"['Bio-inspired', 'Fish Schooling', 'Physically Based Simulation', 'Deep Reinforcement Learning', 'Adaptive']","[6, 6, 5, 7]","[3, 4, 3, 4]",0,"[360, 505, 493, 393]",Accept
voV_TRqcWh,Poisson Flow Generative Models,"['poisson equation', 'generative model', 'ODE']","[6, 4, 6]","[4, 4, 2]",0,"[230, 376, 582]",Accept
4BoN6bk-FEz,On the Efficient Implementation of High Accuracy Optimality of Profile Maximum Likelihood,"['property estimation', 'symmetric property estimation', 'profile maximum likelihood']","[8, 5, 5]","[4, 4, 2]",0,"[1219, 334, 356]",Accept
hXzOqPlXDwm,KERPLE: Kernelized Relative Positional Embedding for Length Extrapolation,"['Transformer Language Modeling', 'Length Extrapolation', 'Kernel Method']","[6, 7, 7, 4]","[3, 3, 5, 5]",0,"[240, 467, 1687, 378]",Accept
ah2gZLdT9u,Staggered Rollout Designs Enable Causal Inference Under Interference Without Network Knowledge,"['network interference', 'causal inference', 'staggered rollout design', 'polynomial interpolation', 'total treatment effect', 'global average treatment effect']","[4, 7, 6, 7]","[4, 4, 3, 4]",0,"[362, 302, 326, 416]",Accept
ajH17-Pb43A,AUTOMATA: Gradient Based Data Subset Selection for Compute-Efficient Hyper-parameter Tuning,"['Hyperparameter Optimization', 'Efficiency', 'Data Subset Selection', 'Submodularity']","[6, 4, 6, 6]","[4, 4, 4, 3]",0,"[317, 263, 348, 838]",Accept
nEJMdZd8cIi,projUNN: efficient method for training deep networks with unitary matrices,[],"[6, 7, 9, 8]","[3, 3, 4, 3]",0,"[230, 206, 307, 281]",Accept
GIZlheqznkT,SUNMASK: Mask Enhanced Control in Step Unrolled Denoising Autoencoders,"['Diffusion', 'Generative Modeling', 'Music Generation', 'Non-autoregressive Sequence Modeling', 'Transformer', 'Convolutional Neural Network']","[3, 6, 3, 7, 5]","[2, 1, 4, 5, 2]",0,"[540, 380, 285, 360, 250]",Reject
wVc4Qg5Bhah,Extra-Newton: A First Approach to Noise-Adaptive Accelerated Second-Order Methods,"['second-order methods', 'universal methods', 'adaptive methods', 'convex optimization', 'stochastic optimization', 'acceleration']","[7, 4, 7, 8]","[4, 4, 4, 3]",0,"[625, 708, 1698, 220]",Accept
VVcSpAbR4zX,Learning to Discover and Detect Objects,"['Detection and localization in 2D and/or 3D', 'Recognition and classification', 'Representation learning', 'Transfer learning', 'Vision applications and systems']","[7, 5, 8, 4]","[4, 3, 4, 4]",0,"[246, 385, 685, 259]",Accept
H4DqfPSibmx,FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,"['Attention', 'GPUs', 'Hardware-efficient model', 'Long context', 'IO complexity']","[8, 6, 8, 7, 7]","[3, 5, 4, 4, 4]",0,"[346, 575, 695, 357, 290]",Accept
Zh21fp1B0vv,Rate-Optimal Online Convex Optimization in Adaptive Linear Control,"['linear control', 'optimism', 'online convex optimization', 'adaptive control']","[7, 7, 7, 7]","[4, 4, 3, 3]",0,"[348, 230, 266, 360]",Accept
6I3zJn9Slsb,Model-based Lifelong Reinforcement Learning with Bayesian Exploration,"['Deep Reinforcement Learning', 'Lifelong Reinforcement Learning']","[7, 6, 6]","[3, 4, 4]",0,"[958, 800, 699]",Accept
0ISChqjlrq,Knowledge Distillation: Bad Models Can Be Good Role Models,"['Knowledge Distillation', 'Teacher-Student', 'Learning Theory', 'Learning to Sample', 'Ensembling']","[6, 6, 6, 7]","[3, 3, 4, 4]",0,"[360, 479, 586, 374]",Accept
1Re5RKwpieG,AVLEN: Audio-Visual-Language Embodied Navigation in 3D Environments,"['audio-visual navigation', 'hierarchical policy learning', 'vision and language navigation']","[6, 5, 7, 4]","[3, 3, 4, 5]",0,"[345, 712, 307, 278]",Accept
zp_Cp38qJE0,Transferring Fairness under Distribution Shifts via Fair Consistency Regularization,"['Fairness', 'Distribution Shifts', 'Self-training', 'Transfer Learning']","[6, 5, 4]","[3, 1, 4]",0,"[300, 427, 501]",Accept
HMs5pxZq1If,A Consistent and Differentiable Lp Canonical Calibration Error Estimator,"['uncertainty calibration', 'calibration error estimator', 'dirichlet kernel density estimation']","[8, 6, 6]","[2, 3, 3]",0,"[600, 326, 617]",Accept
wKf5dRSartn,On Batch Teaching with Sample Complexity Bounded by VCD,"['Machine Teaching', 'VC Dimension', 'Collusion-Freeness']","[7, 5, 8, 7]","[2, 1, 3, 3]",0,"[258, 367, 214, 408]",Accept
U6vBmFL9SxP,Nonlinear Sufficient Dimension Reduction with a Stochastic Neural Network,"['Adaptive Stochastic Gradient MCMC', 'Big Data', 'Deep Learning', 'Stochastic Neural Network', 'Sufficient Dimension Reduction']","[5, 4, 6]","[3, 4, 3]",0,"[147, 372, 206]",Accept
-r6-WNKfyhW,Fine-Tuning Pre-Trained Language Models Effectively by Optimizing Subnetworks Adaptively,[],"[6, 7, 7, 7]","[4, 4, 3, 4]",0,"[812, 292, 468, 351]",Accept
WHqVVk3UHr,Exploring the Whole Rashomon Set of Sparse Decision Trees,"['Rashomon Set', 'Sparse Decision Trees', 'Interpretebility']","[9, 7, 9, 6]","[3, 4, 5, 3]",0,"[249, 158, 587, 406]",Accept
NtwEUZE6VcL,Global Convergence of Direct Policy Search for State-Feedback $\mathcal{H}_\infty$ Robust Control: A Revisit of Nonsmooth Synthesis with Goldstein Subdifferential,"['policy gradient', 'robust control', 'reinforcement learning', 'nonsmooth optimization']","[7, 7, 7, 7]","[3, 3, 4, 3]",0,"[135, 372, 557, 665]",Accept
riIaC2ivcYA,Improved Algorithms for Neural Active Learning,"['Active Learning', 'Neural Network', 'Deep Learning']","[6, 6, 6, 7]","[3, 4, 3, 2]",0,"[212, 515, 394, 350]",Accept
kxXvopt9pWK,Denoising Diffusion Restoration Models,[],"[6, 5, 5, 6]","[3, 4, 4, 4]",0,"[390, 480, 241, 326]",Accept
ZLsZmNe1RDb,"How to talk so AI will learn: Instructions, descriptions, and autonomy","['value alignment', 'language', 'instructions', 'descriptions', 'pragmatics', 'social learning']","[7, 7, 7, 6, 6]","[5, 4, 4, 3, 2]",0,"[566, 402, 531, 1155, 1385]",Accept
zSeoDvsDCe,Sign and Basis Invariant Networks for Spectral Graph Representation Learning,"['Invariance', 'Equivariance', 'Graph Neural Networks', 'Eigenvectors', 'Spectral']","[3, 7, 6, 6]","[4, 3, 4, 3]",0,"[491, 582, 223, 147]",Reject
a01PL2gb7W5,Spectral Bias Outside the Training Set for Deep Networks in the Kernel Regime,"['Spectral Bias', 'Neural Tangent Kernel', 'Implicit Bias']","[7, 6, 8, 6]","[2, 3, 4, 4]",0,"[292, 388, 307, 367]",Accept
WDS1M0gsfXk,On Image Segmentation With Noisy Labels: Characterization and Volume Properties of the Optimal Solutions to Accuracy and Dice,"['Image Segmentation', 'Computer Vision']","[6, 6, 5, 7]","[1, 3, 3, 1]",0,"[119, 463, 292, 144]",Accept
Inj9ed0mzQb,Weisfeiler and Leman Go Walking: Random Walk Kernels Revisited,"['graph kernels', 'Weisfeiler-Leman', 'random walks']","[5, 5, 9, 7]","[3, 4, 5, 3]",0,"[214, 297, 780, 194]",Accept
PrJSZxup-U,Provably Efficient Reinforcement Learning in Partially Observable Dynamical Systems,"['Reinforcement learning theory', 'Provably efficient RL', 'POMDPs', 'PAC RL']","[6, 7, 6, 4]","[1, 3, 2, 1]",0,"[123, 505, 271, 222]",Accept
PRsjhKIrVg,WeightedSHAP: analyzing and improving Shapley based feature attributions,"['Attribution problem', 'Model interpretation', 'Shapley value']","[4, 6, 6, 6]","[4, 4, 4, 4]",0,"[367, 555, 489, 190]",Accept
C2Mikd2WpOc,The Burer-Monteiro SDP method can fail even above the Barvinok-Pataki bound,"['non-convex optimization', 'semidefinite programming', 'Burer-Monteiro', 'manifold optimization', 'low-rank SDP']","[3, 8, 7, 8]","[2, 3, 3, 4]",0,"[536, 524, 647, 519]",Accept
U3gobB4oKv,Fairness Transferability Subject to Bounded Distribution Shift,"['Fairness transferability', 'bounded distribution shift', 'demographic parity', 'equal opportunity', 'covariate shift', 'label shift']","[8, 5, 8, 5]","[4, 3, 3, 3]",0,"[587, 419, 535, 378]",Accept
ZJ7Lrtd12x_,Near-Optimal Sample Complexity Bounds for Constrained MDPs,"['Constrained Markov Decision Processes', 'Sample complexity', 'Generative model', 'Model-based RL', 'Primal-dual algorithm']","[7, 7, 5, 6]","[4, 3, 5, 4]",0,"[244, 654, 250, 612]",Accept
OtjQ7NTu3j,Multi-Fidelity Best-Arm Identification,"['best-arm identification', 'fixed-confidence', 'multi-fidelity', 'multi-armed bandit']","[5, 8, 7, 3]","[3, 4, 3, 3]",0,"[135, 396, 146, 1218]",Accept
p6hArCtwLAU,TreeMoCo: Contrastive Neuron Morphology Representation Learning,"['neuron morphology', 'cell types', 'contrastive learning', 'tree graph augmentation', 'tree-LSTM']","[6, 6, 6, 6]","[3, 4, 3, 3]",0,"[475, 246, 323, 733]",Accept
p3w4l4nf_Rr,Learning in Congestion Games with Bandit Feedback,"['reinforcement learning theory', 'multi-agent reinforcement learning', 'congestion game']","[7, 6, 6]","[3, 4, 3]",0,"[260, 531, 347]",Accept
401LFvBGIb,Deep feedforward functionality by equilibrium-point control in a shallow recurrent network.,"['recurrent physical network', 'combinational logic', 'equilibrium-point control', 'piecewise-linear', 'parity function']","[4, 6, 7, 2]","[2, 1, 2, 1]",0,"[299, 522, 383, 196]",Reject
ACThGJBOctg,Kernel Interpolation with Sparse Grids,['Gaussian processes'],"[7, 6, 5, 8]","[4, 3, 3, 4]",0,"[284, 1229, 657, 291]",Accept
FFPcFtWJwsB,Large-scale Optimization of Partial AUC in a Range of False Positive Rates,"['AUC maximization', 'non-convex optimization', 'first-order method', 'difference-of-convex program']","[5, 7, 6, 6]","[3, 4, 4, 3]",0,"[435, 336, 223, 444]",Accept
WXdSp8k0TMn,Revisiting Non-Parametric Matching Cost Volumes for  Robust and Generalizable Stereo Matching,"['Stereo Matching', 'Contextualized Non-Parametric Cost Volume', 'Adversarial Robustness', 'Simulation-to-Real Generalizability']","[6, 7, 6, 4]","[3, 3, 5, 5]",0,"[290, 933, 909, 210]",Accept
2Bus7sfjZh8,Learning and Covering Sums of Independent Random Variables with Unbounded Support,"['Distribution Learning', 'Sums of Independent Random Variables', 'Covering', 'Density Estimation']","[6, 8, 7]","[2, 2, 4]",0,"[370, 392, 509]",Accept
vDeh2yxTvuh,When Do Flat Minima Optimizers Work?,"['deep learning', 'optimization', 'flatness']","[5, 5, 7, 7]","[4, 5, 5, 4]",0,"[530, 413, 470, 564]",Accept
IIDC-pVqkrf,Using Partial Monotonicity in Submodular Maximization,"['submodular maximization', 'non-convex optimization', 'monotonicity ratio', 'cardinality constraint', 'matroid constraint', 'movie recommendation', 'image summarization']","[7, 4, 7, 7]","[3, 5, 4, 4]",0,"[214, 443, 408, 364]",Accept
GL-3WEdNRM,Phase diagram of Stochastic Gradient Descent in high-dimensional two-layer neural networks,"['stochastic gradient descent', 'two-layer neural networks', 'overparametrization', 'gaussian inputs', 'statistical physics']","[6, 7, 7, 7, 6, 7]","[2, 4, 4, 4, 2, 4]",0,"[356, 636, 410, 416, 203, 526]",Accept
WrIrYMCZgbb,Exploiting Semantic Relations for Glass Surface Detection,"['Glass surface detection', 'semantic relation learning']","[6, 5, 5, 4]","[4, 4, 3, 5]",0,"[357, 488, 539, 249]",Accept
ccYOWWNa5v2,Lifelong Neural Predictive Coding: Learning Cumulatively Online without Forgetting,"['Continual Learning', 'Lifelong Learning', 'Deep Learning', 'Credit Assignment', 'Sparsity', 'Brain-inspired Learning', 'Predictive Coding']","[5, 5, 7]","[5, 3, 3]",0,"[684, 415, 562]",Accept
VgX6ceDerh2,Stochastic Online Learning with Feedback Graphs: Finite-Time and Asymptotic Optimality,"['Bandits', 'Online learning']","[4, 7, 7, 6]","[2, 3, 2, 1]",0,"[741, 427, 483, 207]",Accept
mrt90D00aQX,FedSR: A Simple and Effective Domain Generalization Method for Federated Learning,"['domain generalization', 'representation alignment', 'federated learning']","[6, 7, 6, 4]","[4, 4, 4, 4]",0,"[408, 505, 413, 236]",Accept
8hoDLRLtl9h,Distribution-Informed Neural Networks for Domain Adaptation Regression,[],"[5, 5, 5, 5, 6]","[1, 2, 4, 4, 2]",0,"[415, 413, 263, 567, 321]",Accept
XcDVT8HarS,Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?,"['neural network', 'nonparametric regression', 'local adaptivity']","[6, 6, 4, 5]","[3, 1, 4, 4]",0,"[896, 297, 471, 282]",Reject
Jpxd93u2vK-,Rare Gems: Finding Lottery Tickets at Initialization,[],"[4, 5, 8, 6]","[3, 3, 4, 4]",0,"[128, 358, 221, 494]",Accept
qJpEiCrM3XK,A Curriculum Perspective of Robust Loss Functions,[],"[6, 5, 4, 6]","[4, 2, 5, 4]",0,"[369, 190, 574, 473]",Reject
-welFirjMss,Optimal Transport of Classifiers to Fairness,"['fairness', 'optimal transport', 'projection', 'regularization', 'classification']","[6, 6, 6]","[3, 2, 3]",0,"[254, 211, 848]",Accept
tVbJdvMxK2-,Navigating Memory Construction by Global Pseudo-Task Simulation for Continual Learning,"['continual learning', 'experience replay', 'pseudo-task simulation', 'global optimization', 'dynamic memory construction']","[4, 6, 5]","[3, 4, 3]",0,"[221, 1112, 516]",Accept
8XWP2ewX-im,Hidden Progress in Deep Learning: SGD Learns Parities Near the Computational Limit,"['deep learning', 'feature learning', 'parity', 'emergence', 'phase transitions']","[6, 4, 7]","[4, 4, 3]",0,"[584, 389, 443]",Accept
9i7Sf1aRYq,How and Why to Manipulate Your Own Agent: On the Incentives of Users of Learning Agents,"['Learning agents', 'Regret minimization', 'Meta games', 'User incentives', 'Parameter manipulation', 'Algorithmic game theory', 'Multi-agent systems']","[6, 6, 7, 4]","[3, 4, 4, 3]",0,"[196, 642, 381, 548]",Accept
qC2BwvfaNdd,Data-IQ: Characterizing subgroups with heterogeneous outcomes in tabular data,"['data-centric AI', 'data characterization', 'data quality']","[6, 6, 7, 7, 3]","[3, 4, 4, 3, 3]",0,"[603, 350, 557, 230, 341]",Accept
pluyPFTiTeJ,Domain Generalization without Excess Empirical Risk,"['Domain Generalization', 'Penalty-Based Methods', 'Optimization', 'Rate-Distortion']","[6, 7, 5]","[3, 3, 3]",0,"[240, 593, 274]",Accept
FJ42JCNNUYT,LECO: Learnable Episodic Count for Task-Specific Intrinsic Reward,"['Reinforcement learning', 'Intrinsic reward', 'exploration']","[4, 6, 6]","[4, 4, 3]",0,"[1000, 538, 291]",Accept
wiHzQWwg3l,Extrapolative Continuous-time Bayesian Neural Network for Fast Training-free Test-time Adaptation,"['Brain-informed AI', 'Test-time Adaptation', 'Real-time Domain Adaptation', 'Bayesian Deep Learning', 'Dynamical system', 'Neural Differential Equation', 'Particle Filtering']","[5, 7, 6]","[3, 2, 3]",0,"[515, 301, 604]",Accept
thirVlDJ2IL,A Fourier Approach to Mixture Learning,"['Gaussian mixture models', 'mixture learning']","[7, 6, 7]","[3, 2, 2]",0,"[362, 256, 313]",Accept
2hp6sIBsCDH,Global Linear and Local Superlinear Convergence of IRLS for Non-Smooth Robust Regression,"['Convergence Rate Analysis', 'Non-Smooth Optimization', 'Robust Regression', 'Outliers', 'Iteratively Reweighted Least-Squares', 'Sparsity']","[6, 6, 6]","[4, 4, 4]",0,"[461, 482, 566]",Accept
22hMrSbQXzt,Constrained Update Projection Approach to Safe Policy Optimization,"['Reinforcement Learning', 'Constrained MDP', 'Deep Reinforcement Learning']","[5, 5, 7, 6]","[3, 4, 3, 4]",0,"[255, 373, 437, 245]",Accept
IfgOWI5v2f,Conformal Off-Policy Prediction in Contextual Bandits,"['conformal prediction', 'contextual bandits', 'uncertainty quantification', 'robust ML']","[5, 5, 7]","[3, 5, 4]",0,"[356, 505, 295]",Accept
JLWOTZpWZzY,AutoML Two-Sample Test,"['Two-Sample Test', 'AutoML', 'MMD']","[7, 5, 6, 4]","[3, 4, 4, 4]",0,"[162, 537, 574, 363]",Accept
Ul1legCUGIV,Constraining Gaussian Processes to Systems of Linear Ordinary Differential Equations,"['Gaussian Process', 'Ordinary Differential Equations', 'Machine Learning', 'Probabilistic Model']","[7, 6, 6, 6]","[3, 4, 3, 4]",0,"[625, 479, 1286, 135]",Accept
pNEisJqGuei,Value Function Decomposition for Iterative Design of Reinforcement Learning Agents,"['reinforcement learning', 'explainable AI', 'machine learning', 'decision making', 'deep learning']","[4, 7, 7, 3]","[5, 3, 3, 4]",0,"[287, 970, 244, 453]",Accept
7fdVZR_cl7,Perfect Sampling from Pairwise Comparisons,"['Exact Sampling', 'Pairwise Comparisons', 'Truncated Statistics', 'Coupling From the Past']","[4, 8, 7, 8]","[3, 3, 4, 2]",0,"[158, 311, 821, 580]",Accept
2zQx2Pxbd7J,An $\alpha$-No-Regret Algorithm For Graphical Bilinear Bandits,[],"[5, 6, 7]","[3, 3, 4]",0,"[264, 323, 344]",Accept
FhuM-kk8Pbk,Listen to Interpret: Post-hoc Interpretability for Audio Networks with NMF,"['audio interpretability', 'post-hoc explainability', 'non-negative matrix factorization', 'audio recognition']","[7, 7, 6, 6]","[4, 4, 4, 4]",0,"[501, 559, 1509, 760]",Accept
r-CsquKaHvk,Temporally-Consistent Survival Analysis,"['survival analysis', 'time-to-event', 'dynamic survival', 'temporal-difference learning', 'policy evaluation']","[6, 7, 7, 7]","[5, 4, 3, 4]",0,"[415, 532, 278, 647]",Accept
jjlQkcHxkp0,Exponential Separations in Symmetric Neural Networks,"['deepsets', 'relational network', 'self-attention', 'symmetric function', 'set-based', 'separation']","[7, 8, 7, 7]","[4, 3, 3, 3]",0,"[462, 435, 654, 261]",Accept
_3ELRdg2sgI,STaR: Bootstrapping Reasoning With Reasoning,"['chain-of-thought', 'reasoning', 'language model', 'bootstrapping']","[7, 7, 6, 7]","[3, 4, 4, 4]",0,"[387, 527, 408, 567]",Accept
I1mkUkaguP,Gradient Estimation with Discrete Stein Operators,"['Gradient estimation', ""Stein's method"", 'Markov chain', 'score function', 'REINFORCE', 'discrete latent variables', 'VAE', 'control variates', 'variance reduction']","[7, 7, 7, 8]","[3, 3, 4, 4]",0,"[553, 168, 432, 448]",Accept
-9PV7GKwYpM,Composite Feature Selection Using Deep Ensembles,"['Feature Selection', 'Group Feature Selection']","[6, 6, 5, 6]","[5, 5, 4, 3]",0,"[500, 545, 697, 403]",Accept
sof8l4cki9,Fast Mixing of Stochastic Gradient Descent with Normalization and Weight Decay,"['stochastic gradient descent', 'weight decay', 'stochastic differential equation', 'equilibrium', 'mixing']","[6, 6, 5, 8]","[2, 1, 2, 4]",0,"[251, 269, 633, 353]",Accept
rrYWOpf_Vnf,Sobolev Acceleration and Statistical Optimality for Learning Elliptic Equations via Gradient Descent,"['PDE', 'Ritz Methods', 'nonparametric estimation', 'Physics']","[6, 4, 6, 6, 8]","[2, 3, 1, 2, 4]",0,"[306, 463, 183, 573, 457]",Accept
B4OTsjq63T5,Bayesian inference via sparse Hamiltonian flows,"['Bayes', 'coresets', 'flows', 'Hamiltonian']","[9, 7, 8]","[3, 3, 3]",0,"[295, 819, 628]",Accept
BjGawodFnOy,SHAQ: Incorporating Shapley Value Theory into Multi-Agent Q-Learning,"['Multi-Agent Reinforcement Learning', 'Shapley value', 'Q-Learning']","[6, 7, 6]","[3, 3, 4]",0,"[187, 200, 636]",Accept
OGM9dXemmq,Neural Stochastic PDEs: Resolution-Invariant Learning of Continuous Spatiotemporal Dynamics,"['operator learning', 'PDEs', 'neural differential equations', 'spatiotemporal data']","[5, 6, 7]","[1, 2, 3]",0,"[174, 800, 1032]",Accept
6aIYRZvbmk-,Amortized Inference for Heterogeneous Reconstruction in Cryo-EM,"['Cryo-electron microscopy', '3D Reconstruction', 'Neural Scene Representation']","[5, 6, 5, 7]","[5, 4, 4, 4]",0,"[1151, 565, 451, 368]",Accept
Fn17vlng9pD,NIERT: Accurate Numerical Interpolation through Unifying Scattered Data Representations using Transformer Encoder,"['numerical interpolation', 'transformer encoder', 'mask mechanism', 'pre-training model']","[5, 6, 6]","[3, 4, 4]",0,"[304, 260, 408]",Reject
0xbP4W7rdJW,VAEL: Bridging Variational Autoencoders and Probabilistic Logic Programming,"['neuro-symbolic', 'variational autoencoders', 'probabilistic logic programming']","[5, 6, 4, 6]","[4, 3, 3, 3]",0,"[217, 456, 462, 429]",Accept
Qx6UPW0r9Lf,Reinforced Genetic Algorithm for Structure-based Drug Design,"['molecule generation', 'molecule optimization', 'drug design']","[7, 6, 3, 4]","[3, 4, 4, 5]",0,"[160, 295, 206, 401]",Accept
nV230sPnEBN,One for All: Simultaneous Metric and Preference Learning over Multiple Users,"['metric learning', 'preference learning', 'paired comparisons', 'recommender system', 'multiple users']","[6, 6, 6, 8]","[2, 3, 4, 3]",0,"[573, 212, 567, 454]",Accept
TIPyxNbzeB8,Uplifting Bandits,"['Structure bandits', 'Regret minimization', 'Uplift']","[6, 6, 6, 4]","[4, 3, 4, 4]",0,"[447, 248, 284, 847]",Accept
I-6yh2-dkyD,CyCLIP: Cyclic Contrastive Language-Image Pretraining,"['CLIP', 'Contrastive', 'Language-Image Pretraining', 'Multimodal Learning', 'Representation Learning', 'Cyclic Consistency', 'Zero-shot transfer', 'Robustness']","[7, 7, 7]","[2, 5, 4]",0,"[422, 330, 368]",Accept
m16lH6XJsbb,Spectrum Random Masking for Generalization in Image-based Reinforcement Learning,"['Data augmentation', 'Image-based Reinforcement Learning', 'Specturm']","[7, 5, 6, 7]","[4, 5, 4, 3]",0,"[141, 259, 439, 342]",Accept
Z72wo6oOZQp,First Contact: Unsupervised Human-Machine Co-Adaptation via Mutual Information Maximization,"['reinforcement learning', 'human-computer interaction']","[5, 5, 7]","[3, 3, 4]",0,"[339, 374, 1009]",Accept
ByMYEibhiXO,Learning Superpoint Graph Cut for 3D Instance Segmentation,[],"[7, 5, 6]","[4, 4, 4]",0,"[115, 533, 275]",Accept
WNSyF9qZaMd,Learning Bipartite Graphs: Heavy Tails and Multiple Components,"['graphical models', 'bipartite graphs', 'heavy tails', 'financial markets']","[7, 4, 5]","[3, 4, 4]",0,"[485, 670, 396]",Accept
6TJryN46h7j,MissDAG: Causal Discovery in the Presence of Missing Data with Continuous Additive Noise Models,"['Causal discovery', 'Incomplete data', 'Additive noise models', 'EM method', 'Monte Carlo sampling']","[6, 5, 7, 6]","[3, 4, 4, 4]",0,"[269, 323, 275, 1584]",Accept
7KKL3Z5sod,Efficient Scheduling of Data Augmentation for Deep Reinforcement Learning,"['DeepRL', 'Data augmentation', 'Scheduling', 'Generalization', 'Sample efficiency']","[7, 7, 6, 6]","[3, 3, 3, 4]",0,"[385, 466, 417, 602]",Accept
_VjQlMeSB_J,Chain of Thought Prompting Elicits Reasoning in Large Language Models,"['Language models', 'natural language processing', 'reasoning']","[6, 6, 9]","[3, 4, 4]",0,"[368, 434, 139]",Accept
6ZI4iF_T7t,Weakly Supervised Representation Learning with Sparse Perturbations,"['representation learning', 'identifiability']","[6, 6, 7, 6]","[4, 2, 4, 4]",0,"[508, 267, 299, 357]",Accept
Q82UCjXNSWL,Association Graph Learning for Multi-Task Classification with Category Shifts,"['multi-task learning', 'category shifts', 'association graph']","[6, 7, 6, 5]","[3, 5, 3, 4]",0,"[377, 298, 243, 741]",Accept
cqyBfRwOTm1,Learning from Label Proportions by Learning with Label Noise,"['Machine Learning', 'Semi-supervised Learning', 'Learning Theory', 'Learning from Label Proportions', 'Learning from Label Noise']","[7, 5, 5, 7]","[2, 4, 2, 5]",0,"[416, 738, 195, 339]",Accept
ZfaEZyQDrok,SignRFF: Sign Random Fourier Features,[],"[5, 5, 4, 7]","[4, 3, 4, 3]",0,"[337, 93, 304, 340]",Accept
n6QYLjlYhkG,HYPRO: A Hybridly Normalized Probabilistic Model for Long-Horizon Prediction of Event Sequences,"['probabilistic model', 'event sequences', 'energy-based model', 'long-horizon prediction']","[6, 6, 7]","[3, 4, 4]",0,"[367, 688, 803]",Accept
PuagBLcAf8n,Off-Policy Evaluation for Action-Dependent Non-stationary Environments,"['non-stationarity', 'off-policy', 'reinforcement learning', 'counterfactual']","[7, 5, 4, 6]","[3, 4, 3, 2]",0,"[345, 977, 478, 827]",Accept
z2cG3k8xa3C,Asymptotics of smoothed Wasserstein distances in the small noise regime,"['Optimal transport', 'statistical estimation']","[7, 7, 7, 7]","[3, 4, 4, 3]",0,"[455, 446, 308, 845]",Accept
9BL0-oS7W7_,Defending Against Adversarial Attacks via Neural Dynamic System,['ordinary differential equation (ODE)'],"[8, 4, 7, 6]","[5, 2, 5, 4]",0,"[297, 168, 646, 219]",Accept
tmer8WAEzV,Sampling with Riemannian Hamiltonian Monte Carlo in a Constrained Space,"['Sampling', 'Hamiltonian Monte Carlo']","[8, 8, 5, 7, 4]","[3, 4, 3, 4, 3]",0,"[561, 582, 354, 764, 384]",Accept
Xa1T165JEhB,Optimal-er Auctions through Attention,"['automated mechanism design', 'attention', 'transformers', 'optimal auctions', 'revenue', 'incentive-compatibility']","[6, 4, 6, 8]","[3, 5, 3, 4]",0,"[663, 392, 375, 630]",Accept
qTCiw1frE_l,The Phenomenon of Policy Churn,"['Reinforcement Learning', 'Exploration', 'Deep learning', 'Deep RL', 'Policy space', 'Stability']","[5, 6, 8]","[3, 4, 4]",0,"[476, 326, 585]",Accept
kMiL9hWbD1z,RTFormer: Efficient Design for Real-Time Semantic Segmentation with Transformer,[],"[5, 5, 5, 5]","[5, 4, 5, 5]",0,"[174, 351, 146, 341]",Accept
VE8QRTrWAMb,Near-Optimal Regret for Adversarial MDP with Delayed Bandit Feedback,"['regret minimization', 'adversarial mdp', 'delay', 'reinforcement learning', 'online learning']","[5, 8, 6]","[4, 4, 4]",0,"[457, 879, 247]",Accept
rTvH1_SRyXs,Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post Hoc Explanations,"['explainability', 'transparency']","[5, 5, 8, 6]","[4, 3, 3, 2]",0,"[291, 254, 149, 350]",Accept
iivHwZoWzR4,On the Computational Efficiency of Adapting Transformer Models via Adversarial Noise,"['Efficient Training Methods', 'Pre-trained Transformer Networks', 'Distributed Training']","[7, 5, 6]","[3, 3, 3]",0,"[321, 237, 358]",Reject
zSdz5scsnzU,Latent Planning via Expansive Tree Search,[],"[6, 6, 6, 6]","[4, 3, 4, 4]",0,"[844, 610, 1130, 731]",Accept
qqHMvHbfu6,Emergent Communication: Generalization and Overfitting in Lewis Games,"['Emergent communication', 'Lewis games', 'Signaling games', 'generalization', 'compositionality']","[5, 8, 8]","[4, 3, 4]",0,"[887, 378, 558]",Accept
E28hy5isRzC,Entropy-Driven Mixed-Precision Quantization for Deep Network Design,[],"[7, 5, 6, 8]","[4, 3, 3, 5]",0,"[120, 722, 518, 294]",Accept
o3HXEEBKnD,Label-Aware Global Consistency for Multi-Label Learning with Single Positive Labels,[],"[7, 8, 7, 7]","[3, 4, 4, 5]",0,"[229, 373, 396, 280]",Accept
vdh62914QR,Black-Box Generalization: Stability of Zeroth-Order Learning,"['Generalization Error', 'Zeroth-Order Optimization', 'Black-Box Learning']","[5, 6, 7, 6]","[3, 3, 3, 3]",0,"[358, 201, 254, 256]",Accept
hPkGV4BPsmv,DReS-FL: Dropout-Resilient Secure Federated Learning for Non-IID Clients via Secret Data Sharing,"['Federated Learning', 'non-IID problem', 'client dropouts', 'privacy-preserving learning', 'Lagrange coded computing']","[4, 7, 6, 4]","[4, 4, 4, 4]",0,"[1078, 346, 236, 270]",Accept
nosngu5XwY9,Dynamic Inverse Reinforcement Learning for Characterizing Animal Behavior,"['Neuroscience', 'decision-making', 'inverse reinforcement learning']","[8, 6, 6, 10]","[5, 2, 3, 5]",0,"[308, 1206, 770, 403]",Accept
7fGIR2oIHTl,Confidence-based Reliable Learning under Dual Noises,"['Noisy data', 'model uncertainty']","[7, 4, 5]","[3, 3, 4]",0,"[210, 305, 441]",Accept
CFAsKosKwwk,Interpolation and Regularization for Causal Learning,"['Causality', 'Interpolation', 'High-dimensional linear regression']","[6, 7, 6, 6]","[3, 4, 3, 1]",0,"[302, 267, 172, 115]",Accept
FO0Gb8IL1p5,Off-Policy Evaluation with Policy-Dependent Optimization Response,"['causal inference', 'off-policy evaluation', 'debiased data-driven optimization']","[7, 7, 6, 4]","[3, 3, 3, 3]",0,"[729, 373, 349, 232]",Accept
BuQIv5Qe35,"PDSketch: Integrated Domain Programming, Learning, and Planning","['Model-Based Learning', 'Neuro-Symbolic Programming', 'Heuristic Planning']","[5, 5, 5]","[5, 3, 2]",0,"[709, 627, 431]",Accept
AlkMMzUX95,Spatial Mixture-of-Experts,"['deep learning', 'mixture of experts', 'regression', 'weather prediction']","[3, 7, 6, 6, 5]","[4, 4, 3, 4, 3]",0,"[126, 318, 591, 709, 276]",Accept
qOgSCLE5E8,Adaptive Distribution Calibration for Few-Shot Learning with Hierarchical Optimal Transport,[],"[6, 5, 7, 6]","[4, 2, 4, 3]",0,"[417, 375, 305, 876]",Accept
N_D-JLau3Z,Iterative Structural Inference of Directed Graphs,"['Structural Inference', 'Graph Neural Networks', 'Information Bottleneck', 'Deep Learning']","[6, 5, 6]","[2, 3, 3]",0,"[162, 362, 420]",Accept
lhl_rYNdiH6,Contrastive Graph Structure Learning via Information Bottleneck for Recommendation,"['Recommender system', 'Graph Neural Networks', 'contrastive learning']","[6, 6, 5, 8]","[5, 3, 4, 3]",0,"[474, 321, 576, 291]",Accept
PBmJC6rDnR6,A Geometric Perspective on Variational Autoencoders,"['Variational autoencoders', 'latent space modeling', 'Riemannian geometry']","[7, 6, 6]","[3, 2, 2]",0,"[261, 705, 376]",Accept
DbEVhhuNjr,Foundation Posteriors for Approximate Probabilistic Inference,"['approximate inference', 'masked language modeling', 'probabilistic program', 'graphical model']","[8, 6, 7, 7]","[4, 4, 3, 4]",0,"[444, 366, 372, 732]",Accept
MZoyeKrpVYP,On Non-Linear operators for Geometric Deep Learning,"['Manifold', 'Deep learning', 'Diffeomorphisms']","[7, 5, 6]","[2, 2, 2]",0,"[252, 143, 189]",Accept
F2Gk6Vr3wu,Scale-invariant Learning by Physics Inversion,"['Higher-order Optimization', 'Neural Networks', 'Inverse Problems', 'Physical Simulations']","[6, 6, 6]","[3, 3, 3]",0,"[297, 457, 322]",Accept
9Hjh0tMT1pm,Towards Improving Faithfulness in Abstractive Summarization,"['summarization', 'faithfulness']","[6, 7, 7, 6]","[4, 4, 4, 4]",0,"[376, 291, 554, 372]",Accept
3vpvnMVOUKE,Nonlinear MCMC for Bayesian Machine Learning,"['bayesian machine learning', 'markov chain monte carlo']","[7, 7, 5, 7]","[4, 1, 3, 4]",0,"[427, 657, 317, 1049]",Accept
qwjrO7Rewqy,Neural Approximation of Graph Topological Features,"['Persistent Homology', 'Topological Data Analysis', 'Neural Execution', 'Graph Nerual Networks']","[5, 5, 7]","[3, 3, 4]",0,"[464, 439, 630]",Accept
7TGpLKADODE,Self-Supervised Fair Representation Learning without Demographics,"['fairness without demographics', 'reweighing', 'representation learning']","[5, 5, 7, 6]","[3, 3, 4, 4]",0,"[358, 408, 327, 272]",Accept
2B2xIJ299rx,Efficient Training of Low-Curvature Neural Networks,"['Deep neural networks', 'curvature', 'spectral norm', 'Lipschitz constant', 'robustness']","[7, 6, 4, 4]","[4, 5, 3, 4]",0,"[1045, 487, 728, 789]",Accept
wzJcEb5Mm4,Log-Polar Space Convolution Layers,"['Log-Polar Space', 'Convolution Kernel', 'Local Receptive Field', 'Spatial Context']","[5, 5, 5, 7]","[4, 4, 4, 3]",0,"[449, 425, 236, 876]",Accept
g2cM5983pw,Reinforcement Learning with Logarithmic Regret and Policy Switches,"['reinforcement learning theory', 'function approximation', 'instance-dependent regret']","[7, 6, 4, 8]","[3, 3, 3, 5]",0,"[187, 172, 210, 183]",Accept
peZSbfNnBp4,Ensemble of Averages: Improving Model Selection and Boosting Performance in Domain Generalization,"['ensemble', 'model averaging', 'simple moving average', 'domain generalization', 'model selection', 'bias-variance trade-off']","[7, 6, 6, 6]","[4, 5, 4, 4]",0,"[274, 812, 956, 708]",Accept
L74c-iUxQ1I,Gradient flow dynamics of shallow ReLU networks for square loss and orthogonal inputs,"['implicit bias', 'two-layer neural networks', 'gradient flow', 'gradient descent', 'global convergence', 'ReLU networks', 'variation norm', 'non-convex optimisation']","[7, 6, 7, 7]","[3, 4, 3, 5]",0,"[774, 364, 631, 472]",Accept
TwyEk7HzJb6,Bandit Learning in Many-to-one Matching Markets with Uniqueness Conditions,"['Multi-armed Bandits', 'Many-to-one Matching', 'Uniqueness Conditions']","[7, 6, 3, 5]","[3, 2, 3, 4]",0,"[240, 414, 392, 278]",Reject
lMrpZ-ycIaT,Self-Supervised Learning of Brain Dynamics from Broad Neuroimaging Data,"['pre-training', 'self-supervised learning', 'neuroimaging', 'mental state decoding', 'natural language processing', 'language modelling']","[8, 5, 6]","[4, 5, 5]",0,"[579, 818, 267]",Accept
aPgQdvSAuw,On Translation and Reconstruction Guarantees of the Cycle-Consistent Generative Adversarial Networks,"['Cycle Consistency Loss', 'Theory of Deep Learning', 'CycleGAN', 'Unsupervised Image-to-Image Translation']","[7, 5, 6, 6]","[3, 2, 3, 1]",0,"[205, 133, 236, 141]",Accept
mjVmifxpKqS,Near-Optimal Regret Bounds for Multi-batch Reinforcement Learning,[],"[5, 6, 7, 6]","[3, 4, 4, 4]",0,"[450, 236, 259, 488]",Accept
k_XHLBD4qPO,On Overcompression in Continual Semantic Segmentation,"['Continual Learning', 'Class-Incremental Semantic Segmentation', 'Information Bottleneck', 'overcompression', 'dropout']","[4, 3, 4, 3]","[4, 4, 3, 3]",0,"[262, 483, 318, 483]",Reject
vsNQkquutZk,WaveBound: Dynamic Error Bounds for Stable Time Series Forecasting,"['time series forecasting', 'overfitting', 'regularization']","[6, 5, 7, 7]","[4, 4, 4, 4]",0,"[557, 494, 384, 633]",Accept
nP6e73uxd1,Sampling from Log-Concave Distributions with Infinity-Distance Guarantees,"['sampling', 'differential privacy', 'log-concave distribution', 'infinity distance', 'Markov chains']","[7, 8, 7, 7]","[3, 3, 3, 3]",0,"[318, 249, 526, 836]",Accept
2Tv54LpM9cK,Distributed Inverse Constrained Reinforcement Learning for Multi-agent Systems,"['inverse reinforcement learning', 'distributed bi-level optimization']","[8, 5, 6, 6]","[4, 3, 3, 4]",0,"[735, 205, 369, 1157]",Accept
T-aVFGCSQNV,Early Stage Convergence and Global Convergence of Training Mildly Parameterized Neural Networks,"['non-convex optimization', 'training dynamics', 'neural network']","[5, 6, 5, 7]","[4, 3, 4, 5]",0,"[403, 1342, 867, 415]",Accept
FhyrZ92DcI9,Task-level Differentially Private Meta Learning,"['Privacy', 'Meta Learning', 'Distributed Learning']","[5, 6, 4]","[3, 3, 4]",0,"[298, 233, 372]",Accept
vkhYWVtfcSQ,Surprise Minimizing Multi-Agent Learning with Energy-based Models,"['Energy-based Models', 'Multi-Agent Learning', 'Surprise Minimization']","[5, 7, 6]","[2, 5, 5]",0,"[354, 328, 236]",Accept
5OLcPQaYTVg,Learning Predictions for Algorithms with Predictions,"['algorithms with predictions', 'learning-augmented algorithms', 'online learning', 'combinatorial optimization', 'meta-learning']","[7, 6, 5, 7]","[4, 2, 4, 5]",0,"[368, 292, 289, 532]",Accept
UmFSx2c4ubT,GLIF: A Unified Gated Leaky Integrate-and-Fire Neuron for Spiking Neural Networks,"['Spiking Neural Networks', 'Leaky Integrate-and-Fire', 'Unified Spiking Neuron', 'Biological Features']","[6, 3, 5, 5]","[4, 5, 5, 4]",0,"[544, 382, 290, 178]",Accept
BqnMaAvTNVq,Spectral Bias in Practice: The Role of Function Frequency in Generalization,"['spectral bias', 'generalization', 'data augmentation', 'self-distillation', 'image classification']","[4, 7, 7, 6]","[4, 4, 5, 4]",0,"[753, 371, 376, 791]",Accept
5g-h_DILemH,Robust Binary Models by Pruning Randomly-initialized Networks,"['Adversarial Robustness', 'Model Compression']","[7, 4, 7, 5]","[3, 4, 3, 4]",0,"[184, 382, 655, 251]",Accept
Ep98SUx9gka,Re-Analyze Gauss: Bounds for Private Matrix Approximation via Dyson Brownian Motion,"['Differential Privacy', 'Dyson Brownian Motion', 'Random Matrices', 'Rank-k Covariance Approximation', 'Subspace Recovery']","[6, 6, 3, 7]","[3, 3, 4, 4]",0,"[375, 499, 124, 267]",Accept
oOte_397Q4P,Sparse Structure Search for Delta Tuning,"['Parameter Efficient Tuning', 'Pre-trained Models', 'Neural Architecture Search', 'Delta Tuning']","[5, 6, 6, 6]","[4, 4, 2, 3]",0,"[262, 494, 102, 294]",Accept
W1MUJv5zaXP,Modeling Human Exploration Through Resource-Rational Reinforcement Learning,"['Exploration', 'Meta-Learning', 'Cognitive Science', 'Resource-Rationality']","[7, 7, 7, 9]","[3, 4, 4, 5]",0,"[703, 610, 988, 333]",Accept
GTde0BIHMGB,Order-Invariant Cardinality Estimators Are Differentially Private,"['streaming algorithms', 'differential privacy', 'cardinality estimation', 'distinct elements']","[7, 6, 7, 6]","[4, 4, 4, 5]",0,"[553, 334, 293, 519]",Accept
n3lr7GdcbyD,Optimal and Adaptive Monteiro-Svaiter Acceleration,"['convex optimization', 'optimization theory', 'second-order methods', 'Monteiro-Svaiter acceleration', 'proximal points', 'momentum', ""Newton's method"", 'cubic regularization', 'conjugate residuals', 'oracle complexity', 'optimal algorithms', 'adaptive methods', 'parameter-free methods']","[5, 8, 7, 8]","[4, 4, 2, 4]",0,"[552, 1525, 315, 335]",Accept
mTra5BIUyRV,Fair Ranking with Noisy Protected Attributes,"['fair ranking', 'group fairness', 'stochastic noise in protected attributes']","[6, 6, 7, 8]","[3, 3, 3, 4]",0,"[624, 802, 904, 660]",Accept
A0WsxAzR_yn,A consistently adaptive trust-region method,"['trust-region method', 'adaptive', 'optimization']","[6, 7, 6]","[3, 3, 3]",0,"[325, 241, 354]",Accept
w4X7GLThiuJ,Alternating Mirror Descent for Constrained Min-Max Games,"['Min-max games', 'regret bound', 'mirror descent', 'alternating method', 'Hamiltonian', 'symplectic integrator']","[6, 6, 6]","[3, 3, 3]",0,"[342, 393, 452]",Accept
BOQr80FBX_,Semi-Supervised Video Salient Object Detection Based on Uncertainty-Guided Pseudo Labels,"['Semi-Supervised Video Salient Object Detection', 'Adversarial Learning']","[5, 6, 5]","[4, 4, 2]",0,"[531, 223, 238]",Accept
suplyBhTDjC,Beyond Time-Average Convergence: Near-Optimal Uncoupled Online Learning via Clairvoyant Multiplicative Weights Update,"['Regret', 'Coarse correlated equilibria', 'Online learning', 'Game theory']","[6, 5, 6, 7]","[4, 3, 4, 4]",0,"[339, 430, 655, 237]",Accept
w6fj2r62r_H,Torsional Diffusion for Molecular Conformer Generation,"['conformer generation', 'diffusion models', 'score-based models', 'molecular structure', 'equivariance', 'geometric deep learning', 'Boltzmann generator']","[8, 7, 7, 7]","[3, 3, 5, 4]",0,"[296, 275, 409, 203]",Accept
foMcvT6R3VT,Can Variance-Based Regularization Improve Domain Generalization?,"['Variance-Based Regularization', 'Domain Generalization', 'Robustness']","[5, 4, 4, 5]","[3, 4, 4, 2]",0,"[196, 430, 228, 270]",Reject
Hb37zNk14e5,Learning to Find Proofs and Theorems by Learning to Refine Search Strategies: The Case of Loop Invariant Synthesis,"['Theorem Proving', 'Program Synthesis', 'AlphaZero', 'Reinforcement Learning']","[4, 7, 5]","[4, 5, 4]",0,"[134, 443, 515]",Accept
FJVB_tkiWpw,ZooD: Exploiting Model Zoo for Out-of-Distribution Generalization,"['Out-of-Distribution Generalization', 'Model Zoo', 'Probabilistic Models']","[7, 5, 5]","[3, 3, 4]",0,"[307, 366, 267]",Accept
ex60CCi5GS,Debiasing Graph Neural Networks via Learning Disentangled Causal Substructure,"['Graph Neural Networks', 'Debiasing', 'Causal substructure']","[3, 4, 8, 8]","[5, 5, 5, 4]",0,"[347, 488, 460, 506]",Accept
nDemfqKHTpK,GraB: Finding Provably Better Data Permutations than Random Reshuffling,[],"[7, 6, 6]","[3, 4, 4]",0,"[645, 738, 486]",Accept
GH4q4WmGAsl,Enhancing Safe Exploration Using Safety State Augmentation,"['safe reinforcement learning', 'safety during training']","[4, 7, 3, 7]","[4, 5, 4, 3]",0,"[446, 316, 778, 368]",Accept
jdsmBlsHGF2,Generalization Error Bounds on Deep Learning with Markov Datasets,"['Generalization Errors', 'Deep Learning', 'Bayesian Deep Learning']","[8, 7, 3]","[4, 2, 4]",0,"[2618, 675, 430]",Accept
EFnI8Qc--jE,Posterior Matching for Arbitrary Conditioning,"['arbitrary conditioning', 'variational autoencoders', 'density estimation', 'inpainting', 'unsupervised learning']","[7, 6, 8, 6]","[3, 4, 3, 5]",0,"[249, 606, 309, 808]",Accept
Dh7eLBlTXb5,Learning to Re-weight Examples with Optimal Transport for Imbalanced Classification,[],"[6, 4, 5, 6]","[4, 3, 4, 4]",0,"[316, 526, 338, 638]",Accept
FFZYhY2z3j,Matrix Multiplicative Weights Updates in Quantum Zero-Sum Games: Conservation Laws & Recurrence,"['online learning in quantum games', 'Poincare recurrence', 'dynamical systems', 'zero-sum games']","[7, 6, 5, 7]","[4, 3, 3, 5]",0,"[752, 215, 277, 520]",Accept
Leg6spUEFFf,On the non-universality of deep learning: quantifying the cost of symmetry,[],"[5, 7, 6, 6]","[3, 3, 2, 2]",0,"[449, 417, 274, 295]",Accept
D87gRf2-np,Dont fear the unlabelled: safe semi-supervised learning via simple debiasing,"['Semi-supervised learning', 'deep learning', 'empirical risk minimization', 'control variate', 'variance reduction']","[4, 3, 7, 6]","[3, 4, 4, 5]",0,"[291, 216, 503, 421]",Reject
wwW-1k1ljIg,Pre-activation Distributions Expose Backdoor Neurons,"['Backdoor Defense', 'Backdoor Attack', 'Adversarial Learning']","[5, 8, 4, 6]","[3, 3, 5, 4]",0,"[535, 274, 274, 794]",Accept
EbMuimAbPbs,Flamingo: a Visual Language Model for Few-Shot Learning,[],"[3, 8, 8, 7, 8]","[4, 5, 4, 4, 4]",0,"[570, 603, 370, 350, 386]",Accept
b57KM4ydqpp,The Curse of Unrolling: Rate of Differentiating Through Optimization,"['implicit differentiation', 'unrolling', 'optimization', 'bi-level', 'meta-learning', 'sobolev']","[8, 6, 6]","[3, 3, 3]",0,"[288, 365, 287]",Accept
kS5KG3mpSY,Adaptive Multi-stage Density Ratio Estimation for Learning Latent Space Energy-based Model,[],"[7, 7, 7]","[4, 4, 4]",0,"[488, 242, 158]",Accept
Yg2CRGUln5k,Distributionally robust weighted k-nearest neighbors,[],"[5, 8, 7, 5]","[3, 3, 4, 4]",0,"[191, 341, 704, 495]",Accept
CEjuyeZj1jz,Finite-Time Analysis of Fully Decentralized Single-Timescale Actor Critic ,"['Actor Critic', 'finite-time analysis']","[5, 6, 6]","[5, 5, 4]",0,"[386, 299, 567]",Reject
O0HTonUP2A2,Towards Disentangling Information Paths with Coded ResNeXt,"['Deep Learning', 'Image classification', 'ResNeXt', 'Explainability']","[4, 6, 6, 7]","[4, 4, 2, 4]",0,"[483, 376, 317, 673]",Accept
P7TayMSBhnV,Stability and Generalization for Markov Chain Stochastic Gradient Methods,"['statistical learning theory', 'algorithmic stability', 'generalization analysis', 'stochastic gradient methods']","[6, 7, 4]","[3, 4, 1]",0,"[392, 468, 211]",Accept
YpHb0IVJu92,Safe Opponent-Exploitation Subgame Refinement,[],"[7, 4, 6]","[3, 4, 4]",0,"[211, 213, 684]",Accept
nZRTRevUO-,Local Latent Space Bayesian Optimization over Structured Inputs,"['Bayesian optimization', 'ML for molecules']","[7, 7, 6]","[4, 4, 4]",0,"[353, 366, 957]",Accept
deyqjpcTfsG,Iron: Private Inference on Transformers,[],"[7, 6, 6]","[2, 4, 5]",0,"[192, 490, 312]",Accept
AJ_flTkNFhP,Uncertainty-Aware Hierarchical Refinement for Incremental Implicitly-Refined Classification,['incremental learning'],"[5, 4, 5, 5]","[4, 3, 4, 2]",0,"[313, 608, 463, 203]",Accept
rjbl59Qkf_,Understanding Why Generalized Reweighting Does Not Improve Over ERM,"['Distributional Shift', 'Generalization', 'Algorithmic Fairness', 'Class Imbalance']","[4, 5, 7, 4]","[4, 3, 3, 2]",0,"[286, 415, 376, 280]",Reject
e4Wf6112DI,Increasing the Scope as You Learn: Adaptive Bayesian Optimization in Nested Subspaces,"['Bayesian optimization', 'global optimization', 'Gaussian process', 'high-dimensional']","[7, 7, 7]","[3, 5, 3]",0,"[605, 595, 289]",Accept
oMhmv3hLOF2,Streaming Radiance Fields for 3D Video Synthesis,"['NeRF', 'Dynamic Scenes', 'Streaming', '3D Video Synthesis']","[5, 6, 6]","[4, 4, 3]",0,"[560, 585, 318]",Accept
ePgJfxYxl7m,Universal approximation and model compression for radial neural networks,"['universal approximation', 'model compression', 'radial functions', 'parameter space symmetries', 'projected gradient descent']","[6, 7, 3]","[3, 4, 3]",0,"[291, 224, 387]",Reject
-t9FUWW5f3u,MOVE: Unsupervised Movable Object Segmentation and Detection,"['Object Discovery', 'Saliency Detection', 'Object Segmentation', 'Object Detection', 'Self-Supervised Learning', 'Unsupervised Learning']","[8, 3, 8]","[5, 5, 4]",0,"[360, 385, 548]",Accept
lDohSFOHr0,Robust Semi-Supervised Learning when Not All Classes have Labels,"['semi-supervised learning', 'novel class discovery', 'robust']","[4, 8, 7, 8]","[5, 4, 5, 4]",0,"[479, 310, 363, 306]",Accept
dfOBSd3tF9p,An Error Analysis of Deep Density-Ratio Estimation with Bregman Divergence,"['Curse of dimensionality', 'error analysis', 'KL divergence', 'telescoping density ratio estimator']","[5, 6, 6, 7]","[2, 3, 3, 4]",0,"[269, 371, 377, 837]",Reject
2xfJ26BuFP,Near-Optimal Collaborative Learning in Bandits,"['collaborative learning', 'multi-armed bandit', 'centralized learning', 'communication', 'elimination based-algorithm', 'data-driven sampling']","[7, 7, 6]","[4, 4, 3]",0,"[210, 485, 551]",Accept
pfI7u0eJAIr,On Embeddings for Numerical Features in Tabular Deep Learning,"['tabular data', 'deep learning', 'neural network', 'architecture', 'DNN']","[6, 6, 5, 3]","[4, 4, 3, 3]",0,"[497, 645, 285, 955]",Accept
Vj-jYs47cx,Decentralized Gossip-Based Stochastic Bilevel Optimization over Communication Networks,"['Decentralized Optimization', 'Federated Learning', 'Bilevel Optimization', 'Compositional Optimization']","[6, 7, 6, 7]","[3, 4, 5, 3]",0,"[353, 360, 394, 607]",Accept
yipUuqxveCy,Offline Multi-Agent Reinforcement Learning with Knowledge Distillation,"['offline multi-agent reinforcement learning', 'multi-agent', 'offline reinforcement learning']","[5, 6, 6]","[4, 5, 4]",0,"[279, 294, 448]",Accept
muvlhVKvd4,A Unified Convergence Theorem for Stochastic Optimization Methods,"['stochastic optimization theory', 'almost sure convergence']","[7, 6, 7, 6]","[4, 3, 3, 3]",0,"[447, 223, 216, 291]",Accept
wSVEd3Ta42m,Distributional Reinforcement Learning for Risk-Sensitive Policies,"['distributional reinforcement learning', 'cvar', 'risk-sensitive RL']","[5, 6, 6, 7]","[3, 3, 3, 4]",0,"[214, 211, 611, 348]",Accept
vriLTB2-O0G,Pareto Set Learning for Expensive Multi-Objective Optimization,"['Multi-Objective Optimization', 'Expensive Multi-Objective Optimization', 'Bayesian Optimization', 'Multi-Objective Bayesian Optimization', 'Pareto Set Learning']","[8, 5, 5, 7]","[5, 4, 4, 5]",0,"[318, 869, 165, 210]",Accept
7fU8UPo875w,Tracking Functional Changes in Nonstationary Signals with Evolutionary Ensemble Bayesian Model for Robust Neural Decoding,"['Brain-machine-interface', 'Bayesian filter', 'state-space model', 'evolutionary computation']","[5, 6, 4, 5]","[2, 2, 4, 2]",0,"[136, 897, 325, 766]",Accept
4rm6tzBjChe,Simultaneous Missing Value Imputation and Structure Learning with Groups,"['structure learning', 'missing value', 'variational inference', 'graph neural network']","[6, 5, 7]","[3, 3, 3]",0,"[254, 229, 414]",Accept
ofRmFwBvvXh,Approximation with CNNs in Sobolev Space: with Applications to Classification,"['Approximation', 'error bound', 'smooth functions', 'classification', 'neural networks']","[4, 7, 9]","[5, 2, 5]",0,"[585, 458, 367]",Accept
nSe94hrIWhb,Reduction Algorithms for Persistence Diagrams of Networks: CoralTDA and PrunIT,"['graph decomposition', 'persistent homology']","[4, 5, 8]","[4, 5, 5]",0,"[467, 126, 997]",Accept
G3fswMh9P8y,FedAvg with Fine Tuning: Local Updates Lead to Representation Learning,"['Federated learning', 'Representation learning']","[7, 7, 6, 7]","[3, 4, 2, 3]",0,"[353, 650, 283, 216]",Accept
U_YPSEyN2ls,Improved Regret Analysis for Variance-Adaptive Linear Bandits and Horizon-Free Linear Mixture MDPs,"['linear bandits', 'MDP']","[7, 6, 5]","[4, 3, 3]",0,"[293, 393, 650]",Accept
wfKbtSjHA6F,Sparse Winning Tickets are Data-Efficient Image Recognizers,[],"[6, 5, 7, 6]","[4, 4, 4, 4]",0,"[139, 1111, 279, 431]",Accept
ldxUm0mmhl8,Counterfactual Temporal Point Processes,"['counterfactual explanations', 'temporal point processes', 'structural causal model', 'explainability']","[4, 7, 7, 6]","[4, 3, 4, 3]",0,"[378, 284, 877, 595]",Accept
tq_J_MqB3UB,Diverse Weight Averaging for Out-of-Distribution Generalization,"['Deep Learning', 'Computer Vision', 'Out-of-Distribution Generalization', 'Domain Generalization', 'Distribution Shifts', 'Ensembling', 'Weight Averaging']","[8, 6, 7, 7]","[3, 2, 3, 4]",0,"[326, 283, 242, 834]",Accept
RdJY39KRUCX,Vector Quantized Diffusion Model with CodeUnet for Text-to-Sign Pose Sequences Generation,"['Sign Language Production', 'Discrete Diffusion Model', 'Pose Sequence Generation', 'Vector Quantized']","[5, 5, 5]","[5, 3, 4]",0,"[353, 371, 534]",Reject
x7S1NsUdKZ,Adaptive Sampling for Discovery,"['Bandit', 'Discovery', 'Chemistry']","[4, 6, 6]","[4, 3, 3]",0,"[702, 431, 519]",Accept
VRvMQq3d1l0,Learned Index with Dynamic $\epsilon$,"['Learned Index', 'Dynamic $\\epsilon$']","[5, 6, 6]","[3, 3, 3]",0,"[416, 329, 323]",Reject
PtbGae6Eauy,Smoothed Online Convex Optimization Based on Discounted-Normal-Predictor,"['Smoothed Online Convex Optimization', 'Adaptive regret with switching cost', 'Dynamic regret with switching cost', 'Discounted-Normal-Predictor']","[5, 7, 7, 7]","[2, 3, 4, 3]",0,"[114, 317, 418, 593]",Accept
ju38DG3sbg6,Learning Expressive Meta-Representations with Mixture of Expert Neural Processes,[],"[7, 7, 6]","[3, 3, 4]",0,"[491, 301, 456]",Accept
kFRCvpubDJo,Causal Discovery in Heterogeneous Environments Under the Sparse Mechanism Shift Hypothesis,"['causal discovery', 'sparse mechanism shift', 'causality', 'causal inference', 'distribution shifts', 'structure learning', 'heterogenous data', 'hypothesis testing']","[5, 6, 6]","[5, 4, 3]",0,"[464, 385, 161]",Accept
5wI7gNopMHW,Neural Stochastic Control,"['Stochastic control', 'differential equations', 'neural networks']","[7, 4, 5, 7]","[3, 3, 4, 3]",0,"[478, 794, 583, 389]",Accept
UvQgwhYi7QM,Beyond L1: Faster and Better Sparse Models with skglm,"['nonsmooth optimization', 'cooridnate descent', 'Anderson acceleration']","[6, 7, 5]","[2, 3, 2]",0,"[298, 440, 345]",Accept
DzPWTwfby5d,Promising or Elusive? Unsupervised Object Segmentation from Real-world Single Images,"['Multi-Object Segmentation', 'Unsupervised Learning', 'Object-Centric Representation', 'Dataset Complexity']","[6, 7, 7]","[5, 4, 5]",0,"[593, 434, 658]",Accept
R5pVDJ4FNoc,Mining Multi-Label Samples from Single Positive Labels,"['GANs', 'Markov chain Monte Carlo method', 'sampling', 'conditional generation', 'single positive label', 'multi-label']","[6, 7, 6, 5]","[4, 4, 2, 3]",0,"[230, 222, 368, 396]",Accept
SLA4t66xln9,Unsupervised Domain Adaptation for Semantic Segmentation using Depth Distribution,"['Unsupervised Domain Adaptation', 'Semantic Segmentation', 'depth density', 'multi-task learning', 'pseudo-labels refinement']","[5, 6, 4, 5]","[4, 4, 4, 5]",0,"[2342, 627, 292, 661]",Accept
rjDziEPQLQs,A Damped Newton Method Achieves Global $\mathcal O \left(\frac{1}{k^2}\right)$  and Local Quadratic  Convergence Rate,"['Cubic Newton method', 'Damped Newton method', 'fast global convergence', 'convex optimization']","[6, 6, 8]","[5, 4, 3]",0,"[610, 634, 60]",Accept
Cp9sWmkd1H0,Improving GANs with A Dynamic Discriminator,"['generative adversarial network', 'image synthesis']","[6, 5, 5, 6]","[4, 5, 4, 4]",0,"[535, 449, 414, 734]",Accept
ldRyJb_cjXa,Star Temporal Classification: Sequence Modeling with Partially Labeled Data,[],"[4, 6, 6]","[4, 4, 4]",0,"[403, 568, 334]",Accept
Q9dj3MzY1o7,PKD: General Distillation Framework for Object Detectors via Pearson Correlation Coefficient,"['Knowledge Distillation', 'Object Detection']","[6, 6, 6]","[4, 4, 5]",0,"[345, 216, 1669]",Accept
K2QGzyLwpYG,Data-Efficient Structured Pruning via Submodular Optimization,"['Structured pruning', 'weakly submodular optimization', 'neural networks compression']","[6, 8, 7, 6]","[3, 4, 5, 3]",0,"[277, 255, 322, 464]",Accept
YODI3TcLX,Blessing of Depth in Linear Regression: Deeper Models Have Flatter Landscape Around the True Solution,"['deep linear network', 'trajectory analysis']","[6, 8, 5, 9, 7]","[3, 4, 4, 5, 3]",0,"[370, 602, 379, 172, 159]",Accept
vy7B8z0-4D,Aligning individual brains with fused unbalanced Gromov Wasserstein,"['Brain imaging', 'Optimal transport', 'fMRI', 'registration']","[6, 7, 7]","[5, 4, 3]",0,"[487, 505, 279]",Accept
EgMbj9yWrMI,Minimax Regret for Cascading Bandits,"['online learning-to-rank', 'cascading bandits', 'linear stochastic bandits']","[7, 7, 8, 6]","[3, 4, 4, 4]",0,"[347, 399, 332, 218]",Accept
xxgp42Qz6dL,EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations,"['Image to image translation', 'diffusion probabilistic models', 'stochastic differential equation', 'product of experts']","[5, 6, 6, 6]","[4, 4, 3, 3]",0,"[388, 272, 83, 245]",Accept
9wCQVgEWO2J,Fast Bayesian Inference with Batch Bayesian Quadrature via Kernel Recombination,"['Bayesian Quadrature', 'Kernel Quadrature', 'Gaussian Process', 'Active Learning', 'Model Evidence', 'Approximate Bayesian Computation']","[7, 6, 5]","[4, 3, 4]",0,"[277, 661, 1008]",Accept
y-E1htoQl-n,Efficient Adversarial Training without Attacking: Worst-Case-Aware Robust Reinforcement Learning,"['Reinforcement Learning', 'Robustness', 'Worst-case Aware', 'Adversarial Learning']","[6, 7, 7, 7]","[4, 3, 4, 4]",0,"[282, 325, 480, 637]",Accept
mjVZw5ADSbX,CoNT: Contrastive Neural Text Generation,[],"[6, 7, 6, 5]","[4, 4, 3, 4]",0,"[180, 198, 521, 935]",Accept
oiztwzmM9l,Sample-Then-Optimize Batch Neural Thompson Sampling,"['Bayesian optimization', 'Gaussian processes', 'neural tangent kernel']","[6, 7, 7, 6]","[4, 3, 2, 4]",0,"[503, 355, 465, 914]",Accept
Cgmk9CicWFl,RSA: Reducing Semantic Shift from Aggressive Augmentations for Self-supervised Learning,[],"[8, 7, 5, 4]","[4, 4, 3, 4]",0,"[542, 757, 247, 396]",Accept
unb1wyXf-aC,Concurrent 3D super resolution on intensity and segmentation maps improves detection of structural effects in neurodegenerative disease,"['brain', 'perceptual super resolution', 'MRI', 'neurodegenerative disease']","[6, 3, 3, 3, 7, 4]","[3, 4, 4, 4, 4, 3]",0,"[304, 247, 594, 171, 309, 265]",Reject
Xwz9B6LDM5c,Communication Efficient Federated Learning for Generalized Linear Bandits,"['contextual bandit', 'generalized linear model', 'federated learning', 'communication efficiency']","[6, 6, 5]","[4, 4, 4]",0,"[367, 318, 314]",Accept
1cJ1cbA6NLN,Brain Network Transformer,"['Brain Network', 'Graph Transformer', 'Graph Neural Network']","[6, 3, 6, 7]","[2, 5, 4, 4]",0,"[173, 686, 290, 1767]",Accept
SFeKNSxect,AZ-whiteness test: a test for signal uncorrelation on spatio-temporal graphs,"['Whiteness test', 'spatiotemporal time series', 'residual analysis', 'uncorrelated signals', 'graph neural networks']","[6, 6, 6, 6]","[3, 3, 3, 3]",0,"[398, 237, 499, 968]",Accept
X0m9q0IcsmX,ViewFool: Evaluating the Robustness of Visual Recognition to Adversarial Viewpoints,"['Visual Recognition', 'Robustness', 'Viewpoint Changes', 'OOD Generalization']","[7, 6, 6, 5]","[4, 3, 4, 5]",0,"[173, 475, 415, 613]",Accept
Owz3dDKM32p,Discovery of Single Independent Latent Variable,['Independent Component revcovery'],"[8, 5, 7, 6]","[3, 3, 3, 3]",0,"[405, 546, 531, 268]",Accept
_gA20SUfd4a,Between Stochastic and Adversarial Online Convex Optimization: Improved Regret Bounds via Smoothness,['Online Convex Optimization'],"[6, 7, 6]","[2, 3, 4]",0,"[462, 212, 330]",Accept
KeIuNChob1H,Pseudo-Riemannian Graph Convolutional Networks,"['Graph Convolutional Networks', 'Graph Embeddings', 'Non-Euclidean Embeddings']","[7, 4, 7, 7]","[3, 1, 4, 4]",0,"[436, 715, 342, 228]",Accept
0Uejkm1GB1U,Conditional Meta-Learning of Linear Representations,"['Conditional Meta-Learning', 'Linear Representation Learning', 'Statistical Learning Theory', 'Online Learning']","[4, 5, 7, 7]","[3, 3, 2, 2]",0,"[301, 238, 326, 177]",Accept
AbLj0l8YbYt,Grounding Aleatoric Uncertainty for Unsupervised Environment Design,"['reinforcement learning', 'curriculum learning', 'generalization', 'environment design', 'procedural content generation']","[6, 5, 6]","[3, 3, 3]",0,"[427, 387, 247]",Accept
LKPtAaJcuLx,Alleviating ``Posterior Collapse'' in Deep Topic Models via Policy Gradient,"['Deep Topic Models', 'Posterior Collapse', 'Reinforcement Learning']","[6, 5, 6]","[4, 4, 3]",0,"[533, 588, 335]",Accept
Mn_HoKBcWK,Fast Algorithms for Packing Proportional Fairness and its Dual,"['proportional fairness', 'packing constraints', 'acceleration', 'width-independence']","[5, 7, 5, 5]","[3, 4, 2, 4]",0,"[219, 1065, 172, 64]",Accept
8U5J6zK_MtV,LobsDICE: Offline Learning from Observation via Stationary Distribution Correction Estimation,"['offline learning from observation', 'learning from observation', 'imitation from observation', 'imperfect demonstration', 'imitation learning']","[4, 6, 8, 7]","[4, 3, 3, 3]",0,"[163, 625, 321, 505]",Accept
J3s8i8OfZZX,MoGDE: Boosting Mobile Monocular 3D Object Detection with Ground Depth Estimation,"['Monocular 3D Object Detection', 'Transformer', 'Ground Depth Estimation.']","[7, 6, 5, 5]","[4, 4, 5, 4]",0,"[220, 447, 261, 537]",Accept
Jb-d9fZX14,Finding Second-Order Stationary Points in Nonconvex-Strongly-Concave Minimax Optimization,"['Minimax optimization', 'Second-order optimization', 'Cubic regularization']","[6, 5, 7, 6]","[3, 3, 3, 4]",0,"[104, 292, 431, 720]",Accept
F0DowhX7_x,Structured Energy Network As a Loss,"['Structured Prediction', 'Structured Energy network', 'Energy-based models', 'Trainable Loss-function', 'Dynamic loss function', 'Noise-Contrastive Estimation']","[7, 6, 7]","[3, 4, 4]",0,"[392, 414, 380]",Accept
Tq2XqINV1Jz,Moment Distributionally Robust Tree Structured Prediction,"['structured prediction', 'robustness', 'arborescence', 'projection', 'dependency parsing']","[7, 7, 7]","[1, 3, 4]",0,"[364, 680, 323]",Accept
6LBfSduVg0N,Iso-Dream: Isolating Noncontrollable Visual Dynamics in World Models,"['Reinforcement learning', 'World model', 'Visual dynamics']","[7, 7, 7]","[4, 4, 5]",0,"[652, 643, 305]",Accept
Mf3CwoSuvwv,Improving RENet by Introducing Modified Cross Attention for Few-Shot Classification,"['few-shot classification', 'attention']","[4, 4, 3, 3]","[3, 5, 4, 5]",0,"[215, 496, 274, 285]",Reject
gthKzdymDu2,On the Spectral Bias of Convolutional Neural Tangent and Gaussian Process Kernels,"['Convolutional Neural Tangent Kernel', 'Spectral Theory', 'Reproducing Kernel Hilbert Space']","[7, 7, 5, 7]","[4, 4, 3, 4]",0,"[330, 900, 312, 291]",Accept
KCN0ZRqxcDm,On Robust Multiclass Learnability,[],"[5, 8, 7, 9]","[4, 3, 2, 5]",0,"[687, 350, 144, 257]",Accept
SGQeKZ126y-,Formulating Robustness Against Unforeseen Attacks,[],"[7, 5, 6]","[5, 3, 4]",0,"[777, 253, 627]",Accept
Nlsr4DepNt,Improving Barely Supervised Learning by Discriminating Unlabeled Samples with Super-Class,['barely supervised learning'],"[6, 6, 6, 4]","[3, 4, 3, 4]",0,"[134, 543, 551, 364]",Accept
458a8dN8L6,Alleviating Adversarial Attacks on Variational Autoencoders with MCMC,"['VAE', 'MCMC', 'Adversarial Attack']","[5, 6, 7, 6]","[3, 4, 3, 4]",0,"[423, 490, 197, 577]",Accept
d_m7OKOmPiM,MORA: Improving Ensemble Robustness Evaluation with Model Reweighing Attack,"['adversarial attack', 'ensemble adversarial defense', 'model robustness']","[6, 5, 6, 5]","[4, 4, 4, 5]",0,"[676, 123, 515, 451]",Accept
prQT0gN81oG,Shadow Knowledge Distillation: Bridging Offline and Online Knowledge Transfer,['Knowledge Distillation'],"[5, 5, 6]","[3, 4, 5]",0,"[583, 311, 467]",Accept
p9zeOtKQXKs,A Theoretical Understanding of Gradient Bias in Meta-Reinforcement Learning,"['Meta Reinforcement Learning', 'Gradient Bias']","[6, 6, 6, 5]","[3, 2, 3, 4]",0,"[663, 293, 218, 472]",Accept
SPoiDLr3WE7,EvenNet: Ignoring Odd-Hop Neighbors Improves Robustness of Graph Neural Networks,"['Graph Neural Networks', 'Homophily', 'Robustness']","[5, 7, 6]","[4, 4, 4]",0,"[448, 196, 740]",Accept
LPB2BFZvncQ,An Information-theoretic Perspective of Hierarchical Clustering,"['hierarchical clustering', 'information theory', 'non-binary cluster tree']","[3, 7, 4, 4]","[3, 3, 3, 4]",0,"[586, 459, 562, 881]",Reject
2bE4He5a9eQ,Generalization Bounds with Minimal Dependency on Hypothesis Class via Distributionally Robust Optimization,"['distributionally robust optimization', 'generalization bound', 'maximum mean discrepancy', 'reproducing kernel Hilbert space', 'hypothesis class complexity']","[6, 5, 7]","[4, 2, 5]",0,"[306, 468, 490]",Accept
_WQ6XkVP23f,PALBERT: Teaching ALBERT to Ponder,"['Early exit', 'ALBERT', 'GLUE']","[6, 3, 6, 4]","[3, 4, 3, 5]",0,"[374, 396, 467, 722]",Accept
-uxUxmlr3qT,Provable General Function Class Representation Learning in Multitask Bandits and MDP,"['reinforcement learning', 'multi-task', 'representation learning', 'theory']","[6, 3, 7, 6]","[2, 3, 2, 4]",0,"[576, 486, 358, 293]",Accept
f39vsgpEaY5,Exact Shape Correspondence via 2D graph convolution,"['Applications', 'Vision', 'Shapes', 'Correspondences']","[6, 6, 5, 6]","[4, 3, 4, 4]",0,"[171, 338, 591, 862]",Accept
jwGa6cEUFRn,NeMF: Neural Motion Fields for Kinematic Animation,"['Motion Modeling', 'Implicit Neural Representations', 'Neural Fields']","[6, 7, 8, 8]","[4, 4, 5, 3]",0,"[426, 1135, 218, 215]",Accept
wiGXs_kS_X,Logical Credal Networks,"['graphical models', 'probabilistic logic', 'knowledge representation', 'bayesian networks']","[4, 7, 7, 7]","[4, 4, 3, 5]",0,"[383, 616, 465, 899]",Accept
K3efgD7QzVp,Asymmetric Temperature Scaling Makes Larger Networks Teach Well Again,"['knowldege distillation', 'larger teacher', 'temperature scaling']","[6, 6, 6]","[3, 5, 3]",0,"[701, 223, 257]",Accept
m_JSC3r9td7,DeepMed: Semiparametric Causal Mediation Analysis with Debiased Deep Learning,"['Causal Inference', 'Causal Mediation Analysis', 'Causal Machine Learning', 'Deep Learning', 'Semiparametric Statistics', 'Fairness']","[6, 5, 7, 6]","[4, 1, 1, 3]",0,"[291, 100, 103, 103]",Accept
QudXypzItbt,SnAKe: Bayesian Optimization with Pathwise Exploration,"['Bayesian Optimization', 'Path-based', 'Travelling Salesman', 'Chemistry Applications', 'Cost-aware']","[4, 5, 5, 6]","[3, 4, 3, 3]",0,"[620, 900, 194, 345]",Accept
0ZKyTHwF5V1,Distributionally Robust Optimization via Ball Oracle Acceleration,"['convex optimization', 'distributionally robust optimization', 'theory', 'oracle complexity', 'monteiro-svaiter acceleration', 'accelerated methods', 'algorithm design', 'entropy regularization', 'multilevel monte-carlo']","[7, 7, 6, 3]","[3, 3, 3, 3]",0,"[530, 151, 131, 638]",Accept
bydKs84JEyw,VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts,[],"[7, 6, 6]","[2, 4, 5]",0,"[242, 260, 709]",Accept
IwC_x50fvU,Unknown-Aware Domain Adversarial Learning for Open-Set Domain Adaptation,"['domain adaptation', 'open-set domain adaptation', 'domain adversarial learning', 'representation learning', 'open set recognition']","[5, 5, 6]","[4, 4, 4]",0,"[316, 447, 361]",Accept
uKYvlNgahrz,Constrained Monotonic Neural Networks,"['Neural Network', 'Monotonicity', 'Deep Learning']","[4, 7, 3, 6]","[4, 4, 4, 3]",0,"[324, 358, 807, 231]",Reject
KpuObEWvvOX,Semi-Supervised Generative Models for Multiagent Trajectories,"['Generative Models and Autoencoders', 'Graph Neural Networks', 'Recurrent Networks', 'Sequential Models', 'Semi-Supervised', 'Multi-Agent']","[5, 6, 6, 5]","[4, 4, 3, 3]",0,"[346, 872, 413, 725]",Accept
iy2G-yLGuku,Learning to Generate Inversion-Resistant Model Explanations,"['model inversion defense', 'model explanation', 'explainable AI']","[6, 8, 7, 6]","[5, 5, 4, 3]",0,"[243, 263, 516, 262]",Accept
78aj7sPX4s-,Stability Analysis and Generalization Bounds of Adversarial Training,"['Generalization', 'Adversarial Training', 'Uniform Stability']","[7, 7, 7, 7]","[4, 3, 4, 4]",0,"[843, 323, 100, 375]",Accept
rQ1cNbi07Vq,Rethinking and Improving Robustness of Convolutional Neural Networks: a Shapley Value-based Approach in Frequency Domain,"['Convolutional Neural Network', 'adversarial robustness', 'frequency domain', 'Shapley value']","[7, 4, 6, 8]","[4, 3, 4, 4]",0,"[184, 809, 496, 293]",Accept
ScwfQ7hdwyP,On the Convergence of Stochastic Multi-Objective Gradient Manipulation and Beyond,"['stochastic optimization', 'multi-objective learning']","[4, 6, 7, 4, 7]","[3, 3, 3, 4, 4]",0,"[433, 305, 533, 637, 252]",Accept
e5HTq2VA7mu,Revisiting Injective Attacks on Recommender Systems,"['Recommender system', 'Injective Attacks', 'Poisoning Attack']","[5, 7, 7]","[3, 3, 3]",0,"[1142, 194, 300]",Accept
4WgqjmYacAf,"Seeing Differently, Acting Similarly: Heterogeneously Observable Imitation Learning","['Imitation Learning', 'Heterogeneous Observation Space', 'Importance Weighting', 'Learning with Rejection']","[6, 6, 6]","[3, 4, 2]",0,"[1396, 328, 469]",Reject
btpIaJiRx6z,Pruning Neural Networks via Coresets and Convex Geometry: Towards No Assumptions,"['Coresets', 'Convex Geometry', 'Neural Network Pruning']","[5, 7, 7, 6]","[4, 3, 3, 4]",0,"[1031, 302, 634, 446]",Accept
uNYqDfPEDD8,The Policy-gradient Placement and Generative Routing Neural Networks for Chip Design,"['Reinforcement learning', 'Machine learning', 'Combinatorial optimization', 'Electronic design automation']","[4, 6, 8, 6]","[5, 4, 4, 3]",0,"[433, 373, 461, 286]",Accept
H1FQgq2QbV1,Distributed Learning of Conditional Quantiles in the Reproducing Kernel Hilbert Space,"['Distributed learning', 'Quantile regression', 'Rademacher complexity', 'Reproducing Kernel Hilbert Space']","[5, 6, 5, 4]","[2, 4, 4, 1]",0,"[201, 287, 259, 349]",Accept
8OH6t0YQGPJ,Modeling the Machine Learning Multiverse,"['reproducibility', 'transparency', 'replication', 'multiverse analysis', 'batch size', 'generalization gap', 'adaptive optimizers']","[7, 6, 6, 7]","[4, 4, 3, 4]",0,"[901, 250, 290, 387]",Accept
2uAaGwlP_V,DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps,"['diffusion probabilistic models', 'score-based generative models', 'fast sampling', 'ODE solver']","[8, 8, 7]","[2, 4, 4]",0,"[277, 233, 1070]",Accept
UBqGF-tW6A2,Bezier Gaussian Processes for Tall and Wide Data,"['Gaussian processes', 'high-dimensional', 'scalable', 'kernels']","[5, 5, 6, 6]","[4, 3, 4, 4]",0,"[360, 471, 1061, 537]",Accept
1W8UwXAQubL,Multi-Agent Reinforcement Learning is a Sequence Modeling Problem,"['Multi-Agent Reinforcement Learning', 'Sequence Modeling', 'Transformer']","[6, 7, 6]","[3, 4, 4]",0,"[347, 585, 339]",Accept
ofwkaIWFqqv,GRASP: Navigating Retrosynthetic Planning with Goal-driven Policy,"['Retrosynthesis prediction', 'retrosynthetic planning']","[6, 7, 6]","[3, 4, 1]",0,"[305, 228, 296]",Accept
agJEk7FhvKL,Uni-Perceiver-MoE: Learning Sparse Generalist Models with Conditional MoEs,"['Generalist Models', 'Task Interference', 'Mixture of Experts']","[6, 6, 7, 4]","[3, 5, 4, 3]",0,"[248, 369, 474, 505]",Accept
TEmAR013vK,Efficient Architecture Search for Diverse Tasks,"['Neural Architecture Search', 'Automated Machine Learning']","[6, 5, 6]","[4, 3, 3]",0,"[415, 180, 261]",Accept
sMezXGG5So,NodeFormer: A Scalable Graph Structure Learning Transformer for Node Classification,"['Graph Neural Networks', 'Graph Transformers', 'Large Graph Analysis', 'Scalable Message Passing', 'Graph Structure Learning']","[7, 7, 7, 5]","[3, 3, 3, 4]",0,"[224, 364, 493, 251]",Accept
uIXyp4Ip9fG,Active Surrogate Estimators: An Active Learning Approach to Label-Efficient Model Evaluation,"['active testing', 'sample-efficiency', 'model evaluation', 'active evaluation', 'active learning', 'bayesian active learning', 'experimental design']","[6, 6, 6, 8]","[4, 4, 4, 4]",0,"[777, 411, 235, 186]",Accept
XQu7UFSbzd2,Towards Out-of-Distribution Sequential Event Prediction: A Causal Treatment,"['Sequential Event Prediction', 'Sequential Recommendation', 'Causal Inference', 'Out-of-Distribution Generalization']","[4, 6, 7, 6]","[4, 3, 2, 3]",0,"[623, 433, 502, 310]",Accept
pF5aR69c9c,Learning to Constrain Policy Optimization with Virtual Trust Region,"['trust region policy optimization', 'attention mechanism', 'policy memory']","[6, 3, 5]","[4, 5, 4]",0,"[654, 784, 555]",Accept
7WGNT3MHyBm,Geometric Knowledge Distillation: Topology Compression for Graph Neural Networks,"['Graph Neural Networks', 'Knowledge Distillation', 'Geometric Deep Learning']","[6, 5, 4, 7]","[3, 4, 3, 4]",0,"[292, 586, 231, 167]",Accept
U8k0QaBgXS,Exploring evolution-aware & -free protein language models as protein function predictors,[],"[8, 6, 6, 4]","[5, 4, 5, 1]",0,"[633, 491, 500, 309]",Accept
VVCI8-PYYv,Robust Graph Structure Learning over Images via Multiple Statistical Tests,"['Graph Structure Learning', 'Graph Convolutional Networks (GCNs)', 'Computer Vision']","[7, 8, 4]","[4, 4, 4]",0,"[461, 287, 459]",Accept
LqGA2JMLwBw,On the Tradeoff Between Robustness and Fairness,"['Adversarial training', 'robust fairness']","[3, 7, 6]","[3, 4, 4]",0,"[224, 304, 367]",Accept
u6MpfQPx9ck,Active Learning Through a Covering Lens,"['Active learning', 'AL', 'low budget', 'probability cover', 'max cover', 'ProbCover', 'Deep active learning', 'Active learning theory']","[4, 6, 6]","[3, 4, 4]",0,"[251, 229, 452]",Accept
Qr8n979lusV,NeIF: Representing General Reflectance as Neural Intrinsics Fields for Uncalibrated Photometric Stereo,[],"[5, 3, 5, 6]","[5, 5, 3, 3]",0,"[665, 853, 855, 344]",Reject
mT18WLu9J_,Amplifying Membership Exposure via Data Poisoning,"['Data poisoning', 'membership inference', 'data privacy']","[6, 3, 3, 7]","[4, 5, 4, 5]",0,"[289, 832, 436, 569]",Accept
ebCk2FNI1za,Universality of Group Convolutional Neural Networks Based on Ridgelet Analysis on Groups,"['group convolutional neural network (GCNN)', 'universal approximation', 'group equivariance', 'ridgelet transform']","[5, 6, 7, 5]","[4, 2, 2, 2]",0,"[169, 231, 701, 313]",Accept
0PfIQs-ttQQ,Self-supervised surround-view depth estimation with volumetric feature fusion,"['Surround-view depth estimation', 'Monocular depth', 'Self-supervised learning', 'Depth synthesis']","[6, 5, 5]","[3, 4, 4]",0,"[409, 172, 338]",Accept
7YXXt9lRls,Learning Representations via a Robust Behavioral Metric for Deep Reinforcement Learning,"['deep reinforcement learning', 'representation learning', 'deep learning']","[7, 7, 5, 6]","[4, 3, 4, 4]",0,"[327, 447, 559, 428]",Accept
hgNxCMKARgt,Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph Neural Networks,"['heterogeneous graph neural networks', 'bilevel optimization', 'unfolded optimization']","[7, 6, 6, 5]","[4, 3, 5, 4]",0,"[220, 149, 424, 354]",Accept
hT0RbC2jCYZ,"Learning to Reason with Neural Networks: Generalization, Unseen Data and Boolean Measures","['generalization', 'implicit bias', 'reasoning', 'distribution shift', 'Boolean influence', 'noise sensitivity', 'deep learning']","[5, 6, 7, 7]","[3, 2, 4, 3]",0,"[271, 186, 848, 344]",Accept
e2TBb5y0yFf,Large Language Models are Zero-Shot Reasoners,"['chain of thought (CoT)', 'zero-shot learning', 'multi-step reasoning', 'arithmetic', 'commonsense reasoning', 'prompting', 'large language models (LLMs)']","[5, 6, 6, 6, 6]","[4, 3, 4, 4, 4]",0,"[291, 389, 397, 253, 706]",Accept
HwP4XJ04Je1,Effective Adaptation in Multi-Task Co-Training for Unified Autonomous Driving,[],"[6, 5, 6]","[2, 3, 4]",0,"[243, 336, 345]",Accept
KOHC_CYEIuP,Escaping Saddle Points with Bias-Variance Reduced Local Perturbed SGD for Communication Efficient Nonconvex Distributed Learning,"['nonconvex optimization', 'distributed learning', 'local SGD', 'escaping saddle points', 'communication efficiency']","[6, 6, 6]","[4, 3, 4]",0,"[146, 327, 772]",Accept
pz2UcXyX0Cj,Causality-driven Hierarchical Structure Discovery for Reinforcement Learning,"['hierarchical reinforcement learning', 'causal discovery', 'causalty', 'subgoal']","[6, 6, 6, 6]","[4, 3, 3, 3]",0,"[623, 210, 384, 677]",Accept
yZ_JlZaOCzv,Are AlphaZero-like Agents Robust to Adversarial Perturbations?,"['Reinforcement Learning', 'AlphaGo', 'AlphaZero', 'Robustness']","[5, 6, 5, 3]","[4, 2, 4, 5]",0,"[668, 971, 527, 359]",Accept
wmdbwZz65FM,Learning to Drop Out: An Adversarial Approach to Training Sequence VAEs,"['VAE', 'Dropout', 'posterior collapse']","[6, 5, 5]","[4, 3, 3]",0,"[434, 420, 343]",Accept
GiEnzxTnaMN,Wasserstein Iterative Networks for Barycenter Estimation,"['optimal transport', 'continuous barycenter', 'neural networks', 'Wasserstein-2 distance']","[5, 6, 7, 6]","[4, 3, 3, 4]",0,"[307, 530, 339, 350]",Accept
KETwimTQexH,FedPop: A Bayesian Approach for Personalised Federated Learning,"['Bayesian inference', 'latent variable', 'MCMC', 'federated learning']","[6, 5, 6]","[3, 3, 3]",0,"[203, 283, 905]",Accept
ATiz_CDA66,AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition,"['Efficient Finetuning', 'Visual Adapter']","[5, 6, 5, 4]","[4, 4, 4, 4]",0,"[281, 544, 310, 498]",Accept
dNXg-h6YX9h,Active Learning of Classifiers with Label and Seed Queries,"['Active learning', 'Clustering', 'Multiclass classification']","[7, 7, 5]","[3, 3, 1]",0,"[96, 358, 208]",Accept
pm8Y8unXkkJ,Optimal Binary Classification Beyond Accuracy,"['binary classification', 'imbalanced classification', 'bayes classifier', 'minimax risk', 'nearest neighbor classification']","[7, 8, 7, 4]","[4, 3, 1, 3]",0,"[604, 163, 515, 657]",Accept
PW1VAoxeOU,On Margin Maximization in Linear and ReLU Networks,"['Implicit bias', 'Homogeneous neural networks', 'Maximum margin']","[6, 7, 6, 5]","[4, 4, 4, 4]",0,"[605, 349, 547, 372]",Accept
XdMusblCkB,Causality Preserving Chaotic Transformation and Classification using Neurochaos Learning,"['Neurochaos Learning', 'Granger Causality', 'Compression-Complexity Causality', 'Coupled Auto Regressive Processes', 'Coupled Chaotic Maps', 'Causal Machine Learning', 'Transfer Learning']","[4, 8, 4, 4]","[3, 5, 4, 4]",0,"[224, 737, 859, 413]",Accept
mn1MWh0iDCA,A Closer Look at Offline RL Agents,"['RL', 'Offline RL', 'Representation Learning', 'MBRL']","[5, 7, 6]","[5, 4, 5]",0,"[382, 278, 680]",Accept
-H6kKm4DVo,Picking on the Same Person: Does Algorithmic Monoculture lead to Outcome Homogenization?,"['systemic harms of ML', 'sharing', 'fairness', 'algorithmic monoculture', 'foundation models', 'AI Ethics']","[4, 6, 6]","[4, 4, 3]",0,"[764, 792, 230]",Accept
XIDSEPE68yO,Thinking Outside the Ball: Optimal Learning with Gradient Descent for Generalized Linear Stochastic Convex Optimization,"['stochastic', 'convex', 'optimization']","[6, 6, 6]","[3, 3, 4]",0,"[667, 446, 539]",Accept
sj9l1JCrAk6,Federated Submodel Optimization for Hot and Cold Data Features,"['federated learning', 'optimization', 'recommender system', 'natural language processing']","[4, 5, 5, 6]","[3, 3, 4, 4]",0,"[330, 321, 391, 572]",Accept
215KQFiU65l,Parameter-free Dynamic Graph Embedding for Link Prediction,[],"[5, 6, 7]","[3, 4, 3]",0,"[310, 388, 225]",Accept
ldl2V3vLZ5,S3GC: Scalable Self-Supervised Graph Clustering,"['Graph Clustering', 'GNN', 'Contrastive Learning']","[6, 5, 6]","[4, 3, 3]",0,"[630, 621, 578]",Accept
kHNKDNLVp1E,Consistent Sufficient Explanations and Minimal Local Rules for explaining the decision of any classifier or regressor,"['Interpretability', 'Trustworthy ML', 'Robust and Reliable ML', 'rule-based models', 'learning theory', 'random forests', 'explainable ai', 'consistency', 'tree-based models']","[4, 7, 5, 6]","[4, 3, 1, 4]",0,"[288, 280, 324, 376]",Accept
1r1GDXPtuWz,Detecting danger in gridworlds using Gromov's Link Condition,"['safety', 'multi-agent navigation', 'geometry', 'topology', 'braiding', 'collision-avoidance', 'curvature', 'cube complex', 'gridworld', 'configuration space']","[2, 4, 3]","[3, 2, 4]",0,"[862, 622, 132]",Reject
o8H6h13Avjy,MExMI: Pool-based Active Model Extraction Crossover Membership Inference,"['AI Safety', 'Model Extraction', 'Membership Inference']","[7, 7, 5, 5]","[3, 4, 4, 4]",0,"[463, 74, 602, 341]",Accept
vbPsD-BhOZ,Neural Sheaf Diffusion: A Topological Perspective on Heterophily and Oversmoothing in GNNs,"['sheaf', 'graph', 'neural network', 'diffusion', 'heterophily', 'oversmoothing', 'algebraic topology']","[6, 6, 9, 7]","[3, 4, 4, 3]",0,"[535, 354, 513, 487]",Accept
-OfK_B9Q5hI,Improving Neural Ordinary Differential Equations with Nesterov's Accelerated Gradient Method,"['neural ordinary differential equations', 'nesterov', 'momentum']","[7, 6, 7]","[4, 4, 4]",0,"[1144, 734, 823]",Accept
NpeHeIkbfYU,Stimulative Training of Residual Networks: A Social Psychology Perspective of Loafing,"['Residual Networks', 'Network Loafing', 'Stimulative Training']","[6, 4, 3, 4]","[3, 2, 3, 5]",0,"[465, 674, 530, 814]",Accept
VT0Y4PlV2m0,Transformers from an Optimization Perspective,"['Transformers', 'self-attention', 'unfolded optimization', 'energy function minimization']","[7, 5, 6, 5]","[3, 3, 5, 3]",0,"[196, 681, 156, 220]",Accept
J5e13zmpj-Z,LDSA: Learning Dynamic Subtask Assignment in Cooperative Multi-Agent Reinforcement Learning,"['Multi-agent Reinforcement Learning', 'Task Decomposition', 'Subtask Representation', 'Subtask Assignment']","[5, 8, 6, 6]","[4, 4, 4, 4]",0,"[509, 240, 1221, 569]",Accept
7yHte3tH8Xh,Knowledge Distillation Improves Graph Structure Augmentation for Graph Neural Networks,"['Graph Structure Augmentation', 'Graph Neural Networks', 'Graph Knowledge Distillation']","[5, 5, 7, 7]","[4, 4, 4, 4]",0,"[284, 231, 282, 147]",Accept
6niwHlzh10U,Guaranteed Conservation of Momentum for Learning Particle-based Fluid Dynamics,"['particle-based fluids', 'conservation of momentum', 'symmetry', 'antisymmetry', 'physical simulation']","[7, 6, 7]","[4, 4, 3]",0,"[522, 521, 364]",Accept
L6aVjBmtVE,Characterization of Excess Risk for Locally Strongly Convex Population Risk,"['Excess risk', 'Algorithmic stability', 'Loss Landscape']","[7, 7, 5, 7]","[3, 3, 3, 4]",0,"[377, 297, 840, 469]",Accept
tNXumks8yHv,A Probabilistic Graph Coupling View of Dimension Reduction,"['Dimension Reduction', 'Graphical Models', 'Random Graphs']","[6, 5, 4, 8]","[2, 3, 4, 2]",0,"[587, 371, 439, 810]",Accept
L0U7TUWRt_X,Revisiting Graph Contrastive Learning from the Perspective of Graph Spectrum,"['graph neural network', 'graph contrastive learning', 'graph spectral theory', 'graph self-supervised learning']","[8, 3, 5, 5, 8]","[4, 5, 2, 3, 5]",0,"[226, 284, 690, 351, 460]",Accept
wuunqp9KVw,Pluralistic Image Completion with Gaussian Mixture Models,[],"[6, 6, 6, 6]","[3, 2, 3, 4]",0,"[325, 160, 349, 597]",Accept
GGBe1uQ_g_8,Effective Decision Boundary Learning for Class Incremental Learning,"['Class Incremental Learning', 'Catastrophic Forgetting', 'Long Tail', 'Mixup', 'Knowledge Distillation', 'Influence Balance']","[4, 5, 5, 4]","[4, 5, 3, 3]",0,"[324, 602, 419, 511]",Reject
xLnfzQYSIue,Top Two Algorithms Revisited,"['Multi-armed bandits', 'Best-arm identification', 'Bounded distribution', 'Top Two algorithm', 'Thompson Sampling']","[7, 4, 7, 6]","[4, 4, 3, 3]",0,"[291, 264, 347, 114]",Accept
ZlCpRiZN7n,Attracting and Dispersing: A Simple Approach for Source-free Domain Adaptation,['source-free domain adaptation'],"[6, 6, 7, 6]","[3, 4, 4, 4]",0,"[369, 344, 223, 581]",Accept
flBYpZkW6ST,Mingling Foresight with Imagination: Model-Based Cooperative Multi-Agent Reinforcement Learning,"['Multi-Agent Systems', 'Model-Based Reinforcement Learning']","[6, 5]","[4, 3]",0,"[595, 523]",Accept
dFs4d0kqs2,Generalization Analysis on Learning with a Concurrent Verifier,"['Generalization analysis', 'verifier', 'learning theory']","[6, 7, 7]","[2, 4, 2]",0,"[289, 597, 620]",Accept
nE6vnoHz9--,Bridge the Gap Between Architecture Spaces via A Cross-Domain Predictor,"['neural architecture search', 'neural predictor', 'domain adaptation']","[5, 6, 7, 6]","[4, 2, 4, 5]",0,"[265, 380, 175, 268]",Accept
swIARHfCaUB,Online Frank-Wolfe with Arbitrary Delays,"['Online Convex Optimization', 'Online Frank-Wolfe', 'Arbitrary Delays']","[7, 6, 6, 4]","[2, 3, 3, 5]",0,"[351, 110, 194, 382]",Accept
WrZZcwxMNhT,One Positive Label is Sufficient: Single-Positive Multi-Label Learning with Label Enhancement,"['Label Enhancement', 'Multi-Label Learning']","[6, 8, 8, 8]","[3, 5, 4, 4]",0,"[220, 408, 347, 435]",Accept
ohk8bILFDkk,Semi-infinitely Constrained Markov Decision Processes,[],"[4, 6, 7]","[4, 5, 3]",0,"[693, 217, 322]",Accept
pELM0QgWIjn,Quasi-Newton Methods for Saddle Point Problems,"['Minimax Optimization', 'Quasi-Newton']","[8, 6, 6, 6]","[4, 5, 3, 3]",0,"[478, 501, 262, 210]",Accept
i3k6WjDXECC,Hierarchical Channel-spatial Encoding for Communication-efficient Collaborative Learning,"['Collaborative Learning', 'Feature Encoding', 'Traffic Saving']","[6, 6, 5, 6]","[2, 3, 1, 3]",0,"[119, 243, 256, 291]",Accept
XEoih0EwCwL,Retrospective Adversarial Replay for Continual Learning,"['continual learning', 'adversarial perturbations', 'class incremental learning', 'boundary samples', 'catastrophic forgetting']","[4, 5, 6, 6]","[4, 5, 4, 3]",0,"[344, 306, 328, 645]",Accept
BbaSRgUHW3,LTMD: Learning Improvement of Spiking Neural Networks with Learnable Thresholding Neurons and Moderate Dropout,"['Spiking neural networks', 'SNN', 'Spiking neuronal mechanism', 'SNN learning enhancement']","[4, 5, 6]","[5, 4, 3]",0,"[434, 516, 300]",Accept
lCGDKJGHoUv,Benign Underfitting of Stochastic Gradient Descent,"['Stochastic Gradient Descent', 'Convex Optimization', 'Generalization Error Bounds', 'Algorithmic Stability']","[5, 4, 7, 7]","[2, 3, 2, 4]",0,"[84, 453, 112, 351]",Accept
ywxtmG1nU_6,Equivariant Graph Hierarchy-Based Neural Networks,['equivariant graph neural network'],"[6, 7, 7]","[4, 3, 4]",0,"[253, 702, 357]",Accept
GXOC0zL0ZI,Learning Neural Set Functions Under the Optimal Subset Oracle,"['set function', 'variaitional inference', 'energy-based models']","[7, 6, 7, 8, 8]","[2, 4, 4, 4, 4]",0,"[367, 450, 280, 142, 334]",Accept
W23_S057z94,Conditional Independence Testing with Heteroskedastic Data and Applications to Causal Discovery,"['conditional independence test', 'heteroskedasticity', 'causal discovery', 'causal model']","[6, 7, 6]","[3, 4, 4]",0,"[310, 272, 357]",Accept
ATfARCRmM-a,Molecule Generation by Principal Subgraph Mining and Assembling,"['molecule generation', 'principal subgraph', 'global assembling']","[7, 6, 6]","[4, 3, 3]",0,"[451, 589, 463]",Accept
CgkjJaKBvkX,Receding Horizon Inverse Reinforcement Learning,['Inverse Reinforcement Learning'],"[6, 6, 7, 3]","[4, 3, 3, 2]",0,"[431, 1065, 644, 677]",Accept
_7bphw9JosH,AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment of Implicit Graph Generators,"[""Stein's method"", 'kernel method', 'synthetic graph generator']","[7, 6, 7, 6]","[3, 5, 4, 3]",0,"[332, 483, 159, 511]",Accept
yfrDD_rmD5,First is Better Than Last for Language Data Influence,"['influence', 'interpretation', 'explanation']","[6, 5, 8]","[3, 4, 4]",0,"[239, 286, 270]",Accept
0vJH6C_h4-,Learning to Share in Multi-Agent Reinforcement Learning,"['Cooperative Multi-Agent Reinforcement Learning', 'Networked Multi-Agent Reinforcement Learning']","[5, 6, 6]","[4, 3, 3]",0,"[465, 628, 711]",Accept
PeJO709WUup,EF-BV: A Unified Theory of Error Feedback and Variance Reduction Mechanisms for Biased and Unbiased Compression in Distributed Optimization,"['distributed optimization', 'federated learning', 'communication', 'compression', 'randomized algorithm', 'variance reduction', 'error feedback']","[5, 7, 5]","[5, 3, 4]",0,"[224, 2334, 214]",Accept
Magl9CSHB87,Improving Generative Adversarial Networks via Adversarial Learning in Latent Space,"['Generative Adversarial Networks', 'Adversarial Learning', 'Latent Space']","[5, 5, 8, 5]","[4, 4, 4, 4]",0,"[923, 258, 395, 608]",Accept
wlqb_RfSrKh,Self-supervised Amodal Video Object Segmentation,"['Amodal Segmentation', 'Self-supervised Learning', 'Spatiotemporal', 'Video']","[7, 6, 7, 6]","[3, 4, 4, 5]",0,"[557, 238, 573, 959]",Accept
9h3KsOVXhLZ,SwinTrack: A Simple and Strong Baseline for Transformer Tracking,[],"[7, 6, 4, 9]","[5, 5, 4, 5]",0,"[269, 506, 435, 250]",Accept
T2DBbSh6_uY,MaskPlace: Fast Chip Placement via Reinforced Visual Representation Learning,"['Applications', 'Reinforcement Learning', 'Electronics Design Automation', 'Combinatorial Optimization']","[7, 5, 7, 5]","[4, 4, 5, 5]",0,"[760, 314, 481, 565]",Accept
-zlJOVc580,Mask-based Latent Reconstruction for Reinforcement Learning,"['Reinforcement learning', 'mask-based modeling', 'sample efficiency', 'representation learning']","[5, 6, 7, 5]","[4, 4, 4, 4]",0,"[386, 526, 329, 886]",Accept
ocg4JWjYZ96,Debugging and Explaining Metric Learning Approaches: An Influence Function Based Perspective,"['metric learning', 'influence function', 'noisy data']","[5, 6, 6]","[3, 3, 4]",0,"[692, 397, 603]",Accept
sYDX_OxNNjh,Unsupervised Skill Discovery via Recurrent Skill Training,"['Deep Reinforcement Learning', 'Unsupervised Skill Discovery', 'Deep Learning', 'Unsupervised Reinforcement Learning']","[4, 5, 7]","[5, 4, 4]",0,"[330, 555, 947]",Accept
jxPJ4QA0KAb,"Convolutional Neural Networks on Graphs with Chebyshev Approximation, Revisited","['Graph Neural Networks', 'Chebyshev Approximation', 'Chebyshev Interpolation']","[8, 6, 6]","[5, 4, 3]",0,"[255, 229, 277]",Accept
XDZhagjfMP,Gradient Methods Provably Converge to Non-Robust Networks,"['implicit bias', 'deep learning theory', 'robustness']","[7, 6, 7, 6]","[4, 2, 3, 4]",0,"[626, 215, 313, 261]",Accept
74fJwNrBlPI,TA-GATES: An Encoding Scheme for Neural Network Architectures,"['Architecture Encoding Scheme', 'Neural architecture search (NAS)', 'Predictor-based NAS', 'AutoML']","[4, 6, 7]","[4, 4, 4]",0,"[473, 591, 365]",Accept
LYXTPNWJLr,PaCo: Parameter-Compositional Multi-task Reinforcement Learning,['multi-task reinforcement learning'],"[5, 6, 6]","[4, 4, 3]",0,"[319, 638, 832]",Accept
0Kv7cLhuhQT,NUWA-Infinity: Autoregressive over Autoregressive Generation for Infinite Visual Synthesis,"['Image synthesis', 'video synthesis']","[5, 6, 5, 7]","[4, 4, 5, 2]",0,"[367, 318, 577, 160]",Accept
mxzIrQIOGIK,Multi-Objective Online Learning,"['online algorithms', 'multi-objective online learning']","[7, 6, 5, 3]","[3, 4, 3, 3]",0,"[176, 176, 519, 880]",Reject
-KPNRZ8i0ag,A Differentiable Semantic Metric Approximation in Probabilistic Embedding for Cross-Modal Retrieval,"['cross-modal retrieval', 'probabilistic embedding', 'image-text matching', 'multiplicity', 'metric learning', 'robust']","[7, 8, 5, 5]","[5, 4, 5, 5]",0,"[482, 404, 577, 279]",Accept
m97Cdr9IOZJ,Para-CFlows: $C^k$-universal diffeomorphism approximators as superior neural surrogates,"['Invertible Neural Networks', 'Bayesian Optimization', 'Universality']","[7, 5, 7]","[3, 1, 3]",0,"[383, 379, 371]",Accept
stAKQ6vnFti,Learning Contrastive Embedding in Low-Dimensional Space,"['contrastive learning', 'dimensionality reduction', 'autoencoder', 'representation learning']","[3, 8, 4, 7]","[4, 5, 5, 3]",0,"[342, 911, 452, 291]",Accept
0VFQhPGF1M3,Improving Transformer with an Admixture of Attention Heads,"['transformer', 'admixture', 'attentions', 'redundant heads']","[7, 7, 6]","[3, 4, 4]",0,"[129, 148, 336]",Accept
cNrglG_OAeu,On the Theoretical Properties of Noise Correlation in Stochastic Optimization,"['Stochastic Optimization', 'Fractional Brownian Motion', 'Noise injection']","[5, 7, 6]","[4, 2, 4]",0,"[743, 257, 646]",Accept
Vi-sZWNA_Ue,Temporally Disentangled Representation Learning,"['Unsupervised learning', 'Disentanglement', 'Nonlinear ICA', 'Identifiability theory']","[5, 6, 6, 6]","[3, 3, 3, 3]",0,"[171, 490, 1114, 767]",Accept
eRBVi61Vct1,Robust Rent Division,"['fair division', 'computational social choice', 'learning theory']","[8, 8, 6, 8]","[4, 4, 4, 4]",0,"[560, 682, 455, 629]",Accept
I4aSjFR7jOm,Truncated Matrix Power Iteration for Differentiable DAG Learning,"['DAG', 'Structure Learning', 'Causal Discovery']","[5, 7, 6, 6]","[3, 2, 3, 4]",0,"[355, 426, 408, 1112]",Accept
3AxaYRmJ2KY,Semantic Field of Words Represented as Non-Linear Functions,"['nonlinear word representation', 'field representation', 'word polysemy', 'semantic compositionality']","[3, 6, 8, 3]","[4, 3, 5, 4]",0,"[319, 607, 213, 793]",Accept
AhccnBXSne,VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training,"['video representation learning', 'action recognition', 'self-supervised learning']","[5, 7, 6]","[5, 5, 4]",0,"[562, 572, 430]",Accept
NySDKS9SxN,Most Activation Functions Can Win the Lottery Without Excessive Depth,"['lottery tickets', 'deep learning', 'theory', 'subset sum']","[5, 2, 7]","[5, 3, 3]",0,"[281, 955, 243]",Accept
zVglD2W0EAS,"Debiased, Longitudinal and Coordinated Drug Recommendation through Multi-Visit Clinic Records","['Drug recommendation', 'Causal inference']","[6, 6, 7, 5]","[4, 2, 4, 3]",0,"[701, 199, 327, 328]",Accept
NmUWaaFEDdn,On the Double Descent of Random Features Models Trained with SGD,"['random features', 'over-parameterized model', 'double descent', 'SGD']","[7, 4, 6, 6]","[2, 2, 3, 4]",0,"[298, 453, 244, 212]",Accept
157Usp_kbi,Knowledge Distillation from A Stronger Teacher,[],"[5, 7, 7, 5]","[2, 4, 4, 5]",0,"[244, 270, 288, 336]",Accept
bF4eYy3LTR9,Generic bounds on the approximation error for physics-informed (and) operator learning,"['deep learning', 'PINN', 'DeepONet', 'FNO', 'neural network approximation theory']","[5, 8, 4]","[2, 4, 3]",0,"[383, 335, 201]",Accept
3AV_53iRfTi,Perceptual Attacks of No-Reference Image Quality Models with Human-in-the-Loop,[],"[8, 6, 5, 5]","[5, 2, 3, 3]",0,"[528, 214, 220, 230]",Accept
eCUeRHHupF,Refining Low-Resource Unsupervised Translation by Language Disentanglement of Multilingual Translation Model,"['machine translation', 'unsupervised machine translation', 'low-resource translation']","[6, 7, 6, 5]","[4, 5, 3, 4]",0,"[445, 592, 223, 274]",Accept
ez6VHWvuXEx,GT-GAN: General Purpose Time Series Synthesis with Generative Adversarial Networks,[],"[7, 7, 5]","[3, 2, 3]",0,"[351, 591, 308]",Accept
rxrLt7rTlAr,Fair Wrapping for Black-box Predictions,"['Fairness', 'post-processing', 'loss functions', 'boosting']","[4, 6, 4]","[3, 1, 3]",0,"[1226, 197, 546]",Accept
L_1GMG_7UTL,Fast Instrument Learning with Faster Rates,"['causal inference', 'kernel method', 'gaussian process']","[7, 7, 7, 6, 4]","[3, 4, 3, 2, 3]",0,"[676, 295, 270, 238, 43]",Accept
3e3IQMLDSLP,Double Check Your State Before Trusting It: Confidence-Aware Bidirectional Offline Model-Based Imagination,[],"[6, 6, 7]","[5, 4, 5]",0,"[345, 348, 391]",Accept
ZFjPtJsQPOv,Bootstrapped Transformer for Offline Reinforcement Learning,"['Reinforcement Learning', 'Offline Reinforcement Learning', 'Sequence Modeling', 'Sequence Generation', 'Bootstrapping']","[6, 5, 6]","[4, 3, 5]",0,"[572, 370, 548]",Accept
jv1bis_HYBL,Towards Skill and Population Curriculum for MARL,"['reinforcement learning', 'mutlit-agent system', 'curriculum learning', 'multi-armed bandit']","[3, 4, 4, 4]","[4, 4, 4, 3]",0,"[858, 409, 369, 637]",Reject
RIArO3o_74Z,Learning from Distributed Users in Contextual Linear Bandits Without Sharing the Context,"['bandits', 'contextual bandits', 'linear bandits', 'distributed contextual bandits', 'bandits with communication constraints']","[7, 6, 5]","[4, 3, 3]",0,"[518, 536, 482]",Accept
8SY8ete3zu,Self-explaining deep models with logic rule reasoning,"['Self-explaining', 'Reasoning', 'Deep Learning', 'Interpretability']","[6, 6, 7, 6]","[4, 4, 3, 3]",0,"[693, 891, 217, 573]",Accept
2gZccSOY04p,Action-modulated midbrain dopamine activity arises from distributed control policies,"['neuroscience', 'reinforcement learning', 'dopamine', 'basal ganglia', 'off-policy learning']","[6, 5, 9]","[4, 4, 5]",0,"[754, 302, 281]",Accept
-eHlU74N9E,Causal Inference with Non-IID Data using Linear Graphical Models,[],"[3, 6, 7]","[1, 3, 2]",0,"[204, 201, 368]",Accept
Sffus7SolE,Off-Beat Multi-Agent Reinforcement Learning,"['multi-agent system', 'multi-agent reinforcement learning']","[5, 5, 6, 5]","[3, 4, 4, 3]",0,"[334, 365, 604, 622]",Reject
uvE-fQHA4t_,On the Importance of Gradient Norm in PAC-Bayesian Bounds,"['generalization bound', 'pac-bayes']","[6, 6, 6, 6]","[3, 3, 4, 3]",0,"[335, 370, 809, 367]",Accept
kvtVrzQPvgb,What are the best Systems? New Perspectives on NLP Benchmarking,[],"[6, 4, 6]","[4, 3, 3]",0,"[519, 398, 588]",Accept
dNyCj1AbOb,Autoinverse: Uncertainty Aware Inversion of Neural Networks,"['Neural networks', 'inverse problems', 'uncertainty', 'deep ensembles']","[7, 6, 7]","[4, 4, 4]",0,"[1244, 610, 775]",Accept
Ql75oqz1npy,Factorized-FL: Personalized Federated Learning with Parameter Factorization & Similarity Matching,['federated learning'],"[6, 6, 7, 4]","[3, 3, 3, 4]",0,"[279, 460, 192, 861]",Accept
lCGYC7pXWNQ,Learning a Condensed Frame for Memory-Efficient Video Class-Incremental Learning,[],"[5, 7, 6, 6]","[3, 3, 4, 4]",0,"[575, 384, 195, 362]",Accept
xDaoT2zlJ0r,FINDE: Neural Differential Equations for Finding and Preserving Invariant Quantities,"['neural ordinary differential equations', 'first integral', 'conservetaion law']","[5, 6, 6, 7]","[2, 3, 5, 4]",0,"[234, 498, 490, 484]",Reject
2nJdh_C-UWe,Towards Effective and Interpretable Human-AI Collaboration in MOBA Games,"['Human-AI Collaboration', 'Game Playing', 'Deep Reinforcement Learning']","[3, 7, 5, 3]","[4, 3, 2, 3]",0,"[1348, 751, 602, 935]",Reject
ecNbEOOtqBU,OGC: Unsupervised 3D Object Segmentation from Rigid Dynamics of Point Clouds,"['3D object segmentation', 'point cloud analysis', 'unsupervised learning', 'scene flow']","[8, 6, 6, 6]","[4, 5, 4, 4]",0,"[281, 302, 622, 597]",Accept
zfQrX05HzBO,Grow and Merge: A Unified Framework for Continuous Categories Discovery,"['Novel Category Discovery', 'Incremental Learning', 'Continuous Learning']","[6, 6, 5]","[4, 5, 5]",0,"[765, 749, 456]",Accept
LvyJX20Rll,Factuality Enhanced Language Models for Open-Ended Text Generation,[],"[6, 7, 5, 4]","[4, 4, 3, 4]",0,"[347, 556, 170, 355]",Accept
37Rf7BTAtAM,Domain Generalization by Learning and Removing Domain-specific Features,"['Domain Generalization', 'Domain-invariant Features', 'Domain-specific Features', 'Transfer Learning']","[4, 6, 8]","[3, 4, 3]",0,"[362, 390, 602]",Accept
LGDfv0U7MJR,To update or not to update? Neurons at equilibrium in deep models,"['Deep Learning', 'Equilibrium']","[6, 6, 3, 7]","[4, 3, 3, 3]",0,"[321, 702, 326, 415]",Accept
L7n7BPTVAr3,Leveraging Inter-Layer Dependency for Post -Training Quantization,"['low-bit', 'post-training quantization', 'computer vision', 'CNN', 'over-fitting', 'discrete optimization']","[6, 4, 7, 4]","[5, 3, 3, 5]",0,"[367, 292, 300, 651]",Accept
2ZNPedOfwB,Zeroth-Order Hard-Thresholding: Gradient Error vs. Expansivity,"['Sparse learning', 'Hard-thresholding', 'Zeroth-order', 'Stochastic optimization']","[6, 8, 7]","[3, 5, 3]",0,"[827, 717, 492]",Accept
ECQ-O1q0saD,Multi-view Subspace Clustering on Topological Manifold,"['Subspace Clustering', 'Multi-view Learning', 'Topological Manifold Learning']","[8, 7, 5]","[4, 5, 5]",0,"[253, 201, 191]",Accept
WuJfPCoj7pT,Globally Convergent Policy Search for Output Estimation,"['Model-free reinforcement learning', 'policy optimization', 'global convergence', 'partially observable systems']","[6, 7, 7, 7, 7]","[3, 3, 2, 2, 1]",0,"[591, 178, 316, 117, 465]",Accept
hgAuik7LoTh,Learning Distributions Generated by Single-Layer ReLU Networks in the Presence of Arbitrary Outliers,"['Learning distribution', 'ReLU', 'Truncated Gaussian', 'Unsupervised learning']","[6, 6, 5]","[4, 4, 4]",0,"[432, 289, 465]",Accept
T1dhAPdS--,Why do We Need Large Batchsizes in Contrastive Learning? A Gradient-Bias Perspective,"['Bayesian data augmentation', 'contrastive learning', 'representation learning']","[6, 7, 5]","[3, 4, 4]",0,"[1234, 410, 482]",Accept
25XwID3wKsi,Follow-the-Perturbed-Leader for Adversarial Markov Decision Processes with Bandit Feedback,"['Reinforcement Learning', 'Follow-the-Perturbed-Leader', 'Adversarial Markov Decision Process', 'Online Learning']","[7, 8, 6, 7]","[4, 4, 4, 4]",0,"[354, 317, 969, 305]",Accept
kuJQ_NwJO8_,Knowledge-Consistent Dialogue Generation with Knowledge Graphs,"['knowledge-grounded dialogue generation', 'knowledge graph']","[4, 6, 3]","[4, 4, 4]",0,"[170, 756, 236]",Reject
xILbvAsHEV,Efficient Phi-Regret Minimization in Extensive-Form Games via Online Mirror Descent,"['extensive-form games', 'regret minimization', 'correlated equilibria', 'multi-agent reinforcement learning', 'reinforcement learning theory']","[7, 7, 8]","[3, 4, 4]",0,"[316, 120, 416]",Accept
DI3hGYPwfT,The Sample Complexity of One-Hidden-Layer Neural Networks,"['Sample complexity', 'one-hidden-layer neural networks', 'Rademacher complexity']","[7, 6, 7, 6]","[5, 3, 3, 3]",0,"[1074, 178, 323, 212]",Accept
0um6VfuBfr,Functional Ensemble Distillation,"['Bayesian inference', 'distillation']","[6, 6, 6, 7]","[4, 4, 4, 4]",0,"[716, 431, 1386, 752]",Accept
SY-TRGQmrG,Provable Benefit of Multitask Representation Learning in Reinforcement Learning,"['Multitask learning', 'representation Learning', 'offline RL', 'suboptimality gap.']","[6, 6, 7]","[4, 1, 3]",0,"[434, 455, 709]",Accept
1Xb3eVZdWp7,GAGA: Deciphering Age-path of Generalized Self-paced Regularizer,"['Self-paced Learning', 'Solution Path', 'Biconvex Optimization', 'Partial Optimum']","[6, 6, 8, 6]","[3, 3, 3, 2]",0,"[350, 229, 667, 644]",Accept
SOqGrmufeRg,A High Performance and Low Latency Deep Spiking Neural Networks Conversion Framework,"['Spiking Neural Network', 'ANN-SNN Conversion', 'Object Detection', 'Object Recognition', 'Event Camera', 'ImageNet', 'MS-COCO']","[2, 4, 3]","[5, 4, 4]",0,"[607, 1304, 420]",Reject
R3JMyR4MvoU,Learn to Match with No Regret: Reinforcement Learning in Markov Matching Markets,"['matching', 'optimal matching', 'sequential matching', 'dynamic matching']","[6, 8, 7, 6]","[2, 1, 4, 3]",0,"[268, 292, 413, 615]",Accept
w1CF57sLstO,Provable Generalization of Overparameterized Meta-learning Trained with SGD,"['MAML', 'generalization theory', 'excess risk', 'mixed linear regression']","[4, 7, 7]","[4, 2, 2]",0,"[445, 182, 205]",Accept
jftNpltMgz,Accelerated Linearized Laplace Approximation for Bayesian Deep Learning,"['Bayesian deep learning', 'Laplace approximation', 'kernel approximation']","[6, 7, 5]","[4, 4, 4]",0,"[748, 1368, 888]",Accept
EwLChH1fJJK,Alleviating the Sample Selection Bias in Few-shot Learning by Removing Projection to the Centroid,"['Few-shot learning', 'metric learning', 'image classification']","[6, 8, 4, 5, 6, 4]","[3, 4, 4, 5, 4, 5]",0,"[299, 307, 316, 535, 480, 399]",Accept
PrkarCHiUsg,Proximal Learning With Opponent-Learning Awareness,"['multi-agent reinforcement learning', 'LOLA', 'opponent shaping', 'proximal point methods']","[6, 5, 7]","[3, 3, 5]",0,"[166, 375, 462]",Accept
nyBJcnhjAoy,Explaining a Reinforcement Learning Agent via Prototyping,"['policy explanation', 'interpretability', 'imitation learning']","[8, 8, 2]","[5, 4, 4]",0,"[917, 702, 967]",Accept
fn0FXlXkzL,Secure Split Learning against Property Inference and Data Reconstruction Attacks,"['split learning', 'security', 'inference attack', 'data privacy']","[5, 6, 4]","[3, 4, 3]",0,"[472, 207, 288]",Reject
f-fVCElZ-G1,ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers,"['Post-Training Quantization', 'Layer-by-Layer Knowledge Distillation', 'BERT', 'GPT-3', 'GPT-Neox-20B']","[6, 4, 7, 7]","[4, 5, 3, 4]",0,"[362, 415, 555, 172]",Accept
VarZY6BY12h,Distributional Reinforcement Learning via Sinkhorn Iterations,"['distributional reinforcement learning', 'sinkhorn divergence']","[6, 6, 5, 6]","[2, 4, 5, 3]",0,"[310, 504, 1249, 623]",Reject
rDT-n9xysO,Symbolic Distillation for Learned TCP Congestion Control,"['symbolic regression', 'TCP congestion control', 'efficiency', 'interpretability']","[6, 5, 5, 6]","[4, 3, 3, 4]",0,"[487, 289, 283, 466]",Accept
Q5kXC6hCr1,Accelerating Sparse Convolution with Column Vector-Wise Sparsity,[],"[4, 7, 7]","[4, 4, 4]",0,"[906, 265, 192]",Accept
msBC-W9Elaa,Generalization Bounds for Stochastic Gradient Descent via Localized $\varepsilon$-Covers,[],"[8, 7, 3, 7, 8]","[4, 3, 4, 3, 3]",0,"[214, 205, 257, 557, 675]",Accept
iFJJevyrIEf,Pyramid Attention For Source Code Summarization,"['deep learning', 'source code summarization', 'software', 'code understanding']","[4, 7, 4, 7]","[3, 4, 4, 4]",0,"[485, 342, 465, 356]",Accept
zXE8iFOZKw,When to Trust Your Simulator: Dynamics-Aware Hybrid Offline-and-Online Reinforcement Learning,[],"[6, 6, 4]","[3, 3, 4]",0,"[404, 668, 793]",Accept
xTYL1J6Xt-z,FasterRisk: Fast and Accurate Interpretable Risk Scores,"['interpretability', 'scoring system', 'risk scores', 'rashomon set']","[6, 7, 7, 7]","[3, 3, 5, 4]",0,"[827, 387, 804, 286]",Accept
8SilFGuXgmk,Taming Fat-Tailed (Heavier-Tailed with Potentially Infinite Variance) Noise in Federated Learning,"['federated learning', 'optimization', 'heavy-tail', 'stochastic gradient descent', 'clipping']","[4, 6, 5, 7, 6, 5]","[4, 5, 3, 4, 3, 4]",0,"[692, 634, 728, 254, 279, 841]",Accept
tWBMPooTayE,FreGAN: Exploiting Frequency Components for Training GANs under Limited Data,"['Generative adversarail networks', 'Limited data', 'Frequency analysis', 'Image generation']","[7, 4, 5]","[4, 4, 4]",0,"[226, 524, 1349]",Accept
C7jm6YgJaT,Momentum Adversarial Distillation: Handling Large Distribution Shifts in Data-Free Knowledge Distillation,"['adversarial', 'data-free knowledge distillation', 'forgetting']","[6, 7, 4, 5]","[4, 5, 4, 4]",0,"[515, 218, 298, 265]",Accept
Fx7oXUVEPW,A Simple and Provably Efficient Algorithm for Asynchronous Federated Contextual Linear Bandits,"['linear bandits', 'federated learning']","[5, 6, 6]","[4, 3, 3]",0,"[350, 203, 265]",Accept
bg7d_2jWv6,On Divergence Measures for Bayesian Pseudocoresets,"['Bayesian pseudocoresets', 'Dataset distillation', 'Bayesian inference', 'Divergence measures']","[5, 5, 7, 7]","[3, 4, 4, 4]",0,"[243, 442, 505, 353]",Accept
OMZG4vsKmm7,Domain Adaptation under Open Set Label Shift,"['Domain Adaptation', 'Label shift', 'PU learning', 'deep learning', 'open set domain adaptation', 'deep learning']","[6, 7, 6, 5]","[3, 3, 4, 3]",0,"[315, 538, 767, 725]",Accept
krV1UM7Uw1,Robust Bayesian Regression via Hard Thresholding,"['Robust regression', 'Hard thresholding', 'Bayesian reweighting', 'Variational inference']","[7, 6, 5]","[3, 3, 3]",0,"[825, 401, 178]",Accept
_WHs1ruFKTD,A Closer Look at the Adversarial Robustness of Deep Equilibrium Models,[],"[5, 5, 6]","[2, 3, 3]",0,"[244, 402, 184]",Accept
z9cpLkoSNNh,"Continual learning: a feature extraction formalization, an efficient algorithm, and fundamental obstructions","['Continual learning', 'learning theory']","[6, 5, 6, 6]","[3, 4, 3, 3]",0,"[434, 742, 486, 367]",Accept
azBVn74t_2,DigGAN: Discriminator gradIent Gap Regularization for GAN Training with Limited Data,"['Generative model', 'limited data', 'regularization']","[6, 5, 6]","[3, 5, 5]",0,"[444, 352, 489]",Accept
mE1QoOe5juz,Tiered Reinforcement Learning: Pessimism in the Face of Uncertainty and Constant Regret,"['Reinforcement Learning', 'Regret Minimization']","[7, 5, 7, 6]","[3, 3, 4, 3]",0,"[381, 434, 257, 345]",Accept
qbSB_cnFSYn,DEQGAN: Learning the Loss Function for PINNs with Generative Adversarial Networks,"['differential equations', 'generative adversarial networks', 'GANs', 'physics-informed neural networks', 'deep learning']","[3, 7, 7]","[5, 4, 3]",0,"[603, 241, 888]",Reject
dmCyoqxEwHf,GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech,"['text-to-speech', 'speech synthesis', 'style transfer', 'domain generalization']","[7, 5, 6]","[4, 4, 5]",0,"[513, 392, 320]",Accept
fHUBa3gQno,Improving Task-Specific Generalization in Few-Shot Learning via Adaptive Vicinal Risk Minimization,"['Few-shot learning', 'Vicinal risk minimization', 'Task-specific generalization']","[7, 4, 5, 6]","[3, 5, 4, 4]",0,"[313, 467, 435, 466]",Accept
hSxK-4KGLbI,Two-Stream Network for Sign Language Recognition and Translation,"['sign language recognition', 'sign language translation']","[7, 5, 9]","[3, 4, 5]",0,"[192, 300, 381]",Accept
GGi4igGZEB-,Characteristic Neural Ordinary Differential Equations,"['Neural ODE', 'Differential Equation', 'Method of characteristics']","[4, 6, 7]","[3, 4, 4]",0,"[297, 844, 293]",Reject
FQtku8rkp3,Pre-Trained Image Encoder for Generalizable Visual Reinforcement Learning,"['Visual RL', 'Generealization', 'Pre-trained Models']","[6, 3, 7]","[4, 3, 4]",0,"[673, 501, 223]",Accept
q-tTkgjuiv5,Graphical Resource Allocation with Matching-Induced Utilities,"['Fair Division', 'Graphical Resources', 'Matching', 'Maximin Share', 'Envy-freeness.']","[5, 3, 4, 8]","[3, 5, 4, 4]",0,"[821, 370, 1265, 584]",Reject
2yvUYc-YNUH,Test Time Adaptation via Conjugate Pseudo-labels,"['Test Time Adaptation', 'Domain Adaptation']","[7, 7, 8, 7]","[4, 4, 4, 4]",0,"[195, 1189, 217, 736]",Accept
MSBDFwGYwwt,TANKBind: Trigonometry-Aware Neural NetworKs for Drug-Protein Binding Structure Prediction,"['drug-protein interaction', 'protein-ligand docking', 'molecular docking', 'drug discovery', 'proteins', 'molecules', 'geometry deep learning', 'trigonometry', 'deep learning', 'neural networks']","[7, 5, 5]","[3, 3, 5]",0,"[260, 237, 411]",Accept
h1IHI5sV4UQ,Reconstruction on Trees and Low-Degree Polynomials,"['kernel', 'polynomials', 'lower bounds', 'computational and statistical gaps', 'statistical query', 'belief propagation', 'graphical models', 'theory']","[7, 8, 5, 7]","[3, 3, 1, 4]",0,"[344, 98, 249, 544]",Accept
R7qthqYx3V1,Discovering Design Concepts for CAD Sketches,"['CAD sketch graph', 'program library induction', 'neural-symbolic learning', 'auto-completion']","[8, 6, 6, 7]","[4, 4, 4, 4]",0,"[1442, 708, 523, 733]",Accept
ITqTRTJ-nAg,HyperMiner: Topic Taxonomy Mining with Hyperbolic Embedding,"['hierarchical topic modeling', 'hyperbolic embedding', 'knowledge incorporation']","[7, 7, 5]","[3, 4, 4]",0,"[398, 277, 533]",Accept
Lvlxq_H96lI,Learning Manifold Dimensions with Conditional Variational Autoencoders,"['Conditional Variational Autoencoder', 'Deep Generative Model']","[6, 6, 5]","[3, 4, 5]",0,"[899, 1704, 2118]",Accept
Sw_zDFDTr4,APG: Adaptive Parameter Generation Network for Click-Through Rate Prediction,[],"[6, 7, 6, 4]","[4, 3, 3, 4]",0,"[329, 329, 245, 443]",Accept
F8UV5CItyRG,On the Effective Number of Linear Regions in Shallow Univariate ReLU Networks: Convergence Guarantees and Implicit Bias,"['Deep Learning Theory', 'Non-convex Optimization', 'Gradient Flow']","[5, 8, 7, 8]","[3, 3, 4, 4]",0,"[384, 911, 313, 505]",Accept
WHFgQLRdKf9,DNA: Proximal Policy Optimization with a Dual Network Architecture,[],"[7, 6, 7]","[4, 4, 3]",0,"[285, 238, 445]",Accept
hd5KRowT3oB,Self-Organized Group for Cooperative Multi-agent Reinforcement Learning,['multi-agent reinforcement learning'],"[5, 7, 7, 5]","[4, 4, 4, 4]",0,"[249, 906, 931, 460]",Accept
hMGSz9PNQes,MaskTune: Mitigating Spurious Correlations by Forcing to Explore,"['spurious correlations', 'selective classification', 'shortcut learning']","[7, 7, 6, 6]","[4, 4, 4, 3]",0,"[539, 327, 1186, 303]",Accept
iAktFMVfeff,House of Cans: Covert Transmission of Internal Datasets via Capacity-Aware Neuron Steganography,"['data stealing', 'deep learning privacy', 'AI security']","[5, 5, 8]","[2, 3, 4]",0,"[122, 383, 591]",Accept
0SVOleKNRAU,Mirror Descent Maximizes Generalized Margin and Can Be Implemented Efficiently,"['mirror descent', 'gradient descent', 'overparameterization', 'implicit regularization']","[6, 6, 7, 6]","[4, 4, 4, 3]",0,"[299, 310, 747, 249]",Accept
9u05zr0nhx,DIMES: A Differentiable Meta Solver for Combinatorial Optimization Problems,"['Combinatorial Optimization', 'Graph Neural Network', 'Meta Learning', 'Traveling Salesman Problem (TSP)', 'Minimum Indepedent Set (MIS)']","[5, 6, 6, 5]","[4, 5, 4, 4]",0,"[275, 581, 952, 1073]",Accept
VdQWVdT_8v,LOG: Active Model Adaptation for Label-Efficient OOD Generalization,"['out-of-distribution generalization', 'active learning', 'domain adaptation']","[5, 5, 8, 8]","[5, 3, 5, 4]",0,"[255, 320, 408, 345]",Accept
9YQPaqVZKP,Neuron with Steady Response Leads to Better Generalization,"['deep learning', 'regularization', 'generalization']","[7, 6, 6]","[4, 4, 3]",0,"[311, 413, 308]",Accept
nQcc_muJyFB,Improved Feature Distillation via Projector Ensemble,"['Knowledge distillation', 'feature distillation', 'ensemble learning']","[5, 5, 5, 6, 5]","[3, 4, 4, 5, 5]",0,"[248, 385, 258, 194, 170]",Accept
XxmOKCt8dO9,ConfounderGAN: Protecting Image Data Privacy with Causal Confounder,"['data privacy', 'generative adversarial network', 'causal confounder']","[6, 7, 8]","[5, 5, 4]",0,"[261, 420, 277]",Accept
0GRBKLBjJE,A Fast Post-Training Pruning Framework for Transformers,"['Pruning', 'Compression', 'Transformers']","[6, 7, 6, 6]","[4, 4, 4, 4]",0,"[187, 162, 369, 430]",Accept
yI7i9yc3Upr,Controllable Text Generation with Neurally-Decomposed Oracle,"['Controllable text generation', 'constrained decoding']","[7, 7, 7]","[3, 4, 3]",0,"[316, 480, 135]",Accept
C7cv9fh8m-b,Moderate-fitting as a Natural Backdoor Defender for Pre-trained Language Models,"['Backdoor Defense', 'Pre-trained Language Models']","[7, 6, 6, 5]","[3, 4, 5, 3]",0,"[376, 490, 684, 403]",Accept
EENzpzcs4Vy,Unsupervised Learning of Shape Programs with Repeatable Implicit Parts,"['shape programs', 'structured shape representation', 'unsupervised shape decomposition']","[7, 5, 6]","[4, 4, 4]",0,"[295, 1510, 416]",Accept
4u-oGqB4Lf6,Efficient Active Learning with Abstention,[],"[3, 8, 7, 6]","[1, 3, 3, 3]",0,"[271, 587, 647, 258]",Accept
J-IZQLQZdYu,Brownian Noise Reduction: Maximizing Privacy Subject to Accuracy Constraints,"['Differential privacy', 'Brownian motion', 'Laplace mechanism', 'Gaussian mechanism', 'Confidence sequences', 'Empirical risk minimization']","[7, 6, 6, 7]","[5, 2, 4, 4]",0,"[844, 632, 576, 280]",Accept
ZL-XYsDqfQz,Make an Omelette with Breaking Eggs: Zero-Shot Learning for Novel Attribute Synthesis,[],"[6, 5, 5, 6]","[4, 4, 4, 4]",0,"[265, 306, 271, 406]",Accept
WSAWRKVjr5K,All Politics is Local: Redistricting via Local Fairness,[],"[4, 4, 6, 6]","[4, 4, 3, 3]",0,"[356, 1426, 1154, 558]",Accept
I4XNmBm2h-E,Adaptive Oracle-Efficient Online Learning,"['online learning', 'oracle efficiency', 'adaptive online learning', 'small-loss bound']","[7, 6, 5, 7]","[3, 3, 3, 3]",0,"[166, 361, 314, 508]",Accept
Zvh6lF5b26N,Neural Collapse with Normalized Features: A Geometric Analysis over the Riemannian Manifold,"['neural collapse', 'Riemannian manifold', 'feature normalization', 'nonconvex optimization']","[5, 6, 6]","[3, 2, 4]",0,"[371, 301, 810]",Accept
H_xAgRM7I5N,Zero-Shot 3D Drug Design by Sketching and Generating,"['Zero-Shot', '3D Drug Design', 'Pre-training', 'Generation']","[6, 4, 7]","[4, 4, 5]",0,"[384, 467, 567]",Accept
-ZPeUAJlkEu,Why neural networks find simple solutions:  The many regularizers of geometric complexity,"['Deep Learning', 'Deep Learning Theory', 'Theory', 'Neural Networks', 'Regularization', 'Implicit Regularization', 'Smoothness', 'Complexity', 'Double-Descent']","[7, 7, 6]","[2, 4, 3]",0,"[240, 697, 667]",Accept
-N-OYK2cY7,Multiclass Learnability Beyond the PAC Framework: Universal Rates and Partial Concept Classes,"['multiclass classification', 'universal learning rates', 'partial concept classes', 'learning theory']","[7, 6, 7]","[3, 4, 4]",0,"[457, 628, 674]",Accept
RjS0j6tsSrf,Diagonal State Spaces are as Effective as Structured State Spaces,"['state spaces', 'long range models', 'efficient', 'Transformer', 'speech recognition', 'language modeling', 'time series model']","[7, 6, 7]","[3, 3, 3]",0,"[504, 618, 690]",Accept
AQd4ugzALQ1,MetaTeacher: Coordinating Multi-Model Domain Adaptation for Medical Image Classification,"['Meta learning', 'Medical image classification', 'Domain adaptation']","[6, 4, 6]","[4, 3, 4]",0,"[462, 192, 321]",Accept
pDUYkwrx__w,Privacy of Noisy Stochastic Gradient Descent: More Iterations without More Privacy Loss,"['private optimization', 'convex optimization', 'noisy-SGD', 'DP-SGD', 'stochastic gradient Langevin dynamics', 'privacy losss']","[6, 7, 6, 7]","[4, 3, 4, 3]",0,"[272, 319, 591, 156]",Accept
uloenYmLCAo,Block-Recurrent Transformers,"['transformers', 'recurrent neural networks', 'recurrence', 'LSTMs', 'language modeling', 'PG19', 'natural language processing']","[7, 5, 6]","[4, 3, 5]",0,"[184, 82, 2030]",Accept
AOSIbSmQJr,Markovian Interference in Experiments,"['Causal inference', 'Off-policy Evaluation', 'Experimentation', 'Interference', 'Reinforcement Learning']","[7, 8, 7, 6]","[3, 4, 2, 3]",0,"[278, 268, 504, 293]",Accept
rZalM6vZ2J,DP-PCA: Statistically Optimal and Differentially Private PCA,"['differential privacy', 'principal component analysis', 'private estimation']","[7, 7, 7, 7]","[2, 5, 3, 3]",0,"[496, 203, 223, 203]",Accept
a3ooPbW0Jzh,Differentially Private Learning with Margin Guarantees,"['Differential Privacy', 'margin theory', 'generalization bounds']","[7, 7, 6, 5]","[2, 2, 4, 3]",0,"[172, 277, 323, 246]",Accept
SbHxPRHPc2u,Oracle-Efficient Online Learning for Smoothed Adversaries,"['Online learning', 'Computational Efficiency', 'Smoothed Analysis']","[8, 9, 7, 6]","[3, 3, 2, 3]",0,"[574, 494, 402, 309]",Accept
qZUHvvtbzy,Systematic improvement of neural network quantum states using Lanczos,[],"[6, 4, 5, 7]","[4, 4, 2, 5]",0,"[880, 477, 456, 276]",Accept
HjwK-Tc_Bc,Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering,"['science question answering', 'multimodal reasoning', 'chain of thought']","[6, 7, 6, 6, 7]","[3, 4, 4, 3, 4]",0,"[235, 569, 357, 881, 294]",Accept
rBCvMG-JsPd,Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning,"['few-shot learning', 'in-context learning', 'parameter-efficient training']","[7, 6, 7, 5]","[4, 4, 4, 3]",0,"[267, 350, 364, 223]",Accept
3LMI8CHDb0g,Reproducibility in Optimization: Theoretical Framework and Limits,"['reproducibility', 'first-order optimization', 'convex optimization', 'inexact gradient oracles']","[6, 8, 7]","[3, 4, 4]",0,"[210, 415, 799]",Accept
RNZ8JOmNaV4,Unsupervised Image-to-Image Translation with Density Changing Regularization,"['image-to-image translation', 'density estimation', 'flow']","[7, 5, 3, 6]","[3, 4, 5, 4]",0,"[310, 495, 249, 337]",Accept
aXf9V5Labm,Network change point localisation under local differential privacy,"['Local differential privacy', 'change point detection']","[6, 7, 6, 5]","[2, 5, 3, 2]",0,"[375, 339, 370, 179]",Accept
qfC1uDXfDJo,Annihilation of Spurious Minima in Two-Layer ReLU Networks,"['Neural networks', 'optimization', 'symmetry', 'symmetry breaking', 'spurious minima', 'bad local minima', 'saddles', 'ReLU', 'two layers']","[5, 7, 6, 5]","[3, 1, 3, 2]",0,"[501, 555, 379, 1197]",Accept
4lw1XqPvLzT,Will Bilevel Optimizers Benefit from Loops,"['Bilevel optimization', 'unified convergence analysis', 'optimization loops', 'lower bound.']","[7, 4, 8, 6]","[4, 5, 4, 5]",0,"[333, 498, 568, 462]",Accept
G4VOQPYxBsI,Algorithms that Approximate Data Removal: New Results and Limitations,"['Online Algorithms', 'Data Deletion']","[7, 5, 6]","[5, 4, 2]",0,"[413, 295, 349]",Accept
Epk1RQUpOj0,Online Minimax Multiobjective Optimization: Multicalibeating and Other Applications,[],"[5, 8, 9]","[2, 3, 2]",0,"[218, 870, 92]",Accept
dpYhDYjl4O,No-regret learning in games with noisy feedback: Faster rates and adaptivity via learning rate separation,"['Learning in game', 'Regret', 'Noise', 'Optimism', 'Adaptivity', 'Nash equilibrium']","[8, 6, 7, 7]","[3, 3, 3, 4]",0,"[283, 449, 601, 950]",Accept
B3TOg-YCtzo,Physics-Embedded Neural Networks: Graph Neural PDE Solvers with Mixed Boundary Conditions,"['PDE', 'numerical analysis', 'physical simulation', 'graph neural network', 'equivariance']","[6, 7, 5, 7]","[2, 4, 3, 3]",0,"[416, 176, 694, 608]",Accept
qHs3qeaQjgl,On Scalable Testing of Samplers ,"['Sampling', 'Distribution Testing', 'Constraints']","[6, 6, 6]","[2, 4, 3]",0,"[439, 289, 654]",Accept
Dqcoao24G8s,A Best-of-Both-Worlds Algorithm for Bandits with Delayed Feedback,"['Multi-armed bandit', 'Delayed Bandit', 'Best-of-both-worlds']","[5, 7, 7]","[3, 4, 3]",0,"[359, 391, 237]",Accept
45p8yDYVr5,Lower Bounds on Randomly Preconditioned Lasso via Robust Sparse Designs,"['sparse linear regression', 'statistical/computational gaps', 'compressed sensing with adversarial erasure', 'preconditioning']","[6, 5, 7, 8]","[3, 2, 3, 4]",0,"[146, 308, 273, 392]",Accept
c39zYHHgQmy,CLIPDraw: Exploring Text-to-Drawing Synthesis through Language-Image Encoders,"['image synthesis', 'clip', 'computer vision', 'language to text', 'creativity', 'art']","[7, 6, 7]","[5, 4, 3]",0,"[375, 315, 334]",Accept
FWMQYjFso-a,Pre-Trained Language Models for Interactive Decision-Making,"['Decision-Making', 'Language Models', 'Combinatorial Generalization']","[7, 7, 7]","[3, 4, 3]",0,"[389, 776, 350]",Accept
TJUNtiZiTKE,Diffusion-based Molecule Generation with Informative Prior Bridges,[],"[6, 6, 7]","[4, 2, 4]",0,"[302, 260, 975]",Accept
fKXiO9sLubb,Learning from Stochastically Revealed Preference,"['Revealed Preference', 'Bayesian Algorithm', 'Sample Complexity', 'Stochastic Models']","[6, 5, 7, 6]","[3, 2, 4, 2]",0,"[132, 187, 382, 580]",Accept
mowt1WNhTC7,When does dough become a bagel? Analyzing the remaining mistakes on ImageNet,"['ImageNet', 'image classification', 'multi-label', 'benchmarking']","[6, 6, 5]","[4, 4, 4]",0,"[362, 467, 773]",Accept
PzI4ow094E,Scalable Sensitivity and Uncertainty Analyses for Causal-Effect Estimates of Continuous-Valued Interventions,"['causal effect inference', 'hidden confounding', 'continuous intervention', 'climate', 'uncertainty', 'dose response', 'deep learning']","[8, 8, 6, 7]","[4, 4, 3, 4]",0,"[548, 761, 283, 562]",Accept
QedyATtQ1H,On the convergence of policy gradient methods to Nash equilibria in general stochastic games,"['Policy gradient methods', 'stochastic games', 'Nash equilibria', 'convergence']","[6, 6, 6, 8]","[4, 3, 3, 5]",0,"[368, 772, 566, 433]",Accept
cZ41U927n8m,Semi-Supervised Learning with Decision Trees: Graph Laplacian Tree Alternating Optimization,"['semi-supervised learning', 'decision trees', 'alternating optimization', 'graph prior', 'interpretability']","[8, 6, 6, 6]","[5, 4, 4, 5]",0,"[798, 368, 313, 434]",Accept
303XqIQ5c_d,You Only Live Once: Single-Life Reinforcement Learning,"['reinforcement learning', 'autonomous reinforcement learning', 'adversarial imitation learning']","[5, 6, 5, 6]","[4, 4, 2, 3]",0,"[511, 449, 379, 459]",Accept
KblXjniQCHY,Neural Circuit Architectural Priors for Embodied Control,"['neuroscience', 'neural circuits', 'motor control']","[6, 4, 4, 6]","[4, 4, 3, 3]",0,"[326, 522, 1067, 494]",Accept
zUbMHIxszNp,Micro and Macro Level Graph Modeling for Graph Variational Auto-Encoders,"['Graph Generative Model', 'Node-Level Properties', 'Graph-Level Properties. Graph Variational Auto-Encoder']","[4, 6, 6, 6]","[4, 3, 4, 3]",0,"[320, 149, 216, 530]",Accept
grzlF-EOxPA,Conformal Frequency Estimation with Sketched Data,"['Sketching', 'conformal inference', 'memory constraints', 'privacy', 'frequency estimation']","[7, 4, 6]","[2, 4, 4]",0,"[188, 416, 654]",Accept
fDDTJakJKR7,A Single-timescale Analysis for Stochastic Approximation with Multiple Coupled Sequences,[],"[6, 6, 8, 8]","[4, 1, 5, 3]",0,"[480, 199, 437, 213]",Accept
Sxk8Bse3RKO,Reconstructing Training Data From Trained Neural Networks,"['implicit bias', 'dataset reconstruction', 'privacy attacks']","[7, 8, 6, 5]","[4, 3, 4, 4]",0,"[218, 528, 214, 483]",Accept
36Yz37cEN_Q,Redeeming intrinsic rewards via constrained policy optimization,"['reinforcement learning', 'intrinsic reward', 'curiosity-driven exploration']","[7, 7, 8]","[3, 5, 3]",0,"[382, 209, 440]",Accept
NdpUjzwsHp,S-PIFu: Integrating Parametric Human Models with PIFu for Single-view Clothed Human Reconstruction,"['Single-view clothed human reconstruction', 'parametric human body models', 'pixel-aligned implicit models']","[3, 6, 4]","[5, 5, 4]",0,"[477, 865, 255]",Accept
48Js-sP8wnv,Use-Case-Grounded Simulations for Explanation Evaluation,"['interpretability', 'explanation', 'evaluation', 'user study']","[5, 8, 6, 6]","[4, 3, 4, 3]",0,"[550, 340, 780, 354]",Accept
s_PJMEGIUfa,LIFT: Language-Interfaced Fine-Tuning for Non-language Machine Learning Tasks,"['language interface', 'language-interfaced learning', 'fine-tuning', 'language models', 'non-language tasks', 'regression', 'classification.']","[7, 6, 7, 5]","[4, 4, 4, 5]",0,"[339, 597, 523, 1552]",Accept
aqLugNVQqRw, Class-Aware Adversarial Transformers for Medical Image Segmentation ,"['Medical Image Segmentation', 'Generative Adversarial Network', 'vision Transformer']","[4, 7, 6]","[5, 3, 5]",0,"[173, 338, 686]",Accept
p4xLHcTLRwh,SALSA: Attacking Lattice Cryptography with Transformers,"['machine learning', 'cryptanalysis']","[7, 3, 7, 6]","[2, 4, 3, 3]",0,"[250, 191, 434, 563]",Accept
huT1G2dtSr,Robust Imitation via Mirror Descent Inverse Reinforcement Learning,"['inverse reinforcement learning', 'regularized Markov decision processes', 'imitation learning', 'learning theory']","[6, 6, 2, 6]","[3, 2, 2, 4]",0,"[463, 131, 890, 733]",Accept
q2nJyb3cvR9,Near-Optimal Randomized Exploration for Tabular Markov Decision Processes,"['randomized exploration', 'reinforcement learning theory', 'tabular MDP']","[7, 4, 8, 6]","[4, 4, 4, 4]",0,"[751, 418, 148, 283]",Accept
Kf8sfv0RckB,TTOpt: A Maximum Volume Quantized Tensor Train-based Optimization and its Application to Reinforcement Learning,"['Black-box', 'Optimization', 'Reinforcement Learning', 'Tensor Train', 'Cross approximation', 'Maximum Volume', 'Quantized networks']","[6, 5, 7, 6]","[2, 3, 4, 3]",0,"[548, 206, 680, 517]",Accept
gnc2VJHXmsG,RKHS-SHAP: Shapley Values for Kernel Methods,"['Kernel Methods', 'Shapley Values', 'Explainable AI']","[6, 4, 7]","[3, 3, 4]",0,"[166, 120, 1287]",Accept
3LBxVcnsEkV,GREED: A Neural Framework for Learning Graph Distance Functions,"['edit distance', 'subgraph edit distance', 'learning graph distance', 'graph neural networks']","[6, 6, 6]","[4, 5, 5]",0,"[642, 478, 400]",Accept
cLx3kbl2AI,Context-Based Dynamic Pricing with Partially Linear Demand Model,"['Partially linear model', 'contextual dynamic pricing', 'online learning']","[6, 7, 5, 7]","[4, 5, 4, 3]",0,"[360, 610, 581, 303]",Accept
SPiQQu2NmO9,Target alignment in truncated kernel ridge regression,"['kernel methods', 'target alignment', 'minimax rates', 'double descent']","[8, 6, 6, 5]","[5, 4, 3, 2]",0,"[119, 436, 383, 306]",Accept
eUAw7dwaOg8,Bridging the Gap: Unifying the Training and Evaluation of Neural Network Binary Classifiers,"['Neural Network', 'Binary Classification', 'Evaluation Metric', 'Confusion Matrix', 'Accuracy', 'F-Score']","[6, 6, 4, 7]","[4, 3, 2, 4]",0,"[573, 265, 177, 324]",Accept
pGLFkjgVvVe,Uncertainty Estimation Using Riemannian Model Dynamics for Offline Reinforcement Learning,"['reinforcement learning', 'Riemannian geometry', 'uncertainty estimation']","[7, 6, 6]","[3, 3, 4]",0,"[289, 214, 1114]",Accept
cJ006qBE8Uv,Adversarial Unlearning: Reducing Confidence Along Adversarial Directions,"['supervised learning', 'overfitting', 'regularization', 'adversarial examples', 'spurious correlations']","[6, 6, 7, 7]","[3, 4, 4, 3]",0,"[400, 330, 364, 190]",Accept
a3W4_OUIRgD,Queue Up Your Regrets: Achieving the Dynamic Capacity Region of Multiplayer Bandits,"['Multi-agent learning', 'Multiplayer bandits', 'Queuing theory', 'Game theory']","[7, 4, 7]","[4, 5, 3]",0,"[493, 225, 685]",Accept
N7-EIciq3R,High-Order Pooling for Graph Neural Networks with Tensor Decomposition,"['Tensor', 'Graph Neural Networks', 'Node Classification', 'Graph Classification', 'CP decomposition']","[6, 6, 6, 6]","[4, 4, 5, 4]",0,"[204, 411, 370, 1061]",Accept
iqCO3jbPjYF,Imitating Past Successes can be Very Suboptimal,[],"[7, 6, 7]","[4, 3, 4]",0,"[319, 412, 134]",Accept
uRSvcqwOm0,Bivariate Causal Discovery for Categorical Data via Classification with Optimal Label Permutation,"['Causal Discovery', 'Categorical Data', 'Qualitative Data', 'Discrete Data', 'Bayesian Network']","[5, 5, 5, 5]","[3, 5, 4, 3]",0,"[546, 165, 734, 1444]",Accept
LYfFj-Vk6lt,Joint Model-Policy Optimization of a Lower Bound for Model-Based RL,"['theory', 'reinforcement learning', 'model-based RL', 'GAN', 'joint optimization', 'unified objective']","[8, 6, 7, 8]","[3, 4, 3, 5]",0,"[391, 628, 653, 300]",Accept
hHrO6-IfskR,TabNAS: Rejection Sampling for Neural Architecture Search on Tabular Datasets,"['neural architecture search', 'tabular dataset', 'reinforcement learning', 'rejection sampling', 'Monte-Carlo sampling']","[5, 6, 7]","[5, 4, 2]",0,"[531, 398, 288]",Accept
GiUpEVQmNx8,SAPD+: An Accelerated Stochastic Method for Nonconvex-Concave Minimax Problems,"['saddle point problems', 'nonconvex optimization', 'stochastic gradient', 'accelerated methods']","[7, 6, 5]","[4, 1, 4]",0,"[294, 283, 489]",Accept
wJwHTgIoE0P,Procedural Image Programs for Representation Learning,"['procedural images', 'representation learning', 'generative image models', 'contrastive learning']","[3, 5, 6]","[1, 3, 4]",0,"[260, 457, 540]",Accept
wk5zDkuSHq,Online Agnostic Multiclass Boosting,"['Boosting', 'Online Convex Optimization', 'Online Learning']","[6, 7, 5, 7]","[3, 3, 5, 3]",0,"[1123, 328, 736, 405]",Accept
x56v-UN7BjD,Momentum Aggregation for Private Non-convex ERM,"['differential privacy', 'momentum', 'non-convex optimization', 'ERM', 'tree-aggregation']","[7, 6, 5]","[3, 3, 4]",0,"[406, 117, 938]",Accept
lzZstLVGVGW,Earthformer: Exploring Space-Time Transformers for Earth System Forecasting,"['Machine Learning for Earth Science', 'Spatiotemporal Forecasting', 'Transformers']","[3, 6, 6, 6]","[5, 3, 4, 4]",0,"[451, 560, 431, 487]",Accept
igMc_C9pgYG,Augmentations in Hypergraph Contrastive Learning: Fabricated and Generative,"['hypergraph contrastive learning', 'generative augmentation']","[6, 6, 4, 5, 5, 6]","[5, 3, 3, 4, 4, 2]",0,"[370, 318, 204, 206, 351, 585]",Accept
tTWCQrgjuM,Data Augmentation MCMC for Bayesian Inference from Privatized Data,"['differential privacy', 'data augmentation', 'MCMC', 'Gibbs sampler']","[3, 5, 7]","[5, 4, 4]",0,"[404, 807, 640]",Accept
Ls0yzIkEk1,Improving Zero-Shot Generalization in Offline Reinforcement Learning using Generalized Similarity Functions,"['reinforcement learning', 'representation learning', 'self-supervised learning', 'generalization']","[5, 6, 6]","[4, 3, 2]",0,"[508, 534, 303]",Accept
4OHRr7gmhd4,Learning to Attack Federated Learning: A Model-based Reinforcement Learning Attack Framework,"['Federated Learning', 'Adversarial Attacks', 'Reinforcement Learning']","[6, 6, 5, 6]","[3, 3, 4, 3]",0,"[238, 493, 426, 425]",Accept
g-I_qqceH2n,Communication-efficient distributed eigenspace estimation with arbitrary node failures,[],"[6, 4, 7, 7]","[4, 4, 2, 4]",0,"[303, 457, 877, 412]",Accept
UQJoGBNRX4,Weighted Mutual Learning with Diversity-Driven Model Compression,"['knowledge distillation', 'model compressing']","[7, 6, 5, 5]","[4, 4, 3, 4]",0,"[388, 470, 213, 278]",Accept
RnjDFZmGqli,NeuForm: Adaptive Overfitting for Neural Shape Editing,"['shape editing', 'localized overfitting', 'neural shape representations']","[7, 8, 7]","[4, 4, 5]",0,"[444, 494, 244]",Accept
OVb3ZY0fzMk,Non-stationary Bandits with Knapsacks,"['Bandits with knapsacks', 'linear program', 'non-stationarity', 'UCB']","[5, 4, 6, 5]","[3, 3, 3, 4]",0,"[293, 300, 396, 571]",Accept
v2es9YoukWO,SKFlow: Learning Optical Flow with Super Kernels,"['Optical flow', 'Computer vision']","[6, 4, 9, 6]","[3, 5, 5, 4]",0,"[348, 537, 439, 448]",Accept
6at6rB3IZm,Towards Understanding Grokking: An Effective Theory of Representation Learning,"['grokking', 'representation learning', 'physics', 'effective theory']","[6, 7, 7]","[4, 4, 3]",0,"[821, 671, 521]",Accept
ZxOO5jfqSYw,Dynamic Sparse Network for Time Series Classification: Learning What to See,"['time series classification', 'dynamic sparse training', 'adaptive receptive field']","[4, 6, 5]","[4, 3, 1]",0,"[372, 527, 271]",Accept
VdUeCoF-0tS,Smooth Fictitious Play in Stochastic Games with Perturbed Payoffs and Unknown Transitions,"['game theory', 'stochastic games', 'fictitious play', 'smooth best response', 'zero-sum stochastic games']","[7, 8, 6, 4, 7]","[3, 5, 5, 2, 3]",0,"[328, 459, 1259, 404, 400]",Accept
QoHSzxp7tSN,Uncertainty-Aware Reinforcement Learning for Risk-Sensitive Player Evaluation in Sports Game,"['Reinforcement Learning', 'Uncertainty Estimation', 'Sports Analytic', 'Agent Evaluation']","[3, 6, 7]","[4, 3, 3]",0,"[586, 513, 851]",Accept
STQOCn4NqBd,Doubly Robust Counterfactual Classification,"['causal inference', 'counterfactual prediction', 'semiparametric theory']","[6, 7, 5, 6]","[3, 4, 3, 2]",0,"[206, 780, 332, 493]",Accept
ahAEhOtVif,Manifold Interpolating Optimal-Transport Flows for Trajectory Inference,[],"[4, 7, 5, 7]","[4, 3, 1, 2]",0,"[1111, 683, 153, 174]",Accept
zb-xfApk4ZK,Local-Global MCMC kernels: the best of both worlds,"['MCMC', 'Markov chains', 'adaptive MCMC']","[6, 6, 8]","[3, 3, 4]",0,"[456, 517, 979]",Accept
vsShetzoRG9,"InsNet: An Efficient, Flexible, and Performant Insertion-based Text Generation Model","['text generation', 'insertion-based', 'neural machine translation']","[7, 5, 4, 6]","[4, 3, 3, 3]",0,"[212, 440, 372, 293]",Accept
0Z0xltoU1q,Accelerated Projected Gradient Algorithms for Sparsity Constrained Optimization Problems,"['projected gradient method', 'sparse optimization', 'accelerated algorithms']","[6, 6, 7, 7]","[3, 4, 4, 4]",0,"[569, 324, 572, 230]",Accept
67NpH8-_h94,Provably sample-efficient RL with side information about latent dynamics,"['Reinforcement Learning', 'Reinforcement Learning Theory', 'Transfer RL', 'Sim-to-real']","[6, 7, 6, 7]","[4, 3, 3, 3]",0,"[428, 851, 796, 446]",Accept
fLOU5jXlJZV,Differentially Private Online-to-batch for Smooth Losses,"['online learning', 'convex optimization', 'differential privacy', 'online-to-batch', 'adaptive']","[4, 4, 8]","[5, 4, 4]",0,"[127, 231, 1051]",Accept
ypXcTtbBsnZ,UniCLIP: Unified Framework for Contrastive Language-Image Pre-training,"['Contrastive Learning', 'Vision-Language Pre-training', 'Self-Supervised Learning']","[5, 5, 6, 6]","[3, 3, 3, 3]",0,"[384, 116, 245, 352]",Accept
ySB7IbdseGC,Structured Recognition for Generative Models with Explaining Away,"['variational inference', 'Gaussian process', 'computational neuroscience', 'graphical models']","[6, 6, 6]","[3, 3, 3]",0,"[234, 580, 526]",Accept
LYcuTyW6Vu,LiteTransformerSearch: Training-free Neural Architecture Search for Efficient Language Models,"['Neural Architecture Search', 'AutoML', 'Transformers']","[5, 6, 6, 5]","[3, 4, 3, 5]",0,"[276, 626, 1282, 324]",Accept
F0wPem89q9y,Adversarial Reprogramming Revisited,"['adversarial reprogramming', 'adversarial examples', 'adversarial robustness', 'random networks', 'implicit bias']","[6, 6, 7]","[3, 2, 4]",0,"[681, 105, 613]",Accept
SQbrWcMOcPR,Scalable and Efficient Training of Large Convolutional Neural Networks with Differential Privacy,"['deep learning', 'differential privacy', 'complexity', 'convolutional neural network', 'vision transformer']","[6, 6, 7]","[4, 3, 2]",0,"[250, 406, 380]",Accept
McjGUq1H-mm,Stochastic Second-Order Methods Improve Best-Known Sample Complexity of SGD for Gradient-Dominated Functions,"['Second-order methods', 'Stochastic optimization', 'Reinforcement learning', 'Gradient-dominated functions']","[6, 4, 7, 6]","[4, 3, 4, 4]",0,"[502, 605, 604, 490]",Accept
LKEYuYNOqx,GENIE: Higher-Order Denoising Diffusion Solvers,"['Diffusion Models', 'Score-based Generative Models', 'Generative Learning', 'ODE Solvers', 'Higher-Order Solvers']","[10, 6, 6, 7]","[4, 3, 4, 4]",0,"[481, 301, 273, 192]",Accept
plu6AK3qs5T,Automatic Clipping: Differentially Private Deep Learning Made Easy and Stronger,"['deep learning', 'differential privacy', 'per-sample gradient clipping', 'convergence']","[6, 3, 6, 4]","[3, 4, 4, 4]",0,"[183, 530, 382, 314]",Reject
zJNqte0b-xn,First-Order Algorithms for Min-Max Optimization in Geodesic Metric Spaces,"['min-max optimization', 'riemannian optimization', 'robust manifold', 'robust PCA', 'Geodesic-convex-concave function']","[5, 7, 6, 7, 6]","[3, 4, 3, 3, 3]",0,"[393, 182, 223, 322, 358]",Accept
zrAUoI2JA2,u-HuBERT: Unified Mixed-Modal Speech Pretraining And Zero-Shot Transfer to Unlabeled Modality,"['multimodal speech', 'audio-visual speech', 'multimodal self-supervised learning', 'zero-shot', 'speech recognition', 'speech translation']","[7, 3, 7, 5]","[4, 4, 4, 3]",0,"[629, 362, 236, 301]",Accept
ODkBI1d3phW,Efficient and Effective Augmentation Strategy for Adversarial Training,"['Adversarial Training', 'Data Augmentation', 'Adversarial Robustness']","[6, 6, 5, 7]","[2, 4, 3, 5]",0,"[457, 408, 278, 197]",Accept
MRpRKU8haea,Efficient Sampling on Riemannian Manifolds via Langevin MCMC,[],"[8, 8, 6, 7]","[4, 3, 3, 4]",0,"[512, 325, 650, 390]",Accept
92leLHqlcvv,A Direct Approximation of AIXI Using Logical State Abstractions,"['AIXI', 'artificial general intelligence', 'higher-order logic', 'reinforcement learning', 'state abstraction', 'feature selection', 'binary decision diagrams']","[6, 6, 5]","[1, 3, 2]",0,"[219, 543, 829]",Accept
1-F7HbLInPy,Instance-based Learning for Knowledge Base Completion,['knowledge base completion'],"[5, 6, 7, 4]","[4, 3, 3, 3]",0,"[295, 173, 388, 305]",Accept
Q7kdFAVPdu,ATD: Augmenting CP Tensor Decomposition by Self Supervision,"['Tensor Decomposition', 'Self-supervised Learning', 'Non-convex Optimization']","[5, 8, 6, 5]","[4, 4, 2, 4]",0,"[281, 434, 71, 382]",Accept
LfHwpvDPGpx,AniFaceGAN: Animatable 3D-Aware Face Image Generation for Video Avatars,"['3D-Aware GAN', 'Face Generation', 'Face Animation', 'Generative Models']","[5, 5, 5, 4]","[5, 4, 4, 4]",0,"[531, 480, 314, 628]",Accept
sL7XH6-V21e,Depth is More Powerful than Width with Prediction Concatenation in Deep Forest,"['ensemble learning', 'deep forest', 'consistency', 'convergence rate']","[8, 5, 7]","[3, 4, 3]",0,"[384, 367, 461]",Accept
pOEN7dDC0d,On the Word Boundaries of Emergent Languages Based on Harris's Articulation Scheme,"['Emergent Communication', 'Emergent Language', 'Unsupervised Word Segmentation', ""Harris's Articulation Scheme""]","[5, 8, 6]","[3, 4, 2]",0,"[445, 252, 232]",Reject
-yiZR4_Xhh,Dance of SNN and ANN: Solving binding problem by combining spike timing and reconstructive attention,"['Perceptual grouping', 'Binding problem', 'Time coding', 'Neuronal synchrony', 'Top-down attention', 'Compositional generalization', 'Object learning', 'Hybrid neural network', 'Spiking neural network', 'Artificial neural network']","[6, 7, 5, 5]","[3, 4, 3, 2]",0,"[263, 682, 442, 549]",Accept
oNnv9XjClGK,Direct Advantage Estimation,"['reinforcement learning', 'advantage function', 'actor-critic', 'causal effect']","[7, 4, 7, 8]","[4, 4, 4, 3]",0,"[579, 648, 553, 428]",Accept
ijzm0EhAY_w,Expectation-Maximization Contrastive Learning for Compact Video-and-Language Representations,"['Expectation-Maximization algorithm', 'contrastive learning', 'video-and-language representation learning', 'cross-modal retrieval']","[4, 6, 6, 6]","[3, 4, 3, 4]",0,"[646, 380, 563, 341]",Accept
pFqgUJxXXz,Adversarial Task Up-sampling for Meta-learning,"['Task augmentation', 'Meta-learning']","[6, 6, 5, 5]","[4, 4, 3, 3]",0,"[405, 330, 366, 417]",Accept
DhHqObn2UW,A Unifying Framework for Online Optimization with Long-Term Constraints,"['online learning', 'long-term constraints']","[6, 6, 6]","[2, 3, 3]",0,"[335, 537, 416]",Accept
Hbvlb4D1aFC,Masked Prediction: A Parameter Identifiability View,"['masked prediction', 'self-supervised learning', 'parameter identifiability', 'tensor decomposition']","[7, 6, 6, 7]","[4, 4, 3, 3]",0,"[342, 294, 642, 142]",Accept
Eccx2-_vZS4,Tabular data imputation: quality over quantity,"['data imputation', 'density estimation', 'nearest neighbors', 'likelihood', 'multimodality']","[3, 3, 4]","[4, 4, 4]",0,"[732, 268, 417]",Reject
uRTW_PgXvc7,ST-Adapter: Parameter-Efficient Image-to-Video Transfer Learning,"['parameter-efficient transfer learning', 'video recognition', 'adapters']","[6, 5, 5, 7]","[3, 5, 5, 4]",0,"[302, 660, 558, 364]",Accept
X6bp8ri8dV,Exact Solutions of a Deep Linear Network,"['Deep Linear Network', 'Exact Solution', 'Collapse']","[5, 7, 5, 7]","[4, 3, 4, 4]",0,"[431, 462, 989, 207]",Accept
TVpZaWNczF6,Constrained Predictive Coding as a Biologically Plausible Model of the Cortical Hierarchy,"['predictive coding', 'biologically plausible', 'calcium plateau', 'cortical hierarchy', 'biologically realistic']","[7, 6, 4]","[3, 4, 4]",0,"[254, 944, 183]",Accept
1fKJLRTUdo,SCL-WC: Cross-Slide Contrastive Learning for Weakly-Supervised Whole-Slide Image Classification,"['Histopathology', 'Whole slide image', 'Multiple instance learning', 'Contrastive Learning']","[5, 7, 3, 7]","[5, 3, 5, 4]",0,"[172, 187, 820, 361]",Accept
NjKAm5wMbo2,VRL3: A Data-Driven Framework for Visual Deep Reinforcement Learning,"['deep reinforcement learning', 'visual control', 'data-driven framework', 'pretraining']","[3, 6, 6, 4]","[4, 3, 4, 5]",0,"[491, 642, 316, 461]",Accept
_B5Y2hvZKpS,Renyi Differential Privacy of Propose-Test-Release and Applications to Private and Robust Machine Learning,"['Renyi Differential Privacy', 'Propose Test Release']","[4, 6, 6, 6]","[3, 3, 3, 5]",0,"[251, 243, 164, 455]",Accept
IXoHxXIGpyV,Towards Diverse and Faithful One-shot Adaption of Generative Adversarial Networks,"['StyleGAN', 'Domain Adaption', 'One-shot', 'CLIP']","[6, 6, 6, 7]","[4, 4, 5, 3]",0,"[188, 242, 422, 475]",Accept
i-8uqlurj1f,Does Momentum Change the Implicit Regularization on Separable Data?,"['Implicit Regularization', 'Momentum-based Optimizers', 'Optimization']","[6, 6, 7, 6]","[4, 4, 3, 4]",0,"[376, 218, 353, 810]",Accept
Tsy9WCO_fK1,Can Push-forward Generative Models Fit Multimodal Distributions?,"['Generative Models', 'GAN', 'VAE', 'Diffusion Models', 'Score-based Models', 'Expressivity', 'Lipschitz Mappings']","[5, 5, 7, 6, 5]","[4, 3, 4, 3, 4]",0,"[473, 398, 202, 605, 335]",Accept
QnajmHkhegH,DualCoOp: Fast Adaptation to Multi-Label Recognition with Limited Annotations,"['Multi-Label Recognition', 'Prompt Learning']","[5, 6, 5, 6]","[4, 3, 4, 4]",0,"[128, 256, 531, 253]",Accept
ZV9WAe-Q0J,When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture,"['Vision Transformer', 'Adversarial Training', 'Robustness']","[5, 5, 9, 5]","[3, 5, 5, 4]",0,"[295, 516, 521, 223]",Accept
QeRAyn4igEA,Block-wise Separable Convolutions: An Alternative Way to Factorize Standard Convolutions,"['convolutional neural network', 'block-wise separable convolution', 'network architecture search']","[4, 5, 4]","[4, 4, 3]",0,"[232, 239, 916]",Reject
xL7B5axplIe,Conservative Dual Policy Optimization for Efficient Model-Based Reinforcement Learning,"['Reinforcement Learning', 'Model-Based Reinforcement Learning']","[5, 7, 7, 5]","[5, 4, 3, 4]",0,"[470, 609, 220, 122]",Accept
OlDEMIbCvTl,Efficient Submodular Optimization under Noise: Local Search is Robust,"['submodular', 'optimization', 'noise', 'local search']","[5, 7, 7]","[4, 3, 3]",0,"[477, 290, 307]",Accept
nE8_DvxAqAB,Egocentric Video-Language Pretraining,"['Video-Language Pretraining', 'Egocentric Video Datasets']","[6, 4, 6, 5]","[3, 5, 4, 4]",0,"[745, 379, 334, 415]",Accept
2fD1Ux9InIW,Generalised Implicit Neural Representations,"['implicit neural representations', 'neural fields']","[6, 6, 7]","[5, 3, 4]",0,"[386, 299, 572]",Accept
Z5SE9PiAO4t,Few-shot Image Generation via Adaptation-Aware Kernel Modulation,"['Few-shot Image Generation', 'Modulation of Deep Neural Networks', 'Transfer Learning', 'Knowledge Preserve']","[6, 7, 6]","[5, 3, 3]",0,"[402, 330, 446]",Accept
-AxpnEv1f1,Look Around and Refer: 2D Synthetic Semantics Knowledge Distillation for 3D Visual Grounding,"['3D Visual Grounding', 'Multi-Modal', '3D', '3D Detection', 'Synthetic 2D generation.']","[5, 5, 7, 5]","[4, 3, 4, 4]",0,"[443, 310, 959, 431]",Accept
xZmjH3Pm2BK,Wavelet Score-Based Generative Modeling,"['score-based generative model', 'diffusion model', 'wavelet decomposition', 'cascading algorithm', 'acceleration']","[7, 6, 7]","[3, 3, 3]",0,"[245, 487, 294]",Accept
fBU4qsM6Fkf,Self-supervised Heterogeneous Graph Pre-training Based on Structural Clustering,"['Graph Self-supervised Learning', 'Heterogeneous Information Networks', 'HGNN Pre-training']","[5, 5, 6, 5]","[5, 4, 3, 3]",0,"[498, 574, 175, 344]",Accept
QRp6viwPRaX,Improving 3D-aware Image Synthesis with A Geometry-aware Discriminator,"['3D-aware image synthesis', 'generative adversarial network']","[3, 6, 6, 6]","[5, 5, 4, 3]",0,"[394, 350, 808, 344]",Accept
7k_J2kkIy3U,Estimating graphical models for count data with applications to single-cell gene network,"['Convergence rate', 'Graphical model', 'Network inference', 'Poisson log-normal model', 'Probabilistic Methods', 'Single-cell RNA-Seq.']","[6, 7, 7]","[4, 3, 3]",0,"[417, 503, 280]",Accept
5VHK0q6Oo4M,Policy Gradient With Serial Markov Chain Reasoning,"['Reinforcement learning', 'Off-policy learning', 'Markov chain', 'Continuous control', 'Machine learning']","[7, 6, 7, 8]","[4, 4, 4, 4]",0,"[508, 326, 836, 553]",Accept
rQAJmrLmGC6,Towards Effective Multi-Modal Interchanges in Zero-Resource Sounding Object Localization,"['sounding object localization', 'knowledge transfer', 'multi-modal', 'zero-resource learning']","[4, 6, 6, 6]","[4, 4, 5, 5]",0,"[413, 355, 526, 446]",Accept
rTTh1RIn6E,Out-of-Distribution Detection via Conditional Kernel Independence Model,"['out-of-distribution detection', 'Hilbert-Schmidt Independence Criterion']","[6, 6, 6, 5]","[3, 4, 4, 5]",0,"[559, 599, 309, 418]",Accept
oDRQGo8I7P,Riemannian Score-Based Generative Modelling,"['Diffusion models', 'generative modeling', 'Riemannian manifolds', 'score matching']","[9, 7, 7, 7]","[4, 3, 3, 2]",0,"[658, 285, 427, 639]",Accept
-Qp-3L-5ZdI,Gradient Descent: The Ultimate Optimizer,"['automatic differentiation', 'differentiable programming', 'hyperparameter optimization']","[6, 7, 7]","[4, 5, 4]",0,"[668, 267, 730]",Accept
Sxf5k90HnvM,Contextual Squeeze-and-Excitation for Efficient Few-Shot Image Classification,"['few-shot learning', 'meta-learning', 'transfer learning']","[6, 7, 5]","[4, 4, 4]",0,"[554, 278, 306]",Accept
-Xdts90bWZ3,Perturbation Learning Based Anomaly Detection,"['Anomaly detection', 'Machie learning', 'Deep learning']","[4, 6, 7]","[4, 4, 3]",0,"[298, 210, 185]",Accept
apC354ZsGwK,Incorporating Bias-aware Margins into Contrastive Loss for Collaborative Filtering,"['Recommendation', 'Collaborative Filtering', 'Popularity Bias', 'Contrastive Loss', 'Popularity Debiasing']","[3, 6, 8]","[4, 4, 4]",0,"[351, 367, 290]",Accept
x-i37an3uym,Module-Aware Optimization for Auxiliary Learning,[],"[8, 6, 5, 5]","[5, 3, 5, 4]",0,"[455, 298, 464, 503]",Accept
Av8b0vxN7MX,A Classification of $G$-invariant Shallow Neural Networks,"['neural network', 'group theory', 'symmetry', 'theorem', 'cohomology', 'architecture search']","[6, 7, 7, 4]","[2, 4, 3, 2]",0,"[664, 513, 441, 333]",Accept
XFCirHGr4Cs,Improved Utility Analysis of Private CountSketch,"['sketching', 'dimension reduction', 'sparsity', 'differential privacy', 'countsketch']","[7, 6, 7]","[3, 4, 4]",0,"[81, 886, 405]",Accept
x3JsaghSj0v,Hierarchical Graph Transformer with Adaptive Node Sampling,['Scalable Graph Transformers'],"[5, 4, 6, 7]","[4, 5, 5, 3]",0,"[337, 467, 517, 551]",Accept
5MgZAu2NR7X,Self-Supervised Learning with an Information Maximization Criterion,"['self-supervised learning', 'information maximization', 'representation learning', 'computer vision']","[6, 6, 6, 4]","[4, 4, 4, 5]",0,"[408, 586, 263, 285]",Accept
fyIjM5CEdYW,Transcormer: Transformer for Sentence Scoring with Sliding Language Modeling,"['Natural Language Processing', 'Language Modeling', 'Reranking']","[3, 6, 6]","[3, 4, 5]",0,"[756, 361, 968]",Accept
skgJy0CjAO,LogiGAN: Learning Logical Reasoning via Adversarial Pre-training,"['NLP', 'Reasoning', 'Logic Pre-training']","[5, 7, 6, 5]","[4, 3, 1, 4]",0,"[430, 203, 375, 651]",Accept
byMcacS8GYZ,Deep Combinatorial Aggregation,"['deep combinatorial aggregation', 'deep combinatorial weight averaging', 'consistency enforcing loss', 'uncertainty estimation']","[6, 6, 4]","[4, 3, 4]",0,"[550, 556, 459]",Accept
W-_4hgRkwb,Revisiting Realistic Test-Time Training: Sequential Inference and Adaptation by Anchored Clustering,"['Test-Time Training', 'Domain Adaptation', 'Pseudo Labeling']","[6, 6, 7, 6]","[5, 4, 4, 5]",0,"[1136, 280, 328, 680]",Accept
GFiqdZOm-Ei,Museformer: Transformer with Fine- and Coarse-Grained Attention for Music Generation,"['music composition', 'music generation', 'music structure', 'Transformer', 'attention', 'efficient Transformer', 'sparse attention']","[4, 7, 7, 4]","[5, 3, 4, 3]",0,"[874, 709, 611, 201]",Accept
I0CiI7Oyp1E,Theoretically Provable Spiking Neural Networks,"['Spiking Neural Networks', 'Self Connection', 'Continuous Dynamical Systems', 'Approximation Power', 'Computational Efficiency']","[6, 6, 6]","[1, 3, 3]",0,"[408, 213, 252]",Accept
2tfv0K8Vbtf,Trading Off Resource Budgets For Improved Regret Bounds,"['Online Learning', 'Bandit Algorithms']","[4, 6, 7, 5]","[3, 3, 3, 4]",0,"[162, 428, 759, 468]",Accept
w_jvWzNXd6n,Transformers meet Stochastic Block Models: Attention with Data-Adaptive Sparsity and Cost,"['Efficient Transformers', 'Sparse Attention', 'Stochastic Block Model']","[6, 6, 6]","[4, 4, 4]",0,"[364, 755, 842]",Accept
C6Iin6nXJy,Outsourcing Training without Uploading Data via Efficient Collaborative Open-Source Sampling,"['outsource training', 'open-source sampling']","[5, 6, 8, 6, 6]","[3, 3, 4, 3, 4]",0,"[571, 127, 602, 474, 337]",Accept
X8mmH03wFlD,Understanding the Failure of Batch Normalization for Transformers in NLP,"['Batch Normalization', 'Transformer', 'Training Inference Discrepancy']","[6, 6, 5]","[3, 3, 3]",0,"[207, 480, 139]",Accept
W-xJXrDB8ik,Unsupervised Visual Representation Learning via Mutual Information Regularized Assignment,"['unsupervised representation learning', 'pseudo-labeling', 'mutual information maximization', 'self-supervised learning']","[7, 7, 8, 6]","[4, 4, 4, 4]",0,"[475, 289, 296, 796]",Accept
um2BxfgkT2_,Pure Transformers are Powerful Graph Learners,"['graph', 'transformer', 'self-attention', 'graph neural network', 'graph transformer', 'equivariant neural network', 'permutation equivariance', 'graph positional embedding']","[5, 7, 6, 6]","[3, 3, 5, 3]",0,"[139, 203, 838, 384]",Accept
Lr2Z85cdvB,Differentiable hierarchical and surrogate gradient search for spiking neural networks,"['spiking neural network', 'architecture search', 'event-based stereo', 'image classification', 'surrogate gradient']","[5, 6, 6, 8]","[4, 3, 3, 5]",0,"[400, 417, 504, 328]",Accept
FRDiimH26Tr,TA-MoE: Topology-Aware Large Scale Mixture-of-Expert Training,[],"[5, 5, 6]","[3, 5, 2]",0,"[380, 349, 238]",Accept
4rTN0MmOvi7,DetCLIP: Dictionary-Enriched Visual-Concept Paralleled Pre-training for Open-world Detection,['Open-world object detectionVisual-language model'],"[6, 6, 6, 6]","[4, 5, 5, 5]",0,"[417, 312, 168, 362]",Accept
Wo1HF2wWNZb,On the Identifiability of Nonlinear ICA: Sparsity and Beyond,"['identifiability', 'nonlinear ICA', 'unsupervised learning']","[7, 7, 8]","[3, 4, 2]",0,"[622, 589, 203]",Accept
nRcyGtY2kBC,Transfer Learning on Heterogeneous Feature Spaces for Treatment Effects Estimation,"['causal inference', 'treatment effects', 'transfer learning', 'healthcare']","[7, 6, 6]","[2, 5, 5]",0,"[245, 197, 357]",Accept
HH_jBD2ObPq,BR-SNIS: Bias Reduced Self-Normalized Importance Sampling,"['Importance Sampling', 'Self Normalized Importance Sampling', 'Monte Carlo', 'Markov Chain Monte Carlo']","[6, 6, 5, 5]","[3, 3, 4, 3]",0,"[366, 258, 651, 362]",Accept
xWvI9z37Xd,Where to Pay Attention in Sparse Training for Feature Selection?,"['Feature Selection', 'Sparse Training', 'Dynamic Sparsity', 'High dimentional data', 'Big data']","[6, 6, 8, 7]","[5, 4, 4, 4]",0,"[514, 241, 313, 362]",Accept
DmT862YAieY,A Continuous Time Framework for Discrete Denoising Models,"['diffusion', 'score-based', 'score', 'markov chain', 'markov', 'continuous time']","[7, 7, 7, 7]","[4, 4, 4, 4]",0,"[978, 330, 431, 538]",Accept
XYDXL9_2P4,AD-DROP: Attribution-Driven Dropout for Robust Language Model Fine-Tuning,"['dropout', 'self-attention', 'attribution', 'fine-tune', 'language model']","[7, 6, 4, 5]","[4, 3, 4, 3]",0,"[476, 696, 579, 188]",Accept
4F7vp67j79I,Verification and search algorithms for causal DAGs,"['Causality', 'Causal Inference', 'Active Structure Learning', 'Interventions']","[5, 7, 5]","[2, 2, 4]",0,"[454, 354, 402]",Accept
yoLGaLPEPo_,Hyperbolic Feature Augmentation via Distribution Estimation and Infinite Sampling on Manifolds,"['Hyperbolic Space', 'Feature Augmentation', 'Distribution Estimation', 'Neural ODE', 'Infinite Augmentation']","[8, 4, 5, 7]","[5, 4, 3, 4]",0,"[279, 692, 350, 271]",Accept
c4o5oHg32CY,TokenMixup: Efficient Attention-guided Token-level Data Augmentation for Transformers,"['data augmentation', 'mixup', 'vision transformer']","[7, 7, 5, 6]","[3, 4, 2, 5]",0,"[260, 246, 364, 438]",Accept
Jw34v_84m2b,IM-Loss: Information Maximization Loss for Spiking Neural Networks,[],"[6, 5, 6, 6]","[4, 4, 4, 5]",0,"[350, 410, 305, 682]",Accept
70bBDacSpNn,Operator-Discretized Representation for Temporal Neural Networks,"['artificial neural network', 'spiking neural network', 'operator algebra', 'diagrammatic category theory']","[4, 3, 3, 3]","[2, 2, 1, 2]",0,"[418, 330, 365, 675]",Reject
_iXQPM6AsQD,Could Giant Pre-trained Image Models Extract Universal Representations?,[],"[6, 4, 5]","[4, 4, 5]",0,"[324, 487, 609]",Accept
IlYS1pLa9y,Searching for Better Spatio-temporal Alignment in Few-Shot Action Recognition,"['Few-Shot Action Recognition', 'Temporal Alignment', 'Neural Architecture Search']","[6, 7, 6]","[4, 4, 4]",0,"[766, 373, 231]",Accept
dIUQ5haSOI,Relation-Constrained Decoding for Text Generation,"['constrained decoding', 'text generation']","[6, 7, 4, 5]","[4, 4, 3, 5]",0,"[461, 302, 533, 293]",Accept
hyc27bDixNR,Margin-Based Few-Shot Class-Incremental Learning with Class-Level Overfitting Mitigation,"['Few-shot class-incremental learning', 'Class-level overfitting', 'Margin-based classification']","[6, 6, 5]","[3, 5, 5]",0,"[274, 426, 198]",Accept
Setj8nJ-YB8,Zeroth-Order Negative Curvature Finding: Escaping Saddle Points  without Gradients,"['Non-Convex', 'Optimization', 'Zeroth-Order', 'Saddle Point']","[7, 6, 7, 6]","[3, 3, 3, 4]",0,"[467, 360, 566, 846]",Accept
JRAlT8ZstmH,Latency-aware Spatial-wise Dynamic Networks,[],"[7, 6, 5]","[4, 4, 3]",0,"[538, 284, 486]",Accept
sexfswCc7B,Learning to Break the Loop: Analyzing and Mitigating Repetitions for Neural Text Generation ,"['Repetition', 'Language Model', 'Analyses', 'Mitigating']","[6, 7, 6]","[3, 4, 4]",0,"[630, 1207, 342]",Accept
Y6A4-R_Hgsw,Toward a realistic model of speech processing in the brain with self-supervised learning,"['Neuroscience', 'Deep Learning', 'Speech Processing', 'Self-supervised learning', 'fMRI']","[6, 5, 7]","[4, 5, 2]",0,"[485, 1334, 207]",Accept
DTD9BRDWtkn,Multi-layer State Evolution Under Random Convolutional Design,"['Approximate Message Passing', 'State Evolution', 'High-dimensional statistics', 'Generative Models', 'Convolution', 'Spatial Coupling']","[7, 6, 7, 7]","[4, 4, 1, 4]",0,"[828, 539, 187, 514]",Accept
UwzrP-B38jK,Learning Robust Rule Representations for Abstract Reasoning via Internal Inferences,"['visual reasoning', 'abstract reasoning']","[7, 6, 7, 8, 5]","[3, 4, 5, 5, 5]",0,"[327, 696, 789, 466, 448]",Accept
8N1NDRGQSQ,CalFAT: Calibrated Federated Adversarial Training with Label Skewness,"['federated learning', 'adversarial training']","[8, 3, 5]","[4, 4, 4]",0,"[361, 436, 145]",Accept
02YXg0OZdG,Eliciting Thinking Hierarchy without a Prior,"['crowdsourcing', 'information elicitation', 'peer prediction', 'cognitive hierarchy', 'bounded rationality']","[6, 7, 5, 6]","[3, 1, 3, 4]",0,"[158, 417, 407, 363]",Accept
vphSm8QmLFm,GBA: A Tuning-free Approach to Switch between Synchronous and Asynchronous Training for Recommendation Models,"['recommendation model', 'synchronous training', 'asynchronous training', 'tuning-free switching', 'global batch size']","[5, 7, 7]","[4, 4, 3]",0,"[170, 209, 565]",Accept
L0OKHqYe_FU,Online Neural Sequence Detection with Hierarchical Dirichlet Point Process,"['Neural sequence detection', 'Online learning', 'Dirichlet process mixture model']","[7, 6, 3, 6]","[3, 3, 3, 4]",0,"[443, 536, 501, 604]",Accept
i0FnLiIRj6U,Iterative Scene Graph Generation,"['Scene Graphs', 'Object Detection', 'Transformer Networks', 'Image Understanding']","[3, 6, 4]","[5, 3, 4]",0,"[393, 907, 314]",Accept
4btNeXKFAQ,"Low-rank Optimal Transport: Approximation, Statistics and Debiasing","['Low-rank Optimal Transport:  Approximation', 'Statistics and Debiasing']","[7, 7, 7, 7]","[4, 4, 4, 3]",0,"[480, 486, 488, 251]",Accept
ZCGDqdK0zG,Fast Distance Oracles for Any Symmetric Norm,"['Distance oracle', 'Sketching', 'Symmetric norm']","[4, 7, 6, 6]","[3, 4, 3, 4]",0,"[660, 408, 266, 230]",Accept
5Fg3XoHjQ4r,Towards Hard-pose Virtual Try-on via 3D-aware Global Correspondence Learning,[],"[7, 5, 6, 5]","[5, 4, 4, 3]",0,"[220, 345, 124, 329]",Accept
A6AFK_JwrIW,Learning Causally Invariant Representations for Out-of-Distribution Generalization on Graphs,"['Graph Neural Networks', 'Out-of-Distribution Generalization', 'Causal Invariance']","[6, 6, 6]","[3, 2, 4]",0,"[229, 330, 280]",Accept
8ow4YReXH9j,Ultra-marginal Feature Importance,"['Feature Importance', 'AI Fairness', 'Interpretable Machine Learning', 'Removing Dependencies']","[7, 6, 7, 8]","[3, 3, 4, 4]",0,"[280, 316, 1530, 325]",Reject
OcNoF7qA4t,Non-Linear Coordination Graphs,"['Coordination graphs', 'Non-linear', 'Multi-agent reinforcement learning']","[7, 7, 7, 7]","[3, 5, 4, 5]",0,"[316, 745, 604, 985]",Accept
0xbhGxgzd1t,ComGAN: Unsupervised Disentanglement and Segmentation via Image Composition,"['Generative Adversarial Networks', 'Trivial solutions', 'Image Disentanglement', 'Unsupervised Segmentation']","[6, 6, 6]","[3, 4, 3]",0,"[566, 270, 342]",Accept
9TsP2Gg0CM,Homomorphic Matrix Completion,"['Matrix completion', 'recommendation system', 'homomorphic encryption', 'differential privacy']","[6, 3, 7]","[2, 4, 3]",0,"[363, 378, 407]",Accept
hqtSdpAK39W,Cluster Randomized Designs for One-Sided Bipartite Experiments,"['causal inference', 'network interference', 'marketplace experiments']","[4, 6, 6, 8]","[2, 4, 4, 3]",0,"[591, 457, 552, 380]",Accept
Qy1D9JyMBg0,Multimodal Contrastive Learning with LIMoE: the Language-Image Mixture of Experts,"['machine learning', 'computer vision', 'natural language processing', 'multimodal', 'mixture of experts', 'conditional computation', 'sparse computation', 'contrastive learning', 'zeroshot classification']","[8, 6, 7]","[4, 3, 5]",0,"[220, 367, 267]",Accept
Rym8_qTIB7o,Node-oriented Spectral Filtering for Graph Neural Networks,"['Graph Neural Networks', 'Node-oriented Spectral Filtering', 'Homophily Assumption']","[4, 7, 7, 4]","[4, 3, 3, 3]",0,"[210, 212, 420, 371]",Reject
vaxPmiHE3S,EGRU: Event-based GRU for activity-sparse inference and learning,"['activity sparse', 'event based', 'scalable', 'recurrent networks', 'GRU']","[6, 6, 5]","[4, 2, 4]",0,"[286, 171, 392]",Reject
mkEPog9HiV,Structure-Preserving 3D Garment Modeling with Neural Sewing Machines,[],"[6, 6, 6, 5]","[4, 5, 4, 4]",0,"[284, 1325, 467, 596]",Accept
sQiEJLPt1Qh,Improved Bounds on Neural Complexity for Representing Piecewise Linear Functions,"['deep neural networks', 'rectified linear units', 'neural complexity', 'piecewise linear functions']","[6, 7, 6]","[2, 3, 4]",0,"[255, 270, 214]",Accept
hTxYJAKY85,Learning Graph-embedded Key-event Back-tracing for Object Tracking in Event Clouds,"['event data', 'object tracking', 'deep learning']","[6, 5, 5, 4]","[4, 4, 4, 4]",0,"[577, 425, 390, 431]",Accept
JpxsSAecqq,OrdinalCLIP: Learning Rank Prompts for Language-Guided Ordinal Regression,"['Ordinal Regression', 'Representation Learning', 'Vision-Language', 'Prompt Learning']","[5, 6, 6]","[4, 3, 4]",0,"[487, 285, 277]",Accept
c7sI8S-YIS_,Unsupervised learning of features and object boundaries from local prediction,"['unsupervised', 'self-supervised', 'segmentation', 'grouping', 'prediction', 'local', 'probabilistic', 'contours', 'object boundaries']","[3, 7, 8]","[4, 3, 4]",0,"[311, 881, 416]",Reject
2dxsDFaESK,Amortized Projection Optimization for Sliced Wasserstein Generative Models,"['Sliced Wasserstein', 'Optimal Transport', 'Amortized Optimization', 'Generative Models']","[6, 8, 6, 4]","[3, 3, 4, 5]",0,"[259, 367, 431, 1236]",Accept
O4Q39aQFz0Y,Revisiting Sliced Wasserstein on Images: From Vectorization to Convolution,"['Sliced Wasserstein', 'Optimal Transport', 'Generative Models', 'Convolutional Operators']","[3, 4, 7, 7]","[3, 2, 4, 4]",0,"[533, 522, 315, 315]",Accept
r-6Z1SJbCpv,Towards Learning Universal Hyperparameter Optimizers with Transformers,"['OptFormer', 'Transformer', 'hyperparameter', 'optimization', 'offline', 'tuning', 'meta', 'learning', 'meta-learning', 'bayesian', 'optimization', 'blackbox']","[4, 7, 7, 6]","[3, 4, 4, 5]",0,"[283, 518, 607, 430]",Accept
H3o9a6l0wz,Optimal Transport-based Identity Matching for Identity-invariant Facial Expression Recognition,"['Facial Expression Recognition', 'optimal transport', 'identity matching', 'identity-invarient']","[4, 6, 6]","[4, 5, 4]",0,"[239, 848, 226]",Accept
xdZs1kf-va,I2Q: A Fully Decentralized Q-Learning Algorithm,['multi-agent reinforcement learning'],"[8, 5, 6]","[3, 3, 4]",0,"[197, 264, 651]",Accept
awdyRVnfQKX,HierSpeech: Bridging the Gap between Text and Speech by Hierarchical Variational Inference using Self-supervised Representations for Speech Synthesis,"['Speech Synthesis', 'Text-to-Speech', 'Self-supervised speech representation']","[6, 6, 7]","[3, 3, 4]",0,"[393, 191, 244]",Accept
XA4ru9mfxTP,Unifying Voxel-based Representation with Transformer for 3D Object Detection,"['Unified representation', 'Multi-modality input', '3D object detection']","[6, 6, 4]","[4, 4, 4]",0,"[436, 584, 447]",Accept
FzdmrTUyZ4g,Monte Carlo Tree Descent for Black-Box Optimization,"['Monte Carlo tree search', 'blackbox optimization', 'stochastic search', 'Bayesian optimization']","[6, 7, 2, 6]","[4, 2, 5, 4]",0,"[248, 393, 254, 304]",Accept
E3LgJdPEkP,A Mean-Field Game Approach to Cloud Resource Management with Function Approximation,"['Mean-field game', 'reinforcement learning', 'serverless computing', 'resource management']","[6, 6, 6, 6]","[3, 3, 3, 2]",0,"[767, 286, 189, 527]",Accept
_vfyuJaXFug,Translation-equivariant Representation in Recurrent Networks with a Continuous Manifold of Attractors,"['Neural coding', 'Equivariant representation', 'Continuous attractor neural network', 'Lie group', ""Drosophila's heading system""]","[6, 8, 7, 7]","[4, 4, 4, 2]",0,"[463, 792, 339, 521]",Accept
RO0wSr3R7y-,3DILG: Irregular Latent Grids for 3D Generative Modeling,"['shape representation', 'generative modeling', 'shape generation', 'probabilistic shape reconstruction from a single image', 'shape reconstruction']","[4, 7, 5, 7]","[4, 3, 4, 4]",0,"[200, 514, 426, 260]",Accept
N0tKCpMhA2,Coresets for Vertical Federated Learning: Regularized Linear Regression and $K$-Means Clustering,"['vertical federated learning', 'coreset', 'linear regression', 'k-means clustering']","[7, 6, 7]","[3, 4, 4]",0,"[469, 479, 387]",Accept
5pvB6IH_9UZ,CHIMLE: Conditional Hierarchical IMLE,"['Mode-covering Generative Model', 'Diverse Conditional Image Synthesis', 'Implicit Maximum Likelihood Estimation (IMLE)']","[5, 5, 5, 6]","[3, 4, 3, 4]",0,"[271, 274, 417, 439]",Accept
xK6wRfL2mv7,Sharpness-Aware Training for Free,"['Efficient learning', 'generalization', 'training algorithm']","[7, 3, 6, 4]","[4, 4, 4, 2]",0,"[283, 724, 380, 403]",Accept
m8YYs8nJF3T,Distributional Convergence of the Sliced Wasserstein Process,[],"[7, 6, 6, 5]","[3, 4, 4, 4]",0,"[230, 254, 633, 487]",Accept
Iksst2czYoB,Stochastic Multiple Target Sampling Gradient Descent,"['Multi objective optimization', 'Multi task learning', 'Stein Variational Gradient Descent']","[6, 6, 7]","[3, 4, 2]",0,"[149, 636, 509]",Accept
wjSHd5nDeo,Multi-Sample Training for Neural Image Compression,[],"[6, 7, 6]","[4, 4, 2]",0,"[593, 474, 329]",Accept
duBoAyn9aI,Controllable and Lossless Non-Autoregressive End-to-End Text-to-Speech,"['text-to-speech', 'prosody modeling', 'VAE', 'flow-based model']","[8, 3, 3]","[3, 5, 4]",0,"[446, 538, 320]",Reject
pZsAwqUgnAs,Implicit Regularization or Implicit Conditioning? Exact Risk Trajectories of SGD in High Dimensions,"['High dimensional', 'least squares', 'SGD', 'implicit regularization', 'exact dynamics', 'SDE']","[4, 5, 6, 5]","[2, 4, 4, 4]",0,"[528, 427, 776, 425]",Accept
OtxyysUdBE,FedRolex: Model-Heterogeneous Federated Learning with Rolling Sub-Model Extraction,"['Federated Learning', 'Model Heterogeneity', 'Inclusive AI']","[8, 5, 8, 4]","[4, 4, 5, 4]",0,"[220, 208, 290, 239]",Accept
ZVuzllOOHS,Differentially Private Covariance Revisited,"['differential privacy', 'covariance estimation']","[6, 7, 8, 7]","[4, 3, 3, 4]",0,"[196, 799, 501, 366]",Accept
tHK5ntjp-5K,LION: Latent Point Diffusion Models for 3D Shape Generation,"['3D Shape Synthesis', 'Generative Learning', 'Diffusion Models', 'Point Cloud Generation', 'Denoising Diffusion', 'Variational Autoencoder']","[5, 7, 5, 7]","[5, 3, 3, 4]",0,"[332, 416, 504, 492]",Accept
crFMP5irwzn,Learning Efficient Vision Transformers via Fine-Grained Manifold Distillation,"['vision transformer', 'knowledge diatillation', 'manifold learning']","[5, 6, 7, 5]","[4, 4, 3, 4]",0,"[388, 154, 285, 627]",Accept
P_eBjUlzlV,On the Limitations of Stochastic Pre-processing Defenses,"['adversarial examples', 'randomized defenses', 'preprocessing defenses', 'input transformation', 'limitations']","[6, 7, 6]","[4, 4, 4]",0,"[935, 278, 408]",Accept
caH1x1ZBLDR,Distributionally Robust Optimization with Data Geometry,"['Distributional Robustness', 'Over-flexibility Problem', 'Data Geometry']","[5, 7, 8, 7]","[4, 4, 4, 5]",0,"[525, 278, 293, 985]",Accept
AIqC7F7xV-d,Learning Unified Representations for Multi-Resolution Face Recognition,"['multi-resolution face recognition', 'deep representation learning']","[4, 3, 5]","[5, 5, 3]",0,"[290, 385, 316]",Reject
OmLNqwnZwmY,Falsification before Extrapolation in Causal Effect Estimation,"['Causal Inference', 'Randomized Trial', 'Hypothesis Testing', 'Causal Effects']","[4, 6, 6, 6]","[4, 3, 4, 3]",0,"[683, 464, 421, 460]",Accept
Yay6tHq1Nw,Improving Policy Learning via Language Dynamics Distillation,"['language grounding', 'reinforcement learning', 'reading to generalize']","[6, 4, 4, 6]","[4, 3, 3, 4]",0,"[491, 186, 293, 303]",Accept
8UUtKmSRkXE,On Gap-dependent Bounds for Offline Reinforcement Learning,"['offline reinforcement learning', 'gap-dependent']","[6, 5, 7, 7]","[4, 5, 4, 3]",0,"[454, 547, 272, 265]",Accept
bdnZ_1qHLCW,ResQ: A Residual Q Function-based Approach for Multi-Agent Reinforcement Learning Value Factorization,"['Multi-Agent Reinforcement Learning', 'Value Factorization', 'residual Q']","[7, 7, 7, 4]","[4, 4, 2, 4]",0,"[1244, 282, 315, 388]",Accept
u4KagP_FjB,Spartan: Differentiable Sparsity via Regularized Transportation,"['sparsity', 'optimal transport']","[5, 8, 6, 6]","[3, 3, 3, 3]",0,"[577, 956, 147, 815]",Accept
GzESlaXaN04,Hardness of Noise-Free Learning for Two-Hidden-Layer Neural Networks,"['PAC learning', 'neural networks', 'SQ lower bounds']","[7, 8, 7]","[5, 3, 3]",0,"[399, 209, 149]",Accept
Q9lm8w6JpXi,BILCO: An Efficient Algorithm for Joint Alignment of Time Series,"['Joint alignment', 'graphical time warping', 'bidirectional-pushing strategy', 'linear component operation', 'BILCO']","[6, 7, 6]","[4, 1, 4]",0,"[465, 196, 215]",Accept
YZ-N-sejjwO,Models Out of Line: A Fourier Lens on Distribution Shift Robustness,"['OOD robustness', 'effective robustness', 'deep neural networks', 'spectral analysis', 'CLIP models']","[7, 6, 6]","[4, 4, 3]",0,"[753, 272, 278]",Accept
A0ejsEHQu9w,Gradient-Free Methods for Deterministic and Stochastic Nonsmooth Nonconvex Optimization,"['gradient-free methods', 'nonsmooth nonconvex optimization', 'finite-time convergence guarantee', 'Goldstein subdifferential', 'smoothing']","[7, 6, 7]","[4, 2, 4]",0,"[289, 470, 142]",Accept
ZqgFbZEb8bW,Visual Clues: Bridging Vision and Language Foundations for Image Paragraph Captioning,"['Image paragraph captioning', 'vision-language models', 'zero-shot learning']","[6, 6, 6, 6]","[5, 3, 4, 3]",0,"[906, 556, 314, 308]",Accept
vQzDYi4dPwM,Size and depth of monotone neural networks: interpolation and approximation,"['Monotone neural networks', 'interpolation', 'expressivity', 'benefit of depth']","[7, 7, 4]","[1, 3, 4]",0,"[344, 758, 151]",Accept
SHMi1b7sjXk,Test-Time Training with Masked Autoencoders,"['Computer Vision', 'Test-Time Training', 'Masked Auto-Encoder']","[8, 6, 6, 6]","[5, 3, 4, 4]",0,"[125, 301, 272, 553]",Accept
o4uFFg9_TpV,Visual Prompting via Image Inpainting,"['Computer Vision', 'Self-Supervised Learning', 'Visual Prompting']","[7, 6, 6, 7]","[3, 4, 4, 5]",0,"[396, 767, 735, 333]",Accept
sBrS3M5lT2w,Global Convergence and Stability of Stochastic Gradient Descent,"['Stochastic Gradient Descent', 'Nonconvexity', 'General Noise Models', 'Global Convergence']","[6, 5, 7, 5, 5]","[4, 3, 2, 2, 3]",0,"[271, 344, 364, 355, 311]",Accept
qj-_HnxQxB,Functional Indirection Neural Estimator for Better Out-of-distribution Generalization,"['functional space', 'analogy-making', 'indirection', 'memory', 'out-of-distribution generalization', 'IQ task']","[3, 6, 6, 5]","[5, 4, 4, 4]",0,"[563, 728, 162, 761]",Accept
n0dD3d54Wgf,SparCL: Sparse Continual Learning on the Edge,"['Continual Learning', 'Sparse Training']","[4, 5, 7, 6]","[3, 5, 4, 4]",0,"[286, 527, 800, 194]",Accept
u3vEuRr08MT,Memorization Without Overfitting:  Analyzing the Training Dynamics of Large Language Models,[],"[6, 7, 7, 8]","[3, 4, 4, 4]",0,"[923, 206, 583, 336]",Accept
Q38D6xxrKHe,High-dimensional limit theorems for SGD: Effective dynamics and critical scaling,"['stochastic gradient descent', 'high-dimensional statistics', 'online algorithms', 'PCA', 'XOR', 'Gaussian mixture model', 'two-layer network']","[7, 7, 8]","[3, 3, 4]",0,"[470, 1103, 545]",Accept
HQDvPsdXS-F,Neur2SP: Neural Two-Stage Stochastic Programming,[],"[4, 7, 8, 7]","[4, 4, 4, 4]",0,"[503, 682, 375, 463]",Accept
S2Awu3Zn04v,Approximate Value Equivalence,"['model-based reinforcement learning', 'reinforcement learning', 'value function', 'muzero', 'value equivalence', 'planning']","[6, 7, 4]","[2, 4, 3]",0,"[333, 641, 297]",Accept
gQBetxnU4Lk,Learning-based Motion Planning in Dynamic Environments Using GNNs and Temporal Encoding,[],"[6, 6, 6]","[3, 4, 4]",0,"[558, 398, 493]",Accept
IJNDyqdRF0m,Decomposing NeRF for Editing via Feature Field Distillation,"['neural radiance field', 'editing', 'semantic segmentation', 'distillation']","[7, 5, 6, 7]","[4, 5, 4, 3]",0,"[330, 295, 312, 393]",Accept
AXDNM76T1nc,Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos,[],"[8, 9, 9, 6]","[4, 4, 4, 5]",0,"[465, 477, 766, 378]",Accept
se2oxj-6Nz,Rethinking Image Restoration for Object Detection,"['Image Restoration', 'Object Detection', 'Image Dehazing', 'Low Light Enhancement', 'Targeted Adversarial Attack']","[5, 4, 8]","[4, 3, 5]",0,"[180, 329, 381]",Accept
Oq2bdIQQOIZ,On Privacy and Personalization in Cross-Silo Federated Learning,"['Differential Privacy', 'Federated Learning', 'Model Personalization']","[7, 4, 3, 6]","[3, 3, 4, 4]",0,"[251, 561, 310, 926]",Accept
Tocn9vYMU-o,Approaching Quartic Convergence Rates for Quasi-Stochastic Approximation with Application to Gradient-Free Optimization,"['Stochastic Approximation', 'Gradient-Free Optimization', 'Optimization']","[7, 7, 7, 5]","[2, 4, 3, 4]",0,"[477, 225, 363, 321]",Accept
KnCS9390Va,Delving into Out-of-Distribution Detection with Vision-Language Representations,[],"[6, 6, 6, 6]","[4, 3, 4, 4]",0,"[246, 638, 267, 295]",Accept
wsnMW0c_Au,Non-convex online learning via algorithmic equivalence,[],"[5, 6, 5]","[4, 5, 3]",0,"[362, 570, 270]",Accept
ePZsWeGJXyp,VICRegL: Self-Supervised Learning of Local Visual Features,"['self-supervised learning', 'representation learning', 'computer vision']","[4, 5, 7]","[4, 4, 4]",0,"[663, 599, 777]",Accept
C0VKVmhlKgb,Bayesian Clustering of Neural Spiking Activity Using a Mixture of Dynamic Poisson Factor Analyzers,"['neural spike data', 'clustering', 'dynamic Poisson factor model (DPFA)', 'mixture of finite mixtures model', 'Markov chain Monte Carlo(MCMC)', 'Laplace Approximation']","[7, 4, 6]","[3, 5, 5]",0,"[558, 420, 1005]",Accept
hX5Ia-ION8Y,"MCVD - Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation","['score-based denoising diffusion', 'video prediction', 'video generation', 'video interpolation']","[5, 6, 6]","[5, 5, 4]",0,"[449, 397, 420]",Accept
IFXTZERXdM7,Solving Quantitative Reasoning Problems with Language Models,"['language models', 'quantitative reasoning', 'transformers', 'math and science word problems']","[9, 7, 6, 2, 6]","[5, 4, 4, 3, 5]",0,"[186, 415, 328, 594, 505]",Accept
9t24EBSlZOa,Attention-based Neural Cellular Automata,"['neural cellular automata', 'cellular automata', 'vision transformer', 'transformer', 'denoising autoencoding', 'computer vision', 'deep learning']","[8, 7, 7, 7]","[3, 4, 3, 4]",0,"[372, 527, 379, 625]",Accept
v9Wjc2OWjz,The price of ignorance: how much does it cost to forget noise structure in low-rank matrix estimation?,"['low-rank matrix estimation', 'mismatch', 'Bayes estimator', 'Approximate Message Passing', 'state evolution', 'spectral method']","[6, 6, 6, 6]","[4, 3, 3, 4]",0,"[279, 366, 308, 325]",Accept
48TmED6BvGZ,Biological Learning of Irreducible Representations of Commuting Transformations,"['learning', 'transformation', 'biologically plausible']","[7, 6, 6, 8]","[4, 3, 4, 3]",0,"[342, 232, 435, 196]",Accept
Bct2f8fRd8S,The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning,[],"[6, 4, 6]","[3, 4, 3]",0,"[1058, 421, 272]",Accept
-vXEN5rIABY,Inductive Logical Query Answering in Knowledge Graphs,"['inductive graph reasoning', 'complex query answering', 'logical queries', 'knowledge graphs', 'graph neural networks', 'inductive representation learning']","[4, 8, 6, 5]","[4, 4, 4, 5]",0,"[343, 552, 311, 348]",Accept
4v7PSPp-TAe,Regularized Gradient Descent Ascent for Two-Player Zero-Sum Markov Games,"['Markov game', 'reinforcement learning', 'minimax optimization']","[6, 4, 6, 7]","[4, 3, 4, 4]",0,"[384, 419, 271, 431]",Accept
UqA1mcOxiq,Posted Pricing and Dynamic Prior-independent Mechanisms with Value Maximizers,[],"[7, 6, 6]","[3, 4, 4]",0,"[307, 442, 153]",Accept
pAq8iDy00Oa,Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel,"['Neural network', 'Gaussian process', 'Composite kernel', 'Nystrom method']","[5, 4, 7, 7]","[4, 4, 3, 3]",0,"[336, 555, 281, 462]",Reject
tadPkBL2gHa,Recruitment Strategies That Take a Chance,"['decision making under uncertainty', 'approximation algorithms', 'stochastic optimization']","[5, 8, 7, 6]","[3, 3, 4, 4]",0,"[585, 200, 323, 554]",Accept
XByg4kotW5,When does return-conditioned supervised learning work for offline reinforcement learning?,[],"[6, 6, 6, 7]","[3, 4, 4, 4]",0,"[361, 320, 686, 285]",Accept
G2kkDEujOw,Detection and Localization of Changes in Conditional Distributions,"['change point analysis', 'nonparametric', 'kernel methods']","[6, 6, 7, 7]","[4, 3, 5, 3]",0,"[340, 304, 248, 320]",Accept
8cC2JeUyz9,Inference and Sampling for Archimax Copulas,"['copula', 'Archimax', 'Archimedean', 'Pareto', 'extreme', 'multivariate', 'stochastic', 'sampling', 'dependence', 'inference', 'generator', 'Kendall']","[7, 8, 7, 7]","[3, 3, 4, 3]",0,"[475, 174, 524, 357]",Accept
4RC_vI0OgIS,Online Deep Equilibrium Learning for Regularization by Denoising,"['inverse problems', 'plug-and-play priors', 'regularization by denoising', 'deep equilibrium models', 'computational imaging']","[6, 7, 6, 5]","[5, 4, 5, 4]",0,"[488, 358, 398, 379]",Accept
Ms6QZafNv01,Optimal algorithms for group distributionally robust optimization and beyond,"['fairness', 'robustness', 'subpopulation fairness', 'conditional value at risk', 'distributionally robust optimization']","[6, 6, 5, 4]","[3, 3, 2, 3]",0,"[421, 312, 360, 400]",Reject
68YyraaeYmc,Exploring through Random Curiosity with General Value Functions,"['exploration', 'curiosity', 'general value functions', 'random network distillation']","[6, 4, 7, 6]","[3, 3, 4, 3]",0,"[275, 468, 1057, 282]",Accept
U14PKEu18bK,Unsupervised Multi-View Object Segmentation Using Radiance Field Propagation,"['Computer Vision', 'Unsupervised Segmentation', '3D Scene Representation', 'Computational Imaging']","[6, 5, 6, 6]","[4, 3, 3, 4]",0,"[539, 236, 226, 189]",Accept
sNcn-E3uPHA,Text Classification with Born's Rule,"['text classification', 'quantum physics', 'quantum-inspired machine learning', 'explainable classification']","[4, 7, 5, 7]","[5, 2, 2, 4]",0,"[918, 280, 355, 541]",Accept
8E8tgnYlmN,SIREN: Shaping Representations for Detecting Out-of-Distribution Objects,[],"[5, 5, 2]","[4, 5, 5]",0,"[266, 254, 792]",Accept
t3X5yMI_4G2,Reincarnating Reinforcement Learning: Reusing Prior Computation to Accelerate Progress,"['Reusing Computation', 'Deep RL', 'Research Workflow']","[7, 7, 6, 8]","[3, 2, 4, 4]",0,"[602, 923, 610, 1199]",Accept
fcMd-tuWwiO,A sharp NMF result with applications in network modeling  ,"['Non-negative matrix factorization (NMF)', 'social networks', 'degree-corrected block model', 'mixed-membership', 'low-rank model']","[5, 6, 6]","[2, 3, 4]",0,"[477, 240, 209]",Accept
RP1CtZhEmR,Generating multivariate time series with COmmon Source CoordInated GAN (COSCI-GAN),"['Synthetic Data', 'Multivariate Time Series', 'Generative Adversarial Networks', 'Generative Modelling', 'Data Augmentation']","[7, 7, 5, 4]","[3, 4, 3, 4]",0,"[492, 464, 753, 346]",Accept
dT0eNsO2YLu,Learnable Polyphase Sampling for Shift Invariant and Equivariant Convolutional Networks,"['Convolutional Neural Networks', 'Shift equivariance', 'Shift invariance', 'Polyphase Decomposition']","[7, 5, 6]","[3, 5, 3]",0,"[234, 334, 216]",Accept
1wVBLK1Xuc,Policy Optimization with Advantage Regularization for Long-Term Fairness in Decision Systems,"['fairness', 'reinforcement learning', 'policy optimization', 'algorithmic decision making']","[5, 6, 6, 5]","[3, 3, 3, 4]",0,"[376, 221, 364, 166]",Accept
5yAmUvdXAve,Cluster and Aggregate: Face Recognition with Large Probe Set,"['feature fusion', 'face recognition']","[6, 5, 6, 6]","[2, 3, 4, 4]",0,"[780, 337, 415, 428]",Accept
toleacrf7Hv,Parameter tuning and model selection in Optimal Transport with semi-dual Brenier formulation,"['Optimal Transport', 'model selection']","[6, 6, 7, 5]","[5, 4, 4, 4]",0,"[176, 538, 985, 1135]",Accept
6yuil2_tn9a,Handcrafted Backdoors in Deep Neural Networks,"['Backdoor attacks', 'handcrafting model parameters', 'neural networks', 'supply-chain attack']","[5, 7, 8]","[3, 4, 5]",0,"[154, 245, 615]",Accept
1xqE9fRZch5,Local Spatiotemporal Representation Learning for Longitudinally-consistent Neuroimage Analysis,"['neuroimaging', 'medical image analysis', 'spatiotemporal representation learning', 'longitudinal learning', 'medical image segmentation']","[7, 7, 7]","[2, 4, 4]",0,"[182, 252, 331]",Accept
o8vYKDWMnq1,Understanding Deep Neural Function Approximation in Reinforcement Learning via $\epsilon$-Greedy Exploration,"['deep reinforcement learning', 'function approximation', '$\\epsilon$-Greedy Exploration']","[7, 6, 6]","[4, 4, 3]",0,"[246, 490, 1039]",Accept
177GzUAds8U,Compositional generalization through abstract representations in human and artificial neural networks,"['neuroscience', 'cognition', 'compositionality', 'generalization', 'neural coding', 'abstraction', 'representations', 'human', 'fMRI', 'artificial neural networks']","[7, 7, 6, 7]","[4, 4, 4, 3]",0,"[530, 888, 546, 902]",Accept
ZwnPdpCw6d,Robust $\phi$-Divergence MDPs,"['Markov decision processes', 'robust optimization', 'phi-divergences']","[6, 5, 5]","[5, 2, 4]",0,"[494, 214, 314]",Accept
PCZfDUH8fIn,The price of unfairness in linear bandits with biased feedback,"['Linear bandits', 'fairness', 'partial monitoring', 'optimal design']","[6, 6, 6]","[1, 3, 4]",0,"[325, 529, 348]",Accept
Yo0s4qp_UMR,Intrinsic Sliced Wasserstein Distances for Comparing Collections of Probability Distributions on Manifolds and Graphs,[],"[4, 6, 4]","[4, 4, 4]",0,"[475, 770, 834]",Reject
oQIJsMlyaW_,SInGE: Sparsity via Integrated Gradients Estimation of Neuron Relevance,"['pruning', 'compression', 'acceleration', 'deep learning', 'efficient inference']","[6, 5, 6]","[2, 3, 4]",0,"[506, 565, 502]",Accept
SYdg8tcFgdG,Sample-Efficient Learning of Correlated Equilibria in Extensive-Form Games,"['extensive-form games', 'imperfect information', 'correlated equilibria', 'reinforcement learning theory', 'multi-agent reinforcement learning']","[6, 7, 7, 7]","[3, 5, 2, 4]",0,"[281, 451, 389, 635]",Accept
a3ymtHbL5p5,"In Differential Privacy, There is Truth: on Vote-Histogram Leakage in Ensemble Private Learning","['adversarial', 'differential privacy', 'privacy', 'attacks']","[4, 7, 3, 10]","[3, 4, 3, 4]",0,"[168, 362, 307, 278]",Accept
3vmKQUctNy,Washing The Unwashable : On The (Im)possibility of Fairwashing Detection,[],"[6, 3, 6, 7]","[4, 4, 3, 4]",0,"[337, 451, 402, 174]",Accept
yts7fLpWY9G,Graph Neural Networks with Adaptive Readouts,"['graph neural networks', 'readout', 'aggregator', 'adaptive', 'differentiable', 'gnn', 'neural', 'permutation', 'invariance', 'invariant', 'deep sets', 'graph representation learning']","[8, 6, 6]","[5, 3, 4]",0,"[735, 434, 396]",Accept
_N4k45mtnuq,Approximate Euclidean lengths and distances beyond Johnson-Lindenstrauss,"['Johnson-Lindenstrauss', 'Hutch++', 'Euclidean distances', 'Statistical leverage scores', 'Random projection', 'Approximate isometry', 'Dimensionality reduction']","[5, 7, 7, 5]","[3, 3, 3, 2]",0,"[313, 277, 241, 474]",Accept
eF_Mx-3Sm92,Change-point Detection for  Sparse and Dense Functional Data in General Dimensions,[],"[4, 8, 7, 7, 6]","[4, 3, 3, 3, 1]",0,"[382, 212, 312, 268, 255]",Accept
ADfBF9PoTvw,Markov Chain Score Ascent: A Unifying Framework of Variational Inference with Markovian Gradients,"['variational inference', 'Bayesian inference', 'inclusive Kullback-Leibler divergence', 'Markov chain gradient descent', 'Markov chain']","[7, 6, 6, 7]","[3, 3, 2, 4]",0,"[562, 264, 119, 787]",Accept
rG7HZZtIc-,D^2NeRF: Self-Supervised Decoupling of Dynamic and Static Objects from a Monocular Video,"['Scene Decomposition', 'Video Segmentation', 'Novel View Synthesis']","[7, 7, 5, 5]","[5, 4, 4, 4]",0,"[313, 406, 262, 256]",Accept
pbILUUf_hBN,A Near-Optimal Best-of-Both-Worlds Algorithm for Online Learning with Feedback Graphs,"['Online Learning', 'Feedback Graphs', 'Beyond Bandits']","[7, 7, 6, 7]","[3, 3, 4, 4]",0,"[291, 142, 492, 515]",Accept
VpHFHz57fT,Improved Imaging by Invex Regularizers with Global Optima Guarantees,"['Invexity', 'Regularizer', 'Imaging', 'Global optima', 'Non-convex optimization', 'Convexity']","[8, 7, 7]","[4, 3, 3]",0,"[310, 529, 169]",Accept
K4W92FUXSF9,Random Normalization Aggregation for Adversarial Defense,"['Adversarial Robustness', 'Adversarial Transferability', 'Normalization']","[6, 7, 7, 3]","[3, 4, 5, 5]",0,"[301, 416, 369, 483]",Accept
8hs7qlWcnGs,ToDD: Topological Compound Fingerprinting in Computer-Aided Drug Discovery,"['Drug discovery', 'topology-based graph classification', 'persistent homology']","[7, 4, 9]","[3, 4, 4]",0,"[699, 330, 438]",Accept
9cU2iW3bz0,Score-Based Diffusion meets Annealed Importance Sampling,"['importance sampling', 'mcmc', 'diffusion']","[7, 6, 7]","[3, 3, 4]",0,"[275, 427, 809]",Accept
0oQv1Ftt_gK,Rethinking Counterfactual Explanations as Local and Regional Counterfactual Policies,"['counterfactuals', 'algorithmic recourse', 'learning theory', 'random forest', 'interpretability', 'explainable models', 'tree-based models']","[6, 3, 6]","[3, 5, 4]",0,"[333, 623, 134]",Reject
HuiLIB6EaOk,VTC-LFC: Vision Transformer Compression with Low-Frequency Components,"['ViT', 'compression', 'low-frequency']","[7, 7, 7]","[5, 5, 3]",0,"[330, 143, 524]",Accept
YiFQqYAk1xH,Dynamic Fair Division with Partial Information,"['dynamic fair division', 'partial information', 'distrortion']","[5, 7, 6, 6]","[3, 3, 4, 3]",0,"[428, 517, 1009, 419]",Accept
78T4K99jvbE,Set-based Meta-Interpolation for  Few-Task Meta-Learning,"['meta-learning', 'task augmentation', 'meta-regularization']","[7, 6, 6, 7]","[4, 4, 3, 4]",0,"[311, 296, 336, 678]",Accept
WyiM4lDJOcK,How To Design Stable Machine Learned Solvers For Scalar Hyperbolic PDEs,"['machine learning for sciences', 'machine learning for physics', 'machine learning for numerical methods', 'numerical methods', 'partial differential equations']","[3, 3, 7, 3]","[4, 4, 3, 4]",0,"[597, 1093, 430, 777]",Reject
pl279jU4GOu,Convergence beyond the over-parameterized regime using Rayleigh quotients,[],"[7, 4, 7]","[5, 4, 4]",0,"[325, 669, 856]",Accept
M_WuaKoaEfQ,A Quadrature Rule combining Control Variates and Adaptive Importance Sampling,"['Monte Carlo', 'quadrature rule', 'control variates', 'adaptive importance sampling', 'Bayesian inference']","[7, 7, 7]","[3, 2, 4]",0,"[272, 267, 287]",Accept
s0AgNH86p8,TransBoost: Improving the Best ImageNet Performance using Deep Transduction,"['Deep Transductive Learning', 'Image Classification']","[5, 5, 8]","[3, 4, 3]",0,"[237, 219, 332]",Accept
lHj-q9BSRjF,Data Distributional Properties Drive Emergent In-Context Learning in Transformers,"['in-context learning', 'few-shot learning', 'transformers']","[4, 9, 7, 8]","[4, 5, 3, 3]",0,"[252, 325, 605, 385]",Accept
WUMH5xloWn,Automatic differentiation of nonsmooth iterative algorithms,"['Fixed point solvers', 'nonsmooth algorithms', 'automatic differentiation', 'unrolling', 'piggy back differentiation', 'conservative gradients.']","[7, 7, 7, 7]","[3, 3, 4, 2]",0,"[272, 382, 564, 614]",Accept
QW98XBAqNRa,Truncated proposals for scalable and hassle-free simulation-based inference,"['likelihood-free inference', 'simulation-based inference', 'Bayesian inference', 'neural density estimation']","[5, 7, 7, 7]","[5, 4, 4, 3]",0,"[2113, 720, 1089, 422]",Accept
M12autRxeeS,Extracting computational mechanisms from neural data using low-rank RNNs,"['RNN', 'computational neuroscience']","[6, 7, 5, 6]","[4, 4, 3, 4]",0,"[581, 413, 284, 984]",Accept
nC8VC8gVGPo,Training Spiking Neural Networks with Local Tandem Learning,"['Spiking Neural Network (SNN)', 'Teacher-Student Learning', 'On-chip Learning', 'Local Learning', 'Neuromorphic Computing']","[6, 6, 8, 8]","[3, 4, 4, 5]",0,"[470, 707, 451, 382]",Accept
OxHn1Yz_Kl3,"Causal Identification under Markov equivalence: Calculus, Algorithm, and Completeness","['causality', 'causal inference', 'Markov equivalence', 'causal effect identification']","[7, 7, 9, 9]","[2, 4, 3, 4]",0,"[680, 342, 357, 478]",Accept
JO9o3DgV9l2,Shield Decentralization for Safe Multi-Agent Reinforcement Learning,"['safety', 'shielding', 'reinforcement learning', 'synthesis', 'multi agent']","[5, 8, 8]","[4, 4, 4]",0,"[293, 690, 590]",Accept
ONB4RdP2GX,Hardness in Markov Decision Processes: Theory and Practice,"['Reinforcement Learning', 'Hardness', 'Benchmarking']","[6, 7, 6, 6]","[4, 3, 4, 3]",0,"[339, 838, 982, 426]",Accept
eXggxYNbQi,On the Interpretability of Regularisation for Neural Networks Through Model Gradient Similarity,"['neural network', 'regularization', 'gradient descent', 'gradient similarity', 'noisy labels', 'generalization']","[7, 3, 6]","[3, 4, 3]",0,"[502, 369, 833]",Accept
U_hOegGGglw,A Closer Look at Prototype Classifier for Few-shot Image Classification,"['few-shot', 'meta-learning', 'prototypical network', 'fine-tuning', 'prototypical classifier']","[5, 6, 6]","[4, 3, 4]",0,"[371, 536, 270]",Accept
_2-r5UurHp,ALIFE: Adaptive Logit Regularizer and Feature Replay for Incremental Semantic Segmentation,"['continual learning', 'incremental learning', 'semantic segmentation']","[8, 6, 6, 6]","[4, 4, 3, 5]",0,"[613, 331, 459, 847]",Accept
RQ385yD9dqR,When are Local Queries Useful for Robust Learning?,"['Learning Theory', 'Robustness', 'Classification']","[6, 6, 6]","[1, 3, 3]",0,"[590, 450, 358]",Accept
vGQiU5sqUe3,Contrastive Learning as Goal-Conditioned Reinforcement Learning,"['contrastive learning', 'reinforcement learning', 'goal-conditioned', 'representation learning']","[7, 8, 7]","[3, 3, 4]",0,"[396, 517, 534]",Accept
fSfcEYQP_qc,A Neural Corpus Indexer for Document Retrieval,"['document retrieval', 'sequence-to-sequence', 'model-based index']","[7, 7, 4, 8]","[4, 3, 5, 3]",0,"[597, 295, 183, 231]",Accept
USoYIT4IQz,Invertible Monotone Operators for Normalizing Flows,"['Normalizing flows', 'invertible neural networks', 'monotone operators', 'deep generative models']","[7, 7, 7, 7]","[4, 4, 4, 3]",0,"[469, 440, 493, 450]",Accept
Ya9lATuQ3gg,Large-Scale Retrieval for Reinforcement Learning,"['reinforcement learning', 'retrieval', 'neural networks', 'offline RL']","[7, 5, 6, 4]","[3, 2, 3, 4]",0,"[172, 437, 1072, 659]",Accept
88_wNI6ZBDZ,Make Sharpness-Aware Minimization Stronger: A Sparsified Perturbation Approach,"['Sharpness-Aware Minimization', 'Fisher information', 'Dynamic sparse training']","[5, 6, 7, 4]","[4, 4, 4, 4]",0,"[450, 488, 232, 285]",Accept
bk8vkdQfBS,Explainability Via Causal Self-Talk,"['explainability', 'reinforcement learning', 'deep learning', 'causality', 'interpretability']","[5, 6, 5, 9]","[2, 3, 3, 3]",0,"[553, 447, 472, 385]",Accept
t0VbBTw-o8,Randomized Message-Interception Smoothing: Gray-box Certificates for Graph Neural Networks,"['Robustness Certificates', 'Adversarial Robustness', 'Randomized Smoothing', 'Graph Neural Networks']","[7, 6, 8, 6]","[4, 2, 3, 4]",0,"[429, 201, 279, 477]",Accept
djOANbV2zSu,UQGAN: A Unified Model for Uncertainty Quantification of Deep Classifiers trained via Conditional GANs,"['uncertainty quantification', 'deep neural network', 'GAN', 'out-of-distribution']","[6, 5, 6, 5]","[2, 3, 2, 4]",0,"[394, 254, 460, 277]",Accept
WOuGTb9QswS,Oscillatory Tracking of Continuous Attractor Neural Networks Account for Phase Precession and Procession of Hippocampal Place Cells,"['theoretical neuroscience', 'hippocampus', 'theta phase coding', 'continuous attractor neural network', 'feedback inhibition']","[5, 7, 6]","[3, 4, 4]",0,"[540, 618, 477]",Accept
gd7ZI0X7Q-h,ELASTIC: Numerical Reasoning with Adaptive Symbolic Compiler,"['Numeral Reasoning', 'Encoder', 'Decoder', 'Deep Learning', 'AI', 'Hierarchical Decoder', 'Mathematical Symbols']","[8, 5, 6]","[4, 4, 3]",0,"[298, 532, 347]",Accept
Y0Bm5tL92lg,Adaptation Accelerating Sampling-based Bayesian Inference in Attractor Neural Networks,"['Neuroscience', 'Sample-based Bayesian inference', 'Continuous attractor neural networks', 'Neural adaptation']","[7, 7, 5, 7]","[2, 4, 3, 4]",0,"[635, 556, 412, 247]",Accept
hYx-xr1wdo,Subspace clustering in high-dimensions: Phase transitions \& Statistical-to-Computational gap,"['Replica method', 'Approximate Message Passing', 'Statistical Physics', 'Statistical-to-Computational Gap']","[4, 6, 5, 5, 8]","[3, 3, 4, 4, 3]",0,"[826, 325, 441, 196, 373]",Accept
K-A4tDJ6HHf,Diagnosing failures of fairness transfer across distribution shift in real-world medical settings,"['Healthcare', 'fairness', 'robustness', 'deep learning']","[6, 7, 7]","[3, 4, 3]",0,"[2000, 525, 322]",Accept
AYQI3rlp9tW,Efficient identification of informative features in simulation-based inference,"['Simulation-based Inference', 'Feature Selection', 'Hodgkin-Huxley Model', 'Mechanistic Models', 'Neuroscience']","[6, 6, 6, 5]","[3, 4, 4, 5]",0,"[496, 557, 476, 654]",Accept
S8-duMv77W3,Sound and Complete Causal Identification with Latent Variables Given Local Background Knowledge,"['background knowledge', 'partial ancestral graph']","[7, 7, 6]","[3, 3, 3]",0,"[249, 570, 437]",Accept
aJ5xc1QB7EX,Deep Active Learning by Leveraging Training Dynamics,"['Deep Active Learning', 'NTK']","[6, 7, 7, 5]","[3, 4, 4, 2]",0,"[198, 414, 886, 383]",Accept
vdxOesWgbyN,Model Extraction Attacks on Split Federated Learning,"['Split Federated Learning', 'Model Extraction Attack']","[6, 6, 6, 4]","[3, 3, 4, 5]",0,"[424, 274, 557, 359]",Reject
kUnHCGiILeU,CageNeRF: Cage-based Neural Radiance Field for Generalized 3D Deformation and Animation,"['Neural Radiance Field', '3D Reconstruction', 'Cage Deformation']","[3, 7, 6]","[4, 4, 4]",0,"[651, 387, 886]",Accept
k5uFiFLWv3X,Boosting the Transferability of Adversarial Attacks with Reverse Adversarial Perturbation,"['Adversarial Transferability', 'Black-Box Attacks', 'Adversarial Examples']","[5, 5, 5, 6]","[4, 3, 4, 5]",0,"[231, 192, 347, 364]",Accept
OoN6TVb4Vkq,Contextual Bandits with Knapsacks for a Conversion Model,"['mutli-armed bandits', 'bandits with knapsacks', 'logistic bandits', 'primal-dual approaches']","[6, 6, 7]","[4, 2, 3]",0,"[345, 368, 438]",Accept
buXZ7nIqiwE,Using natural language and program abstractions to instill human inductive biases in machines,"['meta-learning', 'program induction', 'natural language', 'reinforcement learning', 'human intelligence', 'cognitive science']","[8, 8, 8]","[5, 4, 3]",0,"[296, 1368, 1133]",Accept
5vVSA_cdRqe,FairVFL: A Fair Vertical Federated Learning Framework with Contrastive Adversarial Learning,"['Vertical Federated Learning', 'Fair Representation Learning', 'Adversarial Learning', 'Contrastive Learning']","[6, 6, 6]","[3, 3, 3]",0,"[206, 268, 690]",Accept
U-RsnLYHcKa,Wasserstein Logistic Regression with Mixed Features,"['Distributionally Robust Optimization', 'Wasserstein Distance', 'Logistic Regression']","[6, 4, 7, 6, 6]","[4, 4, 4, 3, 3]",0,"[330, 385, 322, 558, 550]",Accept
RW-OOBU11xl,Forecasting Human Trajectory from Scene History,"['Human trajectory prediction', 'Scene history', 'Group trajectory', 'Cross-modal interaction']","[5, 6, 6, 6]","[5, 4, 4, 5]",0,"[540, 195, 255, 737]",Accept
-QHUWgkh1OY,DOGE-Train: Discrete Optimization on GPU with End-to-end Training,"['Discrete optimization', 'Integer linear programming', 'Combinatorial optimization', 'Graph neural networks', 'End-to-end', 'Self-supervised', 'Backpropagation', 'Message passing']","[3, 4, 7]","[3, 2, 4]",0,"[227, 179, 618]",Reject
Mn4IkuWamy,The Nature of Temporal Difference Errors in Multi-step Distributional Reinforcement Learning,"['Distributional Reinforcement Learning', 'Off-policy Learning']","[6, 7, 5]","[4, 4, 5]",0,"[266, 418, 809]",Accept
VwRFJi9crEH,Personalized Subgraph Federated Learning,"['Graph Representation Learning', 'Graph Neural Networks', 'Federated Learning', 'Subgraph Federated Learning']","[6, 4, 5, 5]","[4, 5, 3, 4]",0,"[679, 330, 270, 679]",Reject
sFQJ0IOkHF,DivBO: Diversity-aware CASH for Ensemble Learning,"['Automated Machine Learning', 'Hyperparameter Optimization', 'CASH', 'Ensemble Learning', 'Diversity']","[6, 6, 6, 7]","[5, 4, 5, 4]",0,"[303, 1505, 680, 352]",Accept
FNzLe2-ppRO,TREC: Transient Redundancy Elimination-based Convolution,"['Transient redundancy', 'convolution acceleration', 'back-propagation']","[5, 6, 5, 5]","[3, 4, 3, 3]",0,"[376, 664, 290, 319]",Accept
_j8yVIyp27Q,Bidirectional Learning for Offline Infinite-width Model-based Optimization,"['offline model-based optimization', 'infinite-width neural network', 'neural tangent kernel', 'bi-level optimization', 'out-of-distribution']","[5, 7, 6]","[4, 4, 2]",0,"[818, 288, 319]",Accept
iuW96ssPQX,A Transformer-Based Object Detector with Coarse-Fine Crossing Representations,[],"[7, 7, 5]","[5, 4, 5]",0,"[248, 236, 473]",Accept
0zlLhfG6rxI,Bessel Equivariant Networks for Inversion of Transmission Effects in Multi-Mode Optical Fibres,"['physics', 'physics informed machine learning', 'inverse problems', 'optical fibre', 'optics', 'fibres', 'multi-mode fibre', 'equivariance', 'group theory']","[6, 5, 8]","[4, 5, 4]",0,"[244, 274, 242]",Accept
WE92fqi-N_g,VICE: Variational Interpretable Concept Embeddings,"['Cognitive Science', 'Latent Variable Models', 'Variational Inference', 'Concept Representations']","[6, 5, 5, 6]","[1, 3, 3, 3]",0,"[323, 500, 251, 296]",Accept
vRwCvlvd8eA,Chefs' Random Tables: Non-Trigonometric Random Features,"['random features', 'gaussian kernel', 'attention', 'Transformers']","[5, 6, 7, 6]","[3, 2, 3, 3]",0,"[457, 495, 1431, 331]",Accept
WSxarC8t-T,SketchBoost: Fast Gradient Boosted Decision Tree for Multioutput Problems,"['gradient boosting', 'decision trees', 'multiple outputs', 'multiclass classification', 'multilabel classification', 'multioutput regression']","[5, 7, 7]","[3, 4, 3]",0,"[451, 300, 505]",Accept
wOI0AUAq9BR,SizeShiftReg: a Regularization Method for Improving Size-Generalization in Graph Neural Networks,"['Graph Neural Networks', 'Graph Representation Learning', 'Deep Learning', 'Graph Classification']","[5, 5, 7]","[3, 4, 4]",0,"[181, 331, 651]",Accept
GkDbQb6qu_r,CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers,"['text-to-image generation', 'pretraining', 'transformer']","[3, 6, 8, 6]","[5, 3, 3, 4]",0,"[243, 361, 945, 524]",Accept
nxw9_ny7_H,Deep invariant networks with differentiable augmentation layers,"['invariance learning', 'data augmentation', 'automatic data augmentation']","[5, 4, 5, 4]","[4, 4, 4, 4]",0,"[300, 336, 518, 902]",Accept
7HTEHRMlxYH,FNeVR: Neural Volume Rendering for Face Animation,"['face animation', 'neural volume rendering', 'lightweight pose editor', 'image synthesis']","[5, 5, 6]","[3, 5, 4]",0,"[225, 713, 296]",Accept
UPnJuDKqOfX,HF-NeuS: Improved Surface Reconstruction Using High-Frequency Details,"['NeRF-based surface reconstruction', 'Multi-view surface reconstruction', 'High-frequency details', 'Signed distance fields']","[6, 6, 6, 5, 7]","[4, 4, 4, 4, 5]",0,"[310, 1582, 443, 617, 404]",Accept
jzd2bE5MxW,TCT: Convexifying Federated Learning using Bootstrapped Neural Tangent Kernels,"['Federated learning', 'Optimization', 'Decentralized learning', 'Distributed optimization']","[6, 6, 6]","[4, 4, 4]",0,"[416, 844, 858]",Accept
OxfI-3i5M8g,Scalable Neural Video Representations with Learnable Positional Features,['coordinate-based neural representations'],"[6, 6, 5]","[4, 3, 4]",0,"[485, 498, 257]",Accept
UPZCt9perOn,Metric-Projected Accelerated Riemannian Optimization: Handling Constraints to Bound Geometric Penalties,"['riemannian optimization', 'acceleration', 'constrained', 'proximal methods']","[5, 5, 6]","[3, 3, 4]",0,"[479, 172, 225]",Reject
bi1BTcXa8Q,Cross-modal Learning for Image-Guided Point Cloud Shape Completion,"['Point Cloud Completion', 'View-guided completion', 'Self-supervised completion', 'Multimodal Learning']","[5, 5, 5, 5]","[4, 2, 5, 4]",0,"[235, 299, 197, 407]",Accept
dp0zWsdOV1h,"Retrieve, Reason, and Refine: Generating Accurate and Faithful Patient Instructions","['Natural Language Generation', 'Medical Text Generation', 'MIMIC-III', 'Patient Instruction', 'Discharge']","[5, 7, 7]","[4, 5, 4]",0,"[221, 589, 494]",Accept
Z9ldMhplBrT,Rethinking the compositionality of point clouds through regularization in the hyperbolic space,"['Hyperbolic space', 'Point cloud classification']","[7, 4, 7, 5, 5]","[4, 3, 3, 4, 4]",0,"[299, 654, 485, 485, 823]",Accept
ZuSiW0EixjX,Redistribution of Weights and Activations for AdderNet Quantization,"['AdderNet', 'Quantization']","[6, 4, 6, 8]","[4, 4, 4, 5]",0,"[463, 417, 311, 393]",Accept
wjClgX-muzB,Rethinking Variational Inference for Probabilistic Programs with Stochastic Support,"['Probabilistic Programming', 'Variational Inference', 'Stochastic Support']","[7, 7, 7, 8]","[3, 3, 3, 5]",0,"[1342, 249, 462, 287]",Accept
rwdpFgfVpvN,Online Convex Optimization with Hard Constraints: Towards the Best of Two Worlds and Beyond,"['online convex optimization', 'hard constraints', 'cumulative absolute violation', 'best of two worlds and beyond']","[6, 7, 6, 6]","[3, 2, 3, 5]",0,"[499, 184, 334, 526]",Accept
sRKNkpUMQNr,Information-Theoretic GAN Compression with Variational Energy-based Model,"['GAN Compression', 'Knowledge Distillation', 'Mutual Information']","[7, 7, 4]","[2, 4, 5]",0,"[869, 450, 285]",Accept
7vmyjUHgm9_,Less-forgetting Multi-lingual Fine-tuning,"['Multi-lingual Language  Models', 'Multi-lingual Fine-tuning', 'Less-forgetting']","[6, 6, 5]","[4, 3, 3]",0,"[295, 529, 412]",Accept
c3HrNgQE7d,Exploring Figure-Ground Assignment Mechanism in Perceptual Organization,"['Figure-Ground Assignment', 'Figure-Ground Segregation', 'Cognitive Inspiration']","[5, 5, 4, 6]","[4, 4, 5, 4]",0,"[267, 309, 640, 700]",Accept
8li9SYYY3eQ,Language Conditioned Spatial Relation Reasoning for 3D Object Grounding,[],"[7, 6, 6, 6]","[3, 4, 3, 2]",0,"[411, 280, 850, 518]",Accept
dz79MhQXWvg,Weakly supervised causal representation learning,"['causal representation learning', 'causality', 'disentangled representation learning', 'causal discovery']","[7, 4, 4, 7]","[4, 3, 4, 4]",0,"[1862, 351, 1044, 338]",Accept
tro0_OqIVde,HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions,"['Model Architectures', 'Dynamic Neural Networks', 'Vision Transformers', 'Convolutional Neural Networks']","[5, 5, 8]","[4, 5, 5]",0,"[178, 228, 370]",Accept
I-ggHgon-Az,What You See is What You Classify: Black Box Attributions,"['Computer Vision', 'Explainable Machine Learning', 'Saliency Maps', 'Attribution']","[8, 5, 7]","[4, 3, 4]",0,"[513, 507, 467]",Accept
p9_Z4m2Vyvr,Amortized Mixing Coupling Processes for Clustering,"['generative model', 'amortized clustering']","[6, 6, 6]","[4, 4, 4]",0,"[290, 448, 230]",Accept
INzRLBAA4JX,Revisiting Sparse Convolutional Model for Visual Recognition,"['Sparse Dictionary Learning', 'inverse models', 'image classification']","[7, 6, 4]","[3, 4, 4]",0,"[426, 641, 296]",Accept
vt516zga8m,Cache-Augmented Inbatch Importance Resampling for Training Recommender Retriever,"['Importance ReSampling', 'Negative Sampling', 'Recommender Systems', 'Retrieval']","[8, 6, 6, 7]","[5, 5, 3, 5]",0,"[527, 265, 432, 432]",Accept
SZDqCOv6vTB,Deep Attentive Belief Propagation: Integrating Reasoning and Learning for Solving Constraint Optimization Problems,"['Constraint Optimization Problems', 'Belief Propagation', 'Damping', 'Attention Mechanism']","[6, 6, 4, 6]","[4, 4, 4, 3]",0,"[311, 394, 633, 383]",Accept
FgDzS8_Fz7c,Category-Level 6D Object Pose Estimation in the Wild: A Semi-Supervised Learning Approach and A New Dataset,[],"[2, 7, 4, 6]","[5, 4, 3, 5]",0,"[341, 417, 830, 404]",Accept
IfFZr1gl0b,Uni-Mol: A Universal 3D Molecular Representation Learning Framework,"['Representation Learning', 'Large-Scale 3D Molecular Pretraining', 'Molecular Property', 'Protein-Ligand Complex']","[6, 4, 6, 4]","[4, 4, 5, 4]",0,"[559, 388, 288, 528]",Reject
k6WzeLZjxuP,Factored DRO: Factored Distributionally Robust Policies for Contextual Bandits,"['Contextual Bandits', 'Distributionally Robust Optimization', 'Distribution Shifts']","[6, 5, 6, 6, 6]","[3, 3, 3, 3, 3]",0,"[426, 139, 183, 384, 582]",Accept
25XIE30VHZE,SecureFedYJ: a safe feature Gaussianization protocol for Federated Learning,[],"[6, 4, 5, 6]","[2, 4, 3, 4]",0,"[252, 430, 409, 363]",Accept
Fytzfxj3Bq7,Fixed-Distance Hamiltonian Monte Carlo,"['Markov Chain Monte Carlo', 'Sampling', 'Hamiltonian Monte Carlo', 'Reversible Jump', 'RJMCMC', 'No-U-Turn sampler']","[6, 6, 6]","[4, 4, 4]",0,"[204, 629, 562]",Accept
BbUxkmrstyk,An Investigation into Whitening Loss for Self-supervised Learning,"['whitening', 'self-supervised learning', 'normalization', 'feature decorrelation']","[5, 7, 7]","[4, 4, 3]",0,"[509, 246, 401]",Accept
q16HXpXtjJn,Beyond the Best:  Distribution Functional Estimation in Infinite-Armed Bandits,"['Multi-armed bandits', 'information-theoretic lower bounds', 'algorithm design', 'functional estimation']","[6, 5, 7, 5]","[3, 3, 3, 4]",0,"[326, 314, 449, 450]",Accept
4-bV1bi74M, ProcTHOR: Large-Scale Embodied AI Using Procedural Generation,"['Embodied AI', 'Large-Scale Environments', 'Procedural Generation']","[4, 8, 9]","[4, 4, 4]",0,"[550, 757, 1245]",Accept
2GsQ8dyfe45,M$^4$I: Multi-modal Models Membership Inference,"['Membership inference attack', 'Data privacy leakage', 'Multimodality']","[6, 4, 9]","[3, 4, 4]",0,"[267, 362, 411]",Accept
qtQ9thon9fV,FOF: Learning Fourier Occupancy Field for Monocular Real-time Human Reconstruction,"['Monocular human reconstruction', 'Representation', 'Real-time', 'Single image']","[5, 5, 7]","[5, 4, 4]",0,"[373, 524, 325]",Accept
pfEIGgDstz0,Non-rigid Point Cloud Registration with Neural Deformation Pyramid,"['Non-rigid registration', 'neural deformation field', 'motion decomposition', 'partial-to-partial point cloud registration', '3D computer vision']","[7, 4, 4, 7]","[4, 4, 3, 4]",0,"[267, 224, 442, 416]",Accept
YgK1wNnoCWy,Green Hierarchical Vision Transformer for Masked Image Modeling,"['Self-Supervised Learning', 'Masked Image Modeling', 'Vision Transformers']","[5, 5, 7]","[5, 4, 5]",0,"[260, 350, 453]",Accept
L8ESR8IQ7Gb,Hub-Pathway: Transfer Learning from A Hub of Pre-trained Models,"['Transfer Learning', 'Deep Learning', 'Pre-trained Model Hub']","[6, 5, 6, 7]","[3, 4, 3, 5]",0,"[321, 351, 440, 723]",Accept
rcrY85WLAKU,Cost-efficient Gaussian tensor network embeddings for tensor-structured inputs,"['tensor networks', 'randomized numerical linear algebra', 'non-convex optimization', 'tensor decomposition', 'tensor train']","[6, 5, 6]","[2, 2, 4]",0,"[308, 256, 549]",Accept
jPx7vYUNUCt,Biologically-plausible backpropagation through arbitrary timespans via local neuromodulators,"['Computational neuroscience', 'learning and plasticity', 'biologically plausible learning', 'neuromodulation', 'cell types', 'neural circuit mechanisms', 'temporal credit assignment', 'recurrent neural networks', 'Hebbian learning']","[7, 7, 7, 5]","[3, 3, 2, 4]",0,"[373, 554, 555, 287]",Accept
OlGu-BXgJ-,Wasserstein $K$-means for clustering probability distributions,"['Barycenter', 'K-means clustering', 'Optimal transport', 'Semi-definite programming', 'Wasserstein distance']","[4, 6, 7, 5]","[2, 3, 4, 3]",0,"[260, 393, 249, 268]",Accept
_4xg5moXVg,Beyond accuracy: generalization properties of bio-plausible temporal credit assignment rules,"['Neuroscience', 'computational neuroscience', 'biologically plausible learning rules', 'learning and plasticity', 'temporal credit assignment', 'generalization', 'recurrent neural networks']","[5, 6, 7, 8]","[3, 3, 5, 4]",0,"[183, 448, 770, 619]",Accept
oDWyVsHBzNT,Model-Based Offline Reinforcement Learning with Pessimism-Modulated Dynamics Belief,"['Offline reinforcement learning', 'model-based reinforcement learning', 'Bayesian learning']","[7, 8, 7, 8]","[4, 5, 3, 4]",0,"[266, 444, 522, 419]",Accept
mNtFhoNRr4i,Hierarchical classification at multiple operating points,"['hierarchical classification', 'image classification', 'class hierarchy', 'inaturalist', 'imagenet', 'deep learning']","[6, 6, 6]","[3, 3, 3]",0,"[336, 608, 540]",Accept
YR-s5leIvh,CLEAR: Generative Counterfactual Explanations on Graphs,"['Counterfactual explanations', 'graph', 'explainability']","[5, 6, 6]","[3, 5, 5]",0,"[492, 528, 882]",Accept
MHjxpvMzf2x,Symmetry Teleportation for Accelerated Optimization,"['optimization', 'parameter space symmetry', 'teleportation']","[7, 6, 6, 6, 6]","[3, 4, 4, 3, 2]",0,"[386, 320, 730, 325, 138]",Accept
y8FN4dHdxOE,Fused Orthogonal Alternating Least Squares for Tensor Clustering,"['High-order tensors', 'Clustering', 'Tensor decomposition']","[7, 7, 6]","[4, 4, 2]",0,"[232, 1029, 239]",Accept
GjWDguPZRmr,Improving Variational Autoencoders with Density Gap-based Regularization,"['Variational Autoencoders', 'Posterior Collapse', 'Hole Problem']","[6, 8, 5]","[4, 4, 4]",0,"[376, 323, 715]",Accept
DSEP9rCvZln,Inherently Explainable Reinforcement Learning in Natural Language,"['knowledge graph', 'reinforcement learning', 'explainable AI', 'natural language processing']","[4, 7, 4]","[3, 4, 3]",0,"[244, 898, 343]",Accept
hciwLGxCt6S,It's DONE: Direct ONE-shot learning with Hebbian weight imprinting,"['One-shot learning', 'Few-shot learning', 'Weight imprinting', 'Hebbian theory', 'ImageNet models', 'New class addition']","[6, 5, 5]","[4, 4, 3]",0,"[716, 804, 342]",Reject
ZidkM5b92G,BagFlip: A Certified Defense Against Data Poisoning,"['data poisoning', 'certified defense', 'backdoor attack', 'trigger-less attack']","[6, 6, 5]","[3, 4, 2]",0,"[469, 198, 213]",Accept
JvIFpZOjLF4,Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction,"['3d reconstruction', 'neural implicit surfaces learning', 'multi-view geometry consistency']","[5, 5, 5, 6]","[3, 5, 4, 4]",0,"[304, 377, 422, 743]",Accept
JSBgIaxAXk9,Differentially Private Linear Regression via Medians,"['differential privacy', 'linear regression', 'robust statistics']","[4, 5, 5]","[4, 3, 3]",0,"[321, 466, 412]",Reject
P6uZ7agiyCT,Sparse2Dense: Learning to Densify 3D Features to Boost 3D Object Detection,"['3D Object Detection', 'Sparse2Dense']","[6, 6, 7, 5]","[4, 5, 3, 5]",0,"[183, 425, 518, 252]",Accept
ByYFpTwgLGO,Deep Multi-Modal Structural Equations For Causal Effect Estimation With Unstructured Proxies,[],"[5, 7, 5]","[4, 4, 3]",0,"[334, 248, 449]",Accept
E9HNxrCFZPV,NOTE: Robust Continual Test-time Adaptation Against Temporal Correlation,"['test-time adaptation', 'domain adaptation', 'deep learning', 'machine learning']","[7, 6, 5, 6]","[3, 5, 4, 4]",0,"[202, 1378, 247, 370]",Accept
tZUOiVGO6jN,A Deep Learning Dataloader with Shared Data Preparation,"['Deep learning infrastructure', 'Deep learning Dataloader', 'Sampling algorithm in Dataloader']","[5, 8, 5]","[5, 5, 3]",0,"[233, 340, 263]",Accept
gE_vt-w4LhL,Squeezeformer: An Efficient Transformer for Automatic Speech Recognition,"['ASR', 'speech recognition', 'efficient model', 'Transformers']","[6, 6, 8]","[5, 5, 5]",0,"[274, 356, 726]",Accept
fpfDusqKZF,Neural Basis Models for Interpretability,"['interpretability', 'explainability', 'trustworthy AI', 'interpretable machine learning', 'generalized additive models']","[7, 5, 5, 5]","[3, 5, 3, 3]",0,"[205, 561, 239, 355]",Accept
TwuColwZAVj,Scalable Interpretability via Polynomials,"['interpretability', 'explainability', 'trustworthy AI', 'polynomials', 'generalized additive models', 'interpretable machine learning']","[7, 7, 6]","[4, 3, 4]",0,"[276, 374, 347]",Accept
kHeotl7q9dU,NS3: Neuro-symbolic Semantic Code Search,"['deep learning', 'ml4code', 'semantic code search']","[5, 5, 5, 7]","[3, 4, 4, 4]",0,"[194, 568, 526, 558]",Accept
Ijq1_a6DESm,On the consistent estimation of optimal Receiver Operating Characteristic (ROC) curve,"['Classification', 'optimal Receiver Operating Characteristic (ROC) curve', 'Consistency', 'Model misspecification']","[7, 7, 6, 6]","[3, 2, 3, 4]",0,"[835, 281, 817, 307]",Accept
-o0kPsyzErW,Parallel Tempering With a Variational Reference,"['Bayesian inference', 'parallel tempering', 'variational inference', 'Markov chain Monte Carlo']","[7, 4, 5]","[3, 5, 2]",0,"[399, 331, 443]",Accept
pqCT3L-BU9T,Periodic Graph Transformers for Crystal Material Property Prediction,"['Periodic Invariance', 'periodic pattern encoding', 'material transformers', 'crystal property prediction', 'material discovery']","[6, 6, 5, 7]","[4, 3, 4, 3]",0,"[242, 273, 529, 534]",Accept
2EBn01PJh17,Adaptive Cholesky Gaussian Processes,[],"[3, 4, 6]","[4, 3, 3]",0,"[843, 400, 634]",Reject
xijYyYFlRIf,GAUDI: A Neural Architect for Immersive 3D Scene Generation,"['generative modeling', '3D', 'radiance fields']","[5, 5, 6, 6]","[4, 3, 3, 3]",0,"[483, 330, 400, 675]",Accept
dRgHxaOJsiV,3DB: A Framework for Debugging Computer Vision Models,"['robustness', 'debugging', 'simulation', 'computer vision', 'deep learning']","[4, 6, 5, 6]","[4, 4, 3, 4]",0,"[466, 383, 328, 788]",Accept
Xg-yZos9qJQ,Exploration via Elliptical Episodic Bonuses,"['reinforcement learning', 'exploration', 'generalization', 'contextual MDP']","[4, 7, 8]","[4, 3, 3]",0,"[788, 516, 624]",Accept
h4kN_apci_R,Probabilistic Missing Value Imputation for Mixed Categorical and Ordered Data,"['Categorical data', 'missing value imputation', 'mixed data']","[7, 5, 5]","[3, 2, 4]",0,"[205, 260, 415]",Accept
_L7f0ySKMWY,Near-Optimal Multi-Agent Learning for Safe Coverage Control,"['Multi-agent learning', 'Submodular optimization', 'Safety', 'Bayesian optimization', 'Coverage control']","[5, 6, 6, 5]","[1, 3, 4, 5]",0,"[376, 974, 620, 322]",Accept
AhbTKBlM7X,Learning State-Aware Visual Representations from Audible Interactions,"['Video Representation learning', 'self-supervised learning', 'contrastive learning', 'audio-visual learning', 'egocentric videos', 'Ego4D', 'EPIC-Kitchens']","[6, 4, 6]","[3, 4, 4]",0,"[558, 861, 241]",Accept
agNTJU1QNw,Geometric Order Learning for Rank Estimation,"['rank estimation', 'order learning', 'metric learning']","[7, 6, 6]","[4, 4, 3]",0,"[290, 237, 459]",Accept
pBpwRkEIjR3,Enhanced Bilevel Optimization via Bregman Distance,[],"[7, 7, 6]","[4, 4, 3]",0,"[279, 242, 402]",Accept
Vg_02McCRnY,Optimal Comparator Adaptive Online Learning with Switching Cost,"['parameter-free online learning', 'adaptive online learning', 'switching cost']","[6, 6, 6, 5, 7]","[1, 4, 3, 4, 1]",0,"[220, 438, 297, 295, 648]",Accept
3uj_8G7fxgs,Multi-objective Deep Data Generation with Correlated Property Control,"['deep generative models', 'controllable generation', 'correlated properties', 'disentangled learning', 'variational autoencoders']","[8, 6, 5]","[5, 4, 2]",0,"[495, 691, 433]",Accept
lgNGDjWRTo-,Deep Generative Model for Periodic Graphs,"['periodic graph', 'deep generative model', 'disentangled learning', 'variational autoencoder']","[6, 8, 5, 5]","[3, 5, 3, 4]",0,"[207, 408, 278, 1017]",Accept
fp33Nsh0O5,Deep Generalized Schrdinger Bridge,"['Mean-Field Game', 'Schrdinger Bridge', 'Deep Reinforcement Learning', 'Forward-Backward Stochastic Differential Equations']","[7, 6, 6, 6]","[3, 3, 4, 4]",0,"[963, 510, 261, 1214]",Accept
espX_4CLr46,Biologically-Plausible Determinant Maximization Neural Networks for Blind Separation of Correlated Sources,"['Biologically Plausible Neural Networks', 'Blind Source Separation', 'Weighted Similarity Matching', 'Determinant Maximization']","[6, 7, 8, 6]","[3, 3, 5, 1]",0,"[338, 413, 397, 372]",Accept
QNjyrDBx6tz,Practical Adversarial Multivalid Conformal Prediction,[],"[7, 7, 7]","[3, 4, 3]",0,"[453, 1497, 535]",Accept
KxVSnZVuZZ,Constrained Langevin Algorithms with L-mixing External Random Variables,"['Langevin algorithms', 'L-mixing processes', 'Gradient descent methods', 'Non-convex optimization', 'Non-asymptotic analysis', 'Markov Chain Monte Carlo sampling']","[5, 4, 4, 6]","[3, 4, 4, 4]",0,"[210, 276, 800, 392]",Accept
Jupoos_K4xt,Equivariant Networks for Zero-Shot Coordination,[],"[4, 4, 8]","[4, 3, 4]",0,"[386, 556, 1034]",Accept
ylila4AYSpV,Simple Mechanisms for Welfare Maximization in Rich Advertising Auctions,"['mechanism design', 'auctions', 'social welfare', 'price of anarchy', 'knapsack']","[4, 7, 8, 6]","[2, 5, 4, 1]",0,"[480, 437, 139, 208]",Accept
Yb3dRKY170h,One-shot Neural Backdoor Erasing via Adversarial Weight Masking,"['Backdoor Defense', 'Adverarial Machine Learning', 'One-shot Learning']","[6, 5, 5]","[4, 4, 4]",0,"[404, 133, 407]",Accept
sr0289wAUa,ASPiRe: Adaptive Skill Priors for  Reinforcement Learning,"['Reinforcement Learning', 'Skill Learning', 'Composing Skill']","[5, 6, 6, 5]","[4, 3, 4, 4]",0,"[291, 418, 535, 567]",Accept
o4neHaKMlse,Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone ,"['vision-language pre-training', 'VQA', 'image captioning', 'object detection']","[6, 7, 5]","[4, 4, 5]",0,"[207, 265, 469]",Accept
AcHUIG2wA8-,Non-Gaussian Tensor Programs,"['deep learning theory', 'infinitely wide networks', 'tensor programs']","[6, 6, 5, 6]","[2, 2, 1, 3]",0,"[331, 243, 205, 332]",Accept
_bqtjfpj8h,Ask4Help: Learning to Leverage an Expert for Embodied Tasks,"['Expert-Agent Interaction', 'Embodied AI', 'Expert-in-the-loop']","[4, 6, 8, 4, 4]","[4, 4, 4, 4, 4]",0,"[394, 654, 460, 736, 714]",Accept
WV1ZXTH0OIn,Bayesian Optimization over Discrete and Mixed Spaces via Probabilistic Reparameterization,['Bayesian Optimization'],"[7, 5, 5, 9]","[4, 3, 5, 4]",0,"[315, 403, 473, 364]",Accept
9a1oV7UunyP,When to Update Your Model: Constrained Model-based Reinforcement Learning,"['Model-Based Reinforcement Learning', 'monotonic improvements', 'event-triggered mechanism']","[6, 5, 6, 5]","[5, 4, 4, 5]",0,"[447, 440, 1132, 428]",Accept
J0nhRuMkdGf,"Distributed Methods with Compressed Communication for Solving Variational Inequalities, with Theoretical Guarantees","['convex optimization', 'compression', 'variational inequalities', 'saddle point problems']","[4, 6, 6, 7, 8]","[1, 3, 3, 3, 3]",0,"[360, 704, 348, 381, 102]",Accept
yfNSUQ3yRo,Noise Attention Learning: Enhancing Noise Robustness by Gradient Scaling,"['Machine Learning', 'Label Noise', 'Robustness']","[6, 4, 6]","[5, 4, 4]",0,"[253, 216, 338]",Accept
G1uywu6vNZe,Exponential Family Model-Based Reinforcement Learning via Score Matching,"['online reinforcement learning', 'exponential family', 'model-based RL']","[7, 6, 7]","[3, 3, 4]",0,"[212, 519, 256]",Accept
fhO6vCGuuag,On the inability of Gaussian process regression to optimally learn compositional functions,"['Gaussian processes', 'Bayesian nonparametrics', 'posterior contraction', 'minimax estimation', 'large-sample asymptotics']","[7, 7, 7]","[5, 4, 3]",0,"[294, 534, 644]",Accept
jHIn0U9U6RO,Understanding the Eluder Dimension,"['reinforcement learning', 'eluder dimension']","[7, 7, 5]","[3, 3, 3]",0,"[357, 274, 399]",Accept
jcIIVkbCaHO,Pessimism for Offline Linear Contextual Bandits using $\ell_p$ Confidence Sets,"['offline reinforcement learning', 'pessimism', 'linear contextual bandits']","[8, 6, 7, 6]","[2, 4, 2, 3]",0,"[308, 314, 222, 427]",Accept
sc7bBHAmcN,Understanding and Extending Subgraph GNNs by Rethinking Their Symmetries,"['Graph Neural Networks', 'Subgraphs', 'Expressive power', 'Equivariance', 'Weisfeiler-Leman']","[7, 7, 7, 7]","[2, 4, 4, 4]",0,"[207, 121, 201, 576]",Accept
e3qH65r_eZS,Semi-supervised Semantic Segmentation with Prototype-based Consistency Regularization,"['semi-supervised semantic segmentation', 'prototype-based learning']","[6, 5, 5, 7]","[5, 4, 5, 4]",0,"[302, 152, 164, 597]",Accept
5L-wxm0YLcZ,CoupAlign: Coupling Word-Pixel with Sentence-Mask Alignments for Referring Image Segmentation,"['Referring Image Segmentation', 'Vision Language Modeling', 'Cross-model Alignment']","[6, 5, 5, 6]","[3, 4, 4, 5]",0,"[312, 276, 527, 445]",Accept
noyKGZYvHH,coVariance Neural Networks,"['Graph Convolutional Networks', 'Covariance', 'Principal Component Analysis', 'Stability', 'Transferability']","[7, 7, 3]","[4, 3, 4]",0,"[280, 271, 443]",Accept
kB9jrZDenff,Unsupervised Cross-Task Generalization via Retrieval Augmentation,[],"[6, 6, 6]","[4, 4, 3]",0,"[343, 523, 509]",Accept
WESmKHEH5nJ,Fast Stochastic Composite Minimization and an Accelerated Frank-Wolfe Algorithm under Parallelization,"['Frank-Wolfe', 'Conditional Gradient', 'Acceleration', 'Randomized Smoothing', 'Convex Optimization']","[3, 7, 7]","[4, 3, 3]",0,"[209, 580, 242]",Accept
CTqjKUAyRBt,Sampling without Replacement Leads to Faster Rates in Finite-Sum Minimax Optimization,"['Minimax Optimization', 'Smooth Games', 'Nonconvex-Nonconcave Minimax Optimization', 'Sampling without Replacement', 'Random Reshuffling', 'Shuffle Once', 'Incremental Gradient', 'Gradient Descent Ascent', 'Proximal Point Method', 'Alternating Gradient Descent Ascent']","[7, 4, 6, 6]","[3, 3, 3, 3]",0,"[986, 149, 316, 518]",Accept
AQgmyyEWg8,Beyond spectral gap: the role of the topology in decentralized learning,"['decentralized optimization', 'distributed training', 'convex optimization', 'stochastic optimization', 'learning rate', 'spectral gap']","[6, 6, 7]","[4, 5, 4]",0,"[419, 341, 654]",Accept
F02H1zNl213,Are GANs overkill for NLP?,"['generative modeling', 'maximum likelihood estimation', 'polynomial reduction', 'GAN', 'language model']","[4, 3, 7, 6]","[2, 3, 3, 3]",0,"[317, 947, 273, 763]",Accept
xONqm0NUJc,Relational Proxies: Emergent Relationships as Fine-Grained Discriminators,"['Fine-grained visual categorization', 'Relational learning', 'Information theory']","[5, 5, 7, 7, 6]","[3, 4, 3, 3, 3]",0,"[136, 239, 554, 243, 360]",Accept
vMQ1V_z0TxU,Out-of-Distribution Detection with An Adaptive Likelihood Ratio on Informative Hierarchical VAE,"['Unsupervised Out-of-Distribution Detection', 'Hierarchical VAE']","[7, 6, 7, 7]","[3, 5, 3, 4]",0,"[1017, 317, 545, 506]",Accept
o762mMj4XK,Towards Reliable Simulation-Based Inference with Balanced Neural Ratio Estimation,"['simulation-based inference', 'likelihood-free inference', 'approximate Bayesian inference', 'neural ratio estimation']","[6, 6, 6, 6]","[4, 4, 4, 5]",0,"[408, 453, 1320, 776]",Accept
d229wqASHOT,Adv-Attribute: Inconspicuous and Transferable Adversarial Attack on Face Recognition,"['adversarial attack', 'face recognition']","[4, 5, 7, 7]","[4, 4, 4, 4]",0,"[351, 367, 306, 240]",Accept
nX-gReQ0OT,Gold-standard solutions to the Schrdinger equation using deep learning: How much physics do we need?,"['Computational Physics', 'Machine Learning for Science', 'Quantum Monte Carlo', 'Fermionic Neural Networks']","[7, 7, 7, 7]","[4, 2, 4, 3]",0,"[134, 257, 518, 320]",Accept
7hhH95QKKDX,Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box Score-Based Query Attacks,"['adversarial defense', 'black-box attack', 'model calibration', 'score-based query attack']","[7, 7, 7, 4]","[3, 4, 4, 5]",0,"[358, 625, 803, 468]",Accept
yW5zeRSFdZ,Outlier Suppression: Pushing the Limit of Low-bit Transformer Language Models,[],"[7, 7, 7]","[4, 3, 4]",0,"[399, 243, 312]",Accept
aAs8KTbZvc9,Fine-Grained Analysis of Stability and Generalization for Modern Meta Learning Algorithms,"['meta learning', 'episodic training strategy', 'algorithmic stability', 'generalization bounds', 'support/query set']","[6, 7, 6, 7]","[4, 4, 4, 2]",0,"[172, 397, 1131, 625]",Accept
xaWO6bAY0xM,Rethinking Lipschitz Neural Networks and Certified Robustness: A Boolean Function Perspective,"['Adversarial Robustness', 'Certified Defense', 'Lipschitz Neural Network', 'Expressive Power']","[5, 8, 8, 8]","[3, 4, 4, 4]",0,"[533, 944, 927, 420]",Accept
mMdRZipvld2,Deconfounded Representation Similarity for Comparison of Neural Networks,"['deep neural networks', 'representation similarity', 'CKA', 'RSA', 'functional similarity', 'covariate adjustment regression']","[7, 7, 6]","[4, 4, 3]",0,"[265, 416, 562]",Accept
kCU2pUrmMih,"Mirror Descent with Relative Smoothness in Measure Spaces, with application to Sinkhorn and EM","['optimization', 'mirror descent', 'measure spaces', ""sinkhorn's algorithm"", 'expectation-maximization']","[6, 9, 6, 6]","[3, 4, 4, 2]",0,"[281, 323, 429, 419]",Accept
CmD5z_2DVuM,Learning Energy Networks with Generalized Fenchel-Young Losses,"['energy networks', 'EBMs', 'structured prediction', 'convex analysis', 'Fenchel conjugates']","[6, 5, 7]","[3, 4, 3]",0,"[312, 395, 181]",Accept
wcBXsXIf-n9,Reaching Nirvana: Maximizing the Margin in Both Euclidean and Angular Spaces for Deep Neural Network Classification,"['open set recognition', 'deep neural network classifier', 'margin maximization']","[5, 5, 6, 4]","[3, 3, 4, 4]",0,"[343, 421, 487, 1231]",Reject
bBgNsEKUxmJ,Universally Expressive Communication in Multi-Agent Reinforcement Learning,"['multi-agent reinforcement learning', 'communication', 'expressivity', 'graph neural networks']","[6, 6, 6, 6]","[4, 3, 4, 4]",0,"[558, 799, 499, 378]",Accept
Q-HOv_zn6G,Efficient and Modular Implicit Differentiation,"['implicit differentiation', 'bilevel optimization', 'autodiff', 'jax']","[6, 9, 6]","[5, 3, 4]",0,"[942, 469, 348]",Accept
Z4kZxAjg8Y,Autoregressive Search Engines: Generating Substrings as Document Identifiers,"['Natural Language Processing', 'Information Retrieval', 'Question Answering']","[7, 6, 8, 6]","[5, 5, 4, 4]",0,"[397, 651, 267, 595]",Accept
7-bMGPCQCm7,Heatmap Distribution Matching for Human Pose Estimation,"['Deep learning', 'Human Pose Estimation', 'Distribution Matching']","[6, 5, 6, 7]","[5, 5, 3, 5]",0,"[413, 337, 239, 223]",Accept
q-FRENiEP_d,SageMix: Saliency-Guided Mixup for Point Clouds,"['point cloud', 'mixup', 'saliency']","[5, 4, 7]","[4, 4, 3]",0,"[267, 218, 280]",Accept
yQDC5ZcqX6l,Efficient and Effective Optimal Transport-Based Biclustering,"['biclustering', 'optimal transport']","[4, 6, 7]","[3, 4, 3]",0,"[1542, 513, 648]",Accept
B_LdLljS842,Spending Thinking Time Wisely: Accelerating MCTS with Virtual Expansions,"['Computer Go', 'Monte-Carlo Tree Search', 'Reinforcement learning', 'Adaptive', 'Acceleration']","[3, 5, 7, 5]","[4, 3, 5, 4]",0,"[207, 1263, 421, 441]",Accept
4MT-e8mn3X,Local Linear Convergence of Gradient Methods for  Subspace Optimization via Strict Complementarity,"['subspace recovery', 'principal component analysis', 'convex optimization', 'Frank-Wolfe', 'low-rank', 'robust PCA', 'nonconvex optimization', 'strict complementarity', 'first-order methods']","[4, 6, 5, 6]","[4, 4, 4, 5]",0,"[1001, 583, 346, 233]",Accept
mSiPuHIP7t8,GraphDE: A Generative Framework for Debiased Learning and Out-of-Distribution Detection on Graphs,"['Graph Data', 'Debiased Learning', 'OOD Detection.']","[7, 6, 3, 4, 6]","[3, 3, 4, 4, 3]",0,"[314, 498, 539, 661, 452]",Accept
AREqvTvv6gG,Frank-Wolfe-based Algorithms for Approximating Tyler's M-estimator,"['Frank-Wolfe', 'conditional gradient', 'projection-free', ""Tyler's M-estimator"", 'robust covariance estimation', 'heavy tailed distributions', 'elliptical distributions', 'convex optimization', 'nonconvex optimization']","[5, 7, 6, 4]","[3, 5, 4, 3]",0,"[300, 439, 538, 572]",Accept
9Qjn_3gWLDc,Object-Category Aware Reinforcement Learning,"['reinforcement learning', 'object', 'unsupervised object discovery']","[6, 7, 7, 4, 5]","[4, 3, 4, 5, 3]",0,"[360, 267, 1291, 604, 189]",Accept
LdAxczs3m0,Efficient Risk-Averse Reinforcement Learning,"['Reinforcement Learning', 'safe RL', 'risk averse RL', 'risk sensitive RL', 'sample efficient RL', 'coherent risk measures', 'CVaR', 'blindness to success', 'cross entropy method', 'CEM']","[6, 6, 6, 6]","[4, 5, 4, 2]",0,"[711, 519, 376, 328]",Accept
qtZac7A3-F,Enhance the Visual Representation via Discrete Adversarial Training,"['Adversarial Training', 'Discrete Visual Representation', 'Robustness', 'Generalization']","[7, 6, 5, 6]","[4, 3, 4, 5]",0,"[371, 129, 410, 731]",Accept
8AB7AXaLIX5,Concept Activation Regions: A Generalized Framework For Concept-Based Explanations,"['explainability', 'interpretability', 'latent', 'representation', 'concept', 'explanation']","[7, 7, 7]","[3, 4, 4]",0,"[299, 338, 324]",Accept
pUPFRSxfACD,ZIN: When and How to Learn Invariance Without Environment Partition?,"['Invariant Risk Minimization', 'Out-of-Domain Generalization', 'Transfer Learning']","[6, 7, 8, 8]","[4, 4, 3, 4]",0,"[585, 198, 641, 415]",Accept
NXHXoYMLIG,EfficientFormer: Vision Transformers at MobileNet Speed,['Vision Transformer'],"[6, 5, 6]","[4, 5, 3]",0,"[479, 143, 469]",Accept
MIhgxhsJMtY,A Near-Optimal Primal-Dual Method for Off-Policy Learning in CMDP,"['reinforcement learning theory', 'offline reinforcement learning', 'statistical optimality', 'safe reinforcement learning', 'primal-dual']","[6, 6, 6, 6]","[2, 3, 4, 3]",0,"[269, 214, 276, 315]",Accept
4qR780g2Mg,Distributional Reward Estimation for Effective Multi-agent Deep Reinforcement Learning,"['Multi-Agent Reinforcement Learning', 'Reward Uncertainty']","[6, 5, 6, 7, 5]","[3, 2, 3, 4, 2]",0,"[485, 308, 181, 619, 150]",Accept
9-SZkJLkCcB,KSD Aggregated Goodness-of-fit Test,"['kernel methods', 'goodness-of-fit', 'Stein methods', 'hypothesis testing']","[6, 7, 6]","[4, 4, 4]",0,"[521, 434, 760]",Accept
pkzwYftNcqY,Efficient Aggregated Kernel Tests using Incomplete $U$-statistics,"['kernel methods', 'hypothesis tests', 'adaptivity']","[7, 7, 6]","[3, 4, 4]",0,"[625, 458, 757]",Accept
YPoRoad6gzY,OST: Improving Generalization of DeepFake Detection via One-Shot Test-Time Training,[],"[8, 5, 5, 6]","[5, 3, 5, 3]",0,"[456, 315, 345, 184]",Accept
adFLKRqRu1h,Fuzzy Learning Machine,"['Classification', 'Cognitive Science', 'Fuzzy Set Theory']","[6, 5, 7]","[4, 4, 4]",0,"[894, 914, 482]",Accept
tYAS1Rpys5,Simulation-guided Beam Search for Neural Combinatorial Optimization,"['Combinatorial Optimization', 'Reinforcement Learning', 'Active Search', 'Beam Search', 'MCTS', 'Tree Search', 'TSP', 'CVRP', 'Flow-Shop Scheduling']","[6, 4, 7, 6]","[4, 4, 2, 4]",0,"[223, 598, 191, 1137]",Accept
3r0yLLCo4fF,Quo Vadis: Is Trajectory Forecasting the Key Towards Long-Term Multi-Object Tracking?,"['multi-object tracking', 'tracking', 'trajectory prediction', 'computer vision']","[6, 5, 7, 6]","[5, 5, 4, 4]",0,"[216, 679, 496, 505]",Accept
cYeYzaP-5AF,Meta-Reinforcement Learning with Self-Modifying Networks,"['Meta-reinforcement learning', 'Synaptic plasticity', 'Hopfield networks', 'Control theory']","[8, 6, 6]","[3, 4, 2]",0,"[284, 1477, 307]",Accept
5K3uopkizS,Robust Models are less Over-Confident,"['Computer Vision', 'Adversarial Robustness', 'Model Calibration']","[5, 3, 5, 6]","[4, 4, 4, 5]",0,"[284, 203, 262, 448]",Accept
tmUGnBjchSC,Generalizing Bayesian Optimization with Decision-theoretic Entropies,"['Bayesian optimization', 'entropy search', 'Bayesian optimal experimental design', 'knowledge gradient']","[6, 6, 6]","[3, 4, 3]",0,"[393, 276, 390]",Accept
wZk69kjy9_d,Deep Hierarchical Planning from Pixels,"['Hierarchical Reinforcement Learning', 'World Models', 'Visual Control', 'Planning to Explore', 'Hierarchical Exploration', 'Goal-Conditioned RL']","[5, 6, 6]","[4, 4, 4]",0,"[463, 319, 1226]",Accept
HFm7AxNa9Wo,Multi-Scale Adaptive Network for Single Image Denoising,"['image denoising', 'multi-scale architecture', 'image restoration']","[7, 7, 7, 7, 7]","[5, 5, 4, 4, 4]",0,"[435, 413, 307, 430, 430]",Accept
NyAJzgHLAr,Intermediate Prototype Mining Transformer for Few-Shot Semantic Segmentation,"['few-shot', 'segmentation']","[6, 5, 7]","[4, 4, 4]",0,"[230, 217, 283]",Accept
0-uBrFiOVf,DTG-SSOD: Dense Teacher Guidance for Semi-Supervised Object Detection,"['object detection', 'semi-supervised learning', 'semi-supervised object detection']","[6, 6, 7, 5]","[4, 4, 3, 4]",0,"[244, 219, 505, 212]",Accept
LIKlL1Br9AT,Contact-aware Human Motion Forecasting,"['scene-aware human motion prediction', 'human-scene contact']","[6, 5, 7]","[3, 4, 3]",0,"[349, 450, 561]",Accept
7CONgGdxsV,Understanding Programmatic Weak Supervision via Source-aware Influence Function,"['Data-centric Method', 'Programmatic Weak Supervision', 'Influence Function', 'Interpretability']","[6, 6, 6]","[4, 2, 3]",0,"[653, 743, 253]",Accept
k7FuTOWMOc7,Elucidating the Design Space of Diffusion-Based Generative Models,"['generative modeling', 'denoising diffusion', 'image generation', 'score matching', 'differential equations']","[8, 9, 8, 7]","[4, 4, 4, 5]",0,"[752, 514, 505, 483]",Accept
HEcYYV5MPxa,Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech,"['Text-to-Speech', 'Online Dictionary', 'Unsupervised Polyphone Disambiguation']","[7, 7, 4, 7]","[4, 4, 5, 5]",0,"[578, 509, 664, 515]",Accept
vhKaBdOOobB,GhostNetV2: Enhance Cheap Operation with Long-Range Attention,[],"[3, 6, 8, 7]","[3, 3, 4, 5]",0,"[475, 411, 434, 319]",Accept
-zYfrOl2I6O,CASA: Category-agnostic Skeletal Animal Reconstruction,"['articulation', 'inverse graphics', '3D reconstruction', 'animation']","[4, 7, 7]","[3, 4, 5]",0,"[415, 438, 577]",Accept
6H00JM-DZjU,Fair and Efficient Allocations Without Obvious Manipulations,"['mechanism design', 'fair division']","[6, 7, 8, 4]","[3, 3, 3, 4]",0,"[621, 311, 309, 264]",Accept
xwBdjfKt7_W,SNN-RAT: Robustness-enhanced Spiking Neural Network through Regularized Adversarial Training,"['Spiking Neural Networks', 'Neural Coding', 'Perturbation Analysis']","[5, 5, 6]","[5, 3, 4]",0,"[305, 308, 277]",Accept
cFOhdl1cyU-,MViT: Mixture-of-Experts Vision Transformer for Efficient Multi-task Learning with Model-Accelerator Co-design,"['multi-task learning', 'mixture of experts', 'vision transformer', 'hardware co-design']","[6, 4, 7, 7]","[2, 4, 4, 2]",0,"[239, 439, 621, 167]",Accept
NaZwgxp-mT_,Training Uncertainty-Aware Classifiers with Conformalized Deep Learning,"['Deep learning', 'Uncertainty', 'Conformal inference', 'Multi-class classification', 'Overfitting', 'Confidence.']","[6, 7, 6, 5]","[4, 4, 3, 2]",0,"[261, 807, 382, 732]",Accept
aPXMGv7aeOn,Compressible-composable NeRF via Rank-residual Decomposition,"['Neural Radiace Fields', 'Tensor Rank Decomposition', 'Compression', 'Composition.']","[6, 4, 6, 5]","[2, 4, 4, 4]",0,"[584, 454, 272, 275]",Accept
uxc8hDSs_xh,Can Hybrid Geometric Scattering Networks Help Solve the Maximum Clique Problem?,"['Graph Neural Networks', 'Geometric Scattering', 'Combinatorial Optimization']","[6, 6, 3]","[3, 4, 4]",0,"[269, 677, 697]",Accept
R5KjUket6w,CEIP: Combining Explicit and Implicit Priors for Reinforcement Learning with Demonstrations,"['reinforcement learning', 'imitation learning', 'normalizing flow', 'action prior']","[5, 6, 7]","[4, 4, 4]",0,"[1005, 425, 372]",Accept
lMMaNf6oxKM,"Recipe for a General, Powerful, Scalable Graph Transformer","['graph transformers', 'graph neural networks', 'transformers', 'learning on graphs', 'graph representation learning']","[6, 7, 5]","[4, 4, 4]",0,"[216, 190, 325]",Accept
NjeEfP7e3KZ,Revisiting Heterophily For Graph Neural Networks,"['Graph Neural Networks', 'Homophily Metrics', 'Heterophily', 'Non-Homophilous', 'Heterophilic Graphs', 'High-pass filter', 'Filterbank', 'Adaptive Channel Mixing']","[6, 3, 4, 6, 7]","[4, 4, 4, 3, 5]",0,"[251, 262, 306, 393, 289]",Accept
2vYmjZVT29T,Hamiltonian Latent Operators for content and motion disentanglement in image sequences,"['Deep generative models', 'Variational Autoencoder', 'Symplectic Geometry', 'Hamiltonian Dynamics', 'Latent Space Disentanglement']","[5, 5, 6]","[4, 3, 3]",0,"[380, 923, 417]",Accept
upuYKQiyxa_,Optimizing Relevance Maps of Vision Transformers Improves Robustness,"['Vision Transformers', 'Explainability', 'Robustness']","[6, 7, 6, 7]","[4, 4, 3, 4]",0,"[989, 317, 353, 751]",Accept
eN2lQxjWL05,Decision-Focused Learning without Decision-Making: Learning Locally Optimized Decision Losses,"['Decision-Focused Learning', 'Prediction', 'Optimization', 'Machine Learning']","[3, 6, 5, 8]","[5, 4, 3, 4]",0,"[688, 697, 326, 461]",Accept
RuNhbvX9o9S,Learning General World Models in a Handful of Reward-Free Deployments,"['Reward-Free Reinforcement Learning', 'Deployment Efficiency', 'World Models', 'Exploration', 'Model-based Reinforcement Learning']","[6, 6, 5, 5]","[4, 5, 4, 4]",0,"[387, 454, 1203, 951]",Accept
3-3XMModtrx,Is a Modular Architecture Enough?,"['modularity', 'attention', 'mixture of experts', 'metrics', 'benchmark', 'specialization', 'collapse']","[8, 7, 6, 6]","[4, 4, 4, 4]",0,"[149, 397, 301, 451]",Accept
68EuccCtO5i,Differentially Private Model Compression,"['Differentially Private Training', 'DP Model Compression', 'DP Language Models', 'NLP Tasks']","[5, 5, 6, 5]","[4, 4, 5, 4]",0,"[287, 538, 544, 846]",Accept
wwyiEyK-G5D,REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual Question Answering,['Knowledge-based VQA'],"[5, 6, 6]","[4, 4, 5]",0,"[337, 539, 278]",Accept
_keb_XuP5oI,Generative Neural Articulated Radiance Fields,"['unsupervised learning', 'GAN', 'neural rendering', 'neural scene representation']","[6, 7, 7]","[5, 5, 4]",0,"[440, 605, 273]",Accept
nYrFghNHzz,Learning Individualized Treatment Rules with Many Treatments: A Supervised Clustering Approach Using Adaptive Fusion,"['Fusion Penalty', 'High-dimensional Regression', 'Individualized Treatment Rule', 'Precision Medicine']","[5, 6, 6, 7]","[3, 4, 3, 4]",0,"[290, 424, 821, 444]",Accept
sipwrPCrIS,Self-Consistent Dynamical Field Theory of Kernel Evolution in Wide Neural Networks,"['Deep Learning Theory', 'Infinite Width', 'Kernel Methods']","[8, 7, 7]","[4, 3, 4]",0,"[364, 289, 450]",Accept
GFgjnk2Q-ju,Parametrically Retargetable Decision-Makers Tend To Seek Power,"['power', 'alignment', 'safety', 'rl', 'reinforcement learning', 'theory']","[6, 4, 7, 7]","[4, 4, 4, 4]",0,"[1291, 556, 1570, 752]",Accept
Z6BFQqzwuS4,Bayesian Persuasion for Algorithmic Recourse,"['bayesian persuasion', 'algorithmic recourse', 'strategic learning']","[5, 5, 7, 6]","[3, 4, 3, 4]",0,"[453, 493, 837, 1296]",Accept
0IywQ8uxJx,Graph Neural Networks as Gradient Flows,"['Graph Neural Networks', 'Spectral analysis', 'Over-smoothing', 'Energy', 'Differential equations']","[4, 4, 6, 6]","[5, 3, 4, 4]",0,"[1162, 306, 255, 896]",Reject
kRgOlgFW9aP,Thompson Sampling Efficiently Learns to Control Diffusion Processes,"['Reinforcement Learning', 'Posterior Sampling', 'Continuous-Time Systems', 'Stochastic Differential Equations', 'Linear Systems', 'Adaptive Control']","[6, 6, 5, 7]","[1, 4, 4, 4]",0,"[46, 339, 280, 624]",Accept
lJHkZbX6Ic1,Is this the Right Neighborhood? Accurate and Query Efficient Model Agnostic Explanations,"['explainable AI', 'adaptive sampling']","[4, 6, 6, 6]","[2, 3, 2, 3]",0,"[231, 530, 212, 181]",Accept
ZQcpYaE1z1r,A Quantitative Geometric Approach to Neural-Network Smoothness,"['Neural Networks', 'Semidefinite Programming', 'Lipschitz Constant']","[7, 5, 8, 5]","[4, 2, 2, 3]",0,"[451, 906, 562, 594]",Accept
foNVYPnQbhk,SCONE: Surface Coverage Optimization in Unknown Environments by Volumetric Integration,"['Computer Vision', '3D reconstruction', 'Next Best View', '3D scene exploration', 'Deep Learning']","[8, 7, 6]","[4, 3, 3]",0,"[360, 473, 993]",Accept
lxdWr1jN8-h,Integrating Symmetry into Differentiable Planning,"['planning', 'equivariance', 'symmetry', 'reinforcement learning', 'model-based reinforcement learning']","[4, 7, 6]","[3, 1, 2]",0,"[515, 290, 394]",Reject
jQR9YF2-Jhg,Respecting Transfer Gap in Knowledge Distillation,"['knowledge distillation', 'transfer gap', 'inverse probability weighting']","[5, 5, 4]","[5, 4, 3]",0,"[269, 283, 584]",Accept
mfxq7BrMfga,Generalized One-shot Domain Adaptation of Generative Adversarial Networks,"['Generative Adversarial Network', 'Computer vision', 'domain adaptation']","[5, 5, 6, 5]","[4, 4, 4, 3]",0,"[295, 325, 219, 773]",Accept
htUvh7xPoa,Random Sharpness-Aware Minimization,"['Sharpness-Aware Minimization', 'Generalization', 'Adversarial Training']","[4, 8, 6, 7]","[5, 3, 4, 3]",0,"[1002, 400, 606, 1151]",Accept
9ND8fMUzOAr,Expediting Large-Scale Vision Transformer for Dense Prediction without Fine-tuning,"['Transformer', 'High-Resolution', 'Semantic Segmentation', 'Depth Estimation', 'Classification', 'Efficient Architecture']","[5, 5, 5, 5]","[1, 4, 4, 4]",0,"[155, 327, 200, 341]",Accept
TjVU5Lipt8F,When Privacy Meets Partial Information: A Refined Analysis of Differentially Private Bandits,"['Differential Privacy', 'Multi-armed Bandits', 'Regret Analysis', 'Stochastic Linear Bandits']","[6, 8, 5, 7]","[3, 4, 5, 3]",0,"[309, 411, 418, 440]",Accept
uOQNvEfjpaC,What is Where by Looking: Weakly-Supervised Open-World Phrase-Grounding without Text Inputs,"['weakly-supervised phrase-grounding', 'open-world', 'weakly-supervised localization', 'CLIP']","[5, 4, 8, 4]","[3, 3, 4, 3]",0,"[322, 355, 546, 252]",Accept
hFni381edL,SAPA: Similarity-Aware Point Affiliation for Feature Upsampling,"['Feature upsampling', 'dense prediction', 'semantic segmentation', 'object detection', 'depth estimation', 'image matting']","[5, 5, 5, 6]","[3, 3, 4, 4]",0,"[336, 258, 435, 230]",Accept
iQpaHC7cPfR,SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image collections,"['inverse rendering', 'reflectance decomposition', 'illumination estimation', 'pose estimation', 'neural fields']","[6, 6, 6]","[3, 4, 4]",0,"[562, 423, 572]",Accept
HjicdpP-Nth,Generalized Laplacian Eigenmaps,"['GCL', 'graph contrastive learning', 'node embedding', 'logdet', 'rank minimization']","[5, 6, 5]","[4, 4, 4]",0,"[465, 520, 354]",Accept
g_bqn4ewVG,PatchComplete: Learning Multi-Resolution Patch Priors for 3D Shape Completion on Unseen Categories,"['3d shape completion', '3d reconstruction', 'zero-shot 3d reconstruction']","[6, 6, 6, 6]","[3, 4, 4, 3]",0,"[210, 348, 608, 639]",Accept
pkfpkWU536D,Neural Shape Deformation Priors,"['Geometric processing', 'Shape Deformation', 'Deformation Fields', 'Shape Editing', 'Shape manipulation']","[5, 4, 5, 6]","[3, 3, 3, 4]",0,"[572, 365, 244, 577]",Accept
Bqk9c0wBNrZ,Semi-Parametric Neural Image Synthesis,"['Image Synthesis', 'Deep Generative Models', 'Retrieval-Augmented Models']","[6, 5, 5, 6]","[4, 4, 4, 4]",0,"[935, 223, 384, 511]",Accept
Yc4MjP2Mnob,Recommender Forest for Efficient Retrieval,"['End-to-end reommender system', 'Tree', 'Forest', 'Sequence', 'Transformer']","[8, 6, 6]","[4, 3, 4]",0,"[208, 296, 413]",Accept
lkrnoLxX1Do,Self-Supervised Image Restoration with Blurry and Noisy Pairs,"['self-supervised learning', 'image restoration', 'blurry and noisy pair']","[6, 5, 5]","[3, 4, 4]",0,"[507, 517, 581]",Accept
dO11Niyc225,A Non-asymptotic Analysis of Non-parametric Temporal-Difference Learning,"['reinforcement learning', 'temporal-difference learning', 'non-parametric', 'kernel methods', 'convergence', 'policy evaluation']","[7, 6, 5, 5]","[3, 4, 4, 3]",0,"[495, 345, 532, 473]",Accept
_zPG0ShaZTc,The Unreasonable Effectiveness of Fully-Connected Layers for Low-Data Regimes,"['Low-data Regime', 'Convolutional Networks']","[6, 6, 7]","[3, 4, 4]",0,"[439, 796, 460]",Accept
rUc8peDIM45,The alignment property of SGD noise and how it helps select flat minima: A stability analysis,"['Flat minima', 'stochastic gradient descent', 'linear stability', 'implicit regularization', 'neural network']","[7, 6, 7]","[3, 4, 4]",0,"[190, 568, 383]",Accept
DSoFfnmUSjS,Recommender Transformers with Behavior Pathways,"['Recommendation', 'Deep Learning', 'Transformers']","[5, 3, 7, 5]","[4, 5, 3, 3]",0,"[453, 340, 272, 599]",Reject
VYYf6S67pQc,Mildly Conservative Q-Learning for Offline Reinforcement Learning,[],"[6, 7, 6, 5]","[4, 4, 4, 4]",0,"[255, 331, 477, 517]",Accept
kOIaB1hzaLe,Contrastive Neural Ratio Estimation,"['simulation-based inference', 'likelihood-free inference', 'implicit likelihood', 'posterior', 'likelihood-to-evidence ratio estimation', 'neural ratio estimation', 'contrastive learning']","[6, 8, 6]","[4, 3, 2]",0,"[414, 395, 234]",Accept
QotmVXC-8T,Muffliato: Peer-to-Peer Privacy Amplification for Decentralized Optimization and Averaging,"['differential privacy', 'decentralized optimization', 'gossip protocols', 'privacy amplification']","[7, 7, 7, 7]","[4, 3, 3, 1]",0,"[315, 340, 337, 192]",Accept
IPcgkUgw3t1,UniGAN: Reducing Mode Collapse in GANs using a Uniform Generator,"['Mode Collapse', 'GANs']","[4, 7, 7, 6]","[4, 2, 3, 3]",0,"[279, 237, 288, 201]",Accept
1WZyphXPLwC,Split-kl and PAC-Bayes-split-kl Inequalities for Ternary Random Variables,"['Concentration Inequalities', 'Ternary Random Variables', 'PAC-Bayes Analysis', 'Learning Theory']","[5, 4, 8, 6]","[4, 3, 4, 5]",0,"[330, 526, 269, 817]",Accept
CTqkruS5Bb,Unsupervised Object Detection Pretraining with Joint Object Priors Generation and Detector Learning,[],"[5, 5, 5, 4]","[4, 4, 4, 4]",0,"[255, 228, 643, 267]",Accept
2EufPS5ABlJ,Spherical Sliced-Wasserstein,"['Optimal Transport', 'Sliced-Wasserstein', 'Sphere']","[4, 5, 5, 7]","[2, 4, 4, 3]",0,"[280, 169, 478, 524]",Reject
xvLWypz8p8,On Margins and Generalisation for Voting Classifiers,"['PAC-Bayes', 'Generalisation bounds', 'Ensemble learning', 'Margins', 'Majority votes', 'Aggregation of experts']","[7, 7, 7]","[3, 3, 4]",0,"[300, 138, 477]",Accept
LC1jyMUalIA,Transferring Textual Knowledge for Visual Recognition,"['video understanding', 'video recognition', 'vision-language pretraining']","[7, 6, 5]","[5, 3, 4]",0,"[264, 324, 198]",Reject
NL05_JGVg99,Open-Ended Reinforcement Learning with Neural Reward Functions,"['Unsupervised skill discovery', 'Reinforcement learning']","[6, 6, 5, 5]","[4, 4, 4, 3]",0,"[521, 433, 705, 579]",Accept
AdK9_GTEvG,LeRaC: Learning Rate Curriculum,"['curriculum learning', 'deep neural networks', 'model-level curriculum', 'data-free curriculum']","[6, 5, 5, 6]","[4, 3, 4, 4]",0,"[282, 635, 642, 725]",Reject
pcgMNVhRslj,Alignment-guided Temporal Attention for Video Action Recognition,"['Temporal Attention', 'Action Recognition', 'Video Learning', 'Mutual Information']","[4, 4, 6, 6]","[4, 5, 5, 4]",0,"[362, 413, 262, 358]",Accept
WyQAmQ8WIU,SlateFree: a Model-Free Decomposition for Reinforcement Learning with Slate Actions,"['reinforcement learning', 'slate', 'MDP', 'decomposition', 'recommender system']","[3, 4, 4, 7]","[4, 3, 5, 4]",0,"[274, 420, 259, 306]",Reject
zzDrPqn57DL,BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework,"['3D Object Detection', ""bird's eye view perception"", 'camera-lidar fusion']","[6, 4, 5, 5, 7]","[3, 3, 4, 4, 3]",0,"[407, 190, 441, 715, 304]",Accept
-V1ITIKPH6,Active Learning for Multiple Target Models,"['active learning', 'machine learning']","[6, 8, 5, 6]","[3, 4, 3, 1]",0,"[210, 370, 1138, 285]",Accept
bZzS_kkJes,Neural Matching Fields: Implicit Representation of Matching Fields for Visual Correspondence,"['Implicit neural representation', 'semantic correspondence']","[5, 7, 4, 6]","[4, 4, 5, 4]",0,"[231, 684, 530, 329]",Accept
ReB7CCByD6U,Beyond Mahalanobis Distance for Textual OOD Detection,"['NLP', 'Out-of-Distribution detection', 'text classifiers']","[6, 7, 4, 4]","[3, 4, 4, 4]",0,"[259, 215, 383, 574]",Accept
KWN3I1koJsU,Learning Generalizable Risk-Sensitive Policies to Coordinate in Decentralized Multi-Agent General-Sum Games,"['multi-agent reinforcement learning', 'risk-sensitive reinforcement learning', 'general-sum games', 'generalization']","[9, 3, 4, 4]","[4, 3, 4, 4]",0,"[273, 736, 364, 546]",Reject
T7114JzrwB,ZeroC: A Neuro-Symbolic Model for Zero-shot Concept Recognition and Acquisition at Inference Time,"['zero-shot concept recognition', 'zero-shot concept acquisition', 'neuro-symbolic', 'inference time']","[6, 5, 5, 6]","[4, 3, 4, 3]",0,"[917, 192, 403, 252]",Accept
xvZtgp5wyYT,Learning to Accelerate Partial Differential Equations via Latent Global Evolution,"['accelerate', 'partial differential equation', 'latent global evolution', 'inverse optimization']","[7, 5, 5, 7]","[3, 4, 2, 3]",0,"[670, 258, 337, 669]",Accept
dcmp81De77k,Localized Curvature-based Combinatorial Subgraph Sampling for Large-scale Graphs,"['Combinatorial subgraph sampling', 'Ollivier-Ricci curvatures']","[3, 4, 5, 3]","[4, 4, 3, 4]",0,"[265, 317, 342, 450]",Reject
JY6fLgR8Yq,Graph Self-supervised Learning with Accurate Discrepancy Learning,"['Graph Neural Network', 'Graph Self-supervised Learning']","[5, 7, 4, 4]","[4, 3, 4, 4]",0,"[635, 485, 263, 430]",Accept
EQgPNPwREa,Tikhonov Regularization is Optimal Transport Robust under Martingale Constraints,"['Distributionally Robust Optimization', 'Optimal Transport', 'Tikhonov Regularization']","[7, 4, 7]","[3, 4, 2]",0,"[241, 206, 446]",Accept
4maAiUt0A4,Boosting Out-of-distribution Detection with Typical Features,"['out-of-distribution detection', 'uncertainty estimation']","[7, 7, 7, 6]","[3, 4, 3, 5]",0,"[921, 516, 313, 488]",Accept
W4ZlZZwsQmt,Symplectic Spectrum Gaussian Processes: Learning Hamiltonians from Noisy and Sparse Data,"['Gaussian processes', 'random Fourier features', 'Hamiltonian mechanics', 'variational Bayes']","[6, 3, 6, 6]","[4, 2, 4, 4]",0,"[420, 305, 365, 519]",Accept
L9YayWPcHA_,Plan To Predict: Learning an Uncertainty-Foreseeing Model For Model-Based Reinforcement Learning,['model-based reinforcement learning'],"[6, 6, 7, 7]","[4, 3, 4, 5]",0,"[586, 1036, 504, 186]",Accept
zTQdHSQUQWc,FiLM: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting,"['Time Series Forecasting', 'Legendre Projection', 'Fourier Transform']","[7, 7, 5]","[3, 3, 5]",0,"[569, 326, 575]",Accept
3MZnNARib5,SAPipe: Staleness-Aware Pipeline for Data Parallel DNN Training,"['data parallelism', 'communication optimization', 'staleness mitigation']","[5, 6, 6]","[3, 4, 4]",0,"[780, 194, 374]",Accept
6hzH8pohyPY,Batch-Size Independent Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms or Independent Arms,"['Combinatorial multi-armed bandits', 'Variance-aware', 'Triggering arms', 'Batch-size']","[6, 7, 7]","[3, 4, 4]",0,"[240, 256, 1050]",Accept
H-6iczs__Ro,A Unified Diversity Measure for Multiagent Reinforcement Learning,[],"[7, 5, 6]","[3, 3, 4]",0,"[167, 339, 554]",Accept
wiBEFdAvl8L,GLIPv2: Unifying Localization and Vision-Language Understanding ,"['region-aware', 'vision-language', 'open-vocabulary object detection and segmentation', 'phrase grounding', 'VQA', 'image captioning']","[6, 6, 6]","[4, 4, 3]",0,"[408, 450, 568]",Accept
08Yk-n5l2Al,Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding,"['text-to-image', 'generative models', 'diffusion models']","[7, 8, 5]","[4, 4, 5]",0,"[239, 604, 439]",Accept
wKd2XtSRsjl,Mutual Information Divergence: A Unified Metric for Multimodal Generative Models,"['text-to-image generation', 'image captioning', 'evaluation metric', 'mutual information', 'vision and language']","[6, 6, 6, 6, 7]","[3, 3, 4, 2, 3]",0,"[225, 345, 219, 188, 299]",Accept
8RKJj1YDBJT,Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera,"['Dynamic Reconstruction', 'Monocular RGB-D Reconstruction', 'Neural Implicit Function']","[6, 7, 7, 7]","[3, 4, 3, 5]",0,"[367, 594, 221, 376]",Accept
K2PTuvVTF1L,Variational inference via Wasserstein gradient flows,"['Bures-Wasserstein', 'Kalman filter', 'mixture of Gaussians', 'variational inference', 'Wasserstein gradient flow']","[7, 6, 8]","[3, 4, 4]",0,"[255, 457, 749]",Accept
GCNIm4cKoRx,Finite-Time Analysis of Adaptive Temporal Difference Learning with Deep Neural Networks,"['Temporal Difference Learning', 'Adaptivity', 'DNN Approximation', 'MDP', 'Finite-Time Analysis']","[6, 7, 5, 4]","[4, 4, 1, 4]",0,"[211, 460, 192, 301]",Accept
Yul402KcD5d,Multi-Granularity Cross-modal Alignment for Generalized Medical Visual Representation Learning,"['medical image', 'medical report', 'cross-modal', 'representation learning']","[5, 8, 7]","[4, 3, 5]",0,"[364, 658, 597]",Accept
-3Pg7QNIF1S,An Embarrassingly Simple Approach to Semi-Supervised Few-Shot Learning,"['Semi-Supervised Few-Shot Learning', 'Negative Learning', 'Few-Shot Learning']","[6, 7, 6, 6]","[4, 4, 4, 3]",0,"[242, 514, 262, 298]",Accept
FhWQzNY2UYR,Geo-SIC: Learning Deformable Geometric Shapes in Deep Image Classifiers,"['Image classification', 'geometric shape representations', 'atlas building', 'diffeomorphic image registration']","[6, 7, 7]","[4, 5, 3]",0,"[392, 332, 293]",Accept
zGvRdBW06F5,On-Device Training Under 256KB Memory,"['on-device training', 'tinyML', 'tiny deep learning']","[6, 6, 8, 6]","[4, 5, 3, 5]",0,"[227, 718, 260, 314]",Accept
StzAAh8RuD,Independence Testing for Bounded Degree Bayesian Networks,"['Distribution testing', 'Bayesian Network', 'Probabilistic Graphical Model']","[6, 6, 5]","[4, 3, 3]",0,"[383, 471, 290]",Accept
yewD_qbYifc,PCRL: Priority Convention Reinforcement Learning for Microscopically Sequencable Multi-agent Problems,"['reinforcement learning', 'social convention', 'priority', 'large discrete action space', 'multi-agent', 'cooperation']","[3, 3, 3]","[4, 4, 5]",0,"[814, 711, 519]",Reject
9GXoMs__ckJ,On the Effect of Pre-training for Transformer in Different Modality on Offline Reinforcement Learning,"['Pre-training', 'Offline Reinforcement Learning', 'Transformer', 'Representation Analysis']","[5, 7, 7]","[4, 4, 4]",0,"[184, 411, 838]",Accept
BK0O0xLntFM,Estimating and Explaining Model Performance When Both Covariates and Labels Shift,"['ML models', 'data distribution shift', 'model deployment and monitoring']","[6, 6, 7, 5]","[2, 4, 4, 4]",0,"[359, 307, 140, 953]",Accept
GWcdXz0M6a,PopArt: Efficient Sparse Regression and Experimental Design for Optimal Sparse Linear Bandits,"['multi-armed bandits', 'linear bandits', 'sparse linear bandits']","[7, 7, 6]","[3, 3, 4]",0,"[283, 349, 460]",Accept
UDmPRm-P1nL,Distinguishing Learning Rules with Brain Machine Interfaces,"['brain-machine interface', 'recurrent neural network', 'reinforcement learning', 'biological learning rules']","[6, 7, 7, 7]","[4, 4, 3, 4]",0,"[1295, 563, 630, 1288]",Accept
wYgRIJ-oK6M,BiT: Robustly Binarized Multi-distilled Transformer,"['Natural language processing', 'BERT', 'Transformers', 'Compression', 'Binary neural networks']","[7, 5, 7]","[4, 3, 3]",0,"[737, 466, 227]",Accept
1C36tFZn7sR,Learning Chaotic Dynamics in Dissipative Systems,"['Dissipative Chaotic systems', 'operator learning', 'invariant statistics', 'attractor learning']","[7, 7, 5, 5]","[4, 4, 3, 5]",0,"[424, 748, 256, 1406]",Accept
9YasTgzma8c,Trading off Image Quality for Robustness is not Necessary with Regularized Deterministic Autoencoders,"['Adversarial robustness', 'Generative models', 'Deterministic autoencoder']","[6, 6, 7, 6]","[2, 4, 2, 3]",0,"[128, 603, 445, 430]",Accept
Upt5wsECVJe,Mean Estimation in High-Dimensional Binary Markov Gaussian Mixture Models,"['High-dimensional statistics', 'parameter estimation', 'hidden Markov model', 'minimax rate', 'spectral estimator']","[6, 6, 6, 6]","[1, 2, 4, 2]",0,"[363, 671, 444, 281]",Accept
d0stFTU2dTI,Exploration via Planning for Information about the Optimal Trajectory,"['reinforcement learning', 'information gain', 'exploration', 'planning']","[6, 6, 7, 5]","[4, 5, 4, 3]",0,"[256, 1012, 964, 471]",Accept
UZJHudsQ7d,Robust Calibration with Multi-domain Temperature Scaling,"['uncertainty quantification', 'calibration', 'distribution shift']","[7, 7, 6]","[3, 4, 5]",0,"[389, 242, 149]",Accept
Q6DJ12oQjrp,Sparse Interaction Additive Networks via Feature Interaction Detection and Sparse Selection,"['interpretability', 'additive models']","[6, 6, 6]","[3, 2, 3]",0,"[306, 225, 280]",Accept
vfR3gtIFd8Y,Fast variable selection makes scalable Gaussian process BSS-ANOVA a speedy and accurate choice for tabular and time series regression,"['scalable Gaussian process', 'timeseries', 'tabular data']","[3, 4, 5, 4]","[4, 3, 3, 3]",0,"[183, 233, 364, 191]",Reject
Rqe-fJQtExY,Efficient and Effective Multi-task Grouping via Meta Learning on Task Combinations,"['multi-task Learning', 'meta Learning', 'representation Learning']","[6, 5, 7, 7, 5]","[3, 4, 3, 3, 5]",0,"[363, 380, 455, 841, 123]",Accept
nLKkHwYP4Au,CAGroup3D: Class-Aware Grouping for 3D Object Detection on Point Clouds,"['3D Object Detection', 'Point Clouds', '3D Bounding Boxes', '3D Deep Learning']","[6, 5, 5, 7]","[4, 3, 4, 4]",0,"[207, 300, 389, 517]",Accept
Fm7Dt3lC_s2,Adaptive Data Debiasing through Bounded Exploration,"['Debiasing', 'bounded exploration', 'fairness']","[7, 6, 7]","[4, 3, 2]",0,"[933, 705, 772]",Accept
bfz-jhJ8wn,Bridging the Gap Between Vision Transformers and Convolutional Neural Networks on Small Datasets,['vision transformer'],"[5, 6, 4, 5]","[4, 5, 4, 4]",0,"[312, 543, 312, 1303]",Accept
Bq2-WN5csW,Loss Landscape Dependent Self-Adjusting Learning Rates in Decentralized Stochastic Gradient Descent,"['Decentralized Training', 'Loss Landscape Dependent Noise', 'Self-Adjusting Learning Rate', 'Learning Dynamics']","[3, 3, 4, 8]","[3, 3, 2, 5]",0,"[721, 879, 432, 528]",Reject
hcVlMF3Nvxg,MultiGuard: Provably Robust Multi-label Classification against Adversarial Examples,"['Adversarial examples', 'multi-label classification', 'certified defense']","[6, 6, 6, 6]","[5, 3, 2, 3]",0,"[447, 263, 296, 408]",Accept
Yopob26XjmL,Natural gradient enables fast sampling in spiking neural networks,"['spiking neural networks', 'sampling', 'Bayesian inference', 'information geometry', 'neural population geometry']","[6, 6, 6, 5]","[1, 5, 4, 4]",0,"[659, 543, 667, 200]",Accept
3AbigH4s-ml,CEBaB: Estimating the Causal Effects of Real-World Concepts on NLP Model Behavior,"['Explainability', 'Causality', 'Benchmark', 'Causal Explanation']","[6, 6, 6, 7]","[3, 4, 4, 4]",0,"[428, 385, 122, 401]",Accept
aLNWp0pn1Ij,GAR: Generalized Autoregression for Multi-Fidelity Fusion,"['Gaussian process', 'autoregression', 'multi fidelity', 'nonparametric Bayesian']","[5, 6, 8]","[4, 3, 3]",0,"[243, 107, 289]",Accept
nrksGSRT7kX,RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning,"['offline reinforcement learning', 'model-based reinforcement learning', 'deep reinforcement learning', 'robust reinforcement learning', 'adversarial learning']","[6, 6, 6, 4]","[4, 4, 4, 4]",0,"[189, 470, 390, 713]",Accept
k713e8vXzwR,Large-Scale Differentiable Causal Discovery of Factor Graphs,"['Causal discovery learning', 'causal learning gene regulatory networks', 'factor graphs', 'graph learning from interventions']","[5, 7, 6]","[5, 4, 3]",0,"[421, 280, 310]",Accept
VnAwNNJiwDb,Generating Long Videos of Dynamic Scenes,"['Video generation', 'GAN', 'generative model', 'dynamics', 'long videos']","[5, 7, 7, 6]","[5, 4, 3, 5]",0,"[531, 465, 484, 516]",Accept
-e2SBzFDE8x,Adaptively Exploiting d-Separators with Causal Bandits,"['bandit', 'causal bandit', 'adaptive', 'd-separation', 'online']","[7, 8, 7, 7]","[3, 4, 4, 3]",0,"[297, 362, 420, 540]",Accept
dMK7EwoTYp,MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface Reconstruction,"['3D Reconstruction', 'Neural Implicit Representations', 'Neural Rendering', 'Multi-view Reconstruction', 'Neural Implicit Surfaces', 'Monocular Priors']","[4, 5, 7, 8]","[5, 3, 4, 4]",0,"[493, 382, 355, 257]",Accept
Euv1nXN98P3,TarGF: Learning Target Gradient Field for Object Rearrangement,"['Object Rearrangement', 'Reward Learning', 'Score-matching', 'Reinforcement Learning']","[7, 6, 6]","[4, 4, 4]",0,"[462, 498, 500]",Accept
rnJzy8JnaX,Rethinking Resolution in the Context of Efficient Video Recognition,"['Efficient Video Recognition', 'Action Recognition']","[4, 6, 6]","[5, 4, 3]",0,"[354, 69, 260]",Accept
hBaI5MY0CBz,Feature-Proxy Transformer for Few-Shot Segmentation,"['Few-shot segmentation', 'vision transformer', 'prompt learning']","[6, 5, 6]","[3, 4, 4]",0,"[327, 341, 433]",Accept
5JdyRvTrK0q,Private Synthetic Data for Multitask Learning and Marginal Queries,[],"[6, 6, 6]","[3, 3, 4]",0,"[849, 201, 687]",Accept
fXq93VpCIy,Sauron U-Net: Simple automated redundancy elimination in medical image segmentation via filter pruning,"['medical image segmentation', 'model compression', 'filter pruning', 'convolutional neural networks']","[5, 4, 5, 4]","[4, 4, 4, 4]",0,"[288, 286, 384, 448]",Reject
TrsAkAbC96,Implicit Warping for Animation with Image Sets,"['image animation', 'attention', 'motion transfer', 'video synthesis']","[7, 7, 7]","[3, 3, 4]",0,"[1084, 378, 820]",Accept
cA8Zor8wFr5,AttCAT: Explaining Transformers via Attentive Class Activation Tokens,"['Transformer', 'Explanation', 'Attribution']","[4, 6, 8, 5]","[3, 4, 3, 3]",0,"[249, 303, 281, 478]",Accept
O5arhQvBdH,"Trading off Utility, Informativeness, and Complexity in Emergent Communication","['emergent communication', 'information bottleneck', 'multi-agent reinforcement learning']","[5, 4, 7]","[4, 4, 4]",0,"[1308, 917, 504]",Accept
4pwCvvel8or,Online PAC-Bayes Learning,"['PAC-Bayes', 'Online Learning', 'Non-Convex losses']","[6, 7, 5, 6]","[2, 3, 2, 3]",0,"[314, 713, 530, 811]",Accept
siG_S8mUWxf,Learning Physical Dynamics with Subequivariant Graph Neural Networks,"['physical dynamics', 'graph neural networks', 'symmetry']","[7, 6, 5, 6]","[4, 3, 5, 4]",0,"[505, 255, 882, 595]",Accept
XtyeppctGgc,Scaling & Shifting Your Features: A New Baseline for Efficient Model Tuning,"['Vision Transformer', 'Efficient', 'Fine-tuning']","[7, 7, 7, 7]","[4, 3, 5, 5]",0,"[417, 365, 312, 306]",Accept
qm5LpHyyOUO,MCMAE: Masked Convolution Meets Masked Autoencoders,"['Masked auto-encoders', 'Convolution Neural Networks', 'Vision Transformer']","[6, 8, 6, 8, 5]","[4, 5, 3, 4, 3]",0,"[457, 116, 263, 158, 403]",Accept
d4JmP1T45WE,Training Spiking Neural Networks with Event-driven Backpropagation,"['Spiking Neural Networks', 'Event-driven Learning', 'Time-based Gradient']","[7, 4, 8, 4]","[4, 5, 2, 3]",0,"[248, 420, 288, 227]",Accept
mjUrg0uKpQ,I2DFormer: Learning Image to Document Attention for Zero-Shot Image Classification,"['Zero-shot Learning', 'Multimodal learning', 'Transformer', 'Attention']","[7, 6, 6, 3]","[1, 4, 4, 3]",0,"[351, 1254, 309, 536]",Accept
fLIgyyQiJqz,Temporal Effective Batch Normalization in Spiking Neural Networks,"['Spiking Neural Networks', 'Batch Normalization', 'Spatio-Temporal Representation']","[4, 6, 3, 8]","[5, 4, 5, 5]",0,"[267, 550, 302, 452]",Accept
js2ssA77fX,Masked Generative Adversarial Networks are Data-Efficient Generation Learners,"['Generative Adversarial Network', 'Data Limited Image Generation', 'Data Efficient GAN']","[5, 7, 3, 6]","[4, 4, 5, 4]",0,"[289, 299, 441, 310]",Accept
w5DacXWzQ-Q,SAViT: Structure-Aware Vision Transformer Pruning via Collaborative Optimization,"['Vision Transformer', 'Pruning', 'Compression']","[4, 5, 6, 5]","[5, 4, 3, 3]",0,"[283, 341, 217, 195]",Accept
ZG5Bi1N4V0U,SeqPATE: Differentially Private Text Generation via Knowledge Distillation,"['Natural Language Generation', 'Text Generation', 'Privacy Protection', 'Differential Privacy']","[6, 7, 4, 7]","[4, 2, 3, 4]",0,"[260, 157, 215, 209]",Accept
wlEOsQ917F,A framework for bilevel optimization that enables  stochastic and global variance reduction algorithms,"['Bilevel opitimization', 'stochastic optimization', 'non-convex optimization']","[8, 7, 6]","[4, 3, 3]",0,"[970, 178, 528]",Accept
bMYU8_qD8PW,A Unified Model for Multi-class Anomaly Detection,['multi-class anomaly detection'],"[6, 5, 6]","[3, 5, 4]",0,"[360, 319, 585]",Accept
0tG59j2efs,Learning from Future: A Novel Self-Training Framework for Semantic Segmentation,"['unsupervised domain adaptive semantic segmentation', 'self-training']","[6, 5, 7]","[4, 4, 4]",0,"[421, 472, 720]",Accept
gRK9SLQHTDV,"Don't Roll the Dice, Ask Twice: The Two-Query Distortion of Matching Problems and Beyond","['Distortion', 'Matching', 'Social Choice', 'Query']","[7, 4, 4, 7]","[2, 4, 1, 3]",0,"[360, 162, 146, 1181]",Accept
1bE24ZURBqm,Biologically Inspired Dynamic Thresholds for Spiking Neural Networks,"['Spiking Neural Networks', 'dynamic threshold', 'robot obstacle avoidance', 'robot continuous control']","[5, 8, 7, 5]","[4, 3, 3, 3]",0,"[505, 184, 218, 500]",Accept
-bLLVk-WRPy,Structural Kernel Search via Bayesian Optimization and Symbolical Optimal Transport,"['Bayesian Optimization', 'Gaussian Process', 'Kernel Search', 'Kernel']","[7, 7, 7, 7]","[3, 4, 3, 3]",0,"[566, 227, 420, 392]",Accept
19MmorTQhho,One Inlier is First: Towards Efficient Position Encoding for Point Cloud Registration,"['Point cloud registration', 'Position encoding', 'One-inlier', 'Joint optimization']","[5, 6, 6, 5]","[5, 5, 4, 5]",0,"[505, 95, 475, 495]",Accept
NI7moUOKtc,Debiased Self-Training for Semi-Supervised Learning,"['Deep learning', 'Semi-supervised learning', 'Self-training', 'Debiased pseudo labeling']","[7, 6, 7]","[4, 3, 4]",0,"[402, 414, 335]",Accept
pd6ipu3jDw,Transformer-based Working Memory for Multiagent Reinforcement Learning with Action Parsing,"['multiagent system', 'deep reinforcement learning', 'action parsing', 'working memory']","[6, 6, 6]","[2, 4, 3]",0,"[426, 705, 469]",Accept
kyY4w4IgtM8,Sharing Knowledge for Meta-learning with Feature Descriptions,['Meta-learning'],"[5, 6, 4, 7]","[3, 3, 4, 3]",0,"[339, 339, 173, 357]",Accept
YxUdazpgweG,MultiScan: Scalable RGBD scanning for 3D environments with articulated objects,[],"[4, 4, 5]","[4, 3, 3]",0,"[170, 587, 346]",Accept
qq84D17BPu,Toward Equation of Motion for Deep Neural Networks: Continuous-time Gradient Descent and Discretization Error Analysis,"['Discretization error', 'Gradient flow', 'Gradient descent', 'Equation of motion']","[6, 6, 7, 8]","[2, 4, 3, 3]",0,"[362, 520, 536, 621]",Accept
QFQoxCFYEkA,DENSE: Data-Free One-Shot Federated Learning,"['federated learning', 'data-free knowledge distillation', 'one-shot FL']","[4, 8, 7, 8]","[5, 5, 4, 4]",0,"[304, 478, 260, 783]",Accept
kImIIKGqDFA,Large-batch Optimization for Dense Visual Predictions,"['Large-batch Training', 'Dense Visual Predictions', 'Object Detection and Segmentation']","[7, 6, 4, 5]","[4, 3, 3, 3]",0,"[780, 273, 432, 343]",Accept
35I4narr5A,Few-Shot Continual Active Learning by a Robot,"['Continual Learning', 'Catastrophic Forgetting', 'Active Learning', 'Human-Robot Intearction']","[5, 5, 6]","[3, 5, 3]",0,"[576, 553, 458]",Accept
s7SukMH7ie9,Adversarial Training with Complementary Labels: On the Benefit of Gradually Informative Attacks,"['adversarial training', 'weakly supervised learning', 'complementary label']","[8, 6, 7, 6]","[4, 3, 4, 4]",0,"[413, 416, 201, 441]",Accept
DGwX7wSoC-,Stationary Deep Reinforcement Learning with Quantum K-spin Hamiltonian Equation,"['deep reinforcement learning', 'instability', 'Hamiltonian policy gradient', 'stationary', 'quantum K-spin']","[7, 3, 5, 4]","[4, 3, 4, 3]",0,"[660, 599, 296, 307]",Reject
kHrE2vi5Rvs,Sym-NCO: Leveraging Symmetricity for Neural Combinatorial Optimization,"['Symmetricity', 'Equivariant', 'Combinatorial Optimization', 'Reinforcement Learning']","[7, 6, 6]","[4, 4, 4]",0,"[540, 1142, 2520]",Accept
PZtIiZ43E2R,List-Decodable Sparse Mean Estimation,[],"[5, 7, 7]","[2, 4, 4]",0,"[127, 730, 1027]",Accept
vK53GLZJes8,The Pitfalls of Regularization in Off-Policy TD Learning,"['regularization', 'ridge', 'td', 'rl', 'reinforcement learning', 'theory']","[7, 7, 6, 7]","[3, 4, 3, 3]",0,"[510, 326, 341, 586]",Accept
mvbr8A_eY2n,Optimal Efficiency-Envy Trade-Off via Optimal Transport,"['Resource Allocation', 'Fair Division', 'Optimal Transport']","[7, 7, 5, 5]","[2, 3, 3, 3]",0,"[393, 260, 571, 1359]",Accept
NN_TpS5dpo5,Physically-Based Face Rendering for NIR-VIS Face Recognition,[],"[7, 5, 5]","[3, 5, 4]",0,"[439, 264, 208]",Accept
i7WqjtdD0u,Learning With an Evolving Class Ontology,"['Computer Vision', 'Machine Learning', 'Lifelong Learning', 'Visual Recognition', 'Continual Learning', 'Semi-Supervised Learning']","[5, 5, 6]","[4, 3, 3]",0,"[424, 813, 558]",Accept
x2WTG5bV977,The Curse of Low Task Diversity: On the Failure of Transfer Learning to Outperform MAML and their Empirical Equivalence,"['meta-learning', 'few-shot learning', 'machine learning', 'deep learning']","[4, 4, 4, 3]","[3, 4, 4, 4]",0,"[430, 247, 771, 443]",Reject
BWEGx_GFCbL,Stability and Generalization Analysis of Gradient Methods for Shallow Neural Networks,"['Statistical Learning Theory', 'Algorithmic Stability', 'Shallow Neural Networks', 'Generalization Error']","[5, 7, 5, 6, 5]","[3, 4, 2, 3, 2]",0,"[316, 562, 276, 865, 354]",Accept
V88BafmH9Pj,A Contrastive Framework for Neural Text Generation,"['Open-ended Text Generation', 'Decoding Method', 'Contrastive Learning']","[5, 8, 5, 7]","[4, 4, 4, 4]",0,"[174, 443, 259, 658]",Accept
Gsbnnc--bnw,Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models,"['generative models', 'energy-based models', 'normalizing flows', 'generative adversarial networks', 'diffusion models', 'amortized inference', 'prompt learning']","[7, 6, 6, 5]","[3, 3, 5, 4]",0,"[534, 565, 687, 526]",Accept
LCWQ8OYsf-O,Polyhistor: Parameter-Efficient Multi-Task Adaptation for Dense Vision Tasks,[],"[7, 5, 7, 6]","[4, 4, 4, 4]",0,"[327, 214, 229, 367]",Accept
hYa_lseXK8,Model-based Safe Deep Reinforcement Learning via a Constrained Proximal Policy Optimization Algorithm,"['Reinforcement Learning', 'Safe Reinforcement Learning', 'Model-based Safe Reinforcement Learning']","[5, 5, 7, 6]","[3, 4, 4, 4]",0,"[335, 406, 301, 236]",Accept
wO53HILzu65,On the Generalizability and Predictability of Recommender Systems,"['recommender systems', 'algorithm selection', 'meta-learning', 'collaborative filtering']","[5, 7, 6, 7]","[5, 4, 3, 4]",0,"[441, 456, 243, 757]",Accept
mMT8bhVBoUa,Generalized Variational Inference in Function Spaces: Gaussian Measures meet Bayesian Deep Learning,"['Function Space Inference', 'Variational Inference', 'Bayesian Learning', 'Bayesian Inference', 'Generalised Variational Inference', 'Gaussian Processes', 'Gaussian Measures']","[7, 6, 7]","[4, 4, 4]",0,"[892, 437, 463]",Accept
zuL5OYIBgcV,Non-deep Networks,[],"[5, 4, 7, 7, 7]","[4, 4, 4, 4, 5]",0,"[436, 1149, 317, 745, 375]",Accept
YpyGV_i8Z_J,Private Estimation with Public Data,"['Differential Privacy', 'Learning', 'Machine Learning', 'Data Privacy', 'Statistics', 'Gaussians', 'Mixtures of Gaussians', 'Covariance Estimation']","[4, 6, 7]","[3, 4, 3]",0,"[356, 381, 427]",Accept
ptUZl8xDMMN,Graph Scattering beyond Wavelet Shackles,"['Geometric Deep Learning', 'Graph Convolutional Networks', 'Scattering', 'Wavelets', 'Stability Guarantees', 'Rigorous Proofs', 'Quantum Chemistry']","[7, 6, 7]","[2, 4, 3]",0,"[125, 896, 426]",Accept
_r8pCrHwq39,PointTAD: Multi-Label Temporal Action Detection with Learnable Query Points,"['multi-label temporal action detection', 'keyframe-based detection', 'query-based detection', 'temporal action detection']","[4, 5, 7, 8]","[4, 5, 5, 4]",0,"[305, 766, 450, 469]",Accept
c63eTNYh9Y,New Lower Bounds for Private Estimation and a Generalized Fingerprinting Lemma,"['Differential Privacy', 'Learning', 'Machine Learning', 'Data Privacy', 'Statistics', 'Gaussians', 'Covariance Estimation', 'Lower Bounds', 'Mean Estimation']","[6, 6, 7]","[2, 3, 3]",0,"[267, 819, 315]",Accept
AezHeiz7eF5,Theory and Approximate Solvers for Branched Optimal Transport with Multiple Sources,"['Combinatorial Optimization', 'Optimal Transport', 'Irrigation Networks', 'Structured Prediction', 'Steiner Tree Problem', 'Branched Optimal Transport', 'Transportation Networks']","[7, 5, 4, 6]","[3, 3, 3, 4]",0,"[690, 537, 254, 628]",Accept
cy1TKLRAEML,Is $L^2$ Physics Informed Loss Always Suitable for Training Physics Informed Neural Network?,"['Physics-Informed Neural Network', 'Partial Differential Equation', 'adversarial training']","[6, 6, 7, 6]","[4, 4, 3, 3]",0,"[731, 428, 187, 455]",Accept
3v44ls_4dbg,Learning Infinite-Horizon Average-Reward Restless Multi-Action Bandits via Index Awareness,"['Restless Bandits', 'Reinforcement Learning', 'Index Policy', 'Finite-time Analysis']","[6, 5, 7, 7]","[2, 4, 3, 4]",0,"[231, 701, 207, 1010]",Accept
SbAaNa97bzp,Understanding Robust Learning through the Lens of Representation Similarities,"['representation similarities', 'robust training', 'visualizations']","[6, 4, 6, 7, 6]","[2, 4, 4, 4, 4]",0,"[187, 284, 706, 1064, 574]",Accept
W-Z8n9HrWn0,Why Do Artificially Generated Data Help Adversarial Robustness,"['adversarial robustness', 'unlabeled data', 'semi-supervised learning']","[5, 6, 7, 8]","[3, 3, 2, 4]",0,"[654, 308, 341, 248]",Accept
t4vTbQnhM8,A Kernelised Stein Statistic for Assessing Implicit Generative Models,"[""Stein's method"", 'kernel method', 'model assessment', 'generative models']","[6, 7, 6]","[3, 4, 4]",0,"[237, 679, 799]",Accept
KqI-bX-TfT,Learning Consistency-Aware Unsigned Distance Functions Progressively from Raw Point Clouds,"['Surface reconstruction', 'Unsigned distance functions', 'Consistency-aware field learning', 'Progressive surface approximation']","[5, 6, 8, 7]","[3, 4, 4, 3]",0,"[358, 836, 274, 222]",Accept
LT6-Mxgb3QB,Bilinear Exponential Family of MDPs: Frequentist Regret Bound with Tractable Exploration $\&$ Planning,"['Reinforcement learning', 'bilinear MDP', 'frequentist regret', 'tractable optimism']","[7, 6, 6]","[4, 3, 3]",0,"[377, 403, 635]",Reject
3I8VTXMhuPx,Hiding Images in Deep Probabilistic Models,[],"[3, 5, 7]","[4, 2, 3]",0,"[314, 382, 184]",Accept
iMK2LP0AogI,CUP: Critic-Guided Policy Reuse,"['reinforcement learning', 'policy reuse', 'transfer learning']","[6, 5, 7, 6]","[4, 4, 4, 5]",0,"[690, 488, 659, 363]",Accept
NJr8GBsyTF0,Non-Markovian Reward Modelling from Trajectory Labels via Interpretable Multiple Instance Learning,"['reward modelling', 'reinforcement learning', 'multiple instance learning', 'interpretability']","[7, 4, 6]","[4, 4, 4]",0,"[729, 723, 313]",Accept
S0TR0W63NKl,Generalization Bounds for Estimating Causal Effects of Continuous Treatments,"['dose-response', 'causal inference', 'selection bias', 'causal effect', 'continuous treatment']","[6, 5, 3, 7]","[4, 5, 3, 4]",0,"[422, 237, 696, 457]",Accept
bGo0A4bJBc,Cost-Sensitive Self-Training for Optimizing Non-Decomposable Metrics,"['Semi-Supervised Learning', 'Long-Tailed Learning', 'Non-Decomposable Objectives']","[4, 3, 8]","[2, 3, 5]",0,"[318, 620, 173]",Accept
jJwy2kcBYv,SPD: Synergy Pattern Diversifying Oriented Unsupervised Multi-agent Reinforcement Learning,"['Unsupervised Reinforcement Learning', 'Multi-agent Reinforcement Learning']","[4, 7, 6, 6]","[4, 4, 3, 4]",0,"[450, 945, 391, 490]",Accept
TTM7iEFOTzJ,EpiGRAF: Rethinking training of 3D GANs,"['3D GANs', 'neural radiance fields', 'nerf', 'patch-wise training']","[7, 5, 6, 5]","[3, 3, 4, 3]",0,"[316, 330, 493, 414]",Accept
oprTuM8F3dt,Coordinates Are NOT Lonely - Codebook Prior Helps Implicit Neural 3D representations,"['Coordinate Learning', 'Implicit Neural Representation', 'Inverse Rendering', 'Neural Radiance Field']","[7, 5, 5, 6]","[4, 3, 4, 3]",0,"[642, 177, 291, 545]",Accept
VQ9fogN1q6e,Factored Adaptation for Non-Stationary Reinforcement Learning,"['non-stationarity', 'non-stationary RL', 'causal RL']","[7, 6, 6, 7]","[3, 1, 3, 4]",0,"[762, 374, 736, 714]",Accept
0JV4VVBsK6a,Bringing Image Scene Structure to Video via Frame-Clip Consistency of Object Tokens,"['video models', 'object centric models', 'image-video']","[6, 4, 6, 5]","[4, 4, 4, 5]",0,"[373, 735, 630, 410]",Accept
NkK4i91VWp,Increasing Confidence in Adversarial Robustness Evaluations,"['adversarial robustness', 'robustness', 'adversarial attack']","[7, 6, 6, 8]","[2, 4, 4, 5]",0,"[211, 180, 286, 827]",Accept
zbuq101sCNV,TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting Decomposition,[],"[5, 4, 6, 6]","[2, 4, 4, 4]",0,"[306, 416, 584, 361]",Accept
HIslGib8XD,AutoMS: Automatic Model Selection for Novelty Detection with Error Rate Control,"['Model Selection', 'FDR', 'Novelty Detection']","[6, 4, 6]","[4, 4, 2]",0,"[453, 125, 380]",Accept
omI5hgwgrsa,Optimal Algorithms for Decentralized Stochastic Variational Inequalities,"['convex optimization', 'variational inequalities', 'stochastic optimization', 'saddle point problems', 'decentralized optimization']","[5, 7, 5]","[2, 4, 3]",0,"[73, 256, 439]",Accept
9U4gLR_lRP,Logit Margin Matters: Improving Transferable Targeted Adversarial Attack by Logit Calibration,[],"[2, 6, 5, 5]","[5, 5, 4, 4]",0,"[241, 185, 434, 769]",Reject
2EQzEE5seF,Adversarially Perturbed Batch Normalization: A Simple Way to Improve Image Recognition,"['Adversarial Training', 'Image Recognition', 'Batch Normalization', 'Robustness', 'Generalization']","[4, 5, 3, 4]","[3, 4, 4, 4]",0,"[442, 547, 99, 226]",Reject
LEqYZz7cZOI,Singular Value Fine-tuning: Few-shot Segmentation requires Few-parameters Fine-tuning,[],"[6, 7, 7, 8]","[4, 5, 5, 4]",0,"[421, 631, 587, 413]",Accept
KCXQ5HoM-fy,Supported Policy Optimization for Offline Reinforcement Learning,"['Offline reinforcement learning', 'Deep reinforcement learning']","[5, 6, 6, 7]","[4, 5, 2, 4]",0,"[556, 156, 174, 592]",Accept
DhmYYrH_M3m,Trajectory-guided Control Prediction for End-to-end Autonomous Driving: A Simple yet Strong Baseline,['End-to-end Autonomous Driving'],"[6, 4, 3, 7]","[3, 5, 5, 4]",0,"[379, 340, 1434, 364]",Accept
jAL8Rt7HqB,Adaptive Attention Link-based Regularization for Vision Transformers,"['Vision transformers', 'Knowledge transfer', 'Knowledge distillation']","[3, 6, 6, 6]","[4, 3, 4, 4]",0,"[428, 507, 597, 523]",Reject
cj6K4IWVomU,Rotation-Equivariant Conditional Spherical Neural Fields for Learning a Natural Illumination Prior,"['Neural Fields', 'Equivariance', 'High Dynamic Range', 'Environment Maps', 'Illumination Prior', 'Inverse Rendering']","[7, 3, 6, 6]","[5, 4, 2, 4]",0,"[479, 649, 527, 553]",Accept
8LE06pFhqsW,E-MAPP: Efficient Multi-Agent Reinforcement Learning with Parallel Program Guidance,"['multi-agent reinforcement learning', 'program guided agents', 'long-horizon tasks']","[6, 6, 6]","[4, 3, 3]",0,"[494, 648, 954]",Accept
htM1WJZVB2I,Vision GNN: An Image is Worth Graph of Nodes,[],"[4, 7, 8, 8]","[4, 5, 5, 4]",0,"[426, 291, 248, 297]",Accept
7a2IgJ7V4W,Semi-supervised Vision Transformers at Scale,[],"[4, 8, 4, 6]","[3, 5, 4, 4]",0,"[280, 950, 140, 223]",Accept
gtCPWaY5bNh,Deep Model Reassembly,"['Transfer Learning from Model Zoo', 'Neural Network Reassembly', 'Representation Similarity']","[8, 8, 6]","[4, 5, 4]",0,"[603, 480, 593]",Accept
ebuR5LWzkk0,Are You Stealing My Model? Sample Correlation for Fingerprinting Deep Neural Networks,"['NN fingerprinting', 'model stealing attack', 'sample correlation']","[5, 7, 6]","[3, 4, 4]",0,"[261, 350, 298]",Accept
xL8sFkkAkw,Towards Theoretically Inspired Neural Initialization Optimization,['initialization optimization'],"[6, 6, 6, 5]","[4, 4, 4, 3]",0,"[627, 303, 334, 364]",Accept
QrK0WDLVHZt,Optimal Gradient Sliding and its Application to Optimal Distributed Optimization Under Similarity,"['convex optimization', 'composite optimization', 'data similarity', 'optimal algorithms', 'sliding']","[7, 7, 6, 4]","[4, 4, 3, 2]",0,"[142, 540, 396, 500]",Accept
Y4vT7m4e3d,Decentralized Local Stochastic Extra-Gradient for Variational Inequalities,"['convex optimization', 'variational inequalities', 'saddle point problems', 'gossip']","[5, 6, 3, 7]","[3, 5, 4, 3]",0,"[70, 217, 480, 401]",Accept
CZNFw38dDDS,P2P: Tuning Pre-trained Image Models for Point Cloud Analysis with Point-to-Pixel Prompting,[],"[6, 6, 4, 6]","[2, 4, 5, 3]",0,"[210, 674, 327, 106]",Accept
NQFFNdsOGD,Your Transformer May Not be as Powerful as You Expect,"['Transformer', 'Positional Encoding', 'Expressive Power']","[7, 8, 8, 7, 6]","[4, 4, 4, 3, 1]",0,"[242, 442, 376, 270, 194]",Accept
2ktj0977QGO,Multi-Instance Causal Representation Learning for Instance Label Prediction and Out-of-Distribution Generalization,"['multi-instance learning', 'variational autoencoder', 'causal representation']","[5, 7, 8, 4]","[3, 3, 5, 4]",0,"[505, 226, 505, 209]",Accept
Siv3nHYHheI,Online Training Through Time for Spiking Neural Networks,"['spiking neural networks', 'online training through time', 'neuromorphic computing']","[7, 7, 5]","[4, 3, 3]",0,"[516, 385, 382]",Accept
y5ziOXtKybL,Asymptotic Properties for Bayesian Neural Network in Besov Space,"['Bayesian neural network', 'sparsity', 'deep learning', 'posterior consistency', 'optimal rate']","[5, 7, 5]","[3, 4, 2]",0,"[379, 358, 1036]",Accept
iKKfdIm81Jt,Planning for Sample Efficient Imitation Learning,[],"[7, 5, 7]","[3, 3, 4]",0,"[387, 354, 418]",Accept
nE8IJLT7nW-,Peripheral Vision Transformer,"['Vision transformers', 'Peripheral vision', 'Image recognition', 'Image classification', 'Inductive bias']","[5, 7, 7, 6]","[4, 3, 4, 3]",0,"[348, 1260, 592, 496]",Accept
QzFJmwwBMd,ZARTS: On Zero-order Optimization for Neural Architecture Search,[],"[5, 7, 8]","[3, 4, 5]",0,"[219, 399, 415]",Accept
IvnoGKQuXi,Class-Dependent Label-Noise Learning with Cycle-Consistency Regularization,"['Label-Noise Learning', 'Transition Matrix']","[3, 8, 7, 7]","[4, 4, 5, 5]",0,"[614, 229, 246, 288]",Accept
V3kqJWsKRu4,InsPro: Propagating Instance Query and Proposal for Online Video Instance Segmentation,"['Video Instance Segmentation', 'Instance Query', 'Instance Segmentation']","[6, 6, 5, 6]","[3, 4, 5, 5]",0,"[215, 320, 405, 205]",Accept
aGFQDrNb-KO,Multi-dataset Training of Transformers for Robust Action Recognition,"['Action Recognition', 'Vision Transformers', 'Multi-task learning', 'Multi-dataset learning', 'Robust Representation']","[5, 5, 5]","[4, 4, 4]",0,"[365, 577, 287]",Accept
a8qX5RG36jd,LasUIE: Unifying Information Extraction with Latent Adaptive Structure-aware Generative Language Model,"['Information extraction', 'Syntactic structure', 'Language model', 'Natural language processing']","[7, 6, 7]","[3, 4, 3]",0,"[300, 358, 145]",Accept
Ojakr9ofova,Scalable Infomin Learning,"['mutual information', 'representation learning', 'fairness', 'disentangled representation learning', 'domain adaptation']","[6, 7, 7]","[3, 4, 3]",0,"[541, 704, 165]",Accept
OzbkiUo24g,Linear tree shap,[],"[7, 7, 7, 7, 7]","[4, 3, 3, 4, 3]",0,"[588, 605, 104, 753, 148]",Accept
L7P3IvsoUXY,CATER: Intellectual Property Protection on Text Generation APIs via Conditional Watermarks,"['natural language generation', 'conditional lexical watermarks', 'IP protection']","[6, 8, 8, 6]","[3, 5, 5, 3]",0,"[461, 411, 420, 293]",Accept
r__gfIasEdN,GAPX: Generalized Autoregressive Paraphrase-Identification X,"['paraphrase identification', 'distribution shift', 'autoregressive transformer', 'out-of-distribution detection']","[5, 7, 6, 8]","[4, 4, 4, 4]",0,"[239, 485, 492, 351]",Accept
-me36V0os8P,Explaining Preferences with Shapley Values,"['Interpretability', 'Preference Learning', 'Kernel', 'Shapley Values', 'RKHS']","[6, 8, 5, 6]","[3, 3, 4, 4]",0,"[435, 336, 448, 1606]",Accept
BgMz5LHc07R,C-Mixup: Improving Generalization in Regression,"['data augmentation', 'regression', 'mixup', 'generalization', 'deep neural networks']","[6, 6, 6]","[3, 4, 4]",0,"[339, 475, 629]",Accept
dUYLikScE-,Infinite-Fidelity Coregionalization  for Physical Simulation,"['Multi-Fidelity Learning', 'Surrogate Modeling', 'Physical Simulation']","[6, 6, 6]","[4, 4, 4]",0,"[283, 727, 434]",Accept
fzvDZ0mraPP,Giga-scale Kernel Matrix-Vector Multiplication on GPU,"['Kernel', 'GPU', 'RKHS', 'kernel matrix vector multiplication', 'interpolation', 'large scale', 'giga scale', '10^9 points', 'big data']","[7, 6, 6, 6]","[4, 3, 2, 2]",0,"[258, 273, 172, 156]",Accept
nJt27NQffr,Self-Supervised Learning via Maximum Entropy Coding,[],"[6, 5, 8]","[5, 4, 4]",0,"[312, 526, 911]",Accept
KglFYlTiASW,Neural Transmitted Radiance Fields,[],"[7, 7, 5, 5]","[3, 4, 4, 4]",0,"[361, 1029, 575, 445]",Accept
wlrYnGZ37Wv,Sequencer: Deep LSTM for Image Classification,"['computer vision', 'image classification', 'network architecture', 'long short-term memory']","[6, 5, 6, 6]","[4, 5, 4, 4]",0,"[359, 292, 444, 154]",Accept
osPA8Bs4MJB,Delving into Sequential Patches for Deepfake Detection,"['Deepfake Detection', 'Digital Forensics']","[6, 5, 5, 5, 5]","[4, 5, 4, 4, 4]",0,"[551, 312, 340, 285, 1591]",Accept
MbVS6BuJ3ql,Maximum Class Separation as Inductive Bias in One Matrix,"['maximum separation', 'inductive bias']","[7, 7, 8, 5]","[4, 3, 4, 3]",0,"[893, 370, 560, 209]",Accept
kcQiIrvA_nz,Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection,"['Ownership Verification', 'Dataset Protection', 'Copyright Protection', 'Backdoor Attack', 'AI Security']","[8, 7, 5]","[4, 4, 3]",0,"[145, 544, 534]",Accept
F7NQzsl334D,ClimbQ: Class Imbalanced Quantization Enabling Robustness on Efficient Inferences,"['Quantization', 'Efficient Inference', 'Neural Networks']","[7, 5, 7, 7]","[3, 3, 4, 3]",0,"[130, 327, 462, 237]",Accept
4F0Pd2Wjl0,Error Correction Code Transformer,"['ECC', 'Deep Learning', 'Transformers']","[6, 7, 7, 7]","[4, 4, 4, 3]",0,"[238, 407, 541, 331]",Accept
vgIz0emVTAd,DISCO: Adversarial Defense with Local Implicit Functions,"['Adversarial Defense', 'Adversarial Attack', 'Implicit Functions', 'Local Implicit Function']","[6, 7, 4, 7, 4]","[4, 4, 3, 4, 3]",0,"[159, 1539, 271, 508, 429]",Accept
6rhl2k1SUGs,Watermarking for Out-of-distribution Detection,['OOD Detection'],"[6, 8, 4]","[4, 5, 4]",0,"[364, 590, 631]",Accept
bIlUqzwObX,Reinforcement Learning with a Terminator,"['reinforcement learning', 'termination']","[7, 7, 7]","[3, 4, 3]",0,"[579, 455, 1000]",Accept
p_g2nHlMus,Rethinking Generalization in Few-Shot Classification,"['Few-shot learning', 'Vision Transformer', 'Transformer', 'Classification']","[6, 7, 7, 5]","[3, 5, 4, 5]",0,"[190, 706, 451, 513]",Accept
--aQNMdJc9x,Misspecified Phase Retrieval with Generative Priors,"['Phase retrieval', 'generative priors', 'model misspecification', 'single index model', 'near-optimal statistical rate']","[5, 6, 6, 5, 6]","[3, 3, 3, 3, 3]",0,"[272, 660, 565, 926, 1379]",Accept
V_4BQGbcwFB,Positively Weighted Kernel Quadrature via Subsampling,"['kernel quadrature', 'recombination', 'reproducing kernel Hilbert space', 'Nystrm approximation']","[8, 5, 6, 6]","[5, 3, 4, 3]",0,"[419, 693, 539, 584]",Accept
IsHRUzXPqhI,SHINE: SubHypergraph Inductive Neural nEtwork,[],"[6, 7, 4, 4]","[4, 4, 4, 4]",0,"[369, 328, 586, 562]",Accept
0TDki1mlcwz,LASSIE: Learning Articulated Shapes from Sparse Image Ensemble via 3D Part Discovery,"['Articulated shape', 'sparse-view optimization', '3D part discovery']","[7, 7, 4, 7]","[4, 4, 5, 4]",0,"[455, 903, 987, 1319]",Accept
PO6cKxILdi,Bayesian Risk Markov Decision Processes,"['risk averse', 'Markov decision processes', 'reinforcement learning', 'parameter uncertainty', 'approximate dynamic programming']","[5, 4, 6, 6]","[3, 3, 4, 3]",0,"[382, 394, 805, 860]",Accept
16nVkS8Twxo,Multi-block-Single-probe Variance Reduced Estimator for Coupled Compositional Optimization,"['variance reduction', 'stochastic non-convex optimization', 'coupled compositional optimization', 'sample complexity']","[6, 6, 7, 7]","[4, 4, 3, 5]",0,"[271, 602, 346, 238]",Accept
tuC6teLFZD,Synergy-of-Experts: Collaborate to Improve Adversarial Robustness,"['adversarial defense', 'collaboration', 'model ensemble.']","[7, 5, 7]","[3, 5, 4]",0,"[274, 537, 307]",Accept
Q8GnGqT-GTJ,Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning,"['language model', 'retrieval', 'prompt-tuning', 'memorization']","[5, 7, 6, 5]","[4, 3, 3, 4]",0,"[288, 187, 290, 849]",Accept
Soadfc-JMeX,HSDF: Hybrid Sign and Distance Field for Modeling Surfaces with Arbitrary Topologies,"['implicit field', 'hybrid representation', 'arbitrary topology', 'mesh extraction']","[5, 5, 5]","[4, 4, 4]",0,"[597, 527, 282]",Accept
cRNl08YWRKq,Obj2Seq: Formatting Objects as Sequences with Class Prompt for Visual Tasks,"['transformer', 'general visual framework', 'sequence prediction', 'multi-task']","[6, 5, 7, 5]","[5, 3, 5, 1]",0,"[456, 530, 306, 416]",Accept
1ryTomA0iKa,Riemannian Neural SDE: Learning Stochastic Representations on Manifolds,"['Stochastic representation on Manifolds', 'Riemannian neural stochastic differential equation']","[6, 6, 6]","[3, 4, 2]",0,"[394, 238, 587]",Accept
C9yUwd72yy,Learning Latent Seasonal-Trend Representations for Time Series Forecasting,[],"[7, 6, 6, 7]","[5, 4, 5, 4]",0,"[324, 362, 404, 311]",Accept
tbId-oAOZo,QueryPose: Sparse Multi-Person Pose Regression via Spatial-Aware Part-Level Query,"['Sparse', 'End-to-end', 'Spatial-aware part-level query.']","[6, 6, 6, 6]","[4, 4, 3, 4]",0,"[354, 549, 216, 252]",Accept
OHkq7qNr72-,A Mixture Of Surprises for Unsupervised Reinforcement Learning,['Unsupervised Reinforcement Learning'],"[5, 6, 5, 6]","[4, 4, 3, 4]",0,"[228, 113, 526, 1153]",Accept
pCrB8orUkSq,Monocular Dynamic View Synthesis: A Reality Check,"['dynamic view synthesis', 'novel-view synthesis', 'single-view 3D', 'dynamic 3D', '3D vision', 'NeRF']","[6, 3, 7, 6]","[4, 2, 4, 4]",0,"[451, 237, 268, 318]",Accept
jSorGn2Tjg,Antigen-Specific Antibody Design and Optimization with Diffusion-Based Generative Models for Protein Structures,"['antibody design', 'diffusion probabilistic model', 'protein structure']","[7, 7, 6]","[4, 4, 4]",0,"[460, 667, 474]",Accept
QLGuUwDx4S,DropCov: A Simple yet Effective Method for Improving Deep Architectures,"['Global covariance pooling', 'post-normalization', 'adaptive channel dropout', 'deep convolutional neural networks', 'vision transformers']","[5, 7, 5, 4]","[3, 3, 3, 4]",0,"[289, 130, 443, 470]",Accept
XrECTbqRCfX,Approximate Secular Equations for the Cubic Regularization Subproblem,"['cubic regularization subproblem', 'approximate secular equations', 'partial eigen information']","[5, 5, 7, 4]","[1, 3, 4, 4]",0,"[253, 339, 498, 565]",Accept
QqWqFLbllZh,Spatial Pruned Sparse Convolution for Efficient 3D Object Detection,"['efficient sparse convolution', '3D detection', 'spatial pruning']","[5, 5, 6, 5]","[3, 4, 4, 5]",0,"[183, 381, 595, 317]",Accept
H5z5Q--YdYd,BMU-MoCo: Bidirectional Momentum Update for Continual Video-Language Modeling,"['Video-language modeling', 'continual learning', 'catastrophic forgetting', 'representation learning']","[4, 6, 5]","[3, 4, 4]",0,"[245, 158, 421]",Accept
GAUwreODU5L,GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images,"['3D GAN', 'mesh', 'texture', 'topology']","[8, 6, 7, 7]","[4, 3, 3, 3]",0,"[422, 287, 391, 529]",Accept
3vYkhJIty7E,Learning Optical Flow from Continuous Spike Streams,"['Optical Flow', 'Neuromorphic Camera', 'Computer Vision']","[7, 5, 5, 4]","[4, 3, 4, 3]",0,"[190, 373, 287, 212]",Accept
7KBzV5IL7W,INRAS: Implicit Neural Representation for Audio Scenes,"['audio scenes', 'spatial audio', 'neural acoustic fields', 'implicit neural representation', 'applications']","[8, 5, 5]","[5, 3, 4]",0,"[1097, 513, 339]",Accept
Zzi8Od19DSU,Posterior and Computational Uncertainty in Gaussian Processes,"['Gaussian processes', 'computational uncertainty', 'numerical methods', 'probabilistic numerics', 'probabilistic linear solvers']","[7, 7, 6, 6]","[2, 5, 3, 4]",0,"[907, 275, 233, 880]",Accept
9s3CbJh4vRP,Precise Regret Bounds for Log-loss via a Truncated Bayesian Algorithm,"['Sequential probability assignment', 'Online Regression', 'Logarithmic Loss', 'Bayesian Algorithm', 'Shtarkov Sum']","[7, 7, 8]","[2, 3, 5]",0,"[1211, 260, 858]",Accept
UVF3yybAjF,Robust Testing in High-Dimensional Sparse Models,"['Robust hypothesis testing', 'Sparse mean testing', 'Sparse linear regression']","[6, 7, 6, 3]","[3, 4, 3, 2]",0,"[698, 462, 631, 476]",Accept
VrJWseIN98,VER: Scaling On-Policy RL Leads to the Emergence of Navigation in Embodied Rearrangement,[],"[5, 7, 3, 6]","[3, 4, 4, 2]",0,"[261, 739, 278, 430]",Accept
KFxIsdIvUj,Identifiability and generalizability from multiple experts in Inverse Reinforcement Learning,['Inverse Reinforcement Learning'],"[4, 7, 6, 6]","[3, 4, 4, 3]",0,"[1018, 774, 764, 217]",Accept
4kjQZTNz-NH,AnimeSR: Learning Real-World Super-Resolution Models for Animation Videos,"['super resolution', 'animation video', 'degradation synthesis']","[5, 6, 7]","[4, 4, 3]",0,"[335, 260, 318]",Accept
NgIf3FpcHie,Rethinking Alignment in Video Super-Resolution Transformers,"['Video Super-Resolution', 'Transformer', 'Self-attention', 'Alignment']","[6, 7, 6, 8]","[5, 4, 3, 4]",0,"[403, 376, 310, 227]",Accept
pGcTocvaZkJ,Censored Quantile Regression Neural Networks for Distribution-Free Survival Analysis,"['deep learning', 'neural networks', 'survival analysis', 'quantile regression', 'censored data']","[7, 7, 6, 6]","[5, 3, 4, 4]",0,"[354, 363, 382, 481]",Accept
AsH-Tx2U0Ug,Effective Backdoor Defense by Exploiting Sensitivity of Poisoned Samples,"['backdoor defense', 'backdoor learning', 'trustworthy AI', 'AI security']","[8, 7, 5, 7]","[3, 4, 4, 4]",0,"[158, 582, 443, 289]",Accept
er4GR0wHWQO,Asymptotically Unbiased Instance-wise Regularized Partial AUC Optimization: Theory and Algorithm,"['partial AUC', 'optimization', 'minimax']","[6, 5, 8, 8]","[2, 5, 5, 5]",0,"[370, 206, 353, 390]",Accept
Lpla1jmJkW,Constants of motion network,"['neural ode', 'learning dynamics', 'constants of motion', 'energy conservation']","[7, 3, 7]","[3, 4, 3]",0,"[415, 682, 381]",Accept
gbXqMdxsZIP,OTKGE: Multi-modal Knowledge Graph Embeddings via Optimal Transport,"['Multi-modal knowledge graph', 'Representation learning', 'Optimal transport']","[7, 6, 7]","[4, 3, 4]",0,"[344, 182, 139]",Accept
m6DJxSuKuqF,Keypoint-Guided Optimal Transport with Applications in Heterogeneous Domain Adaptation,"['optimal transport', 'keypoint-guided model', 'relation preservation']","[5, 5, 6, 7]","[3, 4, 3, 3]",0,"[424, 651, 655, 471]",Accept
qSYVigfakqS,Weak-shot Semantic Segmentation via Dual Similarity Transfer,[],"[4, 6, 6]","[1, 4, 3]",0,"[221, 252, 472]",Accept
V03mpOjCwtg,Learning Generalizable Part-based Feature Representation for 3D Point Clouds,"['Point cloud classification', 'domain generalization', 'generalizable part-based representation']","[6, 6, 6]","[4, 5, 3]",0,"[350, 679, 620]",Accept
Bv8GV6d76Sy,Posterior Refinement Improves Sample Efficiency in Bayesian Neural Networks,"['Bayesian neural networks', 'predictive calibration', 'normalizing flows']","[6, 6, 5, 7]","[2, 3, 4, 4]",0,"[360, 564, 426, 388]",Accept
VMU-hMsonit,Training and Inference on Any-Order Autoregressive Models the Right Way,"['any-order autoregressive models', 'tractable generative models', 'arbitrary marginal and conditional']","[6, 6, 8, 7]","[3, 4, 3, 4]",0,"[534, 515, 221, 525]",Accept
nax3ATLrovW,Versatile Multi-stage Graph Neural Network for Circuit Representation,"['EDA', 'Circuit Design', 'logic synthesis', 'graph neural network', 'graph representation learning']","[6, 6, 6]","[3, 2, 4]",0,"[593, 343, 590]",Accept
tvwkeAIcRP8,S$^3$-NeRF: Neural Reflectance Field from Shading and Shadow under a Single Viewpoint,"['Single-view Reconstruction', 'Photometric Stereo', 'Shape-from-shadow', 'Neural Scene Representation']","[5, 6, 4, 8]","[4, 5, 4, 4]",0,"[780, 419, 339, 301]",Accept
YCPmfirAcc,High-dimensional Additive Gaussian Processes under Monotonicity Constraints,[],"[4, 6, 7]","[5, 3, 4]",0,"[562, 204, 786]",Accept
Qt4rKNYzcO,Enhanced Latent Space Blind Model for Real Image Denoising via Alternative Optimization,"['Guidance Constraint', 'Latent Space', 'Self-Correction', 'Blind Model', 'Real Image Denoising', 'Alternative Optimization']","[6, 5, 5, 6]","[3, 4, 4, 4]",0,"[413, 180, 387, 227]",Accept
2nYz4WZAne4,Generative Evolutionary Strategy For Black-Box Optimizations,"['Optimization', 'Blackbox', 'Generative model', 'Evolution']","[3, 5, 2, 3]","[3, 2, 4, 5]",0,"[303, 847, 398, 466]",Reject
q0XxMcbaZH9,Learning Equivariant Segmentation with Instance-Unique Querying,"['Instance Segmentation', 'Instance-Unique Querying', 'Transformation Equivariant Learning']","[7, 5, 5, 5]","[3, 4, 4, 5]",0,"[363, 137, 179, 375]",Accept
kADW_LsENM,Video-based Human-Object Interaction Detection from Tubelet Tokens,"['human-object interaction', 'Transformer', 'tubelet token', 'video-analysis', 'compution vision']","[6, 5, 5]","[4, 4, 3]",0,"[498, 155, 698]",Accept
r70ZpWKiCW,Semi-Supervised Semantic Segmentation via Gentle Teaching Assistant,"['gentle teaching assistant', 'semi-supervised semantic segmentation']","[6, 4, 6, 6]","[3, 4, 3, 5]",0,"[400, 801, 171, 456]",Accept
JSha3zfdmSo,Faster Stochastic Algorithms for Minimax Optimization under Polyak-{\L}ojasiewicz Condition,"['Stochastic minimax optimization', 'Polyak-Lojasiewicz condition']","[5, 5, 6, 6]","[1, 3, 2, 2]",0,"[150, 449, 541, 454]",Accept
mTXQIpXPDbh,Back Razor: Memory-Efficient Transfer Learning by Self-Sparsified Backpropogation,"['Memory Efficiency', 'Sparsity', 'Prune']","[6, 5, 5, 6]","[3, 2, 5, 4]",0,"[231, 158, 382, 804]",Accept
_atSgd9Np52,DreamShard: Generalizable Embedding Table Placement for Recommender Systems,"['Reinforcement Learning', 'Recommender System', 'Distributed Training', 'Embedding Table', 'Cost Modeling']","[7, 7, 6, 6]","[2, 2, 2, 4]",0,"[377, 102, 123, 195]",Accept
YBsLfudKlBu,Learning Viewpoint-Agnostic Visual Representations by Recovering Tokens in 3D Space,"['Representation Learning', 'Viewpoint-Agnostic', 'Transformer']","[6, 7, 7, 7, 5]","[4, 3, 4, 4, 4]",0,"[394, 359, 457, 791, 679]",Accept
fVslVNBfjd8,Does Self-supervised Learning Really Improve Reinforcement Learning from Pixels?,"['Reinforcement Learning', 'Self-supervised learning', 'evolutionary search', 'representation learning', 'representation analysis']","[6, 6, 3]","[4, 4, 4]",0,"[759, 324, 478]",Accept
8FuITQn6rG3,CRAFT: explaining using Concepts from Recursive Activation FacTorization,"['Explainability', 'Concept', 'Matrix Factorization', 'Implicit Differentiation', 'Attribution Methods', 'Sensitivity Analysis']","[6, 5, 4, 6]","[3, 3, 4, 4]",0,"[243, 466, 1331, 712]",Reject
MAMOi89bOL,Masked Autoencoders that Listen,"['self-supervised learning', 'audio representation learning', 'audio classification']","[8, 4, 8, 4]","[4, 4, 4, 4]",0,"[386, 382, 346, 435]",Accept
Ho_zIH4LA90,MinVIS: A Minimal Video Instance Segmentation Framework without Video-based Training,"['video instance segmentation', 'query-based transformers']","[7, 8, 5, 7]","[4, 5, 5, 4]",0,"[560, 331, 126, 599]",Accept
7b7iGkuVqlZ,Unsupervised Learning of Equivariant Structure from Sequences,"['Symmetry', 'Unsupervised Learning', 'Equivariance', 'Equivariant map']","[6, 5, 5]","[3, 2, 2]",0,"[559, 867, 680]",Accept
HxZpawUrv9Q,A Conditional Randomization Test for Sparse Logistic Regression in High-Dimension,"['high-dimension statistics', 'sparse logistic regression', 'variable selection', 'variable importance', 'brain-imaging analysis', 'statistical inference']","[7, 6, 7, 7]","[2, 3, 3, 3]",0,"[339, 475, 285, 1451]",Accept
A6EmxI3_Xc,Inducing Neural Collapse in Imbalanced Learning: Do We Really Need a Learnable Classifier at the End of Deep Neural Network?,"['neural collapse', 'simplex ETF', 'imbalanced learning', 'machine learning', 'learning theory']","[4, 6, 3]","[4, 5, 5]",0,"[664, 675, 443]",Accept
4R7YrAGhnve,SegViT: Semantic Segmentation with Plain Vision Transformers,"['Semantic segmentation', 'Transformer', 'Efficient']","[5, 5, 4, 5]","[4, 3, 5, 4]",0,"[555, 330, 349, 376]",Accept
Vt3_mJNrjt,Making Sense of Dependence: Efficient Black-box Explanations Using Dependence Measure,"['deep learning', 'machine learning', 'explainability', 'interpretability', 'computer vision', 'black box', 'dependence measure', 'kernel methods', 'sensitivity analysis']","[5, 7, 4, 6]","[2, 2, 3, 3]",0,"[458, 334, 1018, 1010]",Accept
-ZQOx6yaVa-,Causally motivated multi-shortcut identification and removal,"['shortcut learning', 'spurious correlations', 'causality']","[7, 6, 5]","[4, 3, 3]",0,"[531, 656, 321]",Accept
jtq4KwZ9_n9,Geometry-aware Two-scale PIFu Representation for Human Reconstruction,"['3D human reconstruction', 'depth denoising', 'multi-task learning', 'two-scale PIFu representation', 'geometry-aware features']","[6, 5, 5, 5]","[3, 5, 5, 3]",0,"[368, 492, 426, 322]",Accept
SLdfxFdIFeN,A Unified Analysis of Mixed Sample Data Augmentation: A Loss Function Perspective,"['Augmentation', 'MSDA', 'CutMix', 'Mixup', 'Regularization']","[7, 7, 5, 8]","[2, 3, 5, 4]",0,"[334, 448, 427, 324]",Accept
qf12cWVSksq,Inception Transformer,"['Convolution', 'Vision Transformer']","[7, 8, 8, 7]","[4, 4, 5, 5]",0,"[417, 620, 461, 345]",Accept
luGXvawYWJ,Dataset Distillation via Factorization,"['Dataset Distillation', 'Dataset Condensation', 'Dataset Factorization']","[7, 5, 6]","[5, 4, 2]",0,"[816, 1462, 184]",Accept
q6bZruC3dWJ,"Teach Less, Learn More: On the Undistillable Classes in Knowledge Distillation",[],"[5, 5, 6, 5]","[4, 4, 4, 4]",0,"[323, 172, 405, 683]",Accept
xnuN2vGmZA0,VITA: Video Instance Segmentation via Object Token Association,"['video', 'instance segmentation', 'video instance segmentation', 'tracking', 'transformers']","[7, 6, 7, 7]","[4, 4, 5, 5]",0,"[277, 312, 194, 273]",Accept
kZnGYt-3f_X,Hilbert Distillation for Cross-Dimensionality Networks,"['knowledge distillation', 'cross-dimensionality networks', 'video recognition', 'medical imaging']","[6, 8, 7, 7]","[5, 3, 3, 4]",0,"[527, 171, 337, 342]",Accept
ucNDIDRNjjv,Non-stationary Transformers: Exploring the Stationarity in Time Series Forecasting,"['Time series forecasting', 'Transformers', 'Deep learning']","[4, 4, 7, 7]","[2, 4, 4, 4]",0,"[546, 320, 269, 1633]",Accept
lme1MKnSMb,VCT: A Video Compression Transformer,"['Video compression', 'transformers']","[5, 7, 7, 3]","[2, 4, 4, 5]",0,"[457, 489, 329, 565]",Accept
sGugMYr3Hdy,Pragmatically Learning from Pedagogical Demonstrations in Multi-Goal Environments,"['learning from demonstration', 'multi-goal environments', 'pedagogical teaching', 'pragmatic reasoning']","[8, 5, 5, 6]","[4, 4, 3, 4]",0,"[590, 985, 449, 561]",Accept
bntkx18xEb4,HUMANISE: Language-conditioned Human Motion Generation in 3D Scenes,"['language and 3D scene', 'motion generation', 'language-conditioned generation', 'human-scene interaction']","[5, 4, 6, 7]","[4, 4, 4, 5]",0,"[529, 338, 814, 724]",Accept
2-REuflJDT,Fully Convolutional One-Stage 3D Object Detection on LiDAR Range Images,"['3D object detection', 'LiDAR point clould', 'autonomous driving']","[6, 4, 7]","[4, 3, 4]",0,"[262, 300, 386]",Accept
mMuVRbsvPyw,GMMSeg: Gaussian Mixture based Generative Semantic Segmentation Models,"['Semantic Segmentation', 'Generative Classifier', 'Anomaly Segmentation']","[5, 6, 5, 7]","[4, 4, 4, 4]",0,"[134, 105, 427, 1202]",Accept
9aLbntHz1Uq,Counterfactual Fairness with Partially Known Causal Graph,"['causal inference', 'machine learning', 'fairness']","[7, 3, 6]","[4, 4, 4]",0,"[222, 639, 299]",Accept
LMuh9bS4tqF,Learning Distinct and Representative Modes for Image Captioning,"['Image Captioning', 'Discrete Mode Learning']","[5, 6, 7, 7]","[4, 5, 4, 4]",0,"[399, 172, 618, 536]",Accept
7rcuQ_V2GFg,Parameter-Efficient Masking Networks,"['Random weights representative capacity', 'A new network compression paradigm']","[6, 8, 7, 6]","[3, 4, 4, 4]",0,"[600, 516, 298, 467]",Accept
owZdBnUiw2,Look More but Care Less in Video Recognition,"['Action Recognition', 'Dynamic Networks', 'Efficiency']","[6, 6, 5, 4, 5]","[5, 3, 4, 5, 4]",0,"[582, 458, 529, 555, 486]",Accept
evRyKOjOx20,Optimistic Mirror Descent Either Converges to Nash or to Strong Coarse Correlated Equilibria in Bimatrix Games,"['Uncoupled learning dynamics', 'optimistic mirror descent', 'correlated equilibrium', 'Nash equilibrium']","[7, 7, 5]","[4, 3, 4]",0,"[791, 436, 300]",Accept
kEPAmGivMD,Deterministic Langevin Monte Carlo with Normalizing Flows for Bayesian Inference,"['probabilistic methods', 'Bayesian Inference', 'Normalizing Flows']","[7, 6, 4]","[4, 3, 4]",0,"[485, 803, 874]",Accept
CZwh1XdAhNv,Uncoupled Learning Dynamics with $O(\log T)$ Swap Regret in Multiplayer Games,"['Uncoupled learning dynamics', 'optimism', 'swap regret', 'correlated equilibria']","[8, 8, 8]","[4, 3, 4]",0,"[560, 344, 572]",Accept
fT9W53lLxNS,SAVi++: Towards End-to-End Object-Centric Learning from Real-World Videos,"['Object-centric learning', 'Computer Vision', 'Segmentation', 'Video']","[7, 7, 6, 3]","[5, 4, 4, 3]",0,"[734, 360, 325, 635]",Accept
mXP-qQcYCBN,AutoLink: Self-supervised Learning of Human Skeletons and Object Outlines by Linking Keypoints,"['self-supervised Learning', 'keypoints', 'articulated bodies', 'human skeleton']","[8, 6, 6]","[4, 4, 3]",0,"[450, 461, 498]",Accept
f3zNgKga_ep,Video Diffusion Models,"['diffusion', 'score', 'video', 'generative', 'text-to-video']","[5, 6, 9, 7]","[3, 2, 5, 5]",0,"[257, 196, 180, 245]",Accept
ZJe-XahpyBf,UDC: Unified DNAS for Compressible TinyML Models for Neural Processing Units,"['NAS', 'compression', 'NPU']","[5, 6, 6, 6]","[3, 3, 3, 3]",0,"[154, 171, 510, 382]",Accept
vkGk2HI8oOP,Towards Reasonable Budget Allocation in Untargeted Graph Structure Attacks via Gradient Debias,"['graph adversarial attack', 'graph structure attack', 'attack loss design']","[5, 7, 4]","[3, 3, 4]",0,"[279, 376, 916]",Accept
319xcX5qIcO,Signal Recovery with Non-Expansive Generative Network Priors,"['inverse problem', 'generative networks', 'signal recovery', 'compressed sensing']","[5, 5, 7, 7]","[4, 2, 2, 5]",0,"[991, 303, 169, 689]",Accept
1ItkxrZP0rg,A Spectral Approach to Item Response Theory,"['item response theory', 'education testing', 'recommendation systems', 'Rasch model', 'spectral method']","[8, 7, 6, 6]","[4, 4, 2, 4]",0,"[627, 992, 266, 591]",Accept
1pHC-yZfaTK,Regret Bounds for Information-Directed Reinforcement Learning,"['information-directed sampling', 'regret bound']","[7, 6, 6, 7]","[4, 3, 3, 3]",0,"[602, 185, 378, 262]",Accept
VOPiHQUevh5,TUSK: Task-Agnostic Unsupervised Keypoints,"['unsupervised keypoint learning', 'landmark', 'object discovery', 'descriptor']","[5, 4, 7]","[3, 4, 4]",0,"[526, 369, 603]",Accept
mmzkqUKNVm,Semantic Diffusion Network for Semantic Segmentation,[],"[4, 7, 6, 7]","[4, 4, 4, 4]",0,"[772, 267, 304, 408]",Accept
q__FmUtPZd9,Social-Inverse: Inverse Decision-making of Social Contagion Management with Task Migrations,"['social computing', 'structured prediction', 'combinatorial optimization']","[6, 4, 7, 5]","[1, 3, 4, 3]",0,"[476, 470, 594, 381]",Accept
LCIZmSw1DuE,Fair and Optimal Decision Trees: A Dynamic Programming Approach,"['optimal decision trees', 'group fairness', 'dynamic programming']","[4, 5, 7, 5]","[4, 1, 4, 3]",0,"[316, 308, 592, 784]",Accept
v6CqBssIwYw,Instance-Based Uncertainty Estimation for Gradient-Boosted Regression Trees,"['uncertainty estimation', 'gradient-boosted regression trees', 'ibug', 'probabilistic regression', 'instance-based learning', 'tree-ensemble kernel']","[5, 6, 5, 7]","[4, 4, 4, 3]",0,"[425, 542, 606, 621]",Accept
zkQho-Jxky9,Counterfactual harm,"['causality', 'safety', 'ethics', 'counterfactuals', 'decision theory', 'expected utility theory']","[7, 6, 6, 7]","[4, 4, 4, 4]",0,"[658, 410, 497, 581]",Accept
DDEwoD608_l,Hand-Object Interaction Image Generation,"['hand-object interaction', 'complex occulsion', 'image generation']","[4, 10, 4, 4]","[4, 5, 4, 3]",0,"[472, 807, 432, 361]",Accept
8wtaJ9dE9Y2,Predicting Label Distribution from Multi-label Ranking,"['label distribution', 'label polysemy', 'multi-label ranking']","[5, 6, 5, 7]","[4, 4, 4, 3]",0,"[242, 315, 372, 299]",Accept
tbdk6XLYmZj,Learning Best Combination for Efficient N:M Sparsity,"['Network sparsity', 'Efficient Inference']","[4, 7, 6, 6]","[5, 5, 4, 3]",0,"[386, 136, 366, 179]",Accept
6H2pBoPtm0s,ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation,"['Vision transformer', 'Pose estimation']","[6, 6, 7, 6]","[5, 5, 4, 4]",0,"[568, 426, 374, 263]",Accept
QNBzcgY0f4e,Easy incremental learning methods to consider for commercial fine-tuning applications,"['Incremental Learning', 'Neural Networks', 'Classification', 'Regression']","[2, 1, 2]","[4, 5, 5]",0,"[164, 402, 246]",Reject
Ho6oWAslz5L,Saliency-Aware Neural Architecture Search,[],"[5, 7, 6, 6]","[4, 4, 3, 3]",0,"[152, 890, 313, 103]",Accept
Il0ymeSnKyL,NeurOLight: A Physics-Agnostic Neural Operator Enabling Parametric Photonic Device Simulation,"['Neural operator', 'optical simulation', 'machine learning for design automation']","[6, 7, 7]","[3, 3, 4]",0,"[332, 383, 200]",Accept
Qq-ge2k8uml,Controllable 3D Face Synthesis with Conditional Generative Occupancy Fields,"['controllable', 'neural radiance field', 'face synthesis']","[7, 4, 5]","[3, 4, 3]",0,"[429, 314, 531]",Accept
p62j5eqi_g2,On the Robustness of Deep Clustering Models: Adversarial Attacks and Defenses,"['Deep Clustering', 'Adversarial Attacks', 'Visual Learning', 'Robust Learning']","[5, 7, 5, 6]","[4, 4, 5, 4]",0,"[467, 575, 736, 508]",Accept
lSfrwyww-FR,Blackbox Attacks via Surrogate Ensemble Search,"['surrogate ensemble', 'bilevel optimization', 'limited query attacks', 'surrogate ensemble', 'hard-label attacks']","[6, 4, 4, 6]","[4, 3, 5, 4]",0,"[527, 221, 627, 408]",Accept
Qoow6uXwjnA,Quadproj: a Python package for projecting onto quadratic hypersurfaces,"['nonconvex optimization', 'projection', 'quadratic hypersurface', 'quadric']","[7, 3, 3, 8]","[3, 4, 4, 4]",0,"[144, 485, 335, 119]",Reject
ymAsTHhrnGm,Inverse Game Theory for Stackelberg Games: the Blessing of Bounded Rationality,"['Stackelberg game', 'inverse game theory', 'quantal response', 'bounded rationality']","[8, 7, 3]","[4, 4, 5]",0,"[459, 913, 481]",Accept
NMTSIY6ykw7,Semi-Discrete Normalizing Flows through Differentiable Tessellation,"['deep probabilistic modeling', 'normalizing flows', 'dequantization', 'disjoint mixture modeling']","[7, 8, 5, 8]","[3, 3, 4, 3]",0,"[193, 165, 368, 253]",Accept
z9poo2GhOh6,Trajectory of Mini-Batch Momentum: Batch Size Saturation and Convergence in High Dimensions,"['Stochastic Gradient Descent with Momentum', 'Random Matrix Theory', 'High Dimensional Probability']","[6, 6, 6, 8]","[3, 3, 3, 3]",0,"[251, 432, 386, 346]",Accept
pn5trhFskOt,A Closer Look at Weakly-Supervised Audio-Visual Source Localization,"['audio-visual learning', 'visual sound source localization', 'self-supervised learning']","[8, 7, 7, 7]","[4, 4, 4, 5]",0,"[522, 531, 509, 661]",Accept
CKbqDtZnSc,A Policy-Guided Imitation Approach for Offline Reinforcement Learning,['Offline RL'],"[7, 6, 8, 7]","[4, 4, 4, 3]",0,"[447, 533, 965, 495]",Accept
zAc2a6_0aHb,Posterior Collapse of a Linear Latent Variable Model,"['Bayesian deep learning', 'loss landscape', 'posterior collapse', 'linear model', 'VAE']","[8, 7, 8]","[3, 4, 3]",0,"[604, 1860, 571]",Accept
pk1C2qQ3nEQ,Active Learning in Bayesian Neural Networks: Balanced Entropy Learning Principle,"['bayesian neural network', 'bayesian active learning', 'balanced entropy learning', 'uncertainty quantification']","[6, 3, 3, 4]","[2, 3, 4, 3]",0,"[159, 554, 699, 511]",Reject
gyZMZBiI9Cw,Weakly-Supervised Multi-Granularity Map Learning for Vision-and-Language Navigation,"['Vision-and-Language Navigation', 'Map Representation', 'Weakly-Supervised Learning']","[8, 7, 7, 7]","[4, 4, 4, 3]",0,"[292, 1419, 496, 758]",Accept
iH4eyI5A7o,Learning Active Camera  for Multi-Object Navigation,"['Multi-object navigation', 'Visual indoor navigation', 'Active perception']","[6, 6, 7]","[4, 3, 4]",0,"[808, 609, 491]",Accept
qqIrESv4f_L,Signal Processing for Implicit Neural Representations,"['Implicit Neural Representation', 'Signal Processing', 'Differential Systems']","[7, 6, 5, 5]","[4, 5, 4, 4]",0,"[672, 1229, 873, 227]",Accept
0ucMtEKCihU,Stochastic Window Transformer for Image Restoration,"['image restoration', 'transformer', 'stochastic window strategy', 'translation invariance', 'locality']","[3, 3, 6, 8]","[4, 4, 3, 5]",0,"[221, 485, 84, 412]",Accept
fJguu0okUY1,An Empirical Study on Disentanglement of Negative-free Contrastive Learning,[],"[5, 6, 5, 5]","[4, 4, 3, 4]",0,"[273, 150, 541, 325]",Accept
59pMU2xFxG,"What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation Framework for Explainability Methods","['Explainability', 'Interpretability', 'Human-centered', 'Evaluation']","[5, 6, 6, 5]","[4, 3, 3, 4]",0,"[434, 283, 251, 765]",Accept
K48UYo0glaJ,Theseus: A Library for Differentiable Nonlinear Optimization,"['robotics', 'differentiable optimization', 'nonlinear least squares', 'implicit differentiation']","[7, 8, 8, 6]","[3, 2, 3, 3]",0,"[424, 785, 249, 341]",Accept
IiCsx9KNVa0,Unsupervised Representation Learning from Pre-trained Diffusion Probabilistic Models,"['Diffusion Probabilistic Models', 'Representation Learning', 'Autoencoders']","[7, 5, 5, 6]","[3, 5, 3, 3]",0,"[279, 425, 295, 411]",Accept
JVoKzM_-lhz,SPoVT: Semantic-Prototype Variational Transformer for Dense Point Cloud Semantic Completion,"['point cloud', '3D vision', 'completion']","[5, 6, 6, 6]","[4, 3, 3, 5]",0,"[460, 251, 329, 241]",Accept
GoOuIrDHG_Y,End-to-end Symbolic Regression with Transformers,"['symbolic regression', 'transformers', 'supervised learning', 'deep learning']","[6, 5, 7]","[1, 3, 5]",0,"[321, 291, 546]",Accept
BRIL0EFvTgc,Pay attention to your loss : understanding misconceptions about Lipschitz neural networks,"['robustness', 'lipschitz', 'certificate', 'orthogonal', 'generalization', 'loss']","[7, 5, 3, 6]","[2, 3, 4, 3]",0,"[260, 398, 454, 520]",Accept
hH9ohGbhyv,Panchromatic and Multispectral Image Fusion via Alternating Reverse Filtering Network,"['multi-spectral image fusion', 'multi-spectral image restoration']","[7, 4, 5]","[4, 5, 4]",0,"[387, 277, 343]",Accept
ZChgD8OoGds,Joint Entropy Search for Multi-Objective Bayesian Optimization,"['Multi-objective Optimization', 'Bayesian Optimization', 'Information-theoretic', 'Gaussian Processes']","[7, 7, 4, 6, 7, 7]","[3, 5, 5, 3, 4, 5]",0,"[754, 1060, 1623, 244, 812, 182]",Accept
b9APFSTylGT,Prompt Learning with Optimal Transport for Vision-Language Models,"['Prompt learning', 'Few shot learning', 'Vision-language pretrained model', 'Optimal transport']","[7, 6, 7]","[5, 3, 5]",0,"[582, 263, 283]",Reject
G1vrYk9uX-_,Mining Unseen Classes via Regional Objectness: A Simple Baseline for Incremental Segmentation,"['Incremental Learning', 'semantic drift', 'catastrophic forgetting', 'regional objectness']","[7, 4, 7, 7, 4]","[4, 4, 5, 4, 4]",0,"[309, 317, 326, 517, 324]",Accept
zfo2LqFEVY,Multi-modal Grouping Network for Weakly-Supervised Audio-Visual Video Parsing,"['Weakly-Supervised Audio-Visual Video Parsing', 'Multi-modal Grouping']","[4, 6, 6]","[4, 3, 4]",0,"[316, 279, 573]",Accept
MG3YN3z1J4M,Unveiling The Mask of Position-Information Pattern Through the Mist of Image Features,"['positional information', 'position encoding', 'padding', 'CNN']","[4, 3, 4]","[2, 3, 4]",0,"[347, 421, 801]",Reject
oW4Zz0zlbFF,Understanding Benign Overfitting in Gradient-Based Meta Learning,"['meta learning', 'benign overfitting', 'excess risk']","[7, 6, 6, 7]","[1, 4, 3, 4]",0,"[193, 319, 472, 440]",Accept
nJWcpq2fco3,Representing Spatial Trajectories as Distributions,"['representation learning', 'human pose', 'video']","[6, 6, 6, 6]","[4, 2, 3, 3]",0,"[346, 204, 549, 372]",Accept
Sj2z__i1wX-,Improved Convergence Rate of Stochastic Gradient Langevin Dynamics with Variance Reduction and its Application to Optimization,"['stochastic gradient Langevin dynamics', 'variance reduction', 'log-Sobolev', 'SGLD', 'SVRG-LD', 'SARAH']","[7, 6, 6]","[3, 3, 2]",0,"[276, 238, 575]",Accept
DgM7-7eMkq0,Decoupling Features in Hierarchical Propagation for Video Object Segmentation,"['Video Object Segmentation', 'Metric Learning', 'Instance Segmentation']","[7, 7, 4, 6]","[4, 4, 5, 5]",0,"[246, 541, 319, 335]",Accept
ZYKWi6Ylfg,Harmonizing the object recognition strategies of deep neural networks with humans,"['Cognitive science', 'human vision', 'explainable AI', 'models of biological vision', 'human and machine alignment']","[4, 2, 3, 7]","[5, 4, 4, 4]",0,"[608, 774, 568, 611]",Accept
JoZyVgp1hm,Bi-directional Weakly Supervised Knowledge Distillation for Whole Slide Image Classification,"['multiple instance learning', 'whole slide image', 'knowledge distillation', 'weakly supervised learning']","[8, 6, 8]","[4, 5, 5]",0,"[584, 669, 424]",Accept
-deKNiSOXLG,RankFeat: Rank-1 Feature Removal for Out-of-distribution Detection,"['out-of-distribution detection', 'distribution shifts']","[6, 3, 6, 5]","[4, 5, 5, 4]",0,"[292, 393, 660, 570]",Accept
ikXoMuy_H4,In the Eye of the Beholder: Robust Prediction with Causal User Modeling,"['Behavioral User Modeling', 'Bounded Rationality', 'Robust Prediction', 'Causal Representation Learning']","[7, 6, 5]","[4, 1, 4]",0,"[353, 151, 1818]",Accept
2OdAggzzF3z,"ResT V2: Simpler, Faster and Stronger","['multi-scale vision Transformer', 'downsampling', 'upsampling', 'computation density']","[5, 6, 6]","[5, 5, 5]",0,"[320, 491, 260]",Accept
CCBJf9xJo2X,Dataset Inference for Self-Supervised Models,"['self-supervised models', 'model stealing', 'defenses']","[5, 7, 5, 7]","[3, 4, 4, 4]",0,"[664, 310, 410, 519]",Accept
RYZyj_wwgfa,Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks,"['Dataset Distillation', 'Bi-level optimization', 'Memories', 'Continual learning']","[7, 6, 6]","[4, 3, 5]",0,"[613, 637, 662]",Accept
QK38rpF8RWL,GenSDF: Two-Stage Learning of Generalizable Signed Distance Functions,"['implicit neural representations', '3d object reconstruction', 'signed distance functions', 'meta-learning', 'generalization']","[6, 7, 6, 4]","[4, 4, 4, 5]",0,"[926, 576, 561, 425]",Accept
wxWTyJtiJZ,Product Ranking for Revenue Maximization with Multiple Purchases,"['Revenue maximization', 'Multiple purchases', 'Product ranking']","[5, 7, 6, 4]","[4, 3, 3, 4]",0,"[366, 186, 328, 267]",Accept
32Ryt4pAHeD,Explainable Reinforcement Learning via Model Transforms,"['Reinforcement Learning', 'Deep Reinforcement Learning', 'Explanability', 'XAI', 'Model Based Reasoning']","[3, 4, 8, 4]","[5, 4, 5, 4]",0,"[645, 467, 418, 1099]",Accept
kb33f8J83c,One Model to Edit Them All: Free-Form Text-Driven Image Manipulation with Semantic Modulations,[],"[5, 8, 6]","[4, 5, 5]",0,"[421, 424, 975]",Accept
6tRhLrki6b8,Privacy-Preserving Logistic Regression Training with A Faster Gradient Variant,"['Homomorphic Encryption', 'Logistic Regression', 'Quadratic Gradient', 'Simplified Fixed Hessian', 'Privacy Preserving', ""Nesterov's accelerated gradient""]","[4, 5, 3]","[3, 4, 5]",0,"[385, 300, 376]",Reject
T5TtjbhlAZH,Towards Practical Control of Singular Values of Convolutional Layers,[],"[6, 6, 7, 6]","[4, 3, 3, 4]",0,"[358, 376, 419, 519]",Accept
QUyasQGv1Nl,Hyperbolic Contrastive Learning for Visual Representations beyond Objects,"['contrastive learning', 'self-supervised learning', 'Riemannian geometry', 'representation learning']","[6, 6, 5]","[3, 4, 4]",0,"[414, 359, 531]",Reject
ZMrZ5SC2G3_,Towards Versatile Embodied Navigation,"['Versatile Embodied Navigation', 'Multitask Multimodal Embodied Navigation']","[8, 6, 6]","[5, 4, 5]",0,"[375, 319, 406]",Accept
wfel7CjOYk,Resource-Adaptive Federated Learning with All-In-One Neural Composition,"['Federated Learning', 'System Heterogeneity']","[5, 6, 7]","[4, 2, 2]",0,"[420, 195, 124]",Accept
Lp-QFq2QRXA,Decision Trees with Short Explainable Rules,"['decision trees', 'explainable models', 'classification', 'approximation algorithms']","[5, 7, 6]","[4, 3, 3]",0,"[316, 350, 893]",Accept
hOVEBHpHrMu,MsSVT: Mixed-scale Sparse Voxel Transformer for 3D Object Detection on Point Clouds,[],"[4, 5, 7]","[5, 4, 5]",0,"[186, 573, 415]",Accept
IvJj3CvjqHC,Generalized Delayed Feedback Model with Post-Click Information in Recommender Systems,"['recommender systems', 'delayed feedback', 'conversion rate prediction']","[6, 3, 7]","[3, 5, 4]",0,"[309, 353, 680]",Accept
r9b6T088_75,Degradation-Aware Unfolding Half-Shuffle Transformer for Spectral Compressive Imaging,"['Applications', 'Computer Vision', 'Low-level Vision', 'Image Restoration', 'Snapshot Compressive Imaging', 'Hyperspectral Image Reconstruction']","[5, 4, 8, 5]","[4, 5, 5, 3]",0,"[414, 557, 469, 303]",Accept
Blbzv2ZjT7,PerfectDou: Dominating DouDizhu with Perfect Information Distillation,"['reinforcement learning', 'poker games', 'card games', 'game AI']","[6, 6, 6]","[3, 4, 4]",0,"[315, 304, 1134]",Accept
ouXTjiP0ffV,NCP: Neural Correspondence Prior for Effective Unsupervised Shape Matching,"['3D Shape matching', 'Deep Learning', 'Neural Prior', 'Geometry Processing']","[6, 7, 7, 3]","[4, 4, 4, 4]",0,"[328, 407, 870, 465]",Accept
SsA-0BZa7B_,A2: Efficient Automated Attacker for Boosting Adversarial Training,"['Adversarial Training', 'Automated Machine Learning']","[6, 6, 7]","[2, 4, 4]",0,"[425, 366, 345]",Accept
V9ngeCMsZK3,Efficient learning of nonlinear prediction models with time-series privileged information,"['Privileged information', 'sample efficiency', 'time series', 'latent dynamics', 'representation learning']","[7, 6, 6, 5]","[3, 3, 5, 4]",0,"[427, 339, 298, 411]",Accept
lAN7mytwrIy,ElasticMVS: Learning elastic part representation for self-supervised multi-view stereopsis,[],"[5, 5, 5, 7]","[4, 5, 3, 5]",0,"[501, 435, 437, 296]",Accept
SeHslYhFx5-,Interaction Modeling with Multiplex Attention,"['interaction modeling', 'social', 'relational graph', 'multi-agent', 'graph neural network', 'attention']","[6, 6, 6, 7]","[3, 4, 3, 3]",0,"[636, 755, 360, 453]",Accept
uP9RiC4uVcR,When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment,"['AI safety', 'Social Aspects of Machine Learning', 'ethics', 'cognitive science', 'moral decision-making']","[5, 6, 7]","[3, 4, 3]",0,"[240, 347, 805]",Accept
9njZa1fm35,Matryoshka Representation Learning,"['Representation Learning', 'Efficient Deployment', 'Large-scale Retrieval', 'Large-scale Classification', 'Deep Learning', 'Computer Vision']","[7, 6, 5, 7]","[3, 3, 5, 3]",0,"[278, 407, 212, 196]",Accept
NIrbtCdxfBl,Deep Fourier Up-Sampling,"['Image restoration', 'image de-raining', 'image de-hazing', 'image super-resolution']","[8, 5, 8, 3]","[5, 5, 5, 4]",0,"[234, 246, 551, 227]",Accept
Mftcm8i4sL,Trajectory Inference via Mean-field Langevin in Path Space,"['trajectory inference', 'path space', 'mean-field dynamics', 'interacting particle methods', 'Langevin algorithm', 'Wiener measure', 'entropic regularization', 'optimal transport', 'Schrdinger bridge']","[5, 7, 8]","[3, 4, 5]",0,"[596, 405, 600]",Accept
NhrbIME2Ljl,Divert More Attention to Vision-Language Tracking,"['Visual Object Tracking', 'Multimodal Learning', 'Vision-Language Representation', 'Asymmetrical Searching Strategy']","[6, 8, 5]","[4, 5, 5]",0,"[200, 793, 404]",Accept
znNmsN_O7Sh,Object Scene Representation Transformer,"['novel view synthesis', 'scene decomposition', 'transformer', 'slot attention', 'unsupervised decomposition', 'representation learning', 'neural rendering', 'scene representations']","[5, 6, 7, 5]","[2, 4, 4, 4]",0,"[443, 465, 558, 686]",Accept
xs9Sia9J_O,Rethinking Individual Global Max in Cooperative Multi-Agent Reinforcement Learning,"['Individual Global Max', 'Cooperative Multi Agent Reinforcement Learning', 'Value Decomposition', 'Imitation Learning', 'Data Aggregation']","[6, 5, 6, 6]","[4, 4, 4, 4]",0,"[403, 318, 334, 396]",Accept
-GgDBzwZ-e7,Discrete-Convex-Analysis-Based Framework for Warm-Starting Algorithms with Predictions,"['combinatorial optimization', 'discrete convex analysis', 'algorithms with predictions', 'time complexity']","[7, 6, 6]","[3, 4, 1]",0,"[220, 444, 342]",Accept
vExdPu73R2z,R^2-VOS: Robust Referring Video Object Segmentation via Relational Cycle Consistency,['Referring video object segmentation'],"[7, 4, 6]","[3, 3, 4]",0,"[483, 248, 396]",Reject
u4dXcUEsN7B,Exploring Example Influence in Continual Learning,['Continual Learning'],"[6, 7, 7]","[3, 4, 4]",0,"[273, 964, 521]",Accept
9t-j3xDm7_Q,Motion Transformer with Global Intention Localization and Local Movement Refinement,"['Motion Prediction', 'Autonomous Driving', 'Transformer']","[5, 8, 7, 7]","[4, 5, 4, 5]",0,"[354, 308, 514, 321]",Accept
aKXBrj0DHm,Bridging the Gap between Object and Image-level Representations for Open-Vocabulary Detection,"['object detection', 'open vocabulary', 'vision-language pretraining']","[6, 6, 5, 4]","[4, 4, 5, 5]",0,"[544, 1153, 753, 472]",Accept
6avZnPpk7m9,"What Makes a ""Good"" Data Augmentation in Knowledge Distillation - A Statistical Perspective","['knowledge distillation', 'data augmentation', 'CutMix', ""teacher's mean probability""]","[5, 7, 7, 5]","[4, 3, 4, 3]",0,"[187, 736, 727, 564]",Accept
agTr-vRQsa,Behavior Transformers: Cloning $k$ modes with one stone,"['Behavioral cloning', 'learning from demonstrations']","[6, 6, 7, 8]","[4, 4, 4, 5]",0,"[535, 440, 506, 281]",Accept
ievxJqXwPCm,Deliberated Domain Bridging for Domain Adaptive Semantic Segmentation,"['domain adaptive semantic segmentation', 'domain bridging', 'data mixing']","[6, 6, 6, 6]","[3, 5, 5, 4]",0,"[287, 558, 412, 489]",Accept
b90lKL1IqcF,VoxGRAF: Fast 3D-Aware Image Synthesis with Sparse Voxel Grids,"['3D-aware image synthesis', 'sparse voxel grids', 'neural radiance fields', '3D generative models']","[7, 5, 6]","[3, 3, 4]",0,"[503, 313, 882]",Accept
wQ2QNNP8GtM,Cross Aggregation Transformer for Image Restoration,"['Cross Aggregation Transformer', 'Locality Complementary Module', 'Image Restoration']","[8, 4, 8, 8]","[5, 4, 5, 5]",0,"[447, 497, 487, 413]",Accept
iCxRsZcVVAH,Optimistic Curiosity Exploration and Conservative Exploitation with Linear Reward Shaping,"['Reward Shifting', 'Value-Based Deep RL', 'Reward Shaping', 'Conservative Exploitation', 'Optimistic Exploration', 'Curiosity-Driven Exploration', 'Online RL', 'Offline RL']","[6, 4, 6]","[3, 5, 4]",0,"[307, 434, 839]",Accept
lgj33-O1Ely,"TotalSelfScan: Learning Full-body Avatars from Self-Portrait Videos of Faces, Hands, and Bodies",['human reconstruction and view synthesis'],"[7, 6, 7]","[4, 4, 4]",0,"[229, 157, 286]",Accept
EAcWgk7JM58,PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies,"['Point Cloud', 'Training Strategy', 'Model Scaling', '3D', 'Geometric Deep Learning']","[5, 6, 4, 7]","[5, 4, 5, 5]",0,"[497, 149, 349, 399]",Accept
wtuYr8_KhyM,Stochastic Adaptive Activation Function,"['activation function', 'neurotransmission', 'adaptive activation']","[7, 7, 9, 3]","[3, 4, 4, 5]",0,"[377, 305, 476, 288]",Accept
YTXIIc7cAQ,Improved Fine-Tuning by Better Leveraging Pre-Training Data,"['Pre-Training', 'Fine-Tuning', 'Learning Theory', 'Self-Supervision']","[6, 5, 5, 5]","[4, 3, 2, 3]",0,"[420, 445, 331, 780]",Accept
0cn6LSqwjUv,RainNet: A Large-Scale Imagery Dataset and Benchmark for Spatial Precipitation Downscaling,"['Machine Learning for Sciences', 'Downscaling', 'Meteorological Problems']","[5, 6, 6, 4]","[3, 2, 4, 4]",0,"[155, 119, 331, 429]",Accept
XdDl3bFUNn5,Towards Robust Blind Face Restoration with Codebook Lookup Transformer,"['Blind Face Restoration', 'Image Restoration', 'Codebook Learning', 'VQGAN', 'Discrete Prior']","[6, 5, 7, 7]","[4, 1, 5, 5]",0,"[340, 166, 463, 374]",Accept
fiBnhdazkyx,A Coupled Design of Exploiting Record Similarity for Practical Vertical Federated Learning,['Vertical federated learning'],"[5, 7, 5, 6, 4]","[3, 2, 3, 3, 4]",0,"[216, 211, 672, 456, 1166]",Accept
x8DNliTBSYY,Memorization and Optimization in Deep Neural Networks with Minimum Over-parameterization,"['deep neural networks', 'Neural Tangent Kernel', 'minimum over-parameterization', 'memorization capacity', 'gradient descent training']","[6, 6, 6, 5]","[2, 1, 2, 4]",0,"[222, 181, 339, 364]",Accept
pMumil2EJh,Multivariate Time-Series Forecasting with Temporal Polynomial Graph Neural Networks,"['Graph Neural Networks', 'Multivariate Time-series Forecasting', 'Spatial-temporal Graph']","[5, 7, 5, 5]","[5, 4, 4, 5]",0,"[383, 334, 198, 2147]",Accept
Zk1SbbdZwS,Model-Based Imitation Learning for Urban Driving,"['Autonomous Driving', 'Imitation Learning', 'World Models']","[6, 7, 6]","[5, 3, 4]",0,"[329, 682, 746]",Accept
2EwEWrNADpT,Learning Multi-resolution Functional Maps with Spectral Attention for Robust Shape Matching,"['Non-rigid shape matching', 'functional map', 'multi-resolution', 'spectral attention']","[7, 7, 6]","[4, 5, 4]",0,"[325, 643, 668]",Accept
evWx_rWWJuG,Fully Sparse 3D Object Detection,"['Autonomous Driving', 'LiDAR', '3D Object Detection']","[6, 6, 7]","[4, 4, 3]",0,"[473, 652, 228]",Accept
fU-m9kQe0ke,Q-ViT: Accurate and Fully Quantized Low-bit Vision Transformer,[],"[6, 8, 7, 7]","[4, 5, 4, 5]",0,"[210, 319, 223, 223]",Accept
QYD9bDWR3R_,Stability and Generalization of Kernel Clustering: from Single Kernel to Multiple Kernel,"['Kernel method', 'Clustering', 'Algorithmic stability']","[6, 7, 7]","[4, 4, 5]",0,"[318, 477, 341]",Accept
IzpgGB5pC_s,UMIX: Improving Importance Weighting for Subpopulation Shift via Uncertainty-Aware Mixup,"['subpopulation shift', 'uncertainty', 'mixup']","[5, 7, 6, 7]","[4, 3, 4, 3]",0,"[270, 270, 355, 475]",Accept
QRKmc0dRP75,On the Strong Correlation Between Model Invariance and Generalization,"['Model Invariance', 'Model Generalization', 'Correlation Study', 'Unsupervised Model Selection']","[2, 7, 7, 6]","[4, 5, 4, 3]",0,"[501, 849, 736, 357]",Accept
_w2-1nXNjvv,Unsupervised Multi-Object Segmentation by Predicting Probable Motion Patterns,"['Computer Vision', 'Unsupervised Learning', 'Object-Centric Learning', 'Object Decomposition']","[7, 7, 8, 3]","[3, 3, 4, 5]",0,"[328, 381, 438, 703]",Accept
QjurhjyTAb,Roadblocks for Temporarily Disabling Shortcuts and Learning New Knowledge,[],"[5, 7, 5, 4]","[4, 4, 4, 4]",0,"[353, 224, 819, 1204]",Accept
RgWjps_LdkJ,Synthetic Model Combination: An Instance-wise Approach to Unsupervised Ensemble Learning,"['instance-wise', 'ensembles']","[7, 6, 4, 5]","[3, 3, 3, 3]",0,"[405, 471, 367, 205]",Accept
eQfuHqEsUj,4D Unsupervised Object Discovery,['Unsupervised Object Detection'],"[5, 6, 6]","[3, 4, 4]",0,"[282, 164, 490]",Accept
BNqRpzwyOFU,Hierarchical  Normalization for Robust Monocular Depth Estimation,"['depth prediction', 'depth estimation']","[5, 5, 6, 6]","[4, 4, 3, 5]",0,"[232, 418, 214, 312]",Accept
TN4UpY_Qzo,Whitening Convergence Rate of Coupling-based Normalizing Flows,"['normalizing flows', 'generative modeling', 'RealNVP', 'theory', 'maximum likelihood', 'kullback leibler divergence', 'invertible neural network', 'information theory', 'convergence', 'coupling block']","[7, 6, 7, 7]","[3, 3, 3, 3]",0,"[122, 476, 774, 618]",Accept
GwXrGy_vc8m,Estimating Noise Transition Matrix with Label Correlations for Noisy Multi-Label Learning,"['label-noise learning', 'multi-label learning', 'transition matrix estimation']","[5, 7, 4, 6]","[5, 5, 3, 1]",0,"[681, 326, 491, 185]",Accept
t6O08FxvtBY,Advancing Model Pruning via Bi-level Optimization,"['pruning', 'bi-level optimization']","[5, 7, 8, 2]","[3, 4, 4, 5]",0,"[652, 517, 370, 643]",Accept
_w-ivKc1cj,Learn what matters: cross-domain imitation learning with task-relevant embeddings,"['Reinforcement Learning', 'Learning from Observations', 'Inverse Reinforcement Learning', 'Imitation Learning', 'Domain Transfer']","[6, 6, 7]","[3, 4, 4]",0,"[285, 1455, 667]",Accept
_VF5QKgXoqt,HumanLiker: A Human-like Object Detector to Model the Manual Labeling Process,"['Human-like', 'Object detection']","[5, 5, 4]","[5, 5, 5]",0,"[232, 504, 529]",Accept
Gpqqm4p91Ez,Towards Lightweight Black-Box Attack Against Deep Neural Networks,"['Adversarial examples', 'Adversarial attacks', 'Black-box attack.']","[6, 6, 5, 7]","[4, 4, 3, 3]",0,"[620, 401, 219, 408]",Accept
BZ92dxDS3tO,OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models,"['Object pose estimation', 'Local feature matching', 'Structure from motion']","[6, 5, 3, 6]","[4, 3, 4, 3]",0,"[161, 347, 1332, 548]",Accept
rY2wXCSruO,DeepInteraction: 3D Object Detection via Modality Interaction,[],"[6, 1, 7]","[3, 4, 4]",0,"[166, 312, 241]",Accept
Qb-AoSw4Jnm,MoVQ: Modulating Quantized Vectors for High-Fidelity Image Generation,"['Vector Quantization', 'Generative Models', 'Transformer Generation']","[7, 5, 4]","[4, 4, 5]",0,"[352, 458, 639]",Accept
A1yGs_SWiIi,TransTab: Learning Transferable Tabular Transformers Across Tables,"['tabular data', 'pretraining', 'transfer learning', 'contrastive learning']","[7, 7, 7]","[4, 4, 4]",0,"[554, 286, 262]",Accept
1tnVNogPUz9,Towards Efficient 3D Object Detection with Knowledge Distillation,"['3D object detection', 'knowledge distillation']","[6, 6, 7, 8]","[4, 5, 5, 2]",0,"[598, 486, 225, 320]",Accept
Ag3ycrdh6n,Tensor Wheel Decomposition and Its Tensor Completion Application,"['Tensor wheel decomposition', 'Computer vision', 'Tensor completion']","[6, 6, 4, 5]","[4, 4, 4, 4]",0,"[316, 378, 363, 598]",Accept
JGLW4DvX11F,Optimistic Tree Searches for Combinatorial Black-Box Optimization,"['Optimization', 'Black-box', 'Combinatorial', 'Tree Search']","[7, 7, 4, 6]","[3, 2, 4, 3]",0,"[798, 254, 269, 842]",Accept
GKfNB4BegL,Recurrent Video Restoration Transformer with Guided Deformable Attention,"['video restoration', 'video super-resolution', 'video deblurring', 'video denoising', 'video alignment']","[6, 6, 8]","[5, 4, 5]",0,"[390, 333, 455]",Accept
kCTZt0b9DQz,Prototypical VoteNet for Few-Shot 3D Point Cloud Object Detection,"['3D Point Cloud Object Detection', 'Few-Shot Learning', 'Geometric Prototype', 'Class-Specific Prototype']","[7, 4, 7, 4]","[2, 4, 4, 5]",0,"[481, 209, 183, 334]",Accept
dVXO3Orjmxk,Decoupling Classifier for Boosting Few-shot Object Detection and Instance Segmentation,"['few-shot object detection', 'few-shot instance segmentaton', 'instance-level few-shot', 'missing label']","[7, 4, 3, 7]","[3, 4, 4, 5]",0,"[389, 390, 612, 714]",Accept
BYLysbfdJOd,Planckian Jitter: countering the color-crippling effects of color jitter on self-supervised training,[],"[7, 7, 3]","[5, 4, 4]",0,"[574, 680, 393]",Reject
0ltDq6SjrfW,Efficient Knowledge Distillation from Model Checkpoints,"['Deep learning', 'image classification', 'intermediate model', 'knowledge distillation', 'mutual information.']","[7, 6, 6, 6]","[4, 4, 4, 2]",0,"[891, 471, 588, 740]",Accept
wS23xAeKwSN,PolarMix: A General Data Augmentation Technique for LiDAR Point Clouds,"['point cloud', 'LiDAR', 'data augmentation', 'semantic segmentation', 'object detection']","[5, 7, 4, 6, 4]","[4, 4, 4, 5, 4]",0,"[321, 123, 692, 653, 727]",Accept
sde_7ZzGXOE,Is Out-of-Distribution Detection Learnable?,['AI Reliability'],"[8, 8, 8, 8]","[3, 5, 1, 5]",0,"[453, 879, 233, 963]",Accept
1qXIyIxLbEu,Let Images Give You More: Point Cloud Cross-Modal Training for Shape Analysis,[],"[6, 5, 5, 7]","[3, 4, 4, 5]",0,"[275, 635, 347, 374]",Accept
_efamP7PSjg,Equiformer: Equivariant Graph Attention Transformer for 3D Atomistic Graphs,"['equivariant neural networks', 'graph neural networks', 'computational physics', 'transformer networks']","[6, 5, 5, 4]","[4, 4, 4, 4]",0,"[322, 496, 469, 663]",Reject
h10xdBrOxNI,Trap and Replace: Defending Backdoor Attacks by Trapping Them into an Easy-to-Replace Subnetwork,[],"[6, 7, 4, 5]","[3, 4, 4, 5]",0,"[489, 291, 257, 396]",Accept
UaXD4Al3mdb,Masked Autoencoders As Spatiotemporal Learners,[],"[7, 8, 7]","[4, 4, 5]",0,"[211, 263, 392]",Accept
V91cZ9i_sV3,TOIST: Task Oriented Instance Segmentation Transformer with Noun-Pronoun Distillation,[],"[7, 5, 5]","[3, 3, 4]",0,"[558, 299, 564]",Accept
QfI_usBXNCM,Cross-Image Context for Single Image Inpainting,"['Single Image Inpainting', 'Visual Representation Learning', 'Memory Bank']","[5, 5, 5, 8, 6]","[4, 4, 4, 4, 4]",0,"[166, 597, 214, 409, 286]",Accept
-T5seeOMnM5,Natural Color Fool: Towards Boosting Black-box Unrestricted Attacks,"['unrestricted color attack', 'transferability', 'flexible', 'natural', 'semantic-based']","[7, 7, 6]","[5, 4, 4]",0,"[276, 501, 237]",Accept
lXUp6skJ7r,Adversarial Style Augmentation for Domain Generalized Urban-Scene Segmentation,"['Domain Generalization', 'Semantic Segmentation', 'Adversarial Style Augmentation']","[6, 3, 7]","[3, 4, 4]",0,"[313, 1016, 294]",Accept
_yEcbgIT68e,HSurf-Net: Normal Estimation for 3D Point Clouds by Learning Hyper Surfaces,"['Point Cloud', 'Normal Estimation', 'Hyper Surface', 'Surface Fitting']","[7, 5, 5, 6]","[3, 4, 4, 5]",0,"[310, 808, 1089, 345]",Accept
gkQkZy-pRik,MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning,"['self-supervised learning', 'representation learning', 'multi-view', 'contrastive learning', 'dimensional analysis']","[8, 6, 6, 5]","[4, 3, 4, 4]",0,"[619, 452, 272, 293]",Accept
vKBdabh_WV,Meta Optimal Transport,"['optimal transport', 'meta learning', 'amortized optimization']","[3, 8, 6, 7]","[4, 4, 4, 4]",0,"[434, 704, 611, 364]",Reject
5VCT-DptDTs,Heterogeneous Skill Learning for Multi-agent Tasks,"['Reinforcement Learning', 'multi-agent reinforcement learning', 'cooperative multi-agent system', 'mutual information']","[6, 4, 6]","[4, 4, 3]",0,"[638, 347, 474]",Accept
RF5Lb6NaZp,End-to-End Learning to Index and Search in Large Output Spaces,"['extreme multi-label classification', 'large output spaces', 'learnable search index']","[7, 6, 7]","[3, 4, 4]",0,"[295, 400, 582]",Accept
oWx_9VJgyV7,SNAKE: Shape-aware Neural 3D Keypoint Field,"['3D Keypoint Detection', 'Implicit Representation']","[6, 6, 5, 3]","[4, 5, 3, 5]",0,"[389, 174, 160, 749]",Accept
m7CmxlpHTiu,Self-Supervised Aggregation of Diverse Experts for Test-Agnostic Long-Tailed Recognition,"['Long-tail Recognition', 'Class Distribution Shifts']","[5, 7, 5]","[5, 5, 5]",0,"[533, 274, 352]",Accept
A6O79ipjlJC,A Novel Matrix-Encoding Method for Privacy-Preserving Neural Networks (Inference),"['Homomorphic Encryption', 'Matrix Encoding', 'Matrix Multiplication', 'Privacy Preserving', 'Neural Networks']","[2, 3, 3, 3]","[4, 4, 4, 4]",0,"[381, 242, 495, 229]",Reject
gwsnBjNcVEe,Phase Transition from Clean Training to Adversarial Training,"['Adversarial robustness', 'Adversarial training']","[4, 6, 4, 3]","[3, 4, 3, 3]",0,"[163, 310, 861, 526]",Accept
G6cJsOOx2R3,On Enforcing Better Conditioned Meta-Learning for Rapid Few-Shot Adaptation,"['Few-shot learning', 'meta-learning', 'condition number', 'preconditioning']","[5, 8, 6, 6]","[3, 4, 3, 4]",0,"[525, 114, 482, 501]",Accept
VhgC3SMTiy,Audio-Driven Co-Speech Gesture Video Generation,"['Audio-Visual', 'Co-Speech Gesture', 'Video Generation']","[6, 7, 6, 7]","[4, 3, 4, 3]",0,"[232, 658, 430, 307]",Accept
rWgfLdqVVl_,Visual Concepts Tokenization,['Disentangled representation learning'],"[5, 7, 5]","[3, 4, 3]",0,"[358, 465, 397]",Accept
GGtH47T31ZC,Orthogonal Transformer: An Efficient Vision Transformer Backbone with Token Orthogonalization,"['Vision Transformer', 'Efficient Self-attention', 'Orthogonality']","[4, 5, 5, 6]","[4, 5, 4, 4]",0,"[265, 483, 252, 484]",Accept
Aisi2oEq1sc,Finding Differences Between Transformers and ConvNets Using Counterfactual Simulation Testing,"['convolutional neural networks', 'vision transformers', 'robustness', 'testing', 'simulation', 'synthetic data', 'out of distribution', 'generalization', 'domain shift']","[6, 5, 7]","[3, 4, 4]",0,"[599, 481, 632]",Accept
juE5ErmZB61,Polynomial Neural Fields for Subband Decomposition and Manipulation,"['Neural Fields', 'Signal Processing', 'Subband Decomposition', 'Signal Manipulation']","[7, 5, 8, 7]","[3, 3, 3, 3]",0,"[395, 116, 240, 201]",Accept
80RnitDehg_,Anticipating Performativity by Predicting from Predictions,"['performative prediction', 'performativity', 'supervised learning', 'domain adaptation', 'domain generalization', 'induced distribution shift', 'social impact']","[6, 4, 6, 7]","[3, 4, 4, 4]",0,"[327, 838, 327, 929]",Accept
acKK8MQe2xc,Learning Invariant Graph Representations for Out-of-Distribution Generalization,"['Graph Representation Learning', 'Graph Neural Network', 'Out-of-Distribution Generalization']","[5, 5, 6, 5]","[3, 3, 4, 3]",0,"[534, 255, 711, 304]",Accept
VgOw1pUPh97,SegNeXt: Rethinking Convolutional Attention Design for Semantic Segmentation,"['Semantic segmentation', 'attention', 'convolutional neural network.']","[6, 7, 5, 6]","[4, 3, 4, 5]",0,"[656, 586, 202, 291]",Accept
Iqm6AiHPs_z,Active Labeling: Streaming Stochastic Gradients,"['Weak supervision', 'partial labeling', 'active learning', 'sgd']","[6, 5, 6, 6]","[2, 4, 4, 3]",0,"[282, 392, 209, 303]",Accept
lTKXh991Ayv,Practical Adversarial Attacks on Spatiotemporal Traffic Forecasting Models,"['Spatiotemporal traffic foresting', 'Adversarial attack']","[6, 4, 6, 7]","[3, 3, 2, 4]",0,"[129, 631, 108, 933]",Accept
Pyd6Rh9r1OT,Fast Vision Transformers with HiLo Attention,"['Vision Transformers', 'Image recognition']","[5, 6, 9, 6]","[5, 4, 5, 5]",0,"[254, 953, 456, 376]",Accept
rA2tItoRUth,LGDN: Language-Guided Denoising Network for Video-Language Modeling,"['video-language modeling', 'video-text retrieval', 'language supervision', 'cross-modal alignment']","[8, 6, 5]","[5, 4, 4]",0,"[691, 566, 255]",Accept
7YTh6S8HIY,PyramidCLIP: Hierarchical Feature Alignment for Vision-language Model Pretraining,['Vision-language Pre-training'],"[6, 5, 8, 5, 7]","[4, 4, 4, 4, 3]",0,"[144, 257, 241, 344, 507]",Accept
NjImFaBEHl,Divide and Contrast: Source-free Domain Adaptation via Adaptive Contrastive Learning,"['domain adaptation', 'source-free', 'contrastive learning']","[5, 5, 5, 8]","[4, 4, 5, 3]",0,"[325, 213, 310, 305]",Accept
S7Evzt9uit3,Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning,"['Multi-modal Representation Learning', 'Contrastive Representation Learning', 'Cone Effect', 'Modality Gap', 'Geometry of Deep Multi-Model Learning']","[4, 6, 6, 7]","[4, 4, 3, 5]",0,"[372, 455, 493, 329]",Accept
OjS3nkNATOw,Adapting Self-Supervised Vision Transformers by Probing Attention-Conditioned Masking Consistency,"['domain adaptation', 'self-supervised learning', 'vision transformer', 'object recognition']","[5, 6, 6]","[4, 4, 4]",0,"[539, 364, 411]",Accept
jowVZoitZYu,On Trace of PGD-Like Adversarial Attacks,"['adversarial attack', 'adversarial attack detection', 'adversarial defense']","[5, 6, 6, 4]","[2, 4, 5, 4]",0,"[172, 254, 1435, 351]",Reject
m67FNFdgLO9,Dense Interspecies Face Embedding,"['Face Understanding', 'Cross Domain', 'Knowledge Distillation']","[5, 6, 6, 5]","[4, 4, 4, 3]",0,"[450, 377, 467, 466]",Accept
H3JObxjd8S,Self-Supervised Visual Representation Learning with Semantic Grouping,"['self-supervised learning', 'representation learning', 'object discovery']","[7, 5, 7, 6]","[4, 4, 3, 4]",0,"[1320, 404, 913, 581]",Accept
uV_VYGB3FCi,Flexible Neural Image Compression via Code Editing,[],"[6, 6, 8]","[3, 4, 5]",0,"[317, 486, 467]",Accept
8rZYMpFUgK,DAGMA: Learning DAGs via M-matrices and a Log-Determinant Acyclicity Characterization,"['structure learning', 'causal discovery', 'graphical models', 'continuous optimization', 'non-convex optimization', 'log-determinant', 'directed acyclic graphs']","[5, 7, 7, 8]","[5, 3, 3, 3]",0,"[757, 378, 567, 415]",Accept
xubxAVbOsw,The Minority Matters: A Diversity-Promoting Collaborative Metric Learning Algorithm,"['Collaborative Metric Learning', 'Machine Learning', 'Recommendation System']","[8, 7, 8]","[4, 4, 4]",0,"[387, 634, 328]",Accept
CJGUABT_COm,DOMINO: Decomposed Mutual Information Optimization for Generalized Context in Meta-Reinforcement Learning,"['Reinforcement Learning', 'Dynamics Generalization', 'Meta Reinforcement Learning']","[6, 7, 6, 6]","[4, 4, 4, 5]",0,"[388, 1007, 663, 530]",Accept
Ddd6FqHXmHA,OpenAUC: Towards AUC-Oriented Open-Set Recognition,[],"[6, 9, 6]","[5, 5, 4]",0,"[373, 300, 481]",Accept
csr9uRmTC3f,Exploring the Algorithm-Dependent Generalization of AUPRC Optimization with List Stability,"['AUPRC optimization', 'generalization via stability', 'learning to rank', 'deep learning']","[8, 7, 7]","[4, 4, 5]",0,"[281, 230, 303]",Accept
MbCAOMGsZXC,Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud Pre-training,"['Masked autoencoders', 'self-supervised learning', '3D point cloud pre-training']","[6, 5, 6]","[4, 4, 4]",0,"[498, 312, 349]",Accept
u4ihlSG240n,OmniVL: One Foundation Model for Image-Language and Video-Language Tasks,"['Vision-Language Pretraining', 'Unified Foundation Model']","[7, 5, 6]","[3, 5, 4]",0,"[224, 335, 449]",Accept
MK_130d4Y0,EcoFormer: Energy-Saving Attention with Linear Complexity,"['Energy-efficient Attention', 'Linear Complexity', 'Transformer', 'Binarization', 'Hashing']","[5, 6, 4]","[3, 5, 4]",0,"[565, 471, 313]",Accept
9uRS5ysgb9,Zero-Shot Video Question Answering via Frozen Bidirectional Language Models,"['Video Question Answering', 'Zero-Shot', 'Vision and Language', 'Computer Vision']","[6, 7, 6]","[4, 4, 4]",0,"[352, 266, 396]",Accept
qVtbqSwOxy6,Align then Fusion: Generalized Large-scale Multi-view Clustering with Anchor Matching Correspondences,"['multi-view graph clustering', 'anchor graph clustering']","[6, 7, 6]","[5, 4, 5]",0,"[208, 440, 321]",Accept
dozWFpOJcOD,RLIP: Relational Language-Image Pre-training for Human-Object Interaction Detection,"['human-object interaction detection', 'language-image pretraining']","[6, 6, 5, 5]","[4, 3, 5, 4]",0,"[496, 323, 489, 602]",Accept
1tIUqrUuJxx,Dynamic Graph Neural Networks Under Spatio-Temporal Distribution Shift,[],"[6, 7, 5, 7]","[4, 4, 2, 4]",0,"[192, 183, 107, 241]",Accept
V0GwAmDclY,Mix and Reason: Reasoning over Semantic Topology with Data Mixing for Domain Generalization,"['Domain generalization', 'distribution shift', 'semantic topology', 'structural invariance', 'data mixing']","[8, 5, 4]","[5, 4, 5]",0,"[539, 429, 736]",Accept
wOUH1VQ9Rcj,Independence Testing-Based Approach to Causal Discovery under Measurement Error and Linear Non-Gaussian Models,"['causal discovery', 'measurement error', 'linear non-Gaussian models', 'transformed independent noise condition']","[5, 7, 6]","[2, 3, 4]",0,"[451, 210, 636]",Accept
AUz5Oig77OS,Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models,"['Sparse', 'Generative Models', 'Diffusion Models', 'GANs', 'Efficiency']","[5, 6, 4]","[3, 4, 4]",0,"[123, 448, 441]",Accept
5kThooa07pf,Subsidiary Prototype Alignment for Universal Domain Adaptation,"['Domain Adaptation', 'Universal Domain Adaptation', 'Object Recognition', 'Bag of visual words']","[6, 4, 6]","[5, 4, 4]",0,"[447, 526, 759]",Accept
C2o5DeL_8L1,Generative Status Estimation and Information Decoupling for Image Rain Removal,"['Rain Removal', 'Image Restoration', 'Generative Model']","[6, 6, 5, 6]","[5, 4, 3, 3]",0,"[454, 136, 394, 181]",Accept
xl39QEYiB-j,Embodied Scene-aware Human Pose Estimation,"['3D human pose estimation', 'Physics simulation', 'Embodied AI']","[8, 5, 4, 6]","[4, 3, 4, 4]",0,"[264, 395, 193, 196]",Accept
NaW6T93F34m,"""Lossless"" Compression of Deep Neural Networks: A High-dimensional Neural Tangent Kernel Approach","['Deep learning theory', 'high-dimensional statistics', 'neural network compression', 'neural tangent kernel', 'random matrix theory.']","[6, 5, 7]","[3, 4, 3]",0,"[371, 324, 401]",Accept
6RoAxmwj0L2,DaDA: Distortion-aware Domain Adaptation for Unsupervised Semantic Segmentation,"['unsupervised domain adaptation', 'relative distortion learning', 'semantic segmentation']","[5, 7, 6]","[5, 3, 4]",0,"[721, 1502, 274]",Accept
AlgbeSuE1lx,Coded Residual Transform for Generalizable Deep Metric Learning,"['Deep metric learning', 'deep feature embedding', 'coded residual transform']","[4, 6, 8, 7]","[4, 3, 3, 5]",0,"[251, 340, 531, 311]",Accept
ZVe_WeMold,S-Prompts Learning with Pre-trained Transformers: An Occams Razor for Domain Incremental Learning,"['Prompts Learning', 'Pre-trained Transformers', ""Occam's Razor"", 'Domain Incremental Learning']","[8, 6, 4, 5]","[4, 3, 3, 5]",0,"[795, 265, 184, 228]",Accept
Nay_rOB-dZv,Fairness Reprogramming,"['Fairness', 'Model Reprogramming']","[5, 5, 6]","[4, 4, 2]",0,"[847, 303, 252]",Accept
Wk-4Tp-gPpv,DeepTOP: Deep Threshold-Optimal Policy for MDPs and RMABs,"['deep reinforcement learning', 'restless bandits', 'threshold policy']","[6, 6, 5, 6]","[4, 3, 4, 3]",0,"[575, 270, 842, 244]",Accept
DRckHIGk8qw,GAMA: Generative Adversarial Multi-Object Scene Attacks,"['adversarial machine learning', 'image classification', 'generative adversarial attack']","[5, 6, 7, 6]","[4, 4, 5, 3]",0,"[360, 416, 287, 148]",Accept
NjP18IbKKlX,RecursiveMix: Mixed Learning with History,"['Data augmentation', 'Historical Knowledge']","[7, 7, 5, 4, 6]","[4, 4, 4, 5, 4]",0,"[209, 342, 229, 305, 238]",Accept
gc87Cs_V9qR,Differentiable Analog Quantum Computing for Optimization and Control,"['analog quantum computing', 'differentiable programming', 'auto-differentiation', 'optimization', 'quantum control']","[8, 8, 5, 7]","[4, 3, 5, 1]",0,"[93, 676, 253, 95]",Accept
QXLue5WoSBE,NeuPhysics: Editable Neural Geometry and Physics from Monocular Videos,"['NeRF', 'Differentiable Physics', '3D Reconstruction', 'Video Editing']","[5, 5, 5]","[3, 3, 4]",0,"[632, 326, 382]",Accept
17KCLTbRymw,SGAM: Building a Virtual 3D World through Simultaneous Generation and Mapping,"['3D generation', 'mapping', 'view synthesis']","[5, 8, 3]","[3, 4, 5]",0,"[517, 347, 165]",Accept
2nWUNTnFijm,Learning Substructure Invariance for Out-of-Distribution Molecular Representations,"['Invariant Learning', 'Out-of-Distribution', 'Molecule Representation Learning']","[6, 5, 7]","[4, 2, 5]",0,"[253, 687, 333]",Accept
PYnSpt3jAz,Lethal Dose Conjecture on Data Poisoning,"['data poisoning', 'robustness', 'theory', 'security']","[6, 7, 7, 6]","[4, 3, 5, 4]",0,"[975, 1028, 463, 679]",Accept
VvOcK2DGM7G,Unsupervised Causal Generative Understanding of Images,"['unsupervised learning', 'generative models', 'object centric models', 'out-of-distribution generalization', 'domain shift', 'causality']","[6, 6, 7, 6]","[5, 3, 5, 4]",0,"[806, 369, 571, 614]",Accept
PCQyUvAmKs,Don't Pour Cereal into Coffee: Differentiable Temporal Logic for Temporal Action Segmentation,"['Temporal action segmentation', 'linear temporal logic', 'neurosymbolic methods']","[5, 7, 5]","[4, 4, 5]",0,"[265, 319, 546]",Accept
tIqzLFf3kk,Rank Diminishing in Deep Neural Networks,"['Interpretability', 'Network Rank', 'Feature Representation', 'Low Rank', 'Learning Theory']","[5, 6, 7, 5]","[4, 4, 4, 3]",0,"[339, 1004, 742, 538]",Accept
k7xZKpYebXL,A Lower Bound of Hash Codes' Performance,"['Learning to hash', 'Compact representation', 'Fast retrieval', 'Hamming space metric learning']","[7, 3, 6]","[4, 4, 3]",0,"[152, 362, 389]",Accept
yam42JWePu,Fine-Grained Semantically Aligned Vision-Language Pre-Training,"['Vision-Language Pre-Training', 'Multimodal Pre-Training', 'Vision and Language', 'Cross-Modal Reasoning', 'Image-Text Retrieval']","[6, 6, 4, 6]","[3, 4, 5, 3]",0,"[574, 314, 166, 845]",Accept
FurHLDnmC5v,Sample Complexity of Learning Heuristic Functions for Greedy-Best-First and A* Search,"['sample complexity', 'data-driven algorithm design', 'heuristic search']","[7, 7, 8]","[1, 3, 2]",0,"[259, 269, 209]",Accept
